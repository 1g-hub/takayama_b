{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"A100","collapsed_sections":["nerYYhdJLoY0"],"toc_visible":true,"machine_shape":"hm","mount_file_id":"1F_O6kqqgJxm1lue9XMqg8UiOovWnPUtF","authorship_tag":"ABX9TyNVmOZjtX0r3UMVjhA0NULS"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"b7c3b62f507d48d09b00bedd7027083a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e34630d23074460fb1973f2c42f2eb40","IPY_MODEL_b5e002c209124851b424d568ad23fa3e","IPY_MODEL_2cad4a0b46504792b8ead2f4e2be1def"],"layout":"IPY_MODEL_653c35e94f204b27bb89a9d4aa6c51e5"}},"e34630d23074460fb1973f2c42f2eb40":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c1fa00128f7a4d7a87829e2c8f76bc34","placeholder":"​","style":"IPY_MODEL_d36eb9a8333040d89e832885452b77a8","value":"tokenizer_config.json: 100%"}},"b5e002c209124851b424d568ad23fa3e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_69c8cdbb77a347519d25ab07ac7baddb","max":251,"min":0,"orientation":"horizontal","style":"IPY_MODEL_526fa5f8ddcf4e00a4be5fab2a8fd83a","value":251}},"2cad4a0b46504792b8ead2f4e2be1def":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_da9a326e9e734905a7686b586b94f3cb","placeholder":"​","style":"IPY_MODEL_c8e4b92edb0c43509afc658fa0e5c3d9","value":" 251/251 [00:00&lt;00:00, 17.6kB/s]"}},"653c35e94f204b27bb89a9d4aa6c51e5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c1fa00128f7a4d7a87829e2c8f76bc34":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d36eb9a8333040d89e832885452b77a8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"69c8cdbb77a347519d25ab07ac7baddb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"526fa5f8ddcf4e00a4be5fab2a8fd83a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"da9a326e9e734905a7686b586b94f3cb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c8e4b92edb0c43509afc658fa0e5c3d9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6778e367a42544619bb9bbffcb5a2be3":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_bc60acc754a24f0db815aa3615dbba21","IPY_MODEL_0bb93d8315fc4dbd95292ddde7c62e4b","IPY_MODEL_7248043e62014f39abf35ae7d7189c6c"],"layout":"IPY_MODEL_743c9903b1664715ad49951b3821752e"}},"bc60acc754a24f0db815aa3615dbba21":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_54ba2e37888543a0a9982ba699f94303","placeholder":"​","style":"IPY_MODEL_ab25445a5fc84795bd554cced8e506b5","value":"vocab.txt: 100%"}},"0bb93d8315fc4dbd95292ddde7c62e4b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_7db947d03d6548cb84ae68483776b8a5","max":231026,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2e91fe7ceb4342fd8df689af9ceb9084","value":231026}},"7248043e62014f39abf35ae7d7189c6c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_74fbaf9ced25434996919f90b3f915c5","placeholder":"​","style":"IPY_MODEL_db4710e11eb84ec6b35fdc148550649b","value":" 231k/231k [00:00&lt;00:00, 542kB/s]"}},"743c9903b1664715ad49951b3821752e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"54ba2e37888543a0a9982ba699f94303":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ab25445a5fc84795bd554cced8e506b5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7db947d03d6548cb84ae68483776b8a5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2e91fe7ceb4342fd8df689af9ceb9084":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"74fbaf9ced25434996919f90b3f915c5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"db4710e11eb84ec6b35fdc148550649b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"dba67fd9e08c4d28b195a012b0ea6488":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_fc3f39b8241f4cffa393cd89b17401c4","IPY_MODEL_2ea439d0eb574c279f1c2ef39e0b0c7a","IPY_MODEL_b87c9c14208e411090ee075c784811ce"],"layout":"IPY_MODEL_a1eb109d00524423bd6fdf6f722e8aaf"}},"fc3f39b8241f4cffa393cd89b17401c4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d5efb082cf1246f2b2049a33c0a3a8c3","placeholder":"​","style":"IPY_MODEL_bb9580df158e434aa99361a5d25e72c7","value":"config.json: 100%"}},"2ea439d0eb574c279f1c2ef39e0b0c7a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_7da3a908aa7a4ab18d7185eccbc17561","max":472,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2ac712fe87e84a17b0a45043bfa99c8d","value":472}},"b87c9c14208e411090ee075c784811ce":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d2b3530235e5464286c96a915dba4d06","placeholder":"​","style":"IPY_MODEL_89b0874823a54f92b33986ea4af3aa2d","value":" 472/472 [00:00&lt;00:00, 52.1kB/s]"}},"a1eb109d00524423bd6fdf6f722e8aaf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d5efb082cf1246f2b2049a33c0a3a8c3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bb9580df158e434aa99361a5d25e72c7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7da3a908aa7a4ab18d7185eccbc17561":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2ac712fe87e84a17b0a45043bfa99c8d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d2b3530235e5464286c96a915dba4d06":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"89b0874823a54f92b33986ea4af3aa2d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"73f7ae2d12aa4476a18bad147775256b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8c04a01c14764fd6a48202bf18af0284","IPY_MODEL_88bf2f5a3d9b4a1a86a5d6c3cf626fc2","IPY_MODEL_d4ee93f1b0f648cbaf864905a1e1ac31"],"layout":"IPY_MODEL_3ffba53031fd4ba3bf0c0aa91d74b9f8"}},"8c04a01c14764fd6a48202bf18af0284":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e9f9563a199942c3922094ab7466640e","placeholder":"​","style":"IPY_MODEL_411f0cf5e390450b8c1720eedf03dc94","value":"pytorch_model.bin: 100%"}},"88bf2f5a3d9b4a1a86a5d6c3cf626fc2":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_643fdb72430c49e2b1ad8dd0ed667684","max":447406217,"min":0,"orientation":"horizontal","style":"IPY_MODEL_9cf53602a3c04259a5e7bb3329dfaaf6","value":447406217}},"d4ee93f1b0f648cbaf864905a1e1ac31":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_eb92d4f41e854605a0a392bc136d1daa","placeholder":"​","style":"IPY_MODEL_6114407cc750404b9d06b72d902f6336","value":" 447M/447M [00:02&lt;00:00, 199MB/s]"}},"3ffba53031fd4ba3bf0c0aa91d74b9f8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e9f9563a199942c3922094ab7466640e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"411f0cf5e390450b8c1720eedf03dc94":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"643fdb72430c49e2b1ad8dd0ed667684":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9cf53602a3c04259a5e7bb3329dfaaf6":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"eb92d4f41e854605a0a392bc136d1daa":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6114407cc750404b9d06b72d902f6336":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"markdown","source":["# 前処理"],"metadata":{"id":"nerYYhdJLoY0"}},{"cell_type":"markdown","source":["## GPU info"],"metadata":{"id":"LXNVcK-YLxbT"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"g2YtrWHnIRsH","executionInfo":{"status":"ok","timestamp":1739975861688,"user_tz":-540,"elapsed":254,"user":{"displayName":"opu就活用","userId":"12365573474540776425"}},"outputId":"8add348f-0d45-4847-ac6d-c41a47a2cbcc"},"outputs":[{"output_type":"stream","name":"stdout","text":["Wed Feb 19 14:37:58 2025       \n","+-----------------------------------------------------------------------------------------+\n","| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n","|-----------------------------------------+------------------------+----------------------+\n","| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n","|                                         |                        |               MIG M. |\n","|=========================================+========================+======================|\n","|   0  NVIDIA A100-SXM4-40GB          Off |   00000000:00:04.0 Off |                    0 |\n","| N/A   30C    P0             40W /  400W |       0MiB /  40960MiB |      0%      Default |\n","|                                         |                        |             Disabled |\n","+-----------------------------------------+------------------------+----------------------+\n","                                                                                         \n","+-----------------------------------------------------------------------------------------+\n","| Processes:                                                                              |\n","|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n","|        ID   ID                                                               Usage      |\n","|=========================================================================================|\n","|  No running processes found                                                             |\n","+-----------------------------------------------------------------------------------------+\n"]}],"source":["gpu_info = !nvidia-smi\n","gpu_info = '\\n'.join(gpu_info)\n","if gpu_info.find('failed') >= 0:\n","  print('Select the Runtime > \"Change runtime type\" menu to enable a GPU accelerator, ')\n","  print('and then re-execute this cell.')\n","else:\n","  print(gpu_info)"]},{"cell_type":"markdown","source":["## Google Drive マウント"],"metadata":{"id":"yt3j2V6lL0i8"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"897syaAvL9lL","executionInfo":{"status":"ok","timestamp":1739975884682,"user_tz":-540,"elapsed":22993,"user":{"displayName":"opu就活用","userId":"12365573474540776425"}},"outputId":"31823f9c-c569-4351-a678-b2eb0e570d83"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","source":["## module インストール (初回のみ)"],"metadata":{"id":"EoHV7JLwMKIS"}},{"cell_type":"code","source":["# ! pip install mecab-python3 unidic-lite #MeCab\n","# ! pip install fugashi\n","\n","# !cp -r /usr/local/lib/python3.10/dist-packages/fugashi /content/drive/MyDrive/colab-packages/\n","# !cp -r /usr/local/lib/python3.10/dist-packages/fugashi-1.3.2.dist-info /content/drive/MyDrive/colab-packages/\n","# !cp -r /usr/local/lib/python3.10/dist-packages/fugashi.libs /content/drive/MyDrive/colab-packages/\n","# !cp -r /usr/local/lib/python3.10/dist-packages/mecab_python3-1.0.9.dist-info /content/drive/MyDrive/colab-packages/\n","# !cp -r /usr/local/lib/python3.10/dist-packages/mecab_python3.libs /content/drive/MyDrive/colab-packages/\n","# !cp -r /usr/local/lib/python3.10/dist-packages/unidic_lite /content/drive/MyDrive/colab-packages/\n","# !cp -r /usr/local/lib/python3.10/dist-packages/unidic_lite-1.0.8.dist-info /content/drive/MyDrive/colab-packages/"],"metadata":{"id":"hJNeCPiUMK6H"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# import"],"metadata":{"id":"mkMR0sNAOey9"}},{"cell_type":"code","source":["# install していた分\n","!cp -r /content/drive/MyDrive/colab-packages/fugashi /usr/local/lib/python3.10/dist-packages/fugashi\n","!cp -r /content/drive/MyDrive/colab-packages/fugashi-1.3.2.dist-info /usr/local/lib/python3.10/dist-packages/fugashi-1.3.2.dist-info\n","!cp -r /content/drive/MyDrive/colab-packages/fugashi.libs /usr/local/lib/python3.10/dist-packages/fugashi.libs\n","!cp -r /content/drive/MyDrive/colab-packages/mecab_python3-1.0.9.dist-info /usr/local/lib/python3.10/dist-packages/mecab_python3-1.0.9.dist-info\n","!cp -r /content/drive/MyDrive/colab-packages/mecab_python3.libs /usr/local/lib/python3.10/dist-packages/mecab_python3.libs\n","!cp -r /content/drive/MyDrive/colab-packages/unidic_lite /usr/local/lib/python3.10/dist-packages/unidic_lite\n","!cp -r /content/drive/MyDrive/colab-packages/unidic_lite-1.0.8.dist-info /usr/local/lib/python3.10/dist-packages/unidic_lite-1.0.8.dist-info"],"metadata":{"id":"MQBZvTuZbQt7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from pathlib import Path\n","from datetime import datetime\n","import pytz\n","import copy\n","import os\n","import time\n","import numpy as np\n","import pandas as pd\n","from IPython.display import display\n","import matplotlib.pyplot as plt\n","import json\n","import random\n","from collections.abc import Iterable\n","from collections import defaultdict\n","import torch\n","import torch.nn as nn\n","from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix\n","from torch.utils.data import DataLoader, Dataset\n","from torch import FloatTensor, LongTensor\n","from tqdm import tqdm, trange\n","from transformers import (\n","    AutoModelForSequenceClassification,\n","    AutoModel,\n","    AutoTokenizer,\n","    PreTrainedModel,\n",")\n","from transformers.modeling_outputs import SequenceClassifierOutput,BaseModelOutputWithPast\n","from transformers.optimization import get_linear_schedule_with_warmup\n","from transformers.tokenization_utils import BatchEncoding, PreTrainedTokenizer\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.metrics.pairwise import cosine_similarity\n","import sys\n","sys.path.append('/content/drive/MyDrive/ex2024/')\n","\n","# colab 関連\n","from google.colab import files\n","\n","# 乱数シードの設定\n","def set_seed(seed):\n","    random.seed(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    if torch.cuda.is_available():\n","        torch.cuda.manual_seed_all(seed)\n"],"metadata":{"id":"mQhRa_ftOhhA"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#utility 関数"],"metadata":{"id":"E6w-3-5bP_VC"}},{"cell_type":"code","source":["def load_jsonl(path: Path | str) -> pd.DataFrame:\n","    path = Path(path)\n","    return pd.read_json(path, lines=True)\n","\n","\n","def load_json(path: Path | str) -> dict:\n","    path = Path(path)\n","    with path.open() as f:\n","        data = json.load(f)\n","    return data\n","\n","def make_dir(path):\n","    os.makedirs(path, exist_ok=True)"],"metadata":{"id":"mdlLNjUnP-xF"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Args (実験に使う定数などなど〜)"],"metadata":{"id":"lPF9l6WpwALE"}},{"cell_type":"code","source":["# -*- coding: utf-8 -*-\n","class Args():\n","    def __init__(self):\n","        ###############################################################################\n","        # 現在の日時を取得してフォルダ名に使用\n","        self.current_time = datetime.now(pytz.utc).astimezone(pytz.timezone('Asia/Tokyo')).strftime('%Y-%m-%d_%H-%M-%S')\n","\n","        # 実験結果を保存するベースディレクトリ\n","        self.base_dir = Path('/content/drive/MyDrive/ex2024/results/')\n","\n","        # フォルダ名に日時を追加してパスを生成\n","        self.experiment_dir = self.base_dir / f'experiment_{self.current_time}'\n","\n","        # フォルダの作成 (必要であれば親ディレクトリも作成)\n","        self.experiment_dir.mkdir(parents=True, exist_ok=True)\n","        print(f\"Experiment directory created at: {self.experiment_dir}\")\n","\n","        #訓練後モデル保存先\n","        self.output_model_dir: Path = self.experiment_dir / f'model.bin'\n","\n","        #学習結果保存先\n","        self.result_csv_dir = {\n","            'train': self.experiment_dir / f'train_result.csv',\n","            'val': self.experiment_dir / f'val_result.csv',\n","            'test': self.experiment_dir / f'test_result.csv'\n","        }\n","        self.result_confusion_matrix_dir = {\n","            'train': self.experiment_dir / f'train_cm.json',\n","            'val': self.experiment_dir / f'val_cm.json',\n","            'test': self.experiment_dir / f'test_cm.json'\n","        }\n","        #学習曲線保存先\n","        self.result_accuracy_dir = self.experiment_dir / f'train_val_accuracy.png'\n","        self.result_loss_dir = self.experiment_dir / f'train_val_loss.png'\n","        self.result_param_dir = self.experiment_dir / f'train_param.png'\n","        ###############################################################################\n","        #BERT訓練済みモデル\n","        self.bert_pretrained_model_name = \"cl-tohoku/bert-base-japanese-v3\"\n","        self.max_seq_len = 512 #BERT入力列最大値\n","\n","        #livedoorニュースコーパスデータセットへのパス\n","        self.dataset_dir: Path = Path('/content/drive/MyDrive/ex2024/livedoor/datasets/livedoor/')\n","        self.summary_dir: Path = Path('/content/drive/MyDrive/ex2024/livedoor/datasets/livedoor/summary/')\n","\n","        #---学習周り---\n","        self.batch_size: int = 16\n","        self.epochs: int = 20\n","        self.lr: float = 3e-5\n","        self.n_class: int = 9\n","        self.seed: int = 42\n","        self.trial: int = 5\n","\n","        self.sampling_flag = {'train': False, 'val': False, 'test': False}\n","        self.sampling_rate = {'train': 0.05, 'val': 0.1, 'test': 0.1}"],"metadata":{"id":"OODC4D0pwBa4"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Net"],"metadata":{"id":"w_VP0y_Q8ABM"}},{"cell_type":"code","source":["class BertPretrainedNet(nn.Module):\n","    def __init__(self, _model_name='cl-tohoku/bert-base-japanese-v3', _fine_tuning_last=True, _fine_tuning_all=False):\n","        super().__init__()\n","        self.bert = AutoModel.from_pretrained(_model_name)\n","        self.hidden_size: int = self.bert.config.hidden_size #768\n","        self.fine_tuning_last = _fine_tuning_last\n","        self.fine_tuning_all = _fine_tuning_all\n","\n","        if self.fine_tuning_all is False:\n","            # Bertの1〜11段目は更新せず、12段目とSequenceClassificationのLayerのみトレーニングする。\n","            # 一旦全部のパラメータのrequires_gradをFalseで更新\n","            for name, param in self.bert.named_parameters():\n","                param.requires_grad = False\n","            if self.fine_tuning_last:\n","                # Bert encoderの最終レイヤのrequires_gradをTrueで更新\n","                for name, param in self.bert.encoder.layer[-1].named_parameters():\n","                    param.requires_grad = True\n","\n","    def forward(self, x_input_ids, x_attention_mask):\n","        x = self.bert(x_input_ids, x_attention_mask)\n","        return x\n","\n","class SimpleClassifierNet(nn.Module):\n","    def __init__(self, _in_dim=768, _out_dim=9):\n","        super().__init__()\n","        self.in_dim = _in_dim\n","        self.out_dim = _out_dim\n","        self.classifier = nn.Linear(self.in_dim, self.out_dim, bias=True)\n","\n","    def forward(self, x):\n","        return self.classifier(x)\n","\n","class Yamato_Pooling(nn.Module):\n","    def __init__(self, init_weights=[nn.Parameter(torch.tensor(0.5)), nn.Parameter(torch.tensor(0.5))]):\n","        super().__init__()\n","        self.p = init_weights[0]\n","        self.q = init_weights[1]\n","\n","    def get_param(self):\n","        # pとqを計算（q = 1 - p)\n","        new_p = self.p.detach()\n","        new_q = self.q.detach()\n","        sum = (new_p ** 2 + new_q ** 2)\n","        p = new_p ** 2 / sum\n","        q = new_q ** 2 / sum\n","        return {'p':p.cpu().numpy(),'q':q.cpu().numpy()}\n","\n","    def forward(self, x_cls, x_avg):\n","        # pとqを計算（q = 1 - p）\n","        sum = (self.p ** 2 + self.q ** 2)\n","        p = self.p ** 2 / sum\n","        q = self.q ** 2 / sum\n","        return q * x_cls + p * x_avg\n","\n","class Takayama_Pooling(nn.Module):\n","    def __init__(self, init_weights=[nn.Parameter(torch.tensor(1/3.0)), nn.Parameter(torch.tensor(1/3.0)), nn.Parameter(torch.tensor(1/3.0))]):\n","        super().__init__()\n","        self.p = init_weights[0]\n","        self.q = init_weights[1]\n","        self.r = init_weights[2]\n","\n","    def get_param(self):\n","        # pとqを計算（q = 1 - p)\n","        new_p = self.p.detach()\n","        new_q = self.q.detach()\n","        new_r = self.r.detach()\n","        sum = (new_p ** 2 + new_q ** 2 + new_r ** 2)\n","        p = new_p ** 2 / sum\n","        q = new_q ** 2 / sum\n","        r = new_r ** 2 / sum\n","        return {'p':p.cpu().numpy(),'q':q.cpu().numpy(), 'r':r.cpu().numpy()}\n","\n","    def forward(self, x_cls, x_avg, s_cls):\n","        # pとqを計算（q = 1 - p）\n","        sum = (self.p ** 2 + self.q ** 2 + self.r ** 2)\n","        p = self.p ** 2 / sum\n","        q = self.q ** 2 / sum\n","        r = self.r ** 2 / sum\n","        return p * x_cls + q * x_avg + r * s_cls"],"metadata":{"id":"gHkHGHjg8B1C"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class Takayama_Pooling_pqrs(nn.Module):\n","    def __init__(self, init_weights=[nn.Parameter(torch.tensor(1/4.0)), nn.Parameter(torch.tensor(1/4.0)), nn.Parameter(torch.tensor(1/4.0)), nn.Parameter(torch.tensor(1/4.0))]):\n","        super().__init__()\n","        self.p = init_weights[0]\n","        self.q = init_weights[1]\n","        self.r = init_weights[2]\n","        self.s = init_weights[3]\n","\n","    def get_param(self):\n","        # pとqを計算（q = 1 - p)\n","        new_p = self.p.detach()\n","        new_q = self.q.detach()\n","        new_r = self.r.detach()\n","        new_s = self.s.detach()\n","        sum = (new_p ** 2 + new_q ** 2 + new_r ** 2 + new_s ** 2)\n","        p = new_p ** 2 / sum\n","        q = new_q ** 2 / sum\n","        r = new_r ** 2 / sum\n","        s = new_s ** 2 / sum\n","        return {'p':p.cpu().numpy(),'q':q.cpu().numpy(), 'r':r.cpu().numpy(), 's':s.cpu().numpy()}\n","\n","    def forward(self, x_cls, x_avg, s_cls, s_avg):\n","        # pとqを計算（q = 1 - p）\n","        sum = (self.p ** 2 + self.q ** 2 + self.r ** 2 + self.s ** 2)\n","        p = self.p ** 2 / sum\n","        q = self.q ** 2 / sum\n","        r = self.r ** 2 / sum\n","        s = self.s ** 2 / sum\n","        return p * x_cls + q * x_avg + r * s_cls + s * s_avg"],"metadata":{"id":"KN1hG5tHWiFZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class ExperimentNet_2024_0812(nn.Module):\n","    def __init__(self, _args: Args):\n","        super().__init__()\n","        self.bert = BertPretrainedNet(_model_name=_args.bert_pretrained_model_name, _fine_tuning_last=True, _fine_tuning_all=False)\n","        self.fc = SimpleClassifierNet()\n","    def forward(self, x):\n","        bert_out = self.bert(x)[0] # 最後の隠れ層\n","        out = self.fc(bert_out[:, 0, :]) # [CLS] に相当する部分のみ使う\n","        return out\n","\n","class ExperimentNet_2024_poster_ex1(nn.Module):\n","    def __init__(self, _args: Args):\n","        super().__init__()\n","        self.bert = BertPretrainedNet(_model_name=_args.bert_pretrained_model_name, _fine_tuning_last=True, _fine_tuning_all=False)\n","        self.pooling = Yamato_Pooling()\n","        self.classifier = SimpleClassifierNet()\n","    def forward(self, x_input_ids, x_attention_mask):\n","        bert_out = self.bert(x_input_ids, x_attention_mask)[0]\n","         # [CLS]トークンのベクトルを取得\n","        cls_vec = bert_out[:, 0, :]  # [batch_size, hidden_size]\n","        # 残りのトークンのベクトルを平均プーリング\n","        avg_vec = bert_out[:, 1:, :].mean(dim=1)  # [batch_size, hidden_size]\n","\n","        # 重み付き和を計算\n","        weighted_sum = self.pooling(cls_vec, avg_vec)  # [batch_size, hidden_size]\n","\n","        # 分類器に渡す\n","        return self.classifier(weighted_sum)  # [batch_size, num_classes]\n","\n","class ExperimentNet_2024_poster_ex2(nn.Module):\n","    def __init__(self, _args: Args):\n","        super().__init__()\n","        self.bert = BertPretrainedNet(_model_name=_args.bert_pretrained_model_name, _fine_tuning_last=True, _fine_tuning_all=False)\n","        self.bert_summary = BertPretrainedNet(_model_name=_args.bert_pretrained_model_name, _fine_tuning_last=True, _fine_tuning_all=False)\n","        self.pooling = Takayama_Pooling()\n","        self.classifier = SimpleClassifierNet()\n","    def forward(self, x_input_ids, x_attention_mask, s_input_ids, s_attention_mask):\n","        bert_out = self.bert(x_input_ids, x_attention_mask)[0]\n","         # [CLS]トークンのベクトルを取得\n","        cls_vec = bert_out[:, 0, :]  # [batch_size, hidden_size]\n","        # 残りのトークンのベクトルを平均プーリング\n","        out_without_cls = bert_out[:, 1:, :]\n","        expanded_mask = x_attention_mask[:, 1:].unsqueeze(-1).expand(out_without_cls.size())\n","        masked_embeddings = out_without_cls * expanded_mask\n","        # 各バッチのトークン数（パディング部分を除く）を計算\n","        sum_mask = expanded_mask.sum(dim=1)\n","        sum_mask = torch.clamp(sum_mask, min=1e-9)  # 0除算を防ぐためにクランプ\n","        avg_vec = masked_embeddings.sum(dim=1) / sum_mask\n","        #summaryのcls\n","        summary_cls_vec = self.bert_summary(s_input_ids, s_attention_mask)[0][:, 0, :]\n","        # 重み付き和を計算\n","        weighted_sum = self.pooling(cls_vec, avg_vec, summary_cls_vec)  # [batch_size, hidden_size]\n","        # 分類器に渡す\n","        return self.classifier(weighted_sum)  # [batch_size, num_classes]"],"metadata":{"id":"ZQE-LNEkqPn_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class ExperimentNet_2024_poster_ex2_pqrs(nn.Module):\n","    def __init__(self, _args: Args):\n","        super().__init__()\n","        self.bert = BertPretrainedNet(_model_name=_args.bert_pretrained_model_name, _fine_tuning_last=True, _fine_tuning_all=False)\n","        self.bert_summary = BertPretrainedNet(_model_name=_args.bert_pretrained_model_name, _fine_tuning_last=True, _fine_tuning_all=False)\n","        self.pooling = Takayama_Pooling_pqrs()\n","        self.classifier = SimpleClassifierNet()\n","    def forward(self, x_input_ids, x_attention_mask, s_input_ids, s_attention_mask):\n","        bert_out = self.bert(x_input_ids, x_attention_mask)[0]\n","         # [CLS]トークンのベクトルを取得\n","        cls_vec = bert_out[:, 0, :]  # [batch_size, hidden_size]\n","        # 残りのトークンのベクトルを平均プーリング\n","        out_without_cls = bert_out[:, 1:, :]\n","        expanded_mask = x_attention_mask[:, 1:].unsqueeze(-1).expand(out_without_cls.size())\n","        masked_embeddings = out_without_cls * expanded_mask\n","        # 各バッチのトークン数（パディング部分を除く）を計算\n","        sum_mask = expanded_mask.sum(dim=1)\n","        sum_mask = torch.clamp(sum_mask, min=1e-9)  # 0除算を防ぐためにクランプ\n","        avg_vec = masked_embeddings.sum(dim=1) / sum_mask\n","\n","        summary_bert_out = self.bert_summary(s_input_ids, s_attention_mask)[0]\n","        #summaryのcls\n","        summary_cls_vec = summary_bert_out[:, 0, :]\n","        # 残りのトークンのベクトルを平均プーリング\n","        out_without_cls = summary_bert_out[:, 1:, :]\n","        expanded_mask = s_attention_mask[:, 1:].unsqueeze(-1).expand(out_without_cls.size())\n","        masked_embeddings = out_without_cls * expanded_mask\n","        # 各バッチのトークン数（パディング部分を除く）を計算\n","        sum_mask = expanded_mask.sum(dim=1)\n","        sum_mask = torch.clamp(sum_mask, min=1e-9)  # 0除算を防ぐためにクランプ\n","        summary_avg_vec = masked_embeddings.sum(dim=1) / sum_mask\n","\n","        # 重み付き和を計算\n","        weighted_sum = self.pooling(cls_vec, avg_vec, summary_cls_vec, summary_avg_vec)  # [batch_size, hidden_size]\n","        # 分類器に渡す\n","        return self.classifier(weighted_sum)  # [batch_size, num_classes]"],"metadata":{"id":"HgxghcUSXLAf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class ExperimentNet_2024_poster_ex4(nn.Module):\n","    def __init__(self, _args: Args):\n","        super().__init__()\n","        self.bert = BertPretrainedNet(_model_name=_args.bert_pretrained_model_name, _fine_tuning_last=True, _fine_tuning_all=False)\n","        self.pooling = Yamato_Pooling()\n","        self.classifier = SimpleClassifierNet()\n","    def forward(self, x_input_ids, x_attention_mask, weights):\n","        bert_out = self.bert(x_input_ids, x_attention_mask)[0] * weights.unsqueeze(-1)\n","         # [CLS]トークンのベクトルを取得\n","        cls_vec = bert_out[:, 0, :] # [batch_size, hidden_size]\n","        # 残りのトークンのベクトルを平均プーリング\n","        out_without_cls = bert_out[:, 1:, :]\n","        expanded_mask = x_attention_mask[:, 1:].unsqueeze(-1).expand(out_without_cls.size())\n","        masked_embeddings = out_without_cls * expanded_mask\n","        # 各バッチのトークン数（パディング部分を除く）を計算\n","        sum_mask = expanded_mask.sum(dim=1)\n","        sum_mask = torch.clamp(sum_mask, min=1e-9)  # 0除算を防ぐためにクランプ\n","        avg_vec = masked_embeddings.sum(dim=1) / sum_mask\n","\n","        # 重み付き和を計算\n","        weighted_sum = self.pooling(cls_vec, avg_vec)  # [batch_size, hidden_size]\n","        # 分類器に渡す\n","        return self.classifier(weighted_sum)  # [batch_size, num_classes]"],"metadata":{"id":"OKX4Vee-8h_a"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Experiment"],"metadata":{"id":"e2TVGotJ2L9v"}},{"cell_type":"code","source":["class Experiment():\n","    def __init__(self, _args: Args):\n","        #実験設定\n","        self.args = _args\n","        self.device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n","        self.phase = ['train', 'val', 'test']\n","        self.mode = 'train'\n","        self.tf_idf_dic = defaultdict(lambda: defaultdict(list)) #key: category-id value: 重み\n","        self.tf_idf_a = 5.0\n","        self.b = 0.1 * self.tf_idf_a + 1.0\n","        #トークナイザー設定\n","        self.tokenizer = AutoTokenizer.from_pretrained(\n","            self.args.bert_pretrained_model_name,\n","            model_max_length = self.args.max_seq_len,\n","        )\n","        #モデル(Net)\n","        self.net = ExperimentNet_2024_poster_ex4(_args=self.args).eval().to(self.device)\n","        #データローダー\n","        self.dataloader = defaultdict(lambda: defaultdict(list))\n","        #データセット(DataFrame)\n","        self.dataset = defaultdict(lambda: defaultdict(list))\n","        for p in self.phase:\n","            self.dataloader[p] = self.load_dataset(phase = p, shuffle = (p=='train'), sampling_flag = self.args.sampling_flag[p], sampling_rate = self.args.sampling_rate[p])\n","        #損失関数とオプティマイザーの定義\n","        self.criterion = torch.nn.CrossEntropyLoss()\n","        # self.optimizer = torch.optim.Adam(self.net.parameters(), lr=self.args.lr)\n","        self.optimizer = torch.optim.Adam([\n","            {'params':self.net.bert.parameters(), 'lr':self.args.lr},\n","            {'params':self.net.pooling.p, 'lr':self.args.lr},\n","            {'params':self.net.pooling.q, 'lr':self.args.lr},\n","            {'params':self.net.classifier.parameters(), 'lr':self.args.lr}\n","        ])\n","        #結果保存用\n","        self.results = defaultdict(lambda: defaultdict(list))\n","        self.results['train'] = []\n","        self.results['val'] = []\n","        self.results['test'] = []\n","        self.results['param'] = []\n","        self.best_model_state = {\n","            'epoch': 0,\n","            'accuracy': 0.0 - 1e-5,\n","            'best_model_state_dict': None\n","        }\n","\n","\n","\n","    def results_update(self, phase, new_eval_metrics):\n","        self.results[phase].append(new_eval_metrics)\n","        if phase == 'val':\n","            if self.best_model_state['accuracy'] < new_eval_metrics['accuracy']:\n","                print('\\nbest score updated :{0}'.format(new_eval_metrics['accuracy']))\n","                self.best_model_state = {\n","                    'epoch': new_eval_metrics['epoch'],\n","                    'accuracy': new_eval_metrics['accuracy'],\n","                    'best_model_state_dict': self.net.state_dict().copy()\n","                }\n","\n","    def load_dataset(self, phase, shuffle: bool = False, sampling_flag = False, sampling_rate = 1.0):\n","        path = self.args.dataset_dir / f'{phase}.jsonl'\n","        summary_data = load_json(self.args.summary_dir / f'livedoor_summary_plamo_beta_{phase}.json')\n","        original = load_jsonl(path)\n","        #summary列を追加\n","        original['summary'] = original['category-id'].map(summary_data)\n","        if sampling_flag == True:\n","            original = original.groupby('label', group_keys=False).apply(\n","                lambda x: x.sample(frac=sampling_rate, random_state=self.args.seed)\n","            ).reset_index(drop=True)\n","        data = original.to_dict(orient=\"records\")\n","        self.dataset[phase] = pd.DataFrame(data.copy())\n","        return DataLoader(data, collate_fn=self.collate_fn, batch_size=self.args.batch_size,shuffle=shuffle,num_workers=2,pin_memory=True)\n","\n","\n","\n","\n","    # カスタムcollate_fnの定義\n","    def collate_fn(self, batch):\n","        texts = [data['title'] + \" [SEP] \" + data['body'] for data in batch]\n","        labels = torch.tensor([data['label'] for data in batch])\n","        encoding = self.tokenizer(texts, return_tensors='pt', padding=True, truncation=True, max_length=512)\n","        encoding['labels'] = labels\n","        #category-idから元のデータを参照できるようにする\n","        category_ids = [data['category-id'] for data in batch]\n","        tf_idf_weights = torch.stack([self.tf_idf_dic[data['category-id']] for data in batch])\n","\n","        input_ids = encoding['input_ids']\n","\n","        return {'input_ids': input_ids, 'attention_mask': encoding['attention_mask'], 'labels': labels, 'category-ids': category_ids, 'tf_idf_weights':tf_idf_weights}\n","\n","    def category_id2article(self, phase, category_id):\n","        return self.dataset[phase][self.dataset[phase]['category-id'] == category_id]\n","\n","\n","    def train(self):\n","        self.results_update('param', self.net.pooling.get_param())\n","        for epoch in range(self.args.epochs):\n","            time_start = time.time()\n","            print('Epoch {}/{}'.format(epoch + 1, self.args.epochs))\n","            print('-------------')\n","            print('p:{0}, q:{1}\\n'.format(self.results['param'][-1]['p'], self.results['param'][-1]['q']))\n","\n","            for phase in ['train', 'val']:\n","                self.mode = phase\n","                self.net.train() if phase == 'train' else self.net.eval()\n","                if phase == 'val':\n","                    self.results_update('param', self.net.pooling.get_param())\n","                dataloader_size = len(self.dataloader[phase])\n","                #### epochごとの記録保存用\n","                running_loss = 0.0\n","                all_preds = []\n","                all_labels = []\n","                ####\n","\n","                for batch_idx, batch in enumerate(self.dataloader[phase]):\n","                    print(\"{}/{}\".format(batch_idx+1,dataloader_size))\n","\n","                    ####入力データの情報\n","                    input_ids = batch['input_ids'].to(self.device)\n","                    attention_mask = batch['attention_mask'].to(self.device)\n","                    labels = batch['labels'].to(self.device)\n","                    category_ids = batch['category-ids']\n","\n","                    tf_idf_weights = batch['tf_idf_weights'].to(self.device)\n","                    ####\n","\n","                    self.optimizer.zero_grad()\n","                    with torch.set_grad_enabled(phase == 'train'):\n","                        y_pred = self.net(input_ids, attention_mask, tf_idf_weights)\n","                        _, predicted = torch.max(y_pred.data, 1)\n","                        # loss 計算・加算\n","                        loss = self.criterion(y_pred, labels)\n","\n","                        running_loss += loss.item()\n","                        all_preds.extend(predicted.cpu().numpy())\n","                        all_labels.extend(labels.cpu().numpy())\n","\n","                        #### 訓練時のみバックプロパゲーション\n","                        if phase == 'train':\n","                            loss.backward()\n","                            self.optimizer.step()\n","                            #### ここでパラメーターp,qの値を取って来ると良い\n","\n","                mean_loss = running_loss / dataloader_size\n","                accuracy = accuracy_score(all_labels, all_preds)\n","                precision, recall, f1, _ = precision_recall_fscore_support(all_labels, all_preds, average='weighted')\n","                cm = confusion_matrix(all_labels, all_preds)\n","                ##################\n","                new_eval_metrics = {\n","                    'accuracy': accuracy,\n","                    'recall': recall,\n","                    'precision': precision,\n","                    'f1': f1,\n","                    'loss': mean_loss,\n","                    'confusion_matrix': cm,\n","                    'epoch': epoch\n","                }\n","                ##################\n","                self.results_update(phase, new_eval_metrics)\n","                print(new_eval_metrics['confusion_matrix'])\n","\n","                # Validation 結果\n","                if phase == 'val':\n","                    print(\"---Validation---\")\n","                else:\n","                    print(\"---TRAIN---\")\n","                print(\"Acc : %.4f\" % accuracy)\n","                print(\"loss : {}\".format(mean_loss))\n","\n","            time_finish = time.time() - time_start\n","            print(\"====================================\")\n","            print(\"残り時間 : {0}\".format(time_finish * (self.args.epochs - epoch)))\n","\n","        self.save_model()\n","        self.visualize()\n","        return 0\n","\n","    def save_model(self):\n","        torch.save(self.best_model_state['best_model_state_dict'], self.args.output_model_dir)\n","\n","    def save_log(self):\n","        for phase in self.phase:\n","            #混合行列以外の acc や loss の推移を dataframe にして csv 保存\n","            filtered_data = [{k: v for k, v in d.items() if k != 'confusion_matrix'} for d in self.results[phase]]\n","            df = pd.DataFrame(filtered_data)\n","            df.to_csv(self.args.result_csv_dir[phase], index=False)\n","            if phase == 'test':\n","                display(df)\n","            #混合行列をjsonに保存\n","            cm_list = [d['confusion_matrix'].tolist() for d in self.results[phase]]\n","            with open(self.args.result_confusion_matrix_dir[phase], 'w') as f:\n","                json.dump(cm_list, f)\n","\n","\n","    def visualize(self):\n","        #学習曲線\n","        epochs = list(range(1, self.args.epochs + 1))  # 1からepochsまでのエポック\n","        train_acc = [d['accuracy'] for d in self.results['train']]\n","        val_acc = [d['accuracy'] for d in self.results['val']]\n","        train_loss = [d['loss'] for d in self.results['train']]\n","        val_loss = [d['loss'] for d in self.results['val']]\n","        p_data = [d['p'] for d in self.results['param']]\n","        q_data = [d['q'] for d in self.results['param']]\n","\n","        self.make_plot(epochs, [{'data':train_acc, 'label':'Train Accuracy'}, {'data':val_acc, 'label':'Validation Accuracy'}],\n","                                title='Train and Validation Accuracy',\n","                                xlabel='Epoch', ylabel='Accuracy', path=self.args.result_accuracy_dir)\n","        self.make_plot(epochs, [{'data':train_loss, 'label':'Train Loss'}, {'data':val_loss, 'label':'Validation Loss'}],\n","                                title='Train and Validation Loss',\n","                                xlabel='Epoch', ylabel='Loss', path=self.args.result_loss_dir)\n","        self.make_plot(list(range(0, self.args.epochs + 1)), [{'data':p_data, 'label':'p'}, {'data':q_data, 'label':'q'}],\n","                                title='p, q',\n","                                xlabel='Epoch', ylabel='Value', path=self.args.result_param_dir)\n","        #paramの変位をグラフ化\n","        pass\n","\n","\n","    def make_plot(self, x_data, y_data, title, xlabel, ylabel, path):\n","        # グラフの作成\n","        plt.clf()\n","        plt.figure(figsize=(10, 6))\n","        for d in y_data:\n","            plt.plot(x_data, d['data'], label=d['label'])\n","        # グラフのタイトルとラベル\n","        plt.title(title)\n","        plt.xlabel(xlabel)\n","        plt.ylabel(ylabel)\n","        # 凡例の表示\n","        plt.legend()\n","        # グラフをPNGファイルとして保存\n","        plt.savefig(path)\n","        # グラフの表示\n","        plt.show()\n","\n","\n","    def test(self):\n","        #ベストモデルをテストデータにロードして評価\n","        self.net.load_state_dict(self.best_model_state['best_model_state_dict'])\n","        self.net.eval()\n","        self.mode = 'test'\n","        all_preds = []\n","        all_labels = []\n","\n","        print('final p:{0}, q:{1}\\n'.format(self.results['param'][-1]['p'], self.results['param'][-1]['q']))\n","\n","        with torch.no_grad():\n","            for batch_idx, batch in enumerate(self.dataloader['test']):\n","                ####入力データの情報\n","                input_ids = batch['input_ids'].to(self.device)\n","                attention_mask = batch['attention_mask'].to(self.device)\n","                labels = batch['labels'].to(self.device)\n","                category_ids = batch['category-ids']\n","\n","                tf_idf_weights = batch['tf_idf_weights'].to(self.device)\n","                # print(labels)\n","                # print(tf_idf_weights)\n","                ####\n","                y_pred = self.net(input_ids, attention_mask, tf_idf_weights)\n","                _, predicted = torch.max(y_pred.data, 1)\n","                all_preds.extend(predicted.cpu().numpy())\n","                all_labels.extend(labels.cpu().numpy())\n","\n","                pre = predicted.cpu().numpy()\n","                labs = labels.cpu().numpy()\n","                for idx in range(0, pre.shape[0]):\n","                    if pre[idx] != labs[idx]:\n","                        print(category_ids[idx])\n","\n","        # テストデータの評価指標の計算\n","        accuracy = accuracy_score(all_labels, all_preds)\n","        precision, recall, f1, _ = precision_recall_fscore_support(all_labels, all_preds, average='weighted')\n","        cm = confusion_matrix(all_labels, all_preds)\n","        ##################\n","        new_eval_metrics = {\n","            'accuracy': accuracy,\n","            'recall': recall,\n","            'precision': precision,\n","            'f1': f1,\n","            'loss': None,\n","            'confusion_matrix': cm,\n","            'epoch': None\n","        }\n","        ##################\n","        self.results_update('test', new_eval_metrics)\n","        print(new_eval_metrics['confusion_matrix'])\n","\n","        self.save_log()\n","\n","    def run(self):\n","        print(\"ex start\")\n","        print(self.device)\n","        # self.set_tf_idf()\n","        self.label_distribution()\n","        self.train()\n","        self.test()\n","\n","        # display(self.dataset['train'])\n","\n","    def label_distribution(self):\n","        # ラベルごとのデータ数を集計\n","        for p in self.phase:\n","            label_counts = self.dataset[p]['label'].value_counts()\n","            print(p, label_counts)\n","\n","    def load_confusion_matrix(self, path):\n","        # JSONファイルからリストを読み込む\n","        with open(path, 'r') as f:\n","            loaded_matrices_list = json.load(f)\n","        # リストをNumPy配列に変換\n","        loaded_matrices = [np.array(matrix) for matrix in loaded_matrices_list]\n","        return loaded_matrices\n","\n","    def set_tf_idf(self):\n","        # 2文字以上のトークンのみを保持するトークナイザ\n","        def custom_tokenizer(text):\n","            return [token for token in text.split(' ') if len(token) >= 2]\n","\n","        def pad_or_truncate(tensor, n):\n","            if tensor.numel() < n:\n","                # 0.0 で埋める\n","                padding = torch.zeros(n - tensor.numel())\n","                return torch.cat([tensor, padding])\n","            else:\n","                # truncate する\n","                return tensor[:n]\n","\n","        stop_words = [\"が\", \"の\", \"は\", \"に\", \"と\", \"も\", \"で\", \"を\", \"から\", \"なら\", \"そして\", \"しかし\", \"だから\", \"ので\", \"また\", \"です\", \"ます\", \"より\", \"まし\", \"この\", \"その\", \"あの\", \"どの\"]\n","        new_stop_words = ['。', '、', '[', ']', '「', '」', '「', '『', '』', '!', '?', '！', '？', '】', '【', '・', '■', ':', ';', '—', '\"', '(', ')', '<', '>', '/',' ','[CLS]','[SEP]','[PAD]','しかし', 'ため', 'へん', 'せい', '回', '段', '自体', '品', '器', 'そちら', 'に', 'か', '全部', 'なかっ', 'うち', '名前', 'たい', 'なり', 'だっ', 'その後', '万', '十', '分', 'きっかけ', '線', 'こう', 'あな', 'なっ', '年', '通', '円', '六', 'ながら', 'られる', 'かつて', 'など', 'その', 'とも', 'し', '子', '近く', 'おまえ', 'だけ', '春', 'もの', '私', 'なん', '書', 'そう', 'だ', 'かけ', 'ヵ所', '多く', '火', '週', 'かたち', 'こ', '略', 'べき', '作', 'おり', '何', '関係', 'ま', '地', '伸', '今', 'まし', 'カ所', 'にて', 'しよう', '都', 'くせ', '課', '以前', '頃', '力', 'こと', 'あちら', '箇所', '違い', 'ほぼ', '百', '半ば', '誌', '係', 'すぐ', '法', '彼', '下記', '者', '家', 'ぬ', 'それぞれ', 'ね', 'ん', 'ここ', '以上', 'つけ', 'すべて', 'ただし', 'なか', '例', '外', 'ヶ月', 'より', 'それ', 'この', 'い', 'ぶり', 'もう', '境', 'え', '手', 'レ', '簿', 'る', 'みつ', 'たら', 'ず', 'すか', 'せる', '新た', 'まま', 'しかた', 'よそ', 'ほか', '毎日', 'さらい', '秒', '系', 'はず', 'どこ', '箇月', 'どちら', '度', '中', '第', 'が', 'これ', 'はるか', 'ちゃ', 'ほど', '士', 'あそこ', 'も', 'から', '二', 'ない', 'そこ', '匹', 'は', 'ヵ月', '彼女', '先', '目', '千', 'つい', 'よう', '間', 'あと', '毎', '土', 'ご', '喜', 'つ', '冬', '男', 'ごと', 'です', 'どれ', '台', '金', '国', 'の', '怒', '様', 'あっ', 'のみ', '町', 'これら', '化', 'いくつ', 'また', '形', '哀', 'みなさん', 'もん', '紀', '場合', 'さまざま', '所', 'ある', '水', '列', 'および', 'できる', 'よ', 'どっか', 'なら', '県', 'かなり', 'で', 'わたし', '府', '本当', 'まで', '店', '的', '室', 'すね', 'らしい', '時間', 'おけ', 'する', '右', 'のち', 'れる', '左', 'なお', '字', '席', '上', '時点', '前', '一', 'みんな', 'あるいは', '以下', 'ぜんぶ', 'かつ', '束', '方法', 'こっち', 'あり', 'くる', 'どこか', 'れ', '見', '結局', '区', 'わけ', 'まとも', '気', '等', 'もっ', 'いう', '点', '何人', '口', 'ほう', 'まさ', '名', '部', 'たび', 'いわ', '類', 'もと', 'さ', 'やっ', '俺', 'べつ', 'よく', '他', 'あまり', 'いく', '集', '下', 'つつ', 'てん', 'たり', 'そっち', '自分', 'こちら', '式', '際', 'しまっ', '前回', '兆', 'ひと', '屋', 'ち', 'を', 'おおまか', 'さん', 'いずれ', '校', '会', 'ば', '我々', 'られ', 'なる', 'おれ', '行', 'なに', '首', 'みたい', '九', 'きた', 'あっち', 'へ', '界', 'ら', 'とおり', 'かく', 'がら', 'あなた', '面', '体', '奴', '木', '女', 'み', '村', '手段', 'す', 'さらに', '個', '論', 'ます', 'ぺん', '楽', '五', 'はじめ', 'なけれ', '文', 'せ', 'なく', '場', '扱い', '話', 'それなり', 'おら', 'いっ', 'あ', '連', '次', '高', 'いい', 'たくさん', '秋', '一つ', '達', '四', 'た', 'おい', 'ちゃん', 'と', '感', '内', '方', '感じ', '後', 'しか', '各', 'くん', '数', 'や', '枚', '確か', 'だめ', 'き', '七', '以降', 'どっち', 'そして', '用', '玉', 'いる', 'でき', 'がい', '八', 'あれ', 'とき', '様々', 'カ月', '同じ', 'なかば', '婦', 'いろいろ', '億', 'お', '元', '誰', 'ふく', 'いま', '歳', '性', '年生', 'いつ', '市', 'ヶ所', '別', 'そで', 'あたり', 'かやの', '事', 'よれ', 'ところ', '未満', '時', 'な', 'ごっちゃ', '員', 'ずつ', '三', 'ハイ', '道', '情', '日', 'て', 'ごろ', 'いや', '以後', '輪', 'しまう', '人', '歴', '上記', 'どう', '向こう', 'なし', 'ひとつ', '今回', 'とっ', 'よる', '観', 'ほとんど', 'よっ', '幾つ', '月', 'やつ', '夏', 'たち']\n","        new_stop_words_without = ['。', '、', '[', ']', '「', '」', '「', '『', '』', '!', '?', '！', '？', '】', '【', '・', '■', ':', ';', '—', '\"', '(', ')', '<', '>', '/',' ','[PAD]','しかし', 'ため', 'へん', 'せい', '回', '段', '自体', '品', '器', 'そちら', 'に', 'か', '全部', 'なかっ', 'うち', '名前', 'たい', 'なり', 'だっ', 'その後', '万', '十', '分', 'きっかけ', '線', 'こう', 'あな', 'なっ', '年', '通', '円', '六', 'ながら', 'られる', 'かつて', 'など', 'その', 'とも', 'し', '子', '近く', 'おまえ', 'だけ', '春', 'もの', '私', 'なん', '書', 'そう', 'だ', 'かけ', 'ヵ所', '多く', '火', '週', 'かたち', 'こ', '略', 'べき', '作', 'おり', '何', '関係', 'ま', '地', '伸', '今', 'まし', 'カ所', 'にて', 'しよう', '都', 'くせ', '課', '以前', '頃', '力', 'こと', 'あちら', '箇所', '違い', 'ほぼ', '百', '半ば', '誌', '係', 'すぐ', '法', '彼', '下記', '者', '家', 'ぬ', 'それぞれ', 'ね', 'ん', 'ここ', '以上', 'つけ', 'すべて', 'ただし', 'なか', '例', '外', 'ヶ月', 'より', 'それ', 'この', 'い', 'ぶり', 'もう', '境', 'え', '手', 'レ', '簿', 'る', 'みつ', 'たら', 'ず', 'すか', 'せる', '新た', 'まま', 'しかた', 'よそ', 'ほか', '毎日', 'さらい', '秒', '系', 'はず', 'どこ', '箇月', 'どちら', '度', '中', '第', 'が', 'これ', 'はるか', 'ちゃ', 'ほど', '士', 'あそこ', 'も', 'から', '二', 'ない', 'そこ', '匹', 'は', 'ヵ月', '彼女', '先', '目', '千', 'つい', 'よう', '間', 'あと', '毎', '土', 'ご', '喜', 'つ', '冬', '男', 'ごと', 'です', 'どれ', '台', '金', '国', 'の', '怒', '様', 'あっ', 'のみ', '町', 'これら', '化', 'いくつ', 'また', '形', '哀', 'みなさん', 'もん', '紀', '場合', 'さまざま', '所', 'ある', '水', '列', 'および', 'できる', 'よ', 'どっか', 'なら', '県', 'かなり', 'で', 'わたし', '府', '本当', 'まで', '店', '的', '室', 'すね', 'らしい', '時間', 'おけ', 'する', '右', 'のち', 'れる', '左', 'なお', '字', '席', '上', '時点', '前', '一', 'みんな', 'あるいは', '以下', 'ぜんぶ', 'かつ', '束', '方法', 'こっち', 'あり', 'くる', 'どこか', 'れ', '見', '結局', '区', 'わけ', 'まとも', '気', '等', 'もっ', 'いう', '点', '何人', '口', 'ほう', 'まさ', '名', '部', 'たび', 'いわ', '類', 'もと', 'さ', 'やっ', '俺', 'べつ', 'よく', '他', 'あまり', 'いく', '集', '下', 'つつ', 'てん', 'たり', 'そっち', '自分', 'こちら', '式', '際', 'しまっ', '前回', '兆', 'ひと', '屋', 'ち', 'を', 'おおまか', 'さん', 'いずれ', '校', '会', 'ば', '我々', 'られ', 'なる', 'おれ', '行', 'なに', '首', 'みたい', '九', 'きた', 'あっち', 'へ', '界', 'ら', 'とおり', 'かく', 'がら', 'あなた', '面', '体', '奴', '木', '女', 'み', '村', '手段', 'す', 'さらに', '個', '論', 'ます', 'ぺん', '楽', '五', 'はじめ', 'なけれ', '文', 'せ', 'なく', '場', '扱い', '話', 'それなり', 'おら', 'いっ', 'あ', '連', '次', '高', 'いい', 'たくさん', '秋', '一つ', '達', '四', 'た', 'おい', 'ちゃん', 'と', '感', '内', '方', '感じ', '後', 'しか', '各', 'くん', '数', 'や', '枚', '確か', 'だめ', 'き', '七', '以降', 'どっち', 'そして', '用', '玉', 'いる', 'でき', 'がい', '八', 'あれ', 'とき', '様々', 'カ月', '同じ', 'なかば', '婦', 'いろいろ', '億', 'お', '元', '誰', 'ふく', 'いま', '歳', '性', '年生', 'いつ', '市', 'ヶ所', '別', 'そで', 'あたり', 'かやの', '事', 'よれ', 'ところ', '未満', '時', 'な', 'ごっちゃ', '員', 'ずつ', '三', 'ハイ', '道', '情', '日', 'て', 'ごろ', 'いや', '以後', '輪', 'しまう', '人', '歴', '上記', 'どう', '向こう', 'なし', 'ひとつ', '今回', 'とっ', 'よる', '観', 'ほとんど', 'よっ', '幾つ', '月', 'やつ', '夏', 'たち']\n","        len(new_stop_words)\n","        # ラベルごとのデータ数を集計\n","        for p in self.phase:\n","            data = self.dataset[p]\n","            for i in range(len(data)):\n","                # print(data['title'][i])\n","                text1 = [data['title'][i] + \" [SEP] \" + data['body'][i]]\n","                t1 = self.tokenizer.convert_ids_to_tokens(self.tokenizer(text1, return_tensors='pt', padding=False, truncation=False)['input_ids'][0], skip_special_tokens=False)\n","                # encoding_1 = ' '.join(map(str, self.tokenizer(text1, return_tensors='pt', padding=False, truncation=False)['input_ids'][0].tolist()))\n","                encoding_1 = ' '.join(map(str, t1))\n","                # print(encoding_1)\n","\n","                text2 = [data['summary'][i]]\n","                t2 = self.tokenizer.convert_ids_to_tokens(self.tokenizer(text2, return_tensors='pt', padding=False, truncation=False)['input_ids'][0], skip_special_tokens=False)\n","                # encoding_2 = ' '.join(map(str, self.tokenizer(text2, return_tensors='pt', padding=False, truncation=False)['input_ids'][0].tolist()))\n","                encoding_2 = ' '.join(map(str, t2))\n","                # print(encoding_2)\n","\n","                # TF-IDF ベクトル化\n","                # vectorizer = TfidfVectorizer(stop_words=new_stop_words, lowercase=False, token_pattern=r\"(?u)\\b\\w{2,}\\b\")\n","                vectorizer = TfidfVectorizer(stop_words=new_stop_words,token_pattern=None, preprocessor=None, lowercase=False, tokenizer=custom_tokenizer)\n","\n","                tfidf_matrix = vectorizer.fit_transform([encoding_1,encoding_2])\n","                feature_names = vectorizer.get_feature_names_out()\n","                # print(feature_names)\n","\n","                # TF-IDF スコア取得\n","                tfidf_scores_2 = dict(zip(feature_names, tfidf_matrix.toarray()[1]))\n","                # print(tfidf_scores_2)\n","                # new_dict = {self.tokenizer.convert_ids_to_tokens(int(k)): v for k, v in tfidf_scores_1.items()}\n","                # print(new_dict)\n","                top_n = 10\n","                top_words1 = sorted(tfidf_scores_2.items(), key=lambda x: x[1], reverse=True)[:top_n]\n","                # print(top_words1)\n","\n","                #重みを求める\n","                self.tf_idf_dic[data['category-id'][i]] = pad_or_truncate(torch.tensor([-self.tf_idf_a if key in new_stop_words_without else (self.tf_idf_a * float(tfidf_scores_2.get(key, 0.0)) + 1.0) for key in encoding_1.split(\" \")]), self.args.max_seq_len)[0:512]"],"metadata":{"id":"7ue0lP8-2NbS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install fugashi\n","!pip install unidic_lite"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ojr1JtyJZ1pZ","executionInfo":{"status":"ok","timestamp":1739975974310,"user_tz":-540,"elapsed":19810,"user":{"displayName":"opu就活用","userId":"12365573474540776425"}},"outputId":"31acea6a-0893-4d28-d1d4-0147a44f3247"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting fugashi\n","  Downloading fugashi-1.4.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.9 kB)\n","Downloading fugashi-1.4.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (698 kB)\n","\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/698.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m698.0/698.0 kB\u001b[0m \u001b[31m32.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: fugashi\n","Successfully installed fugashi-1.4.0\n","Collecting unidic_lite\n","  Downloading unidic-lite-1.0.8.tar.gz (47.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.4/47.4 MB\u001b[0m \u001b[31m38.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Building wheels for collected packages: unidic_lite\n","  Building wheel for unidic_lite (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for unidic_lite: filename=unidic_lite-1.0.8-py3-none-any.whl size=47658818 sha256=082f576f2ad5f650bbc5acaf93b7bb5e38ed7b7d6d737c4cd5302cf1e2d052a5\n","  Stored in directory: /root/.cache/pip/wheels/b7/fd/e9/ea4459b868e6d2902e8d80e82dbacb6203e05b3b3a58c64966\n","Successfully built unidic_lite\n","Installing collected packages: unidic_lite\n","Successfully installed unidic_lite-1.0.8\n"]}]},{"cell_type":"markdown","source":["# Main"],"metadata":{"id":"TQajAeCk2-H1"}},{"cell_type":"code","source":["ex = Experiment(_args = Args())\n","ex.set_tf_idf()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":293,"referenced_widgets":["b7c3b62f507d48d09b00bedd7027083a","e34630d23074460fb1973f2c42f2eb40","b5e002c209124851b424d568ad23fa3e","2cad4a0b46504792b8ead2f4e2be1def","653c35e94f204b27bb89a9d4aa6c51e5","c1fa00128f7a4d7a87829e2c8f76bc34","d36eb9a8333040d89e832885452b77a8","69c8cdbb77a347519d25ab07ac7baddb","526fa5f8ddcf4e00a4be5fab2a8fd83a","da9a326e9e734905a7686b586b94f3cb","c8e4b92edb0c43509afc658fa0e5c3d9","6778e367a42544619bb9bbffcb5a2be3","bc60acc754a24f0db815aa3615dbba21","0bb93d8315fc4dbd95292ddde7c62e4b","7248043e62014f39abf35ae7d7189c6c","743c9903b1664715ad49951b3821752e","54ba2e37888543a0a9982ba699f94303","ab25445a5fc84795bd554cced8e506b5","7db947d03d6548cb84ae68483776b8a5","2e91fe7ceb4342fd8df689af9ceb9084","74fbaf9ced25434996919f90b3f915c5","db4710e11eb84ec6b35fdc148550649b","dba67fd9e08c4d28b195a012b0ea6488","fc3f39b8241f4cffa393cd89b17401c4","2ea439d0eb574c279f1c2ef39e0b0c7a","b87c9c14208e411090ee075c784811ce","a1eb109d00524423bd6fdf6f722e8aaf","d5efb082cf1246f2b2049a33c0a3a8c3","bb9580df158e434aa99361a5d25e72c7","7da3a908aa7a4ab18d7185eccbc17561","2ac712fe87e84a17b0a45043bfa99c8d","d2b3530235e5464286c96a915dba4d06","89b0874823a54f92b33986ea4af3aa2d","73f7ae2d12aa4476a18bad147775256b","8c04a01c14764fd6a48202bf18af0284","88bf2f5a3d9b4a1a86a5d6c3cf626fc2","d4ee93f1b0f648cbaf864905a1e1ac31","3ffba53031fd4ba3bf0c0aa91d74b9f8","e9f9563a199942c3922094ab7466640e","411f0cf5e390450b8c1720eedf03dc94","643fdb72430c49e2b1ad8dd0ed667684","9cf53602a3c04259a5e7bb3329dfaaf6","eb92d4f41e854605a0a392bc136d1daa","6114407cc750404b9d06b72d902f6336"]},"id":"QnD6oRvb2_N8","outputId":"7a53239f-2535-4650-a0d6-a7c26da2e966","executionInfo":{"status":"ok","timestamp":1739976130616,"user_tz":-540,"elapsed":156305,"user":{"displayName":"opu就活用","userId":"12365573474540776425"}},"collapsed":true},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Experiment directory created at: /content/drive/MyDrive/ex2024/results/experiment_2025-02-19_23-39-51\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["tokenizer_config.json:   0%|          | 0.00/251 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b7c3b62f507d48d09b00bedd7027083a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["vocab.txt:   0%|          | 0.00/231k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6778e367a42544619bb9bbffcb5a2be3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["config.json:   0%|          | 0.00/472 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dba67fd9e08c4d28b195a012b0ea6488"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["pytorch_model.bin:   0%|          | 0.00/447M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"73f7ae2d12aa4476a18bad147775256b"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (958 > 512). Running this sequence through the model will result in indexing errors\n"]}]},{"cell_type":"code","source":["ex.run()\n","print('---finish---')"],"metadata":{"id":"be7cfy_nZgxJ"},"execution_count":null,"outputs":[]}]}