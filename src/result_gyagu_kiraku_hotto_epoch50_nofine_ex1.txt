class weight : tensor([0.7389, 0.1767])
best:lr 3.87142481843913e-07
EPOCH : 1 / 50
VAL_LOSS : 0.7817589099760409 
VAL_ACCURACY : 0.7400932400932401
VAL_F1 : 0.04291845482230286

EPOCH : 2 / 50
VAL_LOSS : 0.7705431448088752 
VAL_ACCURACY : 0.7389277389277389
VAL_F1 : 0.05084745749299771

EPOCH : 3 / 50
VAL_LOSS : 0.7602318608098559 
VAL_ACCURACY : 0.7307692307692307
VAL_F1 : 0.06477732773367864

EPOCH : 4 / 50
VAL_LOSS : 0.7579765915870667 
VAL_ACCURACY : 0.7296037296037297
VAL_F1 : 0.07936507913684177

EPOCH : 5 / 50
VAL_LOSS : 0.7475563160799168 
VAL_ACCURACY : 0.7307692307692307
VAL_F1 : 0.10116731492231526

EPOCH : 6 / 50
VAL_LOSS : 0.748086334378631 
VAL_ACCURACY : 0.7307692307692307
VAL_F1 : 0.11494252846470253

EPOCH : 7 / 50
VAL_LOSS : 0.7435584763685862 
VAL_ACCURACY : 0.7272727272727273
VAL_F1 : 0.1459854011379136

EPOCH : 8 / 50
VAL_LOSS : 0.7373357724260401 
VAL_ACCURACY : 0.7191142191142191
VAL_F1 : 0.14840989364187343

EPOCH : 9 / 50
VAL_LOSS : 0.7304669486151801 
VAL_ACCURACY : 0.7191142191142191
VAL_F1 : 0.18855218816361144

EPOCH : 10 / 50
VAL_LOSS : 0.7255075927133914 
VAL_ACCURACY : 0.7202797202797203
VAL_F1 : 0.21052631538523633

EPOCH : 11 / 50
VAL_LOSS : 0.7230864663918813 
VAL_ACCURACY : 0.7097902097902098
VAL_F1 : 0.22429906498558824

EPOCH : 12 / 50
VAL_LOSS : 0.7178444453963527 
VAL_ACCURACY : 0.7074592074592074
VAL_F1 : 0.2507462682024861

EPOCH : 13 / 50
VAL_LOSS : 0.7108119593726264 
VAL_ACCURACY : 0.7086247086247086
VAL_F1 : 0.30555555507733023

EPOCH : 14 / 50
VAL_LOSS : 0.7078510213781286 
VAL_ACCURACY : 0.6958041958041958
VAL_F1 : 0.31134564594846875

EPOCH : 15 / 50
VAL_LOSS : 0.6998477158723054 
VAL_ACCURACY : 0.6888111888111889
VAL_F1 : 0.33082706717229166

EPOCH : 16 / 50
VAL_LOSS : 0.6995364228884379 
VAL_ACCURACY : 0.6853146853146853
VAL_F1 : 0.3632075466686432

EPOCH : 17 / 50
VAL_LOSS : 0.6941348766839063 
VAL_ACCURACY : 0.6771561771561772
VAL_F1 : 0.3690205006372736

EPOCH : 18 / 50
VAL_LOSS : 0.6893916417051245 
VAL_ACCURACY : 0.6771561771561772
VAL_F1 : 0.38852097080126113

EPOCH : 19 / 50
VAL_LOSS : 0.6869259377320608 
VAL_ACCURACY : 0.6713286713286714
VAL_F1 : 0.4075630247115581

EPOCH : 20 / 50
VAL_LOSS : 0.6840121161054682 
VAL_ACCURACY : 0.6596736596736597
VAL_F1 : 0.415999999506024

EPOCH : 21 / 50
VAL_LOSS : 0.6796580089463128 
VAL_ACCURACY : 0.6410256410256411
VAL_F1 : 0.40540540491576604

EPOCH : 22 / 50
VAL_LOSS : 0.6774922211964926 
VAL_ACCURACY : 0.6386946386946387
VAL_F1 : 0.42164179055991735

EPOCH : 23 / 50
VAL_LOSS : 0.6750553658715001 
VAL_ACCURACY : 0.6317016317016317
VAL_F1 : 0.42960288760701304

EPOCH : 24 / 50
VAL_LOSS : 0.6699545239960706 
VAL_ACCURACY : 0.6177156177156177
VAL_F1 : 0.42857142809800414

EPOCH : 25 / 50
VAL_LOSS : 0.6667733335936511 
VAL_ACCURACY : 0.6072261072261073
VAL_F1 : 0.4336134449115063

EPOCH : 26 / 50
VAL_LOSS : 0.6640087399217818 
VAL_ACCURACY : 0.5944055944055944
VAL_F1 : 0.43322475523999726

EPOCH : 27 / 50
VAL_LOSS : 0.6619994066379689 
VAL_ACCURACY : 0.5897435897435898
VAL_F1 : 0.43769968005487964

EPOCH : 28 / 50
VAL_LOSS : 0.6607496451448511 
VAL_ACCURACY : 0.5885780885780886
VAL_F1 : 0.449297971467622

EPOCH : 29 / 50
VAL_LOSS : 0.6560333371162415 
VAL_ACCURACY : 0.5897435897435898
VAL_F1 : 0.46012269893895613

EPOCH : 30 / 50
VAL_LOSS : 0.6556916645279637 
VAL_ACCURACY : 0.5862470862470862
VAL_F1 : 0.4693572491845179

EPOCH : 31 / 50
VAL_LOSS : 0.6520723446651742 
VAL_ACCURACY : 0.5792540792540792
VAL_F1 : 0.46833578748502636

EPOCH : 32 / 50
VAL_LOSS : 0.6487745940685272 
VAL_ACCURACY : 0.5745920745920746
VAL_F1 : 0.46715328423517927

EPOCH : 33 / 50
VAL_LOSS : 0.6467417776584625 
VAL_ACCURACY : 0.5675990675990676
VAL_F1 : 0.4677187944027056

EPOCH : 34 / 50
VAL_LOSS : 0.6449423211592215 
VAL_ACCURACY : 0.5641025641025641
VAL_F1 : 0.4702549570777993

EPOCH : 35 / 50
VAL_LOSS : 0.6426054769092135 
VAL_ACCURACY : 0.5629370629370629
VAL_F1 : 0.47405329550572917

EPOCH : 36 / 50
VAL_LOSS : 0.6382018625736237 
VAL_ACCURACY : 0.5629370629370629
VAL_F1 : 0.4784422805207976

EPOCH : 37 / 50
VAL_LOSS : 0.6394893041363469 
VAL_ACCURACY : 0.5606060606060606
VAL_F1 : 0.4842681254339969

EPOCH : 38 / 50
VAL_LOSS : 0.6364001532395681 
VAL_ACCURACY : 0.5606060606060606
VAL_F1 : 0.48846675670444384

EPOCH : 39 / 50
VAL_LOSS : 0.6341211486745764 
VAL_ACCURACY : 0.5501165501165501
VAL_F1 : 0.4825737261254915

EPOCH : 40 / 50
VAL_LOSS : 0.6308333178361257 
VAL_ACCURACY : 0.5512820512820513
VAL_F1 : 0.48322147609367516

EPOCH : 41 / 50
VAL_LOSS : 0.6304506891303592 
VAL_ACCURACY : 0.5547785547785548
VAL_F1 : 0.49066666625188615

EPOCH : 42 / 50
VAL_LOSS : 0.629053497755969 
VAL_ACCURACY : 0.5547785547785548
VAL_F1 : 0.49202127618161146

EPOCH : 43 / 50
VAL_LOSS : 0.626165693556821 
VAL_ACCURACY : 0.5536130536130536
VAL_F1 : 0.49271523137491857

EPOCH : 44 / 50
VAL_LOSS : 0.6218915625854775 
VAL_ACCURACY : 0.5536130536130536
VAL_F1 : 0.49538866888984023

EPOCH : 45 / 50
VAL_LOSS : 0.6215692460536957 
VAL_ACCURACY : 0.5501165501165501
VAL_F1 : 0.49476439749550116

EPOCH : 46 / 50
VAL_LOSS : 0.620530359171055 
VAL_ACCURACY : 0.5524475524475524
VAL_F1 : 0.4986945165616543

EPOCH : 47 / 50
VAL_LOSS : 0.6144907066115627 
VAL_ACCURACY : 0.5501165501165501
VAL_F1 : 0.4973958329243537

EPOCH : 48 / 50
VAL_LOSS : 0.615488730095051 
VAL_ACCURACY : 0.5501165501165501
VAL_F1 : 0.4987012982929566

EPOCH : 49 / 50
VAL_LOSS : 0.6144382291369967 
VAL_ACCURACY : 0.5501165501165501
VAL_F1 : 0.4987012982929566

EPOCH : 50 / 50
VAL_LOSS : 0.6128129098150465 
VAL_ACCURACY : 0.5524475524475524
VAL_F1 : 0.5038759685851713

# 5話-0
# 文: Bさん、苦手そうだよな…
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
tensor([[ 0.3663, -0.1069]], device='cuda:0')
# 5話-0
# 文: そうなんだ?
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[0.0226, 0.0071]], device='cuda:0')
# 5話-0
# 文: あと、これも読んだよ
正解 : 1 , 予測 : 0 / 元クラス : 憤怒
tensor([[ 0.1987, -0.2881]], device='cuda:0')
# 5話-1
# 文: これ読んだよ
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 0.0500, -0.2256]], device='cuda:0')
# 5話-1
# 文: ありがとうございます…それ何読んでるんですか?
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[-0.0200, -0.1735]], device='cuda:0')
# 5話-1
# 文: そうなんだ?
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[0.0226, 0.0071]], device='cuda:0')
# 5話-1
# 文: 本当に今ハマってる本はこの二冊…
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
tensor([[ 0.0779, -0.2927]], device='cuda:0')
# 6話-0
# 文: 父の分と2つ作ったの
正解 : 1 , 予測 : 0 / 元クラス : UNK
tensor([[ 0.2680, -0.2911]], device='cuda:0')
# 6話-0
# 文: ほとんど冷凍食品詰めただけだよ
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 0.0508, -0.2397]], device='cuda:0')
# 6話-0
# 文: どうぞどうぞ
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[0.0131, 0.0255]], device='cuda:0')
# 6話-0
# 文: キャー!
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[0.2894, 0.1110]], device='cuda:0')
# 6話-1
# 文: キャー!
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[0.2894, 0.1110]], device='cuda:0')
# 6話-1
# 文: ええ…父の分と2つ作ったんだけど
正解 : 1 , 予測 : 0 / 元クラス : UNK
tensor([[ 0.1972, -0.1445]], device='cuda:0')
# 6話-1
# 文: ほとんど冷凍食品詰めただけだよ…
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
tensor([[ 0.0122, -0.1004]], device='cuda:0')
# 7話-0
# 文: チョコは一つしかないし、悪いよ?
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[0.0892, 0.0326]], device='cuda:0')
# 7話-0
# 文: とか言い出すのかな…
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.2628,  0.2839]], device='cuda:0')
# 7話-1
# 文: 差し入れでもらったこの大量のアイスも
正解 : 1 , 予測 : 0 / 元クラス : UNK
tensor([[ 0.0326, -0.0809]], device='cuda:0')
# 7話-1
# 文: チョコ一つしかないね はんぶんこしよっか
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 0.0134, -0.2585]], device='cuda:0')
# 7話-1
# 文: Aくんがいなければ独り占めできたのにな…
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
tensor([[ 0.3291, -0.0061]], device='cuda:0')
# 8話-1
# 文: でもわざわざ国際会議から送ってくれたんだよな…
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
tensor([[0.2007, 0.1208]], device='cuda:0')
# 9話-0
# 文: あれ?スペインからもう戻ってきたのか
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[ 0.1645, -0.2230]], device='cuda:0')
# 9話-0
# 文: あれ？
正解 : 1 , 予測 : 0 / 元クラス : UNK
tensor([[0.2334, 0.1145]], device='cuda:0')
# 9話-1
# 文: 恥ずかしい…
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
tensor([[ 0.0468, -0.0003]], device='cuda:0')
------------------------test acc------------------------
Test Acc : 0.7013
correct: 54, total: 77
------------------------------------------------
                  喜楽        その他  accuracy  macro avg  weighted avg
precision   0.275862   0.958333  0.701299   0.617098      0.869701
recall      0.800000   0.686567  0.701299   0.743284      0.701299
f1-score    0.410256   0.800000  0.701299   0.605128      0.749384
support    10.000000  67.000000  0.701299  77.000000     77.000000
正例のF1値 : 0.4102564098540433
class weight : tensor([0.7389, 0.1767])
best:lr 1.5202176669520055e-06
EPOCH : 1 / 50
VAL_LOSS : 0.7443439629342821 
VAL_ACCURACY : 0.7342657342657343
VAL_F1 : 0.04999999983989584

EPOCH : 2 / 50
VAL_LOSS : 0.7182983535307425 
VAL_ACCURACY : 0.7261072261072261
VAL_F1 : 0.06374501969733813

EPOCH : 3 / 50
VAL_LOSS : 0.6960827068046287 
VAL_ACCURACY : 0.7226107226107226
VAL_F1 : 0.15602836844623008

EPOCH : 4 / 50
VAL_LOSS : 0.6761074353147436 
VAL_ACCURACY : 0.7261072261072261
VAL_F1 : 0.29850746223205166

EPOCH : 5 / 50
VAL_LOSS : 0.6591848344714554 
VAL_ACCURACY : 0.7400932400932401
VAL_F1 : 0.42966751868661246

EPOCH : 6 / 50
VAL_LOSS : 0.6474291384220123 
VAL_ACCURACY : 0.7424242424242424
VAL_F1 : 0.5443298964096673

EPOCH : 7 / 50
VAL_LOSS : 0.6363200909561582 
VAL_ACCURACY : 0.7214452214452215
VAL_F1 : 0.5662431937113513

EPOCH : 8 / 50
VAL_LOSS : 0.6257803539435068 
VAL_ACCURACY : 0.7016317016317016
VAL_F1 : 0.5830618887899978

EPOCH : 9 / 50
VAL_LOSS : 0.6178814106517367 
VAL_ACCURACY : 0.6736596736596736
VAL_F1 : 0.5705521467913781

EPOCH : 10 / 50
VAL_LOSS : 0.6081291006671058 
VAL_ACCURACY : 0.6410256410256411
VAL_F1 : 0.5536231879708843

EPOCH : 11 / 50
VAL_LOSS : 0.6035598384009467 
VAL_ACCURACY : 0.6305361305361306
VAL_F1 : 0.551626590801374

EPOCH : 12 / 50
VAL_LOSS : 0.5963156002539175 
VAL_ACCURACY : 0.6188811188811189
VAL_F1 : 0.5489655168182184

EPOCH : 13 / 50
VAL_LOSS : 0.5890438622898526 
VAL_ACCURACY : 0.6153846153846154
VAL_F1 : 0.5528455280364092

EPOCH : 14 / 50
VAL_LOSS : 0.5838756185990793 
VAL_ACCURACY : 0.6083916083916084
VAL_F1 : 0.5495978548116388

EPOCH : 15 / 50
VAL_LOSS : 0.5762897608456788 
VAL_ACCURACY : 0.6037296037296037
VAL_F1 : 0.5478723400112502

EPOCH : 16 / 50
VAL_LOSS : 0.5725522951947318 
VAL_ACCURACY : 0.6072261072261073
VAL_F1 : 0.5500667552589674

EPOCH : 17 / 50
VAL_LOSS : 0.5656573391622968 
VAL_ACCURACY : 0.6142191142191142
VAL_F1 : 0.5592543271486115

EPOCH : 18 / 50
VAL_LOSS : 0.5615949338233029 
VAL_ACCURACY : 0.6188811188811189
VAL_F1 : 0.5610738250867546

EPOCH : 19 / 50
VAL_LOSS : 0.5549502107832167 
VAL_ACCURACY : 0.627039627039627
VAL_F1 : 0.5652173908847804

EPOCH : 20 / 50
VAL_LOSS : 0.5488080426498696 
VAL_ACCURACY : 0.6328671328671329
VAL_F1 : 0.5690834469111931

EPOCH : 21 / 50
VAL_LOSS : 0.543228981119615 
VAL_ACCURACY : 0.6410256410256411
VAL_F1 : 0.5722222217973342

EPOCH : 22 / 50
VAL_LOSS : 0.5424539910422431 
VAL_ACCURACY : 0.6503496503496503
VAL_F1 : 0.5774647883041499

EPOCH : 23 / 50
VAL_LOSS : 0.5350690395743759 
VAL_ACCURACY : 0.6515151515151515
VAL_F1 : 0.5782792661440556

EPOCH : 24 / 50
VAL_LOSS : 0.528682690527704 
VAL_ACCURACY : 0.6608391608391608
VAL_F1 : 0.5848787442192099

EPOCH : 25 / 50
VAL_LOSS : 0.5251135643985536 
VAL_ACCURACY : 0.668997668997669
VAL_F1 : 0.5907780975490412

EPOCH : 26 / 50
VAL_LOSS : 0.5179929087559382 
VAL_ACCURACY : 0.675990675990676
VAL_F1 : 0.5947521861525342

EPOCH : 27 / 50
VAL_LOSS : 0.5130030374836039 
VAL_ACCURACY : 0.6864801864801865
VAL_F1 : 0.6026587883345369

EPOCH : 28 / 50
VAL_LOSS : 0.511803557475408 
VAL_ACCURACY : 0.6958041958041958
VAL_F1 : 0.6098654704098079

EPOCH : 29 / 50
VAL_LOSS : 0.5079480525520113 
VAL_ACCURACY : 0.7144522144522144
VAL_F1 : 0.6248085753562707

EPOCH : 30 / 50
VAL_LOSS : 0.4995301205802847 
VAL_ACCURACY : 0.7226107226107226
VAL_F1 : 0.6315789469183017

EPOCH : 31 / 50
VAL_LOSS : 0.49279871086279553 
VAL_ACCURACY : 0.7237762237762237
VAL_F1 : 0.6325581390844205

EPOCH : 32 / 50
VAL_LOSS : 0.4902949432531993 
VAL_ACCURACY : 0.7342657342657343
VAL_F1 : 0.6426332283872457

EPOCH : 33 / 50
VAL_LOSS : 0.48647479050689274 
VAL_ACCURACY : 0.7377622377622378
VAL_F1 : 0.6456692908846723

EPOCH : 34 / 50
VAL_LOSS : 0.4831337249941296 
VAL_ACCURACY : 0.7435897435897436
VAL_F1 : 0.6485622998625127

EPOCH : 35 / 50
VAL_LOSS : 0.4787246993294469 
VAL_ACCURACY : 0.747086247086247
VAL_F1 : 0.6516853928004246

EPOCH : 36 / 50
VAL_LOSS : 0.47234832688614176 
VAL_ACCURACY : 0.7575757575757576
VAL_F1 : 0.6612377845552153

EPOCH : 37 / 50
VAL_LOSS : 0.4682684347585396 
VAL_ACCURACY : 0.7575757575757576
VAL_F1 : 0.6612377845552153

EPOCH : 38 / 50
VAL_LOSS : 0.46631025384973596 
VAL_ACCURACY : 0.7634032634032634
VAL_F1 : 0.6666666662038983

EPOCH : 39 / 50
VAL_LOSS : 0.4628148371422732 
VAL_ACCURACY : 0.7692307692307693
VAL_F1 : 0.6721854299991173

EPOCH : 40 / 50
VAL_LOSS : 0.45722543475804506 
VAL_ACCURACY : 0.7715617715617715
VAL_F1 : 0.67441860418603

EPOCH : 41 / 50
VAL_LOSS : 0.4510965595642726 
VAL_ACCURACY : 0.7750582750582751
VAL_F1 : 0.6777963267458788

EPOCH : 42 / 50
VAL_LOSS : 0.4522728346012257 
VAL_ACCURACY : 0.7773892773892774
VAL_F1 : 0.6800670012082299

EPOCH : 43 / 50
VAL_LOSS : 0.44300467051841597 
VAL_ACCURACY : 0.7867132867132867
VAL_F1 : 0.6903553294804126

EPOCH : 44 / 50
VAL_LOSS : 0.4429359651274151 
VAL_ACCURACY : 0.7878787878787878
VAL_F1 : 0.6904761900063805

EPOCH : 45 / 50
VAL_LOSS : 0.4400287331254394 
VAL_ACCURACY : 0.7925407925407926
VAL_F1 : 0.6962457333179128

EPOCH : 46 / 50
VAL_LOSS : 0.43573569920327926 
VAL_ACCURACY : 0.7983682983682984
VAL_F1 : 0.7022375210425019

EPOCH : 47 / 50
VAL_LOSS : 0.4350201763488628 
VAL_ACCURACY : 0.8018648018648019
VAL_F1 : 0.7058823524680679

EPOCH : 48 / 50
VAL_LOSS : 0.42832909690009224 
VAL_ACCURACY : 0.8053613053613053
VAL_F1 : 0.7095652169172205

EPOCH : 49 / 50
VAL_LOSS : 0.43015299130369117 
VAL_ACCURACY : 0.8076923076923077
VAL_F1 : 0.7120418843420228

EPOCH : 50 / 50
VAL_LOSS : 0.42402550136601486 
VAL_ACCURACY : 0.8076923076923077
VAL_F1 : 0.7120418843420228

# 5話-0
# 文: 何読んでるんですか?
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[-0.3099, -0.3902]], device='cuda:0')
# 5話-0
# 文: オススメの本教えて
正解 : 1 , 予測 : 0 / 元クラス : UNK
tensor([[ 0.3990, -0.1192]], device='cuda:0')
# 5話-0
# 文: 少々マニアックだろうか…
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
tensor([[-0.2136, -0.4267]], device='cuda:0')
# 5話-0
# 文: Bさん、苦手そうだよな…
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
tensor([[ 0.1725, -0.1320]], device='cuda:0')
# 5話-0
# 文: そうなんだ?
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 0.1984, -0.4416]], device='cuda:0')
# 5話-0
# 文: 適当に流したな
正解 : 1 , 予測 : 0 / 元クラス : 憤怒
tensor([[0.0460, 0.0450]], device='cuda:0')
# 5話-0
# 文: あと、これも読んだよ
正解 : 1 , 予測 : 0 / 元クラス : 憤怒
tensor([[ 0.4477, -0.2205]], device='cuda:0')
# 5話-1
# 文: これ読んだよ
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 0.7165, -0.0191]], device='cuda:0')
# 5話-1
# 文: オススメの本教えて
正解 : 1 , 予測 : 0 / 元クラス : UNK
tensor([[ 0.3990, -0.1192]], device='cuda:0')
# 5話-1
# 文: そうなんだ?
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 0.1984, -0.4416]], device='cuda:0')
# 5話-1
# 文: 本当に今ハマってる本はこの二冊…
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
tensor([[ 0.1941, -0.1428]], device='cuda:0')
# 6話-0
# 文: 父の分と2つ作ったの
正解 : 1 , 予測 : 0 / 元クラス : UNK
tensor([[ 0.0832, -0.3328]], device='cuda:0')
# 6話-0
# 文: 手作りなんですか?
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[-0.2489, -0.2678]], device='cuda:0')
# 6話-0
# 文: 見てもいいですか?
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[0.2348, 0.1457]], device='cuda:0')
# 6話-0
# 文: キャー!
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[ 0.0930, -0.5095]], device='cuda:0')
# 6話-0
# 文: ベタだなあ
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
tensor([[ 0.4074, -0.3298]], device='cuda:0')
# 6話-1
# 文: キャー!
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[ 0.0930, -0.5095]], device='cuda:0')
# 6話-1
# 文: ベタだなあ
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
tensor([[ 0.4074, -0.3298]], device='cuda:0')
# 6話-1
# 文: 入れ替わってしまったみたい
正解 : 1 , 予測 : 0 / 元クラス : UNK
tensor([[ 0.1765, -0.0146]], device='cuda:0')
# 6話-1
# 文: 手作りなんですか?
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
tensor([[-0.2489, -0.2678]], device='cuda:0')
# 6話-1
# 文: ほとんど冷凍食品詰めただけだよ…
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
tensor([[-0.2870, -0.3679]], device='cuda:0')
# 7話-0
# 文: どれがいいですか?
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 0.0668, -0.3050]], device='cuda:0')
# 7話-0
# 文: とか言い出すのかな…
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.0891,  0.7797]], device='cuda:0')
# 7話-0
# 文: 器用だ!?
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[ 0.0191, -0.1456]], device='cuda:0')
# 7話-1
# 文: 器用だ!?
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[ 0.0191, -0.1456]], device='cuda:0')
# 7話-1
# 文: 差し入れでもらったこの大量のアイスも
正解 : 1 , 予測 : 0 / 元クラス : UNK
tensor([[ 0.2740, -0.0987]], device='cuda:0')
# 7話-1
# 文: チョコ一つしかないね はんぶんこしよっか
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[0.2305, 0.0126]], device='cuda:0')
# 7話-1
# 文: Aくんがいなければ独り占めできたのにな…
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
tensor([[ 0.0563, -0.1670]], device='cuda:0')
# 8話-0
# 文: 今日は良い実験結果が出たな
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.0110,  0.5606]], device='cuda:0')
# 8話-0
# 文: 国際会議でスペインにいるBさんからだ
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[0.2459, 0.1395]], device='cuda:0')
# 8話-1
# 文: でもわざわざ国際会議から送ってくれたんだよな…
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
tensor([[ 0.3355, -0.1151]], device='cuda:0')
# 8話-1
# 文: スペインから…
正解 : 1 , 予測 : 0 / 元クラス : UNK
tensor([[ 0.2733, -0.2694]], device='cuda:0')
# 9話-0
# 文: あれ?スペインからもう戻ってきたのか
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[ 0.2209, -0.0360]], device='cuda:0')
# 9話-0
# 文: Ｂさん…
正解 : 1 , 予測 : 0 / 元クラス : UNK
tensor([[ 0.1856, -0.3060]], device='cuda:0')
# 9話-0
# 文: あれ？
正解 : 1 , 予測 : 0 / 元クラス : UNK
tensor([[-0.1936, -0.4421]], device='cuda:0')
# 9話-0
# 文: 無視！？
正解 : 1 , 予測 : 0 / 元クラス : UNK
tensor([[ 0.2839, -0.0662]], device='cuda:0')
# 9話-0
# 文: Bさ…ちょっと!
正解 : 1 , 予測 : 0 / 元クラス : 憤怒
tensor([[ 0.2524, -0.4947]], device='cuda:0')
# 9話-0
# 文: ?
正解 : 1 , 予測 : 0 / 元クラス : 嫌悪
tensor([[-0.0508, -0.2398]], device='cuda:0')
# 9話-1
# 文: ?
正解 : 1 , 予測 : 0 / 元クラス : 嫌悪
tensor([[-0.0508, -0.2398]], device='cuda:0')
# 9話-1
# 文: ハッ
正解 : 1 , 予測 : 0 / 元クラス : UNK
tensor([[-0.2974, -0.5100]], device='cuda:0')
# 9話-1
# 文: ここは よその研究室…!?
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[ 0.5695, -0.0164]], device='cuda:0')
# 9話-1
# 文: 恥ずかしい…
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
tensor([[ 0.2123, -0.3597]], device='cuda:0')
# 9話-1
# 文: ?
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[-0.0508, -0.2398]], device='cuda:0')
------------------------test acc------------------------
Test Acc : 0.4416
correct: 34, total: 77
------------------------------------------------
                  喜楽        その他  accuracy  macro avg  weighted avg
precision   0.163265   0.928571  0.441558   0.545918      0.829181
recall      0.800000   0.388060  0.441558   0.594030      0.441558
f1-score    0.271186   0.547368  0.441558   0.409277      0.511501
support    10.000000  67.000000  0.441558  77.000000     77.000000
正例のF1値 : 0.271186440387245
class weight : tensor([0.7389, 0.1767])
best:lr 3.2591698553756478e-06
EPOCH : 1 / 50
VAL_LOSS : 0.692395555752295 
VAL_ACCURACY : 0.44638694638694637
VAL_F1 : 0.3790849669106276

EPOCH : 2 / 50
VAL_LOSS : 0.6708890674290834 
VAL_ACCURACY : 0.4358974358974359
VAL_F1 : 0.4265402839748798

EPOCH : 3 / 50
VAL_LOSS : 0.6540930083504429 
VAL_ACCURACY : 0.4324009324009324
VAL_F1 : 0.4395857303469538

EPOCH : 4 / 50
VAL_LOSS : 0.631868980549 
VAL_ACCURACY : 0.4347319347319347
VAL_F1 : 0.4556677886293437

EPOCH : 5 / 50
VAL_LOSS : 0.6169242031044431 
VAL_ACCURACY : 0.44755244755244755
VAL_F1 : 0.46860986509932584

EPOCH : 6 / 50
VAL_LOSS : 0.6017576660271045 
VAL_ACCURACY : 0.47086247086247085
VAL_F1 : 0.48054919870799717

EPOCH : 7 / 50
VAL_LOSS : 0.5868489433217932 
VAL_ACCURACY : 0.5081585081585082
VAL_F1 : 0.498812351157867

EPOCH : 8 / 50
VAL_LOSS : 0.5741668674680922 
VAL_ACCURACY : 0.541958041958042
VAL_F1 : 0.5154130698880954

EPOCH : 9 / 50
VAL_LOSS : 0.5597577304751785 
VAL_ACCURACY : 0.5979020979020979
VAL_F1 : 0.545454545042541

EPOCH : 10 / 50
VAL_LOSS : 0.546519304867144 
VAL_ACCURACY : 0.6445221445221445
VAL_F1 : 0.5734265730000138

EPOCH : 11 / 50
VAL_LOSS : 0.5368141807891704 
VAL_ACCURACY : 0.6701631701631702
VAL_F1 : 0.5916305911965835

EPOCH : 12 / 50
VAL_LOSS : 0.5234414184534991 
VAL_ACCURACY : 0.7027972027972028
VAL_F1 : 0.6165413529398655

EPOCH : 13 / 50
VAL_LOSS : 0.5165311694145203 
VAL_ACCURACY : 0.7167832167832168
VAL_F1 : 0.6267281101506792

EPOCH : 14 / 50
VAL_LOSS : 0.5040859971885328 
VAL_ACCURACY : 0.7319347319347319
VAL_F1 : 0.639498432149011

EPOCH : 15 / 50
VAL_LOSS : 0.4958081333725541 
VAL_ACCURACY : 0.7564102564102564
VAL_F1 : 0.6601626011652852

EPOCH : 16 / 50
VAL_LOSS : 0.4860943274365531 
VAL_ACCURACY : 0.7645687645687645
VAL_F1 : 0.6677631574316298

EPOCH : 17 / 50
VAL_LOSS : 0.4692720263092606 
VAL_ACCURACY : 0.7715617715617715
VAL_F1 : 0.673333332867539

EPOCH : 18 / 50
VAL_LOSS : 0.46957581021167616 
VAL_ACCURACY : 0.7878787878787878
VAL_F1 : 0.6894197947513833

EPOCH : 19 / 50
VAL_LOSS : 0.4588131816298873 
VAL_ACCURACY : 0.7983682983682984
VAL_F1 : 0.7001733097518932

EPOCH : 20 / 50
VAL_LOSS : 0.4496312549820653 
VAL_ACCURACY : 0.8111888111888111
VAL_F1 : 0.7127659569692357

EPOCH : 21 / 50
VAL_LOSS : 0.445108820994695 
VAL_ACCURACY : 0.8193473193473193
VAL_F1 : 0.721723518371218

EPOCH : 22 / 50
VAL_LOSS : 0.43367324272791546 
VAL_ACCURACY : 0.8263403263403264
VAL_F1 : 0.7285974494267107

EPOCH : 23 / 50
VAL_LOSS : 0.4231885219061816 
VAL_ACCURACY : 0.8275058275058275
VAL_F1 : 0.7299270068167524

EPOCH : 24 / 50
VAL_LOSS : 0.41731315078558745 
VAL_ACCURACY : 0.8356643356643356
VAL_F1 : 0.7393715337113239

EPOCH : 25 / 50
VAL_LOSS : 0.412136686068994 
VAL_ACCURACY : 0.8344988344988346
VAL_F1 : 0.7380073795894868

EPOCH : 26 / 50
VAL_LOSS : 0.40596479729369833 
VAL_ACCURACY : 0.8426573426573427
VAL_F1 : 0.7476635509155106

EPOCH : 27 / 50
VAL_LOSS : 0.4006040245294571 
VAL_ACCURACY : 0.8426573426573427
VAL_F1 : 0.7476635509155106

EPOCH : 28 / 50
VAL_LOSS : 0.39426925171304633 
VAL_ACCURACY : 0.8438228438228438
VAL_F1 : 0.7490636699253391

EPOCH : 29 / 50
VAL_LOSS : 0.39132568957629027 
VAL_ACCURACY : 0.844988344988345
VAL_F1 : 0.751401868672506

EPOCH : 30 / 50
VAL_LOSS : 0.38608501685990226 
VAL_ACCURACY : 0.844988344988345
VAL_F1 : 0.751401868672506

EPOCH : 31 / 50
VAL_LOSS : 0.3807511213752959 
VAL_ACCURACY : 0.8508158508158508
VAL_F1 : 0.7584905655499395

EPOCH : 32 / 50
VAL_LOSS : 0.37606527656316757 
VAL_ACCURACY : 0.8531468531468531
VAL_F1 : 0.7604562732753618

EPOCH : 33 / 50
VAL_LOSS : 0.37070184421760066 
VAL_ACCURACY : 0.8589743589743589
VAL_F1 : 0.7677543181277847

EPOCH : 34 / 50
VAL_LOSS : 0.3651541805377713 
VAL_ACCURACY : 0.8566433566433567
VAL_F1 : 0.7648183551508176

EPOCH : 35 / 50
VAL_LOSS : 0.3635981516153724 
VAL_ACCURACY : 0.8601398601398601
VAL_F1 : 0.7692307687402442

EPOCH : 36 / 50
VAL_LOSS : 0.35797967458212815 
VAL_ACCURACY : 0.8636363636363636
VAL_F1 : 0.7736943902243488

EPOCH : 37 / 50
VAL_LOSS : 0.34767183909813565 
VAL_ACCURACY : 0.8624708624708625
VAL_F1 : 0.7722007717097167

EPOCH : 38 / 50
VAL_LOSS : 0.3484250177387838 
VAL_ACCURACY : 0.8624708624708625
VAL_F1 : 0.7722007717097167

EPOCH : 39 / 50
VAL_LOSS : 0.3482347384647087 
VAL_ACCURACY : 0.8624708624708625
VAL_F1 : 0.7722007717097167

EPOCH : 40 / 50
VAL_LOSS : 0.3412816339620837 
VAL_ACCURACY : 0.8601398601398601
VAL_F1 : 0.7692307687402442

EPOCH : 41 / 50
VAL_LOSS : 0.3411648276227492 
VAL_ACCURACY : 0.8624708624708625
VAL_F1 : 0.7722007717097167

EPOCH : 42 / 50
VAL_LOSS : 0.3366333770531195 
VAL_ACCURACY : 0.8682983682983683
VAL_F1 : 0.7797270950242164

EPOCH : 43 / 50
VAL_LOSS : 0.33007287785962774 
VAL_ACCURACY : 0.8682983682983683
VAL_F1 : 0.7797270950242164

EPOCH : 44 / 50
VAL_LOSS : 0.32396861634872576 
VAL_ACCURACY : 0.8706293706293706
VAL_F1 : 0.7827788644777862

EPOCH : 45 / 50
VAL_LOSS : 0.326466574161141 
VAL_ACCURACY : 0.8706293706293706
VAL_F1 : 0.7827788644777862

EPOCH : 46 / 50
VAL_LOSS : 0.322417373182597 
VAL_ACCURACY : 0.8682983682983683
VAL_F1 : 0.7797270950242164

EPOCH : 47 / 50
VAL_LOSS : 0.32267621545879926 
VAL_ACCURACY : 0.8706293706293706
VAL_F1 : 0.7827788644777862

EPOCH : 48 / 50
VAL_LOSS : 0.31455111696764276 
VAL_ACCURACY : 0.8741258741258742
VAL_F1 : 0.7874015743095434

EPOCH : 49 / 50
VAL_LOSS : 0.3224765244457457 
VAL_ACCURACY : 0.8764568764568764
VAL_F1 : 0.7905138334980002

EPOCH : 50 / 50
VAL_LOSS : 0.3096055035237913 
VAL_ACCURACY : 0.8764568764568764
VAL_F1 : 0.7905138334980002

# 5話-0
# 文: オススメの本教えて
正解 : 1 , 予測 : 0 / 元クラス : UNK
tensor([[ 0.0012, -0.0292]], device='cuda:0')
# 5話-0
# 文: Bさん、苦手そうだよな…
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
tensor([[ 0.1681, -0.3210]], device='cuda:0')
# 5話-0
# 文: そうなんだ?
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 0.5451, -0.3158]], device='cuda:0')
# 5話-0
# 文: 適当に流したな
正解 : 1 , 予測 : 0 / 元クラス : 憤怒
tensor([[0.2633, 0.0181]], device='cuda:0')
# 5話-0
# 文: あと、これも読んだよ
正解 : 1 , 予測 : 0 / 元クラス : 憤怒
tensor([[ 1.0028, -0.1986]], device='cuda:0')
# 5話-1
# 文: これ読んだよ
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 0.2399, -0.3190]], device='cuda:0')
# 5話-1
# 文: オススメの本教えて
正解 : 1 , 予測 : 0 / 元クラス : UNK
tensor([[ 0.0012, -0.0292]], device='cuda:0')
# 5話-1
# 文: そうなんだ?
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 0.5451, -0.3158]], device='cuda:0')
# 5話-1
# 文: 本当に今ハマってる本はこの二冊…
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
tensor([[ 0.2250, -0.1242]], device='cuda:0')
# 6話-0
# 文: 父の分と2つ作ったの
正解 : 1 , 予測 : 0 / 元クラス : UNK
tensor([[ 0.9781, -0.2075]], device='cuda:0')
# 6話-0
# 文: 手作りなんですか?
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[0.3101, 0.2491]], device='cuda:0')
# 6話-0
# 文: ほとんど冷凍食品詰めただけだよ
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[0.3461, 0.3273]], device='cuda:0')
# 6話-0
# 文: 見てもいいですか?
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[0.0886, 0.0169]], device='cuda:0')
# 6話-0
# 文: キャー!
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[ 0.6540, -0.2763]], device='cuda:0')
# 6話-0
# 文: ベタだなあ
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
tensor([[ 0.3851, -0.1779]], device='cuda:0')
# 6話-1
# 文: キャー!
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[ 0.6540, -0.2763]], device='cuda:0')
# 6話-1
# 文: ベタだなあ
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
tensor([[ 0.3851, -0.1779]], device='cuda:0')
# 6話-1
# 文: ええ…父の分と2つ作ったんだけど
正解 : 1 , 予測 : 0 / 元クラス : UNK
tensor([[ 0.2842, -0.3272]], device='cuda:0')
# 6話-1
# 文: 入れ替わってしまったみたい
正解 : 1 , 予測 : 0 / 元クラス : UNK
tensor([[0.1485, 0.0012]], device='cuda:0')
# 6話-1
# 文: 手作りなんですか?
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
tensor([[0.3101, 0.2491]], device='cuda:0')
# 7話-0
# 文: どれがいいですか?
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[0.0680, 0.0600]], device='cuda:0')
# 7話-0
# 文: とか言い出すのかな…
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[0.0251, 0.5806]], device='cuda:0')
# 7話-0
# 文: ジャーン!パフェを作ってみました?!
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[0.0855, 0.2271]], device='cuda:0')
# 7話-0
# 文: 器用だ!?
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[0.4254, 0.2254]], device='cuda:0')
# 7話-1
# 文: ジャーン!パフェを作ってみました?!
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[0.0855, 0.2271]], device='cuda:0')
# 7話-1
# 文: 器用だ!?
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[0.4254, 0.2254]], device='cuda:0')
# 7話-1
# 文: 差し入れでもらったこの大量のアイスも
正解 : 1 , 予測 : 0 / 元クラス : UNK
tensor([[ 1.1096, -0.3517]], device='cuda:0')
# 7話-1
# 文: チョコ一つしかないね はんぶんこしよっか
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 0.5222, -0.1018]], device='cuda:0')
# 7話-1
# 文: Aくんがいなければ独り占めできたのにな…
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
tensor([[0.4509, 0.1979]], device='cuda:0')
# 8話-0
# 文: 今日は良い実験結果が出たな
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.3703,  0.5755]], device='cuda:0')
# 8話-0
# 文: 国際会議でスペインにいるBさんからだ
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[ 0.0288, -0.0632]], device='cuda:0')
# 8話-1
# 文: でもわざわざ国際会議から送ってくれたんだよな…
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
tensor([[ 0.5828, -0.3181]], device='cuda:0')
# 8話-1
# 文: スペインから…
正解 : 1 , 予測 : 0 / 元クラス : UNK
tensor([[-0.1330, -0.3188]], device='cuda:0')
# 9話-0
# 文: あれ?スペインからもう戻ってきたのか
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[ 0.0089, -0.0472]], device='cuda:0')
# 9話-0
# 文: Ｂさん…
正解 : 1 , 予測 : 0 / 元クラス : UNK
tensor([[ 0.0568, -0.3248]], device='cuda:0')
# 9話-0
# 文: あれ？
正解 : 1 , 予測 : 0 / 元クラス : UNK
tensor([[ 0.1037, -0.0950]], device='cuda:0')
# 9話-0
# 文: Bさ…ちょっと!
正解 : 1 , 予測 : 0 / 元クラス : 憤怒
tensor([[ 0.6829, -0.2244]], device='cuda:0')
# 9話-1
# 文: ハッ
正解 : 1 , 予測 : 0 / 元クラス : UNK
tensor([[0.4071, 0.2634]], device='cuda:0')
# 9話-1
# 文: ここは よその研究室…!?
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[ 0.2616, -0.3242]], device='cuda:0')
# 9話-1
# 文: 恥ずかしい…
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
tensor([[ 0.3252, -0.0335]], device='cuda:0')
------------------------test acc------------------------
Test Acc : 0.4805
correct: 37, total: 77
------------------------------------------------
                  喜楽        その他  accuracy  macro avg  weighted avg
precision   0.142857   0.885714  0.480519   0.514286      0.789239
recall      0.600000   0.462687  0.480519   0.531343      0.480519
f1-score    0.230769   0.607843  0.480519   0.419306      0.558873
support    10.000000  67.000000  0.480519  77.000000     77.000000
正例のF1値 : 0.2307692304497041
