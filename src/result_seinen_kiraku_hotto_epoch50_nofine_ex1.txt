class weight : tensor([0.7576, 0.1600])
best:lr 3.682319930094113e-07
EPOCH : 1 / 50
VAL_LOSS : 0.7315449500983616 
VAL_ACCURACY : 0.5416666666666666
VAL_F1 : 0.20618556653757042

EPOCH : 2 / 50
VAL_LOSS : 0.7231606245040894 
VAL_ACCURACY : 0.5321428571428571
VAL_F1 : 0.20925553273100173

EPOCH : 3 / 50
VAL_LOSS : 0.7261321443431782 
VAL_ACCURACY : 0.5226190476190476
VAL_F1 : 0.2121807460983399

EPOCH : 4 / 50
VAL_LOSS : 0.7209304087566879 
VAL_ACCURACY : 0.5154761904761904
VAL_F1 : 0.21276595698640796

EPOCH : 5 / 50
VAL_LOSS : 0.7209804901536906 
VAL_ACCURACY : 0.5119047619047619
VAL_F1 : 0.22641509388433606

EPOCH : 6 / 50
VAL_LOSS : 0.7170191744588456 
VAL_ACCURACY : 0.5047619047619047
VAL_F1 : 0.2436363631890314

EPOCH : 7 / 50
VAL_LOSS : 0.716768649389159 
VAL_ACCURACY : 0.5023809523809524
VAL_F1 : 0.2588652477851906

EPOCH : 8 / 50
VAL_LOSS : 0.71426792752068 
VAL_ACCURACY : 0.49047619047619045
VAL_F1 : 0.25951557049810825

EPOCH : 9 / 50
VAL_LOSS : 0.7120416186890512 
VAL_ACCURACY : 0.49523809523809526
VAL_F1 : 0.28378378335313753

EPOCH : 10 / 50
VAL_LOSS : 0.7107524489456752 
VAL_ACCURACY : 0.49404761904761907
VAL_F1 : 0.29284525747638573

EPOCH : 11 / 50
VAL_LOSS : 0.7054468460802762 
VAL_ACCURACY : 0.48928571428571427
VAL_F1 : 0.2932454690974979

EPOCH : 12 / 50
VAL_LOSS : 0.7046614829099404 
VAL_ACCURACY : 0.4845238095238095
VAL_F1 : 0.30048465224552606

EPOCH : 13 / 50
VAL_LOSS : 0.7032737720687434 
VAL_ACCURACY : 0.4773809523809524
VAL_F1 : 0.3020667722388226

EPOCH : 14 / 50
VAL_LOSS : 0.7034172157071671 
VAL_ACCURACY : 0.4773809523809524
VAL_F1 : 0.31298904497103996

EPOCH : 15 / 50
VAL_LOSS : 0.6983675574356655 
VAL_ACCURACY : 0.47023809523809523
VAL_F1 : 0.3100775189697735

EPOCH : 16 / 50
VAL_LOSS : 0.6973689873263521 
VAL_ACCURACY : 0.46785714285714286
VAL_F1 : 0.31755725150208963

EPOCH : 17 / 50
VAL_LOSS : 0.6942554183726041 
VAL_ACCURACY : 0.4607142857142857
VAL_F1 : 0.320839579808069

EPOCH : 18 / 50
VAL_LOSS : 0.6914954028039608 
VAL_ACCURACY : 0.4511904761904762
VAL_F1 : 0.31905465248223

EPOCH : 19 / 50
VAL_LOSS : 0.6927859029679928 
VAL_ACCURACY : 0.4523809523809524
VAL_F1 : 0.3255131960846269

EPOCH : 20 / 50
VAL_LOSS : 0.6931196237510105 
VAL_ACCURACY : 0.4452380952380952
VAL_F1 : 0.3265895949830391

EPOCH : 21 / 50
VAL_LOSS : 0.6894109586499771 
VAL_ACCURACY : 0.45
VAL_F1 : 0.3456090647680786

EPOCH : 22 / 50
VAL_LOSS : 0.6879510767055008 
VAL_ACCURACY : 0.4488095238095238
VAL_F1 : 0.34880450031726473

EPOCH : 23 / 50
VAL_LOSS : 0.6884436809791709 
VAL_ACCURACY : 0.444047619047619
VAL_F1 : 0.3522884878283398

EPOCH : 24 / 50
VAL_LOSS : 0.683588259624985 
VAL_ACCURACY : 0.444047619047619
VAL_F1 : 0.3576341124118828

EPOCH : 25 / 50
VAL_LOSS : 0.6841661334037781 
VAL_ACCURACY : 0.4452380952380952
VAL_F1 : 0.3633879777633664

EPOCH : 26 / 50
VAL_LOSS : 0.6794282130475314 
VAL_ACCURACY : 0.4452380952380952
VAL_F1 : 0.3719676546111951

EPOCH : 27 / 50
VAL_LOSS : 0.6779431678214163 
VAL_ACCURACY : 0.45
VAL_F1 : 0.380697050564336

EPOCH : 28 / 50
VAL_LOSS : 0.6776934974598434 
VAL_ACCURACY : 0.45
VAL_F1 : 0.3839999996273316

EPOCH : 29 / 50
VAL_LOSS : 0.677399458750239 
VAL_ACCURACY : 0.44761904761904764
VAL_F1 : 0.38297872303225794

EPOCH : 30 / 50
VAL_LOSS : 0.6750591925854953 
VAL_ACCURACY : 0.4488095238095238
VAL_F1 : 0.38837516475514666

EPOCH : 31 / 50
VAL_LOSS : 0.6747603427689031 
VAL_ACCURACY : 0.44761904761904764
VAL_F1 : 0.39107611511685997

EPOCH : 32 / 50
VAL_LOSS : 0.6719304221980976 
VAL_ACCURACY : 0.44642857142857145
VAL_F1 : 0.39215686237737624

EPOCH : 33 / 50
VAL_LOSS : 0.6742466631925331 
VAL_ACCURACY : 0.45
VAL_F1 : 0.39843749963324315

EPOCH : 34 / 50
VAL_LOSS : 0.6682176578719661 
VAL_ACCURACY : 0.44761904761904764
VAL_F1 : 0.3974025970364952

EPOCH : 35 / 50
VAL_LOSS : 0.669845924062549 
VAL_ACCURACY : 0.4488095238095238
VAL_F1 : 0.39948119288973005

EPOCH : 36 / 50
VAL_LOSS : 0.6669952723215211 
VAL_ACCURACY : 0.45357142857142857
VAL_F1 : 0.4077419351193641

EPOCH : 37 / 50
VAL_LOSS : 0.666791558265686 
VAL_ACCURACY : 0.45
VAL_F1 : 0.4076923073294116

EPOCH : 38 / 50
VAL_LOSS : 0.662837343395881 
VAL_ACCURACY : 0.45
VAL_F1 : 0.4076923073294116

EPOCH : 39 / 50
VAL_LOSS : 0.6647453128166918 
VAL_ACCURACY : 0.4488095238095238
VAL_F1 : 0.40717029413166417

EPOCH : 40 / 50
VAL_LOSS : 0.6624290931899592 
VAL_ACCURACY : 0.45
VAL_F1 : 0.4107142853526623

EPOCH : 41 / 50
VAL_LOSS : 0.6610237056354307 
VAL_ACCURACY : 0.4511904761904762
VAL_F1 : 0.4127388531418751

EPOCH : 42 / 50
VAL_LOSS : 0.6617564199105749 
VAL_ACCURACY : 0.4511904761904762
VAL_F1 : 0.4127388531418751

EPOCH : 43 / 50
VAL_LOSS : 0.6571015861799132 
VAL_ACCURACY : 0.4488095238095238
VAL_F1 : 0.41168996151988885

EPOCH : 44 / 50
VAL_LOSS : 0.6534392754986601 
VAL_ACCURACY : 0.44642857142857145
VAL_F1 : 0.4106463874726668

EPOCH : 45 / 50
VAL_LOSS : 0.656515618540206 
VAL_ACCURACY : 0.44642857142857145
VAL_F1 : 0.4106463874726668

EPOCH : 46 / 50
VAL_LOSS : 0.6570647954940796 
VAL_ACCURACY : 0.4488095238095238
VAL_F1 : 0.4131812417185412

EPOCH : 47 / 50
VAL_LOSS : 0.6519604100371307 
VAL_ACCURACY : 0.4511904761904762
VAL_F1 : 0.4157160959644157

EPOCH : 48 / 50
VAL_LOSS : 0.6514016254892889 
VAL_ACCURACY : 0.45
VAL_F1 : 0.4166666663075675

EPOCH : 49 / 50
VAL_LOSS : 0.6507411970282501 
VAL_ACCURACY : 0.4523809523809524
VAL_F1 : 0.41772151862760776

EPOCH : 50 / 50
VAL_LOSS : 0.650502472553613 
VAL_ACCURACY : 0.45476190476190476
VAL_F1 : 0.41878172552795423

# 5話-0
# 文: 何読んでるんですか?
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 0.2971, -0.2724]], device='cuda:0')
# 5話-0
# 文: 僕ですか?
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 0.3593, -0.3777]], device='cuda:0')
# 5話-0
# 文: 今ハマってる本はこの二冊…
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 0.4038, -0.3029]], device='cuda:0')
# 5話-0
# 文: 少々マニアックだろうか…
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 0.2623, -0.2511]], device='cuda:0')
# 5話-0
# 文: Bさん、苦手そうだよな…
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
tensor([[ 0.0008, -0.1973]], device='cuda:0')
# 5話-0
# 文: 適当に流そう
正解 : 1 , 予測 : 0 / 元クラス : UNK
tensor([[ 0.3140, -0.6646]], device='cuda:0')
# 5話-0
# 文: 小説はあまり読まないのですが、研究で利用している青空文庫の作品なら少々
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[-0.0292, -0.5456]], device='cuda:0')
# 5話-0
# 文: 適当に流したな
正解 : 1 , 予測 : 0 / 元クラス : UNK
tensor([[ 0.0920, -0.4792]], device='cuda:0')
# 5話-1
# 文: これ読んだよ
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 0.4103, -0.1621]], device='cuda:0')
# 5話-1
# 文: ありがとうございます… それ、何読んでるんですか?
正解 : 1 , 予測 : 0 / 元クラス : 恐怖
tensor([[ 0.2670, -0.2161]], device='cuda:0')
# 5話-1
# 文: 僕ですか?
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 0.3593, -0.3777]], device='cuda:0')
# 5話-1
# 文: 小説はあまり読まないのですが研究で利用している青空文庫の作品なら少々
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[-0.0303, -0.4912]], device='cuda:0')
# 5話-1
# 文: 本当に今ハマってる本はこの二冊…
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[-0.0436, -0.2319]], device='cuda:0')
# 6話-0
# 文: 今日は弁当なんですね
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[ 0.0483, -0.1985]], device='cuda:0')
# 6話-0
# 文: 手作りなんですか?
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 0.1212, -0.3607]], device='cuda:0')
# 6話-0
# 文: ほとんど冷凍食品詰めただけだよ
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[-0.0463, -0.1021]], device='cuda:0')
# 6話-0
# 文: キャー!
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[0.2421, 0.0389]], device='cuda:0')
# 6話-0
# 文: ベタだなあ
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
tensor([[ 0.2754, -0.5361]], device='cuda:0')
# 6話-1
# 文: キャー!
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[0.2421, 0.0389]], device='cuda:0')
# 6話-1
# 文: ベタだなあ
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
tensor([[ 0.2754, -0.5361]], device='cuda:0')
# 6話-1
# 文: 弁当なの珍しいですね
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
tensor([[0.3182, 0.0149]], device='cuda:0')
# 6話-1
# 文: ええ…父の分と2つ作ったんだけど
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
tensor([[ 0.1606, -0.2562]], device='cuda:0')
# 6話-1
# 文: 手作りなんですか?
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 0.1212, -0.3607]], device='cuda:0')
# 6話-1
# 文: ほとんど冷凍食品詰めただけよ…
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
tensor([[0.0450, 0.0211]], device='cuda:0')
# 6話-1
# 文: 俺も今日弁当なんでおかず分けますよ
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
tensor([[ 0.0417, -0.0362]], device='cuda:0')
# 6話-1
# 文: ありがとう…
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
tensor([[ 0.1643, -0.0215]], device='cuda:0')
# 7話-0
# 文: 差し入れで沢山いただいてしまいました
正解 : 1 , 予測 : 0 / 元クラス : UNK
tensor([[0.1426, 0.1283]], device='cuda:0')
# 7話-0
# 文: 本当はチョコが好きなんだけど…
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[-0.0763, -0.3851]], device='cuda:0')
# 7話-0
# 文: じゃあチョコですね
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[-0.0249, -0.1837]], device='cuda:0')
# 7話-0
# 文: チョコは一つしかないし、悪いよ〜
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
tensor([[ 0.0035, -0.2082]], device='cuda:0')
# 7話-0
# 文: 別に気にしませんが…
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 0.0465, -0.1976]], device='cuda:0')
# 7話-0
# 文: はんぶんこしよっか
正解 : 1 , 予測 : 0 / 元クラス : UNK
tensor([[ 0.0816, -0.2570]], device='cuda:0')
# 7話-0
# 文: とか言い出すのかな…
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 0.0348, -0.2017]], device='cuda:0')
# 7話-0
# 文: 器用だ!?
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[0.3720, 0.1246]], device='cuda:0')
# 7話-1
# 文: 器用だ!?
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[0.3720, 0.1246]], device='cuda:0')
# 7話-1
# 文: てっきり
正解 : 1 , 予測 : 0 / 元クラス : UNK
tensor([[0.3016, 0.1491]], device='cuda:0')
# 7話-1
# 文: チョコ一つしかないねはんぶんこしよっか
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 0.0672, -0.2386]], device='cuda:0')
# 7話-1
# 文: とか言い出すのかと思った…
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 0.0383, -0.2043]], device='cuda:0')
# 8話-0
# 文: 国際会議でスペインにいるBさんからだ
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[ 0.1968, -0.0297]], device='cuda:0')
# 8話-0
# 文: ここは日本…何も見ていない
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 0.2282, -0.1730]], device='cuda:0')
# 8話-1
# 文: ここは日本…何も見ていない
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 0.2282, -0.1730]], device='cuda:0')
# 8話-1
# 文: スペインから…
正解 : 1 , 予測 : 0 / 元クラス : UNK
tensor([[ 0.3277, -0.2184]], device='cuda:0')
# 9話-0
# 文: Bさん… あれ?
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[ 0.3044, -0.1506]], device='cuda:0')
# 9話-0
# 文: 無視!?
正解 : 1 , 予測 : 0 / 元クラス : UNK
tensor([[ 0.1537, -0.3767]], device='cuda:0')
# 9話-0
# 文: Bさ…ちょっと!
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
tensor([[ 0.1632, -0.4186]], device='cuda:0')
# 9話-0
# 文: ここはよその研究室…!?
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[ 0.0452, -0.1976]], device='cuda:0')
# 9話-0
# 文: ?
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[ 0.1984, -0.4045]], device='cuda:0')
# 9話-0
# 文: 人違い!?
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[0.5486, 0.3081]], device='cuda:0')
# 9話-1
# 文: Bさ…
正解 : 1 , 予測 : 0 / 元クラス : UNK
tensor([[ 0.1509, -0.4563]], device='cuda:0')
# 9話-1
# 文: ?
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[ 0.1984, -0.4045]], device='cuda:0')
# 9話-1
# 文: 人違い!?
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[0.5486, 0.3081]], device='cuda:0')
# 9話-1
# 文: ここは よその研究室…!?
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[ 0.1349, -0.2191]], device='cuda:0')
# 9話-1
# 文: 恥ずかしい…
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
tensor([[ 0.2261, -0.5114]], device='cuda:0')
# 9話-1
# 文: ?
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[ 0.1984, -0.4045]], device='cuda:0')
------------------------test acc------------------------
Test Acc : 0.2603
correct: 19, total: 73
------------------------------------------------
                  喜楽        その他  accuracy  macro avg  weighted avg
precision   0.205882   1.000000  0.260274   0.602941      0.847703
recall      1.000000   0.084746  0.260274   0.542373      0.260274
f1-score    0.341463   0.156250  0.260274   0.248857      0.191770
support    14.000000  59.000000  0.260274  73.000000     73.000000
正例のF1値 : 0.34146341434265315
class weight : tensor([0.7576, 0.1600])
best:lr 1.4750429587836745e-06
EPOCH : 1 / 50
VAL_LOSS : 0.6706165199009877 
VAL_ACCURACY : 0.4261904761904762
VAL_F1 : 0.35388739908987704

EPOCH : 2 / 50
VAL_LOSS : 0.6693679994007327 
VAL_ACCURACY : 0.41785714285714287
VAL_F1 : 0.3722721434109429

EPOCH : 3 / 50
VAL_LOSS : 0.6633720881534073 
VAL_ACCURACY : 0.4226190476190476
VAL_F1 : 0.3945068660607574

EPOCH : 4 / 50
VAL_LOSS : 0.6593955080464201 
VAL_ACCURACY : 0.4261904761904762
VAL_F1 : 0.4034653461805797

EPOCH : 5 / 50
VAL_LOSS : 0.6546486402457615 
VAL_ACCURACY : 0.43214285714285716
VAL_F1 : 0.4147239260284151

EPOCH : 6 / 50
VAL_LOSS : 0.6484025514350747 
VAL_ACCURACY : 0.43333333333333335
VAL_F1 : 0.4180929091844052

EPOCH : 7 / 50
VAL_LOSS : 0.6421650513163153 
VAL_ACCURACY : 0.444047619047619
VAL_F1 : 0.42699386467869177

EPOCH : 8 / 50
VAL_LOSS : 0.6377989975911267 
VAL_ACCURACY : 0.4523809523809524
VAL_F1 : 0.43209876507857037

EPOCH : 9 / 50
VAL_LOSS : 0.6356183577258632 
VAL_ACCURACY : 0.46190476190476193
VAL_F1 : 0.4378109449182353

EPOCH : 10 / 50
VAL_LOSS : 0.637936312072682 
VAL_ACCURACY : 0.4726190476190476
VAL_F1 : 0.4427672952392643

EPOCH : 11 / 50
VAL_LOSS : 0.6278031232222071 
VAL_ACCURACY : 0.49047619047619045
VAL_F1 : 0.45408163229132725

EPOCH : 12 / 50
VAL_LOSS : 0.6225528008532974 
VAL_ACCURACY : 0.49404761904761907
VAL_F1 : 0.45859872575322325

EPOCH : 13 / 50
VAL_LOSS : 0.6183395981788635 
VAL_ACCURACY : 0.5011904761904762
VAL_F1 : 0.46350832230053396

EPOCH : 14 / 50
VAL_LOSS : 0.6124543120276253 
VAL_ACCURACY : 0.5238095238095238
VAL_F1 : 0.47506561642897543

EPOCH : 15 / 50
VAL_LOSS : 0.6125768895419139 
VAL_ACCURACY : 0.5345238095238095
VAL_F1 : 0.4807436915271469

EPOCH : 16 / 50
VAL_LOSS : 0.6061067479961323 
VAL_ACCURACY : 0.5511904761904762
VAL_F1 : 0.4898511498263132

EPOCH : 17 / 50
VAL_LOSS : 0.606553426328695 
VAL_ACCURACY : 0.5642857142857143
VAL_F1 : 0.4958677682139008

EPOCH : 18 / 50
VAL_LOSS : 0.5986175885740316 
VAL_ACCURACY : 0.575
VAL_F1 : 0.5020920498249137

EPOCH : 19 / 50
VAL_LOSS : 0.5968307026152341 
VAL_ACCURACY : 0.5869047619047619
VAL_F1 : 0.5091937761326721

EPOCH : 20 / 50
VAL_LOSS : 0.5907646884333413 
VAL_ACCURACY : 0.5952380952380952
VAL_F1 : 0.5142857138953674

EPOCH : 21 / 50
VAL_LOSS : 0.5858762202397833 
VAL_ACCURACY : 0.6023809523809524
VAL_F1 : 0.5187319880801061

EPOCH : 22 / 50
VAL_LOSS : 0.5828371520312328 
VAL_ACCURACY : 0.6166666666666667
VAL_F1 : 0.527859237139752

EPOCH : 23 / 50
VAL_LOSS : 0.5772070642912163 
VAL_ACCURACY : 0.625
VAL_F1 : 0.5333333329338382

EPOCH : 24 / 50
VAL_LOSS : 0.5760575887167229 
VAL_ACCURACY : 0.6369047619047619
VAL_F1 : 0.541353383055413

EPOCH : 25 / 50
VAL_LOSS : 0.5727746138032878 
VAL_ACCURACY : 0.6392857142857142
VAL_F1 : 0.5429864249353799

EPOCH : 26 / 50
VAL_LOSS : 0.5713990398173062 
VAL_ACCURACY : 0.6464285714285715
VAL_F1 : 0.5479452050731962

EPOCH : 27 / 50
VAL_LOSS : 0.565710538963102 
VAL_ACCURACY : 0.655952380952381
VAL_F1 : 0.5546995373410795

EPOCH : 28 / 50
VAL_LOSS : 0.5643187530760495 
VAL_ACCURACY : 0.6571428571428571
VAL_F1 : 0.5555555551458666

EPOCH : 29 / 50
VAL_LOSS : 0.5568345312802296 
VAL_ACCURACY : 0.6714285714285714
VAL_F1 : 0.5660377354347386

EPOCH : 30 / 50
VAL_LOSS : 0.5573068002484879 
VAL_ACCURACY : 0.6761904761904762
VAL_F1 : 0.5696202527486831

EPOCH : 31 / 50
VAL_LOSS : 0.5523403309426218 
VAL_ACCURACY : 0.6785714285714286
VAL_F1 : 0.5700636938500903

EPOCH : 32 / 50
VAL_LOSS : 0.5491521993897995 
VAL_ACCURACY : 0.6833333333333333
VAL_F1 : 0.5737179482989553

EPOCH : 33 / 50
VAL_LOSS : 0.5491269140873315 
VAL_ACCURACY : 0.6964285714285714
VAL_F1 : 0.584013050147628

EPOCH : 34 / 50
VAL_LOSS : 0.544845849837897 
VAL_ACCURACY : 0.6976190476190476
VAL_F1 : 0.5849673198377066

EPOCH : 35 / 50
VAL_LOSS : 0.5377676211438089 
VAL_ACCURACY : 0.7011904761904761
VAL_F1 : 0.5878489322515955

EPOCH : 36 / 50
VAL_LOSS : 0.5352624531062145 
VAL_ACCURACY : 0.705952380952381
VAL_F1 : 0.5917355367635654

EPOCH : 37 / 50
VAL_LOSS : 0.5298437802296765 
VAL_ACCURACY : 0.7083333333333334
VAL_F1 : 0.5936981753604118

EPOCH : 38 / 50
VAL_LOSS : 0.5293147569557406 
VAL_ACCURACY : 0.7130952380952381
VAL_F1 : 0.5963149074429883

EPOCH : 39 / 50
VAL_LOSS : 0.5237221318595814 
VAL_ACCURACY : 0.719047619047619
VAL_F1 : 0.6013513509196323

EPOCH : 40 / 50
VAL_LOSS : 0.5253638990645139 
VAL_ACCURACY : 0.7226190476190476
VAL_F1 : 0.6044142610271733

EPOCH : 41 / 50
VAL_LOSS : 0.5186719433316644 
VAL_ACCURACY : 0.7297619047619047
VAL_F1 : 0.6106346479351435

EPOCH : 42 / 50
VAL_LOSS : 0.5198920661548398 
VAL_ACCURACY : 0.7321428571428571
VAL_F1 : 0.6127366604932679

EPOCH : 43 / 50
VAL_LOSS : 0.5141405035864632 
VAL_ACCURACY : 0.7321428571428571
VAL_F1 : 0.6127366604932679

EPOCH : 44 / 50
VAL_LOSS : 0.5139656814764131 
VAL_ACCURACY : 0.7345238095238096
VAL_F1 : 0.6148531947271009

EPOCH : 45 / 50
VAL_LOSS : 0.5069143457232781 
VAL_ACCURACY : 0.7440476190476191
VAL_F1 : 0.6234676002602986

EPOCH : 46 / 50
VAL_LOSS : 0.5068060924422066 
VAL_ACCURACY : 0.7488095238095238
VAL_F1 : 0.6278659607574382

EPOCH : 47 / 50
VAL_LOSS : 0.5045514702796936 
VAL_ACCURACY : 0.7523809523809524
VAL_F1 : 0.6312056733157851

EPOCH : 48 / 50
VAL_LOSS : 0.5034386605586646 
VAL_ACCURACY : 0.7547619047619047
VAL_F1 : 0.6334519568514774

EPOCH : 49 / 50
VAL_LOSS : 0.5017355607365662 
VAL_ACCURACY : 0.7547619047619047
VAL_F1 : 0.6334519568514774

EPOCH : 50 / 50
VAL_LOSS : 0.4919325439435131 
VAL_ACCURACY : 0.7559523809523809
VAL_F1 : 0.6345811047250358

# 5話-0
# 文: 何読んでるんですか?
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 0.2168, -0.3316]], device='cuda:0')
# 5話-0
# 文: 僕ですか?
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[0.2601, 0.0569]], device='cuda:0')
# 5話-0
# 文: 今ハマってる本はこの二冊…
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[-0.3680, -0.4494]], device='cuda:0')
# 5話-0
# 文: 少々マニアックだろうか…
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 0.1867, -0.1917]], device='cuda:0')
# 5話-0
# 文: Bさん、苦手そうだよな…
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
tensor([[-0.0419, -0.4500]], device='cuda:0')
# 5話-0
# 文: 適当に流そう
正解 : 1 , 予測 : 0 / 元クラス : UNK
tensor([[ 0.3703, -0.2795]], device='cuda:0')
# 5話-0
# 文: そうなんだ〜
正解 : 1 , 予測 : 0 / 元クラス : 憤怒
tensor([[ 0.2339, -0.5656]], device='cuda:0')
# 5話-0
# 文: 適当に流したな
正解 : 1 , 予測 : 0 / 元クラス : UNK
tensor([[ 0.2187, -0.2887]], device='cuda:0')
# 5話-1
# 文: これ読んだよ
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 0.3720, -0.7251]], device='cuda:0')
# 5話-1
# 文: ありがとうございます… それ、何読んでるんですか?
正解 : 1 , 予測 : 0 / 元クラス : 恐怖
tensor([[ 0.4971, -0.3171]], device='cuda:0')
# 5話-1
# 文: 僕ですか?
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[0.2601, 0.0569]], device='cuda:0')
# 5話-1
# 文: そうなんだ〜
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[ 0.2339, -0.5656]], device='cuda:0')
# 5話-1
# 文: 本当に今ハマってる本はこの二冊…
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[-0.2465, -0.4875]], device='cuda:0')
# 6話-0
# 文: 手作りなんですか?
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 0.2134, -0.1010]], device='cuda:0')
# 6話-0
# 文: ほとんど冷凍食品詰めただけだよ
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 0.2492, -0.2103]], device='cuda:0')
# 6話-0
# 文: キャー!
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[ 0.4437, -0.4114]], device='cuda:0')
# 6話-0
# 文: ベタだなあ
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
tensor([[ 0.4068, -0.3572]], device='cuda:0')
# 6話-1
# 文: キャー!
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[ 0.4437, -0.4114]], device='cuda:0')
# 6話-1
# 文: ベタだなあ
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
tensor([[ 0.4068, -0.3572]], device='cuda:0')
# 6話-1
# 文: 弁当なの珍しいですね
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
tensor([[ 0.4284, -0.7080]], device='cuda:0')
# 6話-1
# 文: ええ…父の分と2つ作ったんだけど
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
tensor([[-0.1340, -0.4825]], device='cuda:0')
# 6話-1
# 文: 手作りなんですか?
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 0.2134, -0.1010]], device='cuda:0')
# 6話-1
# 文: ほとんど冷凍食品詰めただけよ…
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
tensor([[-0.2219, -0.5276]], device='cuda:0')
# 6話-1
# 文: ありがとう…
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
tensor([[ 0.3263, -0.4587]], device='cuda:0')
# 7話-0
# 文: 本当はチョコが好きなんだけど…
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 0.0163, -0.0840]], device='cuda:0')
# 7話-0
# 文: はんぶんこしよっか
正解 : 1 , 予測 : 0 / 元クラス : UNK
tensor([[ 0.5950, -0.9188]], device='cuda:0')
# 7話-0
# 文: ジャーン!パフェを作ってみました〜!
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.1466, -0.1377]], device='cuda:0')
# 7話-0
# 文: 器用だ!?
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[ 0.0601, -0.2215]], device='cuda:0')
# 7話-1
# 文: ジャーン!パフェを作ってみました〜!
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.1466, -0.1377]], device='cuda:0')
# 7話-1
# 文: 器用だ!?
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[ 0.0601, -0.2215]], device='cuda:0')
# 7話-1
# 文: てっきり
正解 : 1 , 予測 : 0 / 元クラス : UNK
tensor([[ 0.4763, -0.3184]], device='cuda:0')
# 7話-1
# 文: チョコ一つしかないねはんぶんこしよっか
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 0.0038, -0.5347]], device='cuda:0')
# 7話-1
# 文: Aくんがいなければ独り占めできたのにな…
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
tensor([[-0.1350, -0.3395]], device='cuda:0')
# 8話-0
# 文: 今日は良い実験結果が出たな
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[0.1107, 0.4243]], device='cuda:0')
# 8話-0
# 文: ここは日本…何も見ていない
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 0.2831, -0.0926]], device='cuda:0')
# 8話-1
# 文: ここは日本…何も見ていない
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 0.2831, -0.0926]], device='cuda:0')
# 8話-1
# 文: スペインから…
正解 : 1 , 予測 : 0 / 元クラス : UNK
tensor([[ 0.0247, -0.0299]], device='cuda:0')
# 9話-0
# 文: Bさん… あれ?
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[ 0.3599, -0.1697]], device='cuda:0')
# 9話-0
# 文: 無視!?
正解 : 1 , 予測 : 0 / 元クラス : UNK
tensor([[ 0.3162, -0.2941]], device='cuda:0')
# 9話-0
# 文: Bさ…ちょっと!
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
tensor([[ 0.5657, -0.0997]], device='cuda:0')
# 9話-0
# 文: ?
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[ 0.0694, -0.1460]], device='cuda:0')
# 9話-0
# 文: 人違い!?
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[-0.1954, -0.4356]], device='cuda:0')
# 9話-1
# 文: Bさ…
正解 : 1 , 予測 : 0 / 元クラス : UNK
tensor([[ 0.4128, -0.1710]], device='cuda:0')
# 9話-1
# 文: ?
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[ 0.0694, -0.1460]], device='cuda:0')
# 9話-1
# 文: 人違い!?
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[-0.1954, -0.4356]], device='cuda:0')
# 9話-1
# 文: ここは よその研究室…!?
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[ 0.4150, -0.2319]], device='cuda:0')
# 9話-1
# 文: 恥ずかしい…
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
tensor([[ 0.2576, -0.2736]], device='cuda:0')
# 9話-1
# 文: ?
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[ 0.0694, -0.1460]], device='cuda:0')
------------------------test acc------------------------
Test Acc : 0.3425
correct: 25, total: 73
------------------------------------------------
                  喜楽        その他  accuracy  macro avg  weighted avg
precision   0.196429   0.823529  0.342466   0.509979      0.703263
recall      0.785714   0.237288  0.342466   0.511501      0.342466
f1-score    0.314286   0.368421  0.342466   0.341353      0.358039
support    14.000000  59.000000  0.342466  73.000000     73.000000
正例のF1値 : 0.3142857139567347
class weight : tensor([0.7576, 0.1600])
best:lr 3.360291249705098e-06
EPOCH : 1 / 50
VAL_LOSS : 0.6794454061760092 
VAL_ACCURACY : 0.6416666666666667
VAL_F1 : 0.3768115937287056

EPOCH : 2 / 50
VAL_LOSS : 0.6575323635677122 
VAL_ACCURACY : 0.594047619047619
VAL_F1 : 0.45439999958177796

EPOCH : 3 / 50
VAL_LOSS : 0.6463135031034362 
VAL_ACCURACY : 0.5583333333333333
VAL_F1 : 0.4599708875236044

EPOCH : 4 / 50
VAL_LOSS : 0.6303723431983084 
VAL_ACCURACY : 0.5416666666666666
VAL_F1 : 0.4585091416671672

EPOCH : 5 / 50
VAL_LOSS : 0.6183033934179342 
VAL_ACCURACY : 0.5321428571428571
VAL_F1 : 0.4682002702593894

EPOCH : 6 / 50
VAL_LOSS : 0.6052224056900672 
VAL_ACCURACY : 0.5642857142857143
VAL_F1 : 0.4873949575978902

EPOCH : 7 / 50
VAL_LOSS : 0.597734420367007 
VAL_ACCURACY : 0.5761904761904761
VAL_F1 : 0.49859154890903

EPOCH : 8 / 50
VAL_LOSS : 0.5882686989487342 
VAL_ACCURACY : 0.5892857142857143
VAL_F1 : 0.5050215204120468

EPOCH : 9 / 50
VAL_LOSS : 0.573264794529609 
VAL_ACCURACY : 0.6285714285714286
VAL_F1 : 0.5329341313344375

EPOCH : 10 / 50
VAL_LOSS : 0.5665400067590317 
VAL_ACCURACY : 0.6369047619047619
VAL_F1 : 0.5385779118494374

EPOCH : 11 / 50
VAL_LOSS : 0.5539503997226931 
VAL_ACCURACY : 0.6523809523809524
VAL_F1 : 0.5507692303603172

EPOCH : 12 / 50
VAL_LOSS : 0.546407144024687 
VAL_ACCURACY : 0.669047619047619
VAL_F1 : 0.558730158313545

EPOCH : 13 / 50
VAL_LOSS : 0.534288191570426 
VAL_ACCURACY : 0.680952380952381
VAL_F1 : 0.5677419350633351

EPOCH : 14 / 50
VAL_LOSS : 0.5302644051470846 
VAL_ACCURACY : 0.6952380952380952
VAL_F1 : 0.5803278684279549

EPOCH : 15 / 50
VAL_LOSS : 0.5219884717239524 
VAL_ACCURACY : 0.7071428571428572
VAL_F1 : 0.5886287621125211

EPOCH : 16 / 50
VAL_LOSS : 0.5085737086691946 
VAL_ACCURACY : 0.7130952380952381
VAL_F1 : 0.5949579827627767

EPOCH : 17 / 50
VAL_LOSS : 0.5013448314846687 
VAL_ACCURACY : 0.7202380952380952
VAL_F1 : 0.6010186752886449

EPOCH : 18 / 50
VAL_LOSS : 0.4949450729028234 
VAL_ACCURACY : 0.7285714285714285
VAL_F1 : 0.6082474222446653

EPOCH : 19 / 50
VAL_LOSS : 0.48861306624592477 
VAL_ACCURACY : 0.7345238095238096
VAL_F1 : 0.6135181971358818

EPOCH : 20 / 50
VAL_LOSS : 0.47906252179505693 
VAL_ACCURACY : 0.7380952380952381
VAL_F1 : 0.6180555551173624

EPOCH : 21 / 50
VAL_LOSS : 0.47135446262809466 
VAL_ACCURACY : 0.75
VAL_F1 : 0.6276595740250176

EPOCH : 22 / 50
VAL_LOSS : 0.4650656682140422 
VAL_ACCURACY : 0.7559523809523809
VAL_F1 : 0.6332737025960363

EPOCH : 23 / 50
VAL_LOSS : 0.4537398460901009 
VAL_ACCURACY : 0.7678571428571429
VAL_F1 : 0.6448087427202034

EPOCH : 24 / 50
VAL_LOSS : 0.4514623998471026 
VAL_ACCURACY : 0.7726190476190476
VAL_F1 : 0.6495412839528389

EPOCH : 25 / 50
VAL_LOSS : 0.4445068397611942 
VAL_ACCURACY : 0.7738095238095238
VAL_F1 : 0.6507352936664077

EPOCH : 26 / 50
VAL_LOSS : 0.4388564999373454 
VAL_ACCURACY : 0.775
VAL_F1 : 0.6519337012058104

EPOCH : 27 / 50
VAL_LOSS : 0.43086560267322466 
VAL_ACCURACY : 0.7797619047619048
VAL_F1 : 0.6567717991756602

EPOCH : 28 / 50
VAL_LOSS : 0.42520290107097264 
VAL_ACCURACY : 0.7833333333333333
VAL_F1 : 0.6617100367210169

EPOCH : 29 / 50
VAL_LOSS : 0.4210113416302879 
VAL_ACCURACY : 0.7892857142857143
VAL_F1 : 0.6679174479495087

EPOCH : 30 / 50
VAL_LOSS : 0.4179999901438659 
VAL_ACCURACY : 0.794047619047619
VAL_F1 : 0.672967863436766

EPOCH : 31 / 50
VAL_LOSS : 0.41003489606785326 
VAL_ACCURACY : 0.794047619047619
VAL_F1 : 0.672967863436766

EPOCH : 32 / 50
VAL_LOSS : 0.40810085017726105 
VAL_ACCURACY : 0.7988095238095239
VAL_F1 : 0.6780952376362377

EPOCH : 33 / 50
VAL_LOSS : 0.40324893650018945 
VAL_ACCURACY : 0.8071428571428572
VAL_F1 : 0.6872586867968501

EPOCH : 34 / 50
VAL_LOSS : 0.39624100389345634 
VAL_ACCURACY : 0.8119047619047619
VAL_F1 : 0.691406249535759

EPOCH : 35 / 50
VAL_LOSS : 0.3917911224207788 
VAL_ACCURACY : 0.8130952380952381
VAL_F1 : 0.6927592950343788

EPOCH : 36 / 50
VAL_LOSS : 0.3881955613505165 
VAL_ACCURACY : 0.8154761904761905
VAL_F1 : 0.6954813354874037

EPOCH : 37 / 50
VAL_LOSS : 0.38158994603831814 
VAL_ACCURACY : 0.8154761904761905
VAL_F1 : 0.6954813354874037

EPOCH : 38 / 50
VAL_LOSS : 0.37929771306379784 
VAL_ACCURACY : 0.819047619047619
VAL_F1 : 0.6996047426163587

EPOCH : 39 / 50
VAL_LOSS : 0.37428733706474304 
VAL_ACCURACY : 0.8226190476190476
VAL_F1 : 0.7037773355162543

EPOCH : 40 / 50
VAL_LOSS : 0.36969819805532134 
VAL_ACCURACY : 0.8238095238095238
VAL_F1 : 0.7051792824002873

EPOCH : 41 / 50
VAL_LOSS : 0.36618984392229115 
VAL_ACCURACY : 0.8238095238095238
VAL_F1 : 0.7039999995309841

EPOCH : 42 / 50
VAL_LOSS : 0.3632387510448132 
VAL_ACCURACY : 0.8285714285714286
VAL_F1 : 0.7096774188842434

EPOCH : 43 / 50
VAL_LOSS : 0.3609233692569553 
VAL_ACCURACY : 0.8333333333333334
VAL_F1 : 0.7154471539993804

EPOCH : 44 / 50
VAL_LOSS : 0.35333369109990465 
VAL_ACCURACY : 0.8333333333333334
VAL_F1 : 0.7154471539993804

EPOCH : 45 / 50
VAL_LOSS : 0.3511716405738075 
VAL_ACCURACY : 0.8357142857142857
VAL_F1 : 0.7183673464658309

EPOCH : 46 / 50
VAL_LOSS : 0.35266459944113243 
VAL_ACCURACY : 0.8392857142857143
VAL_F1 : 0.7227926073287656

EPOCH : 47 / 50
VAL_LOSS : 0.34397545681809477 
VAL_ACCURACY : 0.8404761904761905
VAL_F1 : 0.7242798349164508

EPOCH : 48 / 50
VAL_LOSS : 0.3426102672545415 
VAL_ACCURACY : 0.8428571428571429
VAL_F1 : 0.727272726797461

EPOCH : 49 / 50
VAL_LOSS : 0.33761293455114905 
VAL_ACCURACY : 0.844047619047619
VAL_F1 : 0.7287784674332525

EPOCH : 50 / 50
VAL_LOSS : 0.3309218335264134 
VAL_ACCURACY : 0.8464285714285714
VAL_F1 : 0.7318087313323163

# 5話-0
# 文: 夏目漱石だよ〜 Aくんはどんな本を読むの?
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.2440,  0.5457]], device='cuda:0')
# 5話-0
# 文: Bさん、苦手そうだよな…
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
tensor([[-0.0481, -0.4440]], device='cuda:0')
# 5話-0
# 文: そうなんだ〜
正解 : 1 , 予測 : 0 / 元クラス : 憤怒
tensor([[ 0.2229, -0.2012]], device='cuda:0')
# 5話-1
# 文: これ読んだよ
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 1.0557, -0.9497]], device='cuda:0')
# 5話-1
# 文: ありがとうございます… それ、何読んでるんですか?
正解 : 1 , 予測 : 0 / 元クラス : 恐怖
tensor([[ 0.2025, -0.5096]], device='cuda:0')
# 5話-1
# 文: 夏目漱石だよ〜 Aくんはどんな本を読むの?
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.2440,  0.5457]], device='cuda:0')
# 5話-1
# 文: そうなんだ〜
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[ 0.2229, -0.2012]], device='cuda:0')
# 5話-1
# 文: 本当に今ハマってる本はこの二冊…
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 0.5315, -0.4233]], device='cuda:0')
# 6話-0
# 文: 今日は弁当なんですね
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[-0.0809, -0.2890]], device='cuda:0')
# 6話-0
# 文: ほとんど冷凍食品詰めただけだよ
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 0.4447, -0.4406]], device='cuda:0')
# 6話-0
# 文: キャー!
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[ 0.0851, -0.0409]], device='cuda:0')
# 6話-1
# 文: キャー!
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[ 0.0851, -0.0409]], device='cuda:0')
# 6話-1
# 文: 弁当なの珍しいですね
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
tensor([[0.2988, 0.0654]], device='cuda:0')
# 6話-1
# 文: ほとんど冷凍食品詰めただけよ…
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
tensor([[ 0.1887, -0.3764]], device='cuda:0')
# 6話-1
# 文: ありがとう…
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
tensor([[ 0.7976, -0.5467]], device='cuda:0')
# 7話-0
# 文: どれがいいですか?
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.1720,  0.0433]], device='cuda:0')
# 7話-0
# 文: 別に気にしませんが…
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[-0.0868, -0.2828]], device='cuda:0')
# 7話-0
# 文: はんぶんこしよっか
正解 : 1 , 予測 : 0 / 元クラス : UNK
tensor([[ 0.7371, -0.4594]], device='cuda:0')
# 7話-0
# 文: とか言い出すのかな…
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[-0.0922, -0.2810]], device='cuda:0')
# 7話-0
# 文: ジャーン!パフェを作ってみました〜!
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.0496,  0.1735]], device='cuda:0')
# 7話-0
# 文: 器用だ!?
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[ 0.0075, -0.1536]], device='cuda:0')
# 7話-1
# 文: ジャーン!パフェを作ってみました〜!
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.0496,  0.1735]], device='cuda:0')
# 7話-1
# 文: 器用だ!?
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[ 0.0075, -0.1536]], device='cuda:0')
# 7話-1
# 文: てっきり
正解 : 1 , 予測 : 0 / 元クラス : UNK
tensor([[0.3254, 0.1652]], device='cuda:0')
# 7話-1
# 文: チョコ一つしかないねはんぶんこしよっか
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 0.2374, -0.0365]], device='cuda:0')
# 7話-1
# 文: とか言い出すのかと思った…
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[-0.0840, -0.2823]], device='cuda:0')
# 8話-0
# 文: 今日は良い実験結果が出たな
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.5008,  0.4922]], device='cuda:0')
# 9話-0
# 文: 無視!?
正解 : 1 , 予測 : 0 / 元クラス : UNK
tensor([[ 0.0839, -0.2108]], device='cuda:0')
# 9話-0
# 文: ここはよその研究室…!?
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[-0.0856, -0.2838]], device='cuda:0')
# 9話-1
# 文: Bさ…
正解 : 1 , 予測 : 0 / 元クラス : UNK
tensor([[ 0.1712, -0.3033]], device='cuda:0')
# 9話-1
# 文: ここは よその研究室…!?
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[ 0.5522, -0.6302]], device='cuda:0')
# 9話-1
# 文: 恥ずかしい…
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
tensor([[0.0293, 0.0024]], device='cuda:0')
------------------------test acc------------------------
Test Acc : 0.5616
correct: 41, total: 73
------------------------------------------------
                  喜楽        その他  accuracy  macro avg  weighted avg
precision   0.235294   0.846154  0.561644   0.540724      0.729003
recall      0.571429   0.559322  0.561644   0.565375      0.561644
f1-score    0.333333   0.673469  0.561644   0.503401      0.608238
support    14.000000  59.000000  0.561644  73.000000     73.000000
正例のF1値 : 0.33333333290625
