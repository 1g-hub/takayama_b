class weight : tensor([0.7724, 0.1474])
best:lr 3.543616207349373e-07
EPOCH : 1 / 50
VAL_LOSS : 0.6937793825681393 
VAL_ACCURACY : 0.3961352657004831
VAL_F1 : 0.34210526278597303

EPOCH : 2 / 50
VAL_LOSS : 0.6875951141119003 
VAL_ACCURACY : 0.3973429951690821
VAL_F1 : 0.3494132981961995

EPOCH : 3 / 50
VAL_LOSS : 0.6824881331278727 
VAL_ACCURACY : 0.3973429951690821
VAL_F1 : 0.3527885858832753

EPOCH : 4 / 50
VAL_LOSS : 0.6807524699431199 
VAL_ACCURACY : 0.3973429951690821
VAL_F1 : 0.35446313029206616

EPOCH : 5 / 50
VAL_LOSS : 0.6700295599607321 
VAL_ACCURACY : 0.3973429951690821
VAL_F1 : 0.3561290318910069

EPOCH : 6 / 50
VAL_LOSS : 0.6728245570109441 
VAL_ACCURACY : 0.39371980676328505
VAL_F1 : 0.3564102560448093

EPOCH : 7 / 50
VAL_LOSS : 0.6701097855201135 
VAL_ACCURACY : 0.392512077294686
VAL_F1 : 0.3559539048845549

EPOCH : 8 / 50
VAL_LOSS : 0.6694578843621107 
VAL_ACCURACY : 0.38768115942028986
VAL_F1 : 0.3541401270246939

EPOCH : 9 / 50
VAL_LOSS : 0.6642826388661678 
VAL_ACCURACY : 0.3864734299516908
VAL_F1 : 0.35696202495419643

EPOCH : 10 / 50
VAL_LOSS : 0.660527283182511 
VAL_ACCURACY : 0.3864734299516908
VAL_F1 : 0.3602015109740085

EPOCH : 11 / 50
VAL_LOSS : 0.6579219389420289 
VAL_ACCURACY : 0.39009661835748793
VAL_F1 : 0.3647798738531356

EPOCH : 12 / 50
VAL_LOSS : 0.6536051848760018 
VAL_ACCURACY : 0.38768115942028986
VAL_F1 : 0.36386449148434613

EPOCH : 13 / 50
VAL_LOSS : 0.6534656790586618 
VAL_ACCURACY : 0.38768115942028986
VAL_F1 : 0.36386449148434613

EPOCH : 14 / 50
VAL_LOSS : 0.6476078188190093 
VAL_ACCURACY : 0.3888888888888889
VAL_F1 : 0.36591478660765636

EPOCH : 15 / 50
VAL_LOSS : 0.65591422525736 
VAL_ACCURACY : 0.38768115942028986
VAL_F1 : 0.36545682066683477

EPOCH : 16 / 50
VAL_LOSS : 0.647158607840538 
VAL_ACCURACY : 0.3888888888888889
VAL_F1 : 0.36591478660765636

EPOCH : 17 / 50
VAL_LOSS : 0.6405502603604243 
VAL_ACCURACY : 0.391304347826087
VAL_F1 : 0.36683417049387956

EPOCH : 18 / 50
VAL_LOSS : 0.6364585768717986 
VAL_ACCURACY : 0.391304347826087
VAL_F1 : 0.36683417049387956

EPOCH : 19 / 50
VAL_LOSS : 0.6383814616845205 
VAL_ACCURACY : 0.392512077294686
VAL_F1 : 0.3688833120614979

EPOCH : 20 / 50
VAL_LOSS : 0.6323271382313508 
VAL_ACCURACY : 0.39492753623188404
VAL_F1 : 0.3729662074002328

EPOCH : 21 / 50
VAL_LOSS : 0.6302416725800588 
VAL_ACCURACY : 0.39492753623188404
VAL_F1 : 0.3729662074002328

EPOCH : 22 / 50
VAL_LOSS : 0.6266744698469455 
VAL_ACCURACY : 0.39855072463768115
VAL_F1 : 0.3790523687187611

EPOCH : 23 / 50
VAL_LOSS : 0.6252469363120886 
VAL_ACCURACY : 0.39855072463768115
VAL_F1 : 0.3790523687187611

EPOCH : 24 / 50
VAL_LOSS : 0.6212482108519628 
VAL_ACCURACY : 0.40217391304347827
VAL_F1 : 0.38202247155124763

EPOCH : 25 / 50
VAL_LOSS : 0.6235855542696439 
VAL_ACCURACY : 0.4082125603864734
VAL_F1 : 0.38596491192088933

EPOCH : 26 / 50
VAL_LOSS : 0.6216581750374574 
VAL_ACCURACY : 0.41183574879227053
VAL_F1 : 0.39352428357697244

EPOCH : 27 / 50
VAL_LOSS : 0.6188034019791163 
VAL_ACCURACY : 0.41545893719806765
VAL_F1 : 0.39950372172701326

EPOCH : 28 / 50
VAL_LOSS : 0.6179485980134743 
VAL_ACCURACY : 0.4178743961352657
VAL_F1 : 0.40198511130517084

EPOCH : 29 / 50
VAL_LOSS : 0.6149928925129083 
VAL_ACCURACY : 0.4190821256038647
VAL_F1 : 0.402484471692018

EPOCH : 30 / 50
VAL_LOSS : 0.6116658059450296 
VAL_ACCURACY : 0.4227053140096618
VAL_F1 : 0.40547263645793113

EPOCH : 31 / 50
VAL_LOSS : 0.6107437352721508 
VAL_ACCURACY : 0.42632850241545894
VAL_F1 : 0.4069912605649181

EPOCH : 32 / 50
VAL_LOSS : 0.6092173915642959 
VAL_ACCURACY : 0.42995169082125606
VAL_F1 : 0.4099999996407532

EPOCH : 33 / 50
VAL_LOSS : 0.6044613690330431 
VAL_ACCURACY : 0.4323671497584541
VAL_F1 : 0.41102756856243045

EPOCH : 34 / 50
VAL_LOSS : 0.6045049406014956 
VAL_ACCURACY : 0.4359903381642512
VAL_F1 : 0.4125786159913801

EPOCH : 35 / 50
VAL_LOSS : 0.5979427775511374 
VAL_ACCURACY : 0.44082125603864736
VAL_F1 : 0.41318124171586185

EPOCH : 36 / 50
VAL_LOSS : 0.6006015212490008 
VAL_ACCURACY : 0.4444444444444444
VAL_F1 : 0.416243654459291

EPOCH : 37 / 50
VAL_LOSS : 0.5924310472149116 
VAL_ACCURACY : 0.44565217391304346
VAL_F1 : 0.4182509502076107

EPOCH : 38 / 50
VAL_LOSS : 0.5914723059305778 
VAL_ACCURACY : 0.45169082125603865
VAL_F1 : 0.42091836698260826

EPOCH : 39 / 50
VAL_LOSS : 0.5927924485160754 
VAL_ACCURACY : 0.4528985507246377
VAL_F1 : 0.42145593833266626

EPOCH : 40 / 50
VAL_LOSS : 0.5919859592731183 
VAL_ACCURACY : 0.4577294685990338
VAL_F1 : 0.423620025308

EPOCH : 41 / 50
VAL_LOSS : 0.5891225160314486 
VAL_ACCURACY : 0.4601449275362319
VAL_F1 : 0.42471042434383643

EPOCH : 42 / 50
VAL_LOSS : 0.5854864630561608 
VAL_ACCURACY : 0.46256038647342995
VAL_F1 : 0.4258064512456658

EPOCH : 43 / 50
VAL_LOSS : 0.5769474810132613 
VAL_ACCURACY : 0.46497584541062803
VAL_F1 : 0.42690814969679464

EPOCH : 44 / 50
VAL_LOSS : 0.5765468369309719 
VAL_ACCURACY : 0.47342995169082125
VAL_F1 : 0.4308093991076256

EPOCH : 45 / 50
VAL_LOSS : 0.577679496545058 
VAL_ACCURACY : 0.4758454106280193
VAL_F1 : 0.4334203651650601

EPOCH : 46 / 50
VAL_LOSS : 0.5720605999231339 
VAL_ACCURACY : 0.47705314009661837
VAL_F1 : 0.43398692773405795

EPOCH : 47 / 50
VAL_LOSS : 0.5720456832876573 
VAL_ACCURACY : 0.48188405797101447
VAL_F1 : 0.4362680679593039

EPOCH : 48 / 50
VAL_LOSS : 0.5749507208283131 
VAL_ACCURACY : 0.48792270531400966
VAL_F1 : 0.43915343877993696

EPOCH : 49 / 50
VAL_LOSS : 0.5684128638643485 
VAL_ACCURACY : 0.49516908212560384
VAL_F1 : 0.44414893579536485

EPOCH : 50 / 50
VAL_LOSS : 0.5667384966061666 
VAL_ACCURACY : 0.5
VAL_F1 : 0.4465240637949291

# 5話-0
# 文: 何読んでるんですか?
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 0.1137, -0.2166]], device='cuda:0')
# 5話-0
# 文: 僕ですか?
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 0.2008, -0.1215]], device='cuda:0')
# 5話-0
# 文: 今ハマってる本はこの二冊…
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[-0.0363, -0.7669]], device='cuda:0')
# 5話-0
# 文: 少々マニアックだろうか…
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[-0.0273, -0.1689]], device='cuda:0')
# 5話-0
# 文: 適当に流そう
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[-0.0249, -0.2073]], device='cuda:0')
# 5話-0
# 文: 小説はあまり読まないのですが、研究で利用している青空文庫の作品なら少々
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[-0.2361, -0.4009]], device='cuda:0')
# 5話-0
# 文: 適当に流したな
正解 : 1 , 予測 : 0 / 元クラス : 憤怒
tensor([[ 0.1320, -0.1214]], device='cuda:0')
# 5話-0
# 文: あと、これも読んだよ
正解 : 1 , 予測 : 0 / 元クラス : 憤怒
tensor([[ 0.2095, -0.9356]], device='cuda:0')
# 5話-1
# 文: これ読んだよ
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[-0.1003, -0.7157]], device='cuda:0')
# 5話-1
# 文: ありがとうございます…それ何読んでるんですか?
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
tensor([[ 0.1528, -0.3772]], device='cuda:0')
# 5話-1
# 文: オススメの本教えて
正解 : 1 , 予測 : 0 / 元クラス : UNK
tensor([[ 0.0618, -0.2018]], device='cuda:0')
# 5話-1
# 文: 僕ですか?
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 0.2008, -0.1215]], device='cuda:0')
# 5話-1
# 文: そうなんだ〜
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 0.0543, -0.3616]], device='cuda:0')
# 6話-0
# 文: そうなんだ〜 父の分と2つ作ったの
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[-0.1549, -0.8021]], device='cuda:0')
# 6話-0
# 文: 手作りなんですか?
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 0.2372, -0.1671]], device='cuda:0')
# 6話-0
# 文: ほとんど冷凍食品詰めただけだよ
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 0.2473, -0.1629]], device='cuda:0')
# 6話-0
# 文: 見てもいいですか?
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[-0.1843, -0.4586]], device='cuda:0')
# 6話-0
# 文: どうぞどうぞ
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 0.1509, -0.4224]], device='cuda:0')
# 6話-0
# 文: キャー!
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[ 0.0844, -0.3639]], device='cuda:0')
# 6話-0
# 文: ベタだなあ
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
tensor([[ 0.1295, -0.2646]], device='cuda:0')
# 6話-1
# 文: キャー!
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[ 0.0844, -0.3639]], device='cuda:0')
# 6話-1
# 文: ベタだなあ
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
tensor([[ 0.1295, -0.2646]], device='cuda:0')
# 6話-1
# 文: 今日弁当なの珍しいですね
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[-0.0528, -0.1039]], device='cuda:0')
# 6話-1
# 文: ええ…父の分と2つ作ったんだけど
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
tensor([[ 0.1729, -0.3819]], device='cuda:0')
# 6話-1
# 文: 入れ替わってしまったみたい…
正解 : 1 , 予測 : 0 / 元クラス : UNK
tensor([[ 0.0322, -0.2243]], device='cuda:0')
# 6話-1
# 文: 手作りなんですか?
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 0.2372, -0.1671]], device='cuda:0')
# 6話-1
# 文: ほとんど冷凍食品詰めただけよ…
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
tensor([[ 0.0639, -0.2948]], device='cuda:0')
# 7話-0
# 文: どれがいいですか?
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 0.3431, -0.0213]], device='cuda:0')
# 7話-0
# 文: チョコは一つしかないし、悪いよ〜
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 0.1202, -0.6351]], device='cuda:0')
# 7話-0
# 文: はんぶんこしよっか
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[-0.0782, -0.3837]], device='cuda:0')
# 7話-1
# 文: 差し入れでもらったこの大量のアイスも
正解 : 1 , 予測 : 0 / 元クラス : UNK
tensor([[ 0.3607, -0.5836]], device='cuda:0')
# 7話-1
# 文: てっきり…
正解 : 1 , 予測 : 0 / 元クラス : UNK
tensor([[ 0.0738, -0.3300]], device='cuda:0')
# 7話-1
# 文: チョコ一つしかないね はんぶんこしよっか
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[-2.7053e-04, -4.5500e-01]], device='cuda:0')
# 7話-1
# 文: Aくんがいなければ独り占めできたのにな…
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
tensor([[ 0.1143, -0.4547]], device='cuda:0')
# 8話-0
# 文: ここは日本。何も見ていない
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 0.1047, -0.3256]], device='cuda:0')
# 8話-1
# 文: ここは日本。何も見ていない
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 0.1047, -0.3256]], device='cuda:0')
# 8話-1
# 文: でもわざわざ国際会議から送ってくれたんだよな…
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
tensor([[ 0.1468, -0.5536]], device='cuda:0')
# 8話-1
# 文: もう少し頑張るか
正解 : 1 , 予測 : 0 / 元クラス : UNK
tensor([[ 0.2678, -0.2013]], device='cuda:0')
# 9話-0
# 文: あれ?スペインからもう戻ってきたのか。
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 0.1300, -0.0377]], device='cuda:0')
# 9話-0
# 文: ハッ
正解 : 1 , 予測 : 0 / 元クラス : UNK
tensor([[-0.0252, -0.3416]], device='cuda:0')
# 9話-0
# 文: 人違い!?
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[ 0.0395, -0.0784]], device='cuda:0')
# 9話-0
# 文: ？
正解 : 1 , 予測 : 0 / 元クラス : UNK
tensor([[0.2508, 0.0094]], device='cuda:0')
# 9話-1
# 文: ？
正解 : 1 , 予測 : 0 / 元クラス : UNK
tensor([[0.2508, 0.0094]], device='cuda:0')
# 9話-1
# 文: 恥ずかしい…
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
tensor([[ 0.0251, -0.2408]], device='cuda:0')
# 9話-1
# 文: ？
正解 : 1 , 予測 : 0 / 元クラス : UNK
tensor([[0.2508, 0.0094]], device='cuda:0')
------------------------test acc------------------------
Test Acc : 0.3836
correct: 28, total: 73
------------------------------------------------
                  喜楽        その他  accuracy  macro avg  weighted avg
precision   0.210526   1.000000  0.383562   0.605263      0.870224
recall      1.000000   0.262295  0.383562   0.631148      0.383562
f1-score    0.347826   0.415584  0.383562   0.381705      0.404446
support    12.000000  61.000000  0.383562  73.000000     73.000000
正例のF1値 : 0.34782608665910525
class weight : tensor([0.7724, 0.1474])
best:lr 1.4967973627020435e-06
EPOCH : 1 / 50
VAL_LOSS : 0.6934203723302255 
VAL_ACCURACY : 0.5374396135265701
VAL_F1 : 0.3772357719332778

EPOCH : 2 / 50
VAL_LOSS : 0.6800106362654612 
VAL_ACCURACY : 0.5217391304347826
VAL_F1 : 0.3981762913852468

EPOCH : 3 / 50
VAL_LOSS : 0.6647608681366994 
VAL_ACCURACY : 0.4975845410628019
VAL_F1 : 0.39710144887908005

EPOCH : 4 / 50
VAL_LOSS : 0.6491997173199286 
VAL_ACCURACY : 0.46618357487922707
VAL_F1 : 0.3911845726192162

EPOCH : 5 / 50
VAL_LOSS : 0.6392096945872674 
VAL_ACCURACY : 0.46980676328502413
VAL_F1 : 0.40915208575950324

EPOCH : 6 / 50
VAL_LOSS : 0.6294133353691834 
VAL_ACCURACY : 0.46497584541062803
VAL_F1 : 0.4283870964069494

EPOCH : 7 / 50
VAL_LOSS : 0.6176830507241763 
VAL_ACCURACY : 0.46980676328502413
VAL_F1 : 0.44076433084612937

EPOCH : 8 / 50
VAL_LOSS : 0.6071846124071342 
VAL_ACCURACY : 0.48429951690821255
VAL_F1 : 0.4546615577450974

EPOCH : 9 / 50
VAL_LOSS : 0.6024843093294364 
VAL_ACCURACY : 0.49033816425120774
VAL_F1 : 0.4575835471914903

EPOCH : 10 / 50
VAL_LOSS : 0.587690899005303 
VAL_ACCURACY : 0.5024154589371981
VAL_F1 : 0.46354166629705473

EPOCH : 11 / 50
VAL_LOSS : 0.5804214190978271 
VAL_ACCURACY : 0.5096618357487923
VAL_F1 : 0.4699738899691422

EPOCH : 12 / 50
VAL_LOSS : 0.5749917144958789 
VAL_ACCURACY : 0.5205314009661836
VAL_F1 : 0.47831800225617105

EPOCH : 13 / 50
VAL_LOSS : 0.5633251781647022 
VAL_ACCURACY : 0.5398550724637681
VAL_F1 : 0.48859060364952933

EPOCH : 14 / 50
VAL_LOSS : 0.5607834458351135 
VAL_ACCURACY : 0.5531400966183575
VAL_F1 : 0.4959128061584354

EPOCH : 15 / 50
VAL_LOSS : 0.5463069952451266 
VAL_ACCURACY : 0.5748792270531401
VAL_F1 : 0.508379887880813

EPOCH : 16 / 50
VAL_LOSS : 0.5442946536036638 
VAL_ACCURACY : 0.5857487922705314
VAL_F1 : 0.5148514847579809

EPOCH : 17 / 50
VAL_LOSS : 0.5344803018065599 
VAL_ACCURACY : 0.5966183574879227
VAL_F1 : 0.5214899709529438

EPOCH : 18 / 50
VAL_LOSS : 0.5337756895101987 
VAL_ACCURACY : 0.6123188405797102
VAL_F1 : 0.5300146408892213

EPOCH : 19 / 50
VAL_LOSS : 0.5224262424386464 
VAL_ACCURACY : 0.6292270531400966
VAL_F1 : 0.5397301345273989

EPOCH : 20 / 50
VAL_LOSS : 0.5163172294314091 
VAL_ACCURACY : 0.6570048309178744
VAL_F1 : 0.5590062107662754

EPOCH : 21 / 50
VAL_LOSS : 0.511227446106764 
VAL_ACCURACY : 0.6751207729468599
VAL_F1 : 0.5723370425056351

EPOCH : 22 / 50
VAL_LOSS : 0.5047940141879595 
VAL_ACCURACY : 0.6944444444444444
VAL_F1 : 0.5872756928856717

EPOCH : 23 / 50
VAL_LOSS : 0.4975882344521009 
VAL_ACCURACY : 0.716183574879227
VAL_F1 : 0.6050420163736685

EPOCH : 24 / 50
VAL_LOSS : 0.48978826862115127 
VAL_ACCURACY : 0.7391304347826086
VAL_F1 : 0.6236933793494701

EPOCH : 25 / 50
VAL_LOSS : 0.48365631756874233 
VAL_ACCURACY : 0.7548309178743962
VAL_F1 : 0.6381461671112129

EPOCH : 26 / 50
VAL_LOSS : 0.4757475159489192 
VAL_ACCURACY : 0.7693236714975845
VAL_F1 : 0.652094717216917

EPOCH : 27 / 50
VAL_LOSS : 0.47358361173134583 
VAL_ACCURACY : 0.7765700483091788
VAL_F1 : 0.6593001837080675

EPOCH : 28 / 50
VAL_LOSS : 0.4649485492935547 
VAL_ACCURACY : 0.7922705314009661
VAL_F1 : 0.6754716976539765

EPOCH : 29 / 50
VAL_LOSS : 0.45217912873396504 
VAL_ACCURACY : 0.7910628019323671
VAL_F1 : 0.6741996228933363

EPOCH : 30 / 50
VAL_LOSS : 0.4540890117104237 
VAL_ACCURACY : 0.7995169082125604
VAL_F1 : 0.6832061064085936

EPOCH : 31 / 50
VAL_LOSS : 0.4466908803352943 
VAL_ACCURACY : 0.8164251207729468
VAL_F1 : 0.7019607838465284

EPOCH : 32 / 50
VAL_LOSS : 0.4406236971800144 
VAL_ACCURACY : 0.8176328502415459
VAL_F1 : 0.7033398816542163

EPOCH : 33 / 50
VAL_LOSS : 0.43602366229662526 
VAL_ACCURACY : 0.8272946859903382
VAL_F1 : 0.71457085781271

EPOCH : 34 / 50
VAL_LOSS : 0.43047261524658936 
VAL_ACCURACY : 0.8357487922705314
VAL_F1 : 0.7246963558018735

EPOCH : 35 / 50
VAL_LOSS : 0.42701522891338056 
VAL_ACCURACY : 0.8369565217391305
VAL_F1 : 0.7250509160223825

EPOCH : 36 / 50
VAL_LOSS : 0.4200450941347159 
VAL_ACCURACY : 0.8429951690821256
VAL_F1 : 0.7314049582004902

EPOCH : 37 / 50
VAL_LOSS : 0.41690077689977795 
VAL_ACCURACY : 0.8502415458937198
VAL_F1 : 0.7405857735791478

EPOCH : 38 / 50
VAL_LOSS : 0.41221397656660813 
VAL_ACCURACY : 0.8526570048309179
VAL_F1 : 0.7436974785114311

EPOCH : 39 / 50
VAL_LOSS : 0.40348333521531177 
VAL_ACCURACY : 0.8538647342995169
VAL_F1 : 0.745263157414205

EPOCH : 40 / 50
VAL_LOSS : 0.40161840044535124 
VAL_ACCURACY : 0.856280193236715
VAL_F1 : 0.7484143758400923

EPOCH : 41 / 50
VAL_LOSS : 0.393313239973325 
VAL_ACCURACY : 0.857487922705314
VAL_F1 : 0.7499999995183766

EPOCH : 42 / 50
VAL_LOSS : 0.39224241559322065 
VAL_ACCURACY : 0.8623188405797102
VAL_F1 : 0.7564102559271954

EPOCH : 43 / 50
VAL_LOSS : 0.39071601915817994 
VAL_ACCURACY : 0.8635265700483091
VAL_F1 : 0.7580299781033064

EPOCH : 44 / 50
VAL_LOSS : 0.38212983539471257 
VAL_ACCURACY : 0.8647342995169082
VAL_F1 : 0.759656651876743

EPOCH : 45 / 50
VAL_LOSS : 0.3804693545859594 
VAL_ACCURACY : 0.8671497584541062
VAL_F1 : 0.7619047614196043

EPOCH : 46 / 50
VAL_LOSS : 0.3743493717450362 
VAL_ACCURACY : 0.8707729468599034
VAL_F1 : 0.7668845311042192

EPOCH : 47 / 50
VAL_LOSS : 0.372708481664841 
VAL_ACCURACY : 0.8731884057971014
VAL_F1 : 0.7712418295791458

EPOCH : 48 / 50
VAL_LOSS : 0.37298053245131785 
VAL_ACCURACY : 0.8743961352657005
VAL_F1 : 0.7729257637055834

EPOCH : 49 / 50
VAL_LOSS : 0.3630041474333176 
VAL_ACCURACY : 0.8780193236714976
VAL_F1 : 0.7780219775344042

EPOCH : 50 / 50
VAL_LOSS : 0.3606656107764978 
VAL_ACCURACY : 0.8792270531400966
VAL_F1 : 0.7787610614583463

# 5話-0
# 文: 夏目漱石だよ〜 Aくんはどんな本を読むの
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.2201,  0.0794]], device='cuda:0')
# 5話-0
# 文: あと、これも読んだよ
正解 : 1 , 予測 : 0 / 元クラス : 憤怒
tensor([[ 0.2051, -0.5170]], device='cuda:0')
# 5話-1
# 文: これ読んだよ
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 0.2289, -0.4347]], device='cuda:0')
# 5話-1
# 文: 夏目漱石だよ〜 Aくんはどんな本を読むの
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.2201,  0.0794]], device='cuda:0')
# 5話-1
# 文: オススメの本教えて
正解 : 1 , 予測 : 0 / 元クラス : UNK
tensor([[-0.0608, -0.0913]], device='cuda:0')
# 5話-1
# 文: そうなんだ〜
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[-0.1133, -0.7569]], device='cuda:0')
# 6話-0
# 文: そうなんだ〜 父の分と2つ作ったの
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 0.3063, -0.0245]], device='cuda:0')
# 6話-0
# 文: ほとんど冷凍食品詰めただけだよ
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 0.0960, -0.4850]], device='cuda:0')
# 6話-0
# 文: どうぞどうぞ
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[-0.2316, -0.4134]], device='cuda:0')
# 6話-0
# 文: キャー!
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[ 0.2016, -0.5075]], device='cuda:0')
# 6話-1
# 文: キャー!
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[ 0.2016, -0.5075]], device='cuda:0')
# 6話-1
# 文: ええ…父の分と2つ作ったんだけど
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
tensor([[ 0.0077, -0.4116]], device='cuda:0')
# 6話-1
# 文: 入れ替わってしまったみたい…
正解 : 1 , 予測 : 0 / 元クラス : UNK
tensor([[ 0.1394, -0.4961]], device='cuda:0')
# 6話-1
# 文: ほとんど冷凍食品詰めただけよ…
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
tensor([[-0.1605, -0.1675]], device='cuda:0')
# 6話-1
# 文: 俺も今日弁当なんでおかず分けますよ
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.2776,  0.1632]], device='cuda:0')
# 7話-0
# 文: はんぶんこしよっか
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 0.0956, -0.2318]], device='cuda:0')
# 7話-0
# 文: ジャーン!パフェを作ってみました〜!
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.0969,  0.3397]], device='cuda:0')
# 7話-1
# 文: ジャーン!パフェを作ってみました〜!
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.0969,  0.3397]], device='cuda:0')
# 7話-1
# 文: こうやっていろんな食べ方をすれば飽きないですね
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.4292, -0.0119]], device='cuda:0')
# 7話-1
# 文: 差し入れでもらったこの大量のアイスも
正解 : 1 , 予測 : 0 / 元クラス : UNK
tensor([[ 0.3624, -0.5355]], device='cuda:0')
# 7話-1
# 文: チョコ一つしかないね はんぶんこしよっか
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 0.0743, -0.5990]], device='cuda:0')
# 7話-1
# 文: Aくんがいなければ独り占めできたのにな…
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
tensor([[ 0.1241, -0.2857]], device='cuda:0')
# 8話-0
# 文: 今日は良い実験結果が出たな
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.4717,  0.2609]], device='cuda:0')
# 8話-1
# 文: でもわざわざ国際会議から送ってくれたんだよな…
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
tensor([[ 0.1241, -0.7133]], device='cuda:0')
# 9話-0
# 文: あれ?スペインからもう戻ってきたのか。
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[-0.0463, -0.2517]], device='cuda:0')
# 9話-0
# 文: ハッ
正解 : 1 , 予測 : 0 / 元クラス : UNK
tensor([[ 0.0277, -0.1603]], device='cuda:0')
# 9話-1
# 文: ただいま〜
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.2633,  0.0749]], device='cuda:0')
# 9話-1
# 文: おかえりなさい!
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.1448, -0.1033]], device='cuda:0')
------------------------test acc------------------------
Test Acc : 0.6164
correct: 45, total: 73
------------------------------------------------
                  喜楽        その他  accuracy  macro avg  weighted avg
precision   0.136364   0.823529  0.616438   0.479947      0.710571
recall      0.250000   0.688525  0.616438   0.469262      0.616438
f1-score    0.176471   0.750000  0.616438   0.463235      0.655721
support    12.000000  61.000000  0.616438  73.000000     73.000000
正例のF1値 : 0.17647058776816607
class weight : tensor([0.7724, 0.1474])
best:lr 3.219763881681676e-06
EPOCH : 1 / 50
VAL_LOSS : 0.6591637971309515 
VAL_ACCURACY : 0.39492753623188404
VAL_F1 : 0.4042806179647466

EPOCH : 2 / 50
VAL_LOSS : 0.6395406780334619 
VAL_ACCURACY : 0.41304347826086957
VAL_F1 : 0.4214285710814484

EPOCH : 3 / 50
VAL_LOSS : 0.6144965061774621 
VAL_ACCURACY : 0.44323671497584544
VAL_F1 : 0.4357405137218262

EPOCH : 4 / 50
VAL_LOSS : 0.5940425533514756 
VAL_ACCURACY : 0.46618357487922707
VAL_F1 : 0.4461152878605882

EPOCH : 5 / 50
VAL_LOSS : 0.5772898827607815 
VAL_ACCURACY : 0.5036231884057971
VAL_F1 : 0.46414602309811676

EPOCH : 6 / 50
VAL_LOSS : 0.561739159318117 
VAL_ACCURACY : 0.5483091787439613
VAL_F1 : 0.48626373588062655

EPOCH : 7 / 50
VAL_LOSS : 0.5491398641696343 
VAL_ACCURACY : 0.6002415458937198
VAL_F1 : 0.5181950505484217

EPOCH : 8 / 50
VAL_LOSS : 0.5278878492804674 
VAL_ACCURACY : 0.644927536231884
VAL_F1 : 0.5504587151862965

EPOCH : 9 / 50
VAL_LOSS : 0.5127461208746984 
VAL_ACCURACY : 0.6884057971014492
VAL_F1 : 0.5825242714207173

EPOCH : 10 / 50
VAL_LOSS : 0.49632388009474826 
VAL_ACCURACY : 0.7222222222222222
VAL_F1 : 0.6101694910903707

EPOCH : 11 / 50
VAL_LOSS : 0.47981943304722124 
VAL_ACCURACY : 0.7681159420289855
VAL_F1 : 0.653429602438511

EPOCH : 12 / 50
VAL_LOSS : 0.4622619255230977 
VAL_ACCURACY : 0.7910628019323671
VAL_F1 : 0.676635513561443

EPOCH : 13 / 50
VAL_LOSS : 0.4567379246537502 
VAL_ACCURACY : 0.8031400966183575
VAL_F1 : 0.6907020868260498

EPOCH : 14 / 50
VAL_LOSS : 0.4382766502407881 
VAL_ACCURACY : 0.8297101449275363
VAL_F1 : 0.7218934906558204

EPOCH : 15 / 50
VAL_LOSS : 0.42799720340050185 
VAL_ACCURACY : 0.8526570048309179
VAL_F1 : 0.74897119293911

EPOCH : 16 / 50
VAL_LOSS : 0.4169917702674866 
VAL_ACCURACY : 0.8671497584541062
VAL_F1 : 0.7669491520606777

EPOCH : 17 / 50
VAL_LOSS : 0.4057225057711968 
VAL_ACCURACY : 0.8743961352657005
VAL_F1 : 0.7768240338509181

EPOCH : 18 / 50
VAL_LOSS : 0.39401922203027284 
VAL_ACCURACY : 0.8852657004830918
VAL_F1 : 0.7921225378062428

EPOCH : 19 / 50
VAL_LOSS : 0.3881249444989058 
VAL_ACCURACY : 0.8900966183574879
VAL_F1 : 0.7973273937197536

EPOCH : 20 / 50
VAL_LOSS : 0.37546508186138594 
VAL_ACCURACY : 0.8913043478260869
VAL_F1 : 0.7982062775363571

EPOCH : 21 / 50
VAL_LOSS : 0.367840931392633 
VAL_ACCURACY : 0.894927536231884
VAL_F1 : 0.8044943815315844

EPOCH : 22 / 50
VAL_LOSS : 0.3577541992641412 
VAL_ACCURACY : 0.8985507246376812
VAL_F1 : 0.8090909085984815

EPOCH : 23 / 50
VAL_LOSS : 0.34821648781116193 
VAL_ACCURACY : 0.8997584541062802
VAL_F1 : 0.8109339402817546

EPOCH : 24 / 50
VAL_LOSS : 0.33722855752477277 
VAL_ACCURACY : 0.9057971014492754
VAL_F1 : 0.8194444439496635

EPOCH : 25 / 50
VAL_LOSS : 0.33350441289635807 
VAL_ACCURACY : 0.9045893719806763
VAL_F1 : 0.8175519625540059

EPOCH : 26 / 50
VAL_LOSS : 0.3316408100609596 
VAL_ACCURACY : 0.9070048309178744
VAL_F1 : 0.8213457071615463

EPOCH : 27 / 50
VAL_LOSS : 0.32451502348367983 
VAL_ACCURACY : 0.9094202898550725
VAL_F1 : 0.8251748246791966

EPOCH : 28 / 50
VAL_LOSS : 0.31487181009008336 
VAL_ACCURACY : 0.9106280193236715
VAL_F1 : 0.8271028032424121

EPOCH : 29 / 50
VAL_LOSS : 0.3043286625582438 
VAL_ACCURACY : 0.9094202898550725
VAL_F1 : 0.8243559714007975

EPOCH : 30 / 50
VAL_LOSS : 0.297277649721274 
VAL_ACCURACY : 0.9118357487922706
VAL_F1 : 0.8282352936209495

EPOCH : 31 / 50
VAL_LOSS : 0.29416455127871954 
VAL_ACCURACY : 0.9130434782608695
VAL_F1 : 0.8301886787483201

EPOCH : 32 / 50
VAL_LOSS : 0.2856073838013869 
VAL_ACCURACY : 0.9142512077294686
VAL_F1 : 0.8321512997391814

EPOCH : 33 / 50
VAL_LOSS : 0.2843425890000967 
VAL_ACCURACY : 0.9154589371980676
VAL_F1 : 0.8349056598803734

EPOCH : 34 / 50
VAL_LOSS : 0.2754237703405894 
VAL_ACCURACY : 0.9178743961352657
VAL_F1 : 0.8388625587441993

EPOCH : 35 / 50
VAL_LOSS : 0.2695856916789825 
VAL_ACCURACY : 0.9190821256038647
VAL_F1 : 0.8408551063905981

EPOCH : 36 / 50
VAL_LOSS : 0.26584160327911377 
VAL_ACCURACY : 0.9227053140096618
VAL_F1 : 0.8468899516545981

EPOCH : 37 / 50
VAL_LOSS : 0.2624485604465008 
VAL_ACCURACY : 0.9251207729468599
VAL_F1 : 0.8509615379625439

EPOCH : 38 / 50
VAL_LOSS : 0.2585552458006602 
VAL_ACCURACY : 0.9251207729468599
VAL_F1 : 0.8509615379625439

EPOCH : 39 / 50
VAL_LOSS : 0.25113028517136204 
VAL_ACCURACY : 0.9263285024154589
VAL_F1 : 0.8523002416310819

EPOCH : 40 / 50
VAL_LOSS : 0.24577343922394973 
VAL_ACCURACY : 0.9299516908212561
VAL_F1 : 0.8592233004709563

EPOCH : 41 / 50
VAL_LOSS : 0.24022977598584616 
VAL_ACCURACY : 0.9299516908212561
VAL_F1 : 0.8599033811430256

EPOCH : 42 / 50
VAL_LOSS : 0.23995378627800024 
VAL_ACCURACY : 0.928743961352657
VAL_F1 : 0.857142856643165

EPOCH : 43 / 50
VAL_LOSS : 0.23075943339902621 
VAL_ACCURACY : 0.9299516908212561
VAL_F1 : 0.8592233004709563

EPOCH : 44 / 50
VAL_LOSS : 0.23835569004026744 
VAL_ACCURACY : 0.9311594202898551
VAL_F1 : 0.8619854716552481

EPOCH : 45 / 50
VAL_LOSS : 0.22847687309751144 
VAL_ACCURACY : 0.9311594202898551
VAL_F1 : 0.8619854716552481

EPOCH : 46 / 50
VAL_LOSS : 0.22620093449950218 
VAL_ACCURACY : 0.9323671497584541
VAL_F1 : 0.8640776694029717

EPOCH : 47 / 50
VAL_LOSS : 0.2210977407029042 
VAL_ACCURACY : 0.9347826086956522
VAL_F1 : 0.8682926824264486

EPOCH : 48 / 50
VAL_LOSS : 0.21908966924708623 
VAL_ACCURACY : 0.9347826086956522
VAL_F1 : 0.8682926824264486

EPOCH : 49 / 50
VAL_LOSS : 0.21489051930033243 
VAL_ACCURACY : 0.9347826086956522
VAL_F1 : 0.8682926824264486

EPOCH : 50 / 50
VAL_LOSS : 0.21128833938676578 
VAL_ACCURACY : 0.9371980676328503
VAL_F1 : 0.8725490191070383

# 5話-0
# 文: 夏目漱石だよ〜 Aくんはどんな本を読むの
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.8977,  0.1625]], device='cuda:0')
# 5話-0
# 文: 今ハマってる本はこの二冊…
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 0.1363, -0.0924]], device='cuda:0')
# 5話-0
# 文: あと、これも読んだよ
正解 : 1 , 予測 : 0 / 元クラス : 憤怒
tensor([[ 0.6581, -1.0326]], device='cuda:0')
# 5話-1
# 文: これ読んだよ
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 0.6601, -0.9841]], device='cuda:0')
# 5話-1
# 文: 夏目漱石だよ〜 Aくんはどんな本を読むの
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.8977,  0.1625]], device='cuda:0')
# 5話-1
# 文: オススメの本教えて
正解 : 1 , 予測 : 0 / 元クラス : UNK
tensor([[-0.1595, -0.2329]], device='cuda:0')
# 5話-1
# 文: そうなんだ〜
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 0.0217, -0.1645]], device='cuda:0')
# 6話-0
# 文: そうなんだ〜 父の分と2つ作ったの
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 0.1443, -0.3389]], device='cuda:0')
# 6話-0
# 文: 見てもいいですか?
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[-0.3089, -0.4208]], device='cuda:0')
# 6話-0
# 文: どうぞどうぞ
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[-0.1499, -0.7305]], device='cuda:0')
# 6話-0
# 文: キャー!
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[ 0.0119, -0.3435]], device='cuda:0')
# 6話-1
# 文: キャー!
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[ 0.0119, -0.3435]], device='cuda:0')
# 6話-1
# 文: 入れ替わってしまったみたい…
正解 : 1 , 予測 : 0 / 元クラス : UNK
tensor([[ 0.3084, -0.1766]], device='cuda:0')
# 6話-1
# 文: 俺も今日弁当なんでおかず分けますよ
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.9977,  0.2514]], device='cuda:0')
# 7話-0
# 文: はんぶんこしよっか
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 0.3560, -0.4183]], device='cuda:0')
# 7話-0
# 文: ジャーン!パフェを作ってみました〜!
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.8228,  0.4213]], device='cuda:0')
# 7話-1
# 文: ジャーン!パフェを作ってみました〜!
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.8228,  0.4213]], device='cuda:0')
# 7話-1
# 文: こうやっていろんな食べ方をすれば飽きないですね
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.4167,  0.1274]], device='cuda:0')
# 7話-1
# 文: 差し入れでもらったこの大量のアイスも
正解 : 1 , 予測 : 0 / 元クラス : UNK
tensor([[ 0.6446, -0.8859]], device='cuda:0')
# 7話-1
# 文: チョコ一つしかないね はんぶんこしよっか
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 0.6327, -0.3325]], device='cuda:0')
# 8話-0
# 文: 今日は良い実験結果が出たな
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.7152,  0.3158]], device='cuda:0')
# 8話-0
# 文: ここは日本。何も見ていない
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[-0.0354, -0.1217]], device='cuda:0')
# 8話-1
# 文: ここは日本。何も見ていない
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[-0.0354, -0.1217]], device='cuda:0')
# 8話-1
# 文: でもわざわざ国際会議から送ってくれたんだよな…
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
tensor([[ 0.3838, -0.6386]], device='cuda:0')
# 9話-1
# 文: ここは よその研究室…!?
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[0.0210, 0.0169]], device='cuda:0')
# 9話-1
# 文: ただいま〜
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.4628,  0.2436]], device='cuda:0')
# 9話-1
# 文: おかえりなさい!
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.1868,  0.0034]], device='cuda:0')
------------------------test acc------------------------
Test Acc : 0.6301
correct: 46, total: 73
------------------------------------------------
                  喜楽        その他  accuracy  macro avg  weighted avg
precision   0.142857   0.826923  0.630137   0.484890      0.714474
recall      0.250000   0.704918  0.630137   0.477459      0.630137
f1-score    0.181818   0.761062  0.630137   0.471440      0.665844
support    12.000000  61.000000  0.630137  73.000000     73.000000
正例のF1値 : 0.1818181813443526
