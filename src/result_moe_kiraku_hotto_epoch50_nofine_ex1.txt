class weight : tensor([0.6008, 0.3322])
best:lr 3.7185862497294014e-07
EPOCH : 1 / 50
VAL_LOSS : 0.6904159156339509 
VAL_ACCURACY : 0.49491525423728816
VAL_F1 : 0.49030786724834974

EPOCH : 2 / 50
VAL_LOSS : 0.6872771041733878 
VAL_ACCURACY : 0.503954802259887
VAL_F1 : 0.5017026101878348

EPOCH : 3 / 50
VAL_LOSS : 0.6840651599424226 
VAL_ACCURACY : 0.5129943502824859
VAL_F1 : 0.516273849127116

EPOCH : 4 / 50
VAL_LOSS : 0.6821638814040593 
VAL_ACCURACY : 0.5175141242937853
VAL_F1 : 0.5229050274536201

EPOCH : 5 / 50
VAL_LOSS : 0.6825900801590511 
VAL_ACCURACY : 0.5231638418079096
VAL_F1 : 0.5311111106326863

EPOCH : 6 / 50
VAL_LOSS : 0.6766616457274982 
VAL_ACCURACY : 0.5310734463276836
VAL_F1 : 0.5394006654484931

EPOCH : 7 / 50
VAL_LOSS : 0.6755335543836866 
VAL_ACCURACY : 0.5344632768361582
VAL_F1 : 0.5452538626573348

EPOCH : 8 / 50
VAL_LOSS : 0.6726113206573895 
VAL_ACCURACY : 0.5389830508474577
VAL_F1 : 0.5526315784711738

EPOCH : 9 / 50
VAL_LOSS : 0.670001357793808 
VAL_ACCURACY : 0.5525423728813559
VAL_F1 : 0.5704989149270002

EPOCH : 10 / 50
VAL_LOSS : 0.6666468626686505 
VAL_ACCURACY : 0.5559322033898305
VAL_F1 : 0.5742145174023752

EPOCH : 11 / 50
VAL_LOSS : 0.6647528250302587 
VAL_ACCURACY : 0.56045197740113
VAL_F1 : 0.5785482118769053

EPOCH : 12 / 50
VAL_LOSS : 0.6630205235310963 
VAL_ACCURACY : 0.5615819209039548
VAL_F1 : 0.5800865796126478

EPOCH : 13 / 50
VAL_LOSS : 0.6612094278846469 
VAL_ACCURACY : 0.5672316384180791
VAL_F1 : 0.5868392659775569

EPOCH : 14 / 50
VAL_LOSS : 0.6589675268956593 
VAL_ACCURACY : 0.5751412429378531
VAL_F1 : 0.5921908888965843

EPOCH : 15 / 50
VAL_LOSS : 0.6559374896543366 
VAL_ACCURACY : 0.5796610169491525
VAL_F1 : 0.5947712413549348

EPOCH : 16 / 50
VAL_LOSS : 0.6562923640012741 
VAL_ACCURACY : 0.5864406779661017
VAL_F1 : 0.6030368758813764

EPOCH : 17 / 50
VAL_LOSS : 0.6500108859368733 
VAL_ACCURACY : 0.592090395480226
VAL_F1 : 0.6080347443679851

EPOCH : 18 / 50
VAL_LOSS : 0.6506088035447257 
VAL_ACCURACY : 0.5966101694915255
VAL_F1 : 0.6132177676731465

EPOCH : 19 / 50
VAL_LOSS : 0.6464058884552547 
VAL_ACCURACY : 0.5988700564971752
VAL_F1 : 0.6162162157424013

EPOCH : 20 / 50
VAL_LOSS : 0.6466433693255697 
VAL_ACCURACY : 0.6022598870056497
VAL_F1 : 0.6198704098935435

EPOCH : 21 / 50
VAL_LOSS : 0.6424045456307275 
VAL_ACCURACY : 0.6045197740112994
VAL_F1 : 0.6220302371073615

EPOCH : 22 / 50
VAL_LOSS : 0.6389462713684354 
VAL_ACCURACY : 0.607909604519774
VAL_F1 : 0.6256742174337838

EPOCH : 23 / 50
VAL_LOSS : 0.6375353698219571 
VAL_ACCURACY : 0.607909604519774
VAL_F1 : 0.6256742174337838

EPOCH : 24 / 50
VAL_LOSS : 0.6369634228093284 
VAL_ACCURACY : 0.6101694915254238
VAL_F1 : 0.6270270265531886

EPOCH : 25 / 50
VAL_LOSS : 0.6332253803099904 
VAL_ACCURACY : 0.6146892655367232
VAL_F1 : 0.629750270969458

EPOCH : 26 / 50
VAL_LOSS : 0.6323115453124046 
VAL_ACCURACY : 0.6237288135593221
VAL_F1 : 0.6360655732946914

EPOCH : 27 / 50
VAL_LOSS : 0.6306001767516136 
VAL_ACCURACY : 0.6293785310734463
VAL_F1 : 0.6395604390836711

EPOCH : 28 / 50
VAL_LOSS : 0.6290688589215279 
VAL_ACCURACY : 0.6338983050847458
VAL_F1 : 0.6431718056902425

EPOCH : 29 / 50
VAL_LOSS : 0.6280540313039508 
VAL_ACCURACY : 0.6372881355932203
VAL_F1 : 0.6476399556156117

EPOCH : 30 / 50
VAL_LOSS : 0.6252110823988914 
VAL_ACCURACY : 0.63954802259887
VAL_F1 : 0.6490649060136686

EPOCH : 31 / 50
VAL_LOSS : 0.6238383086664336 
VAL_ACCURACY : 0.63954802259887
VAL_F1 : 0.6490649060136686

EPOCH : 32 / 50
VAL_LOSS : 0.6211836699928556 
VAL_ACCURACY : 0.6406779661016949
VAL_F1 : 0.6497797352056465

EPOCH : 33 / 50
VAL_LOSS : 0.6173275581427983 
VAL_ACCURACY : 0.6474576271186441
VAL_F1 : 0.6556291385952809

EPOCH : 34 / 50
VAL_LOSS : 0.6177247762680054 
VAL_ACCURACY : 0.6497175141242938
VAL_F1 : 0.6570796455397495

EPOCH : 35 / 50
VAL_LOSS : 0.6148772505777222 
VAL_ACCURACY : 0.6531073446327683
VAL_F1 : 0.660022147916096

EPOCH : 36 / 50
VAL_LOSS : 0.6139707948480334 
VAL_ACCURACY : 0.656497175141243
VAL_F1 : 0.663716813681328

EPOCH : 37 / 50
VAL_LOSS : 0.6098352287496839 
VAL_ACCURACY : 0.6587570621468927
VAL_F1 : 0.6651884695881731

EPOCH : 38 / 50
VAL_LOSS : 0.6079043032867568 
VAL_ACCURACY : 0.6621468926553672
VAL_F1 : 0.6674082308892714

EPOCH : 39 / 50
VAL_LOSS : 0.607219401214804 
VAL_ACCURACY : 0.6621468926553672
VAL_F1 : 0.6674082308892714

EPOCH : 40 / 50
VAL_LOSS : 0.6050176907862935 
VAL_ACCURACY : 0.6644067796610169
VAL_F1 : 0.6696329249938271

EPOCH : 41 / 50
VAL_LOSS : 0.6024137447987284 
VAL_ACCURACY : 0.6700564971751413
VAL_F1 : 0.6733780755827765

EPOCH : 42 / 50
VAL_LOSS : 0.6006889077169555 
VAL_ACCURACY : 0.6700564971751413
VAL_F1 : 0.6733780755827765

EPOCH : 43 / 50
VAL_LOSS : 0.5979982337781361 
VAL_ACCURACY : 0.6711864406779661
VAL_F1 : 0.674132138377732

EPOCH : 44 / 50
VAL_LOSS : 0.5977532022765705 
VAL_ACCURACY : 0.6734463276836158
VAL_F1 : 0.6770949715873538

EPOCH : 45 / 50
VAL_LOSS : 0.595672498856272 
VAL_ACCURACY : 0.6745762711864407
VAL_F1 : 0.6771300443628065

EPOCH : 46 / 50
VAL_LOSS : 0.5921405575105122 
VAL_ACCURACY : 0.6757062146892655
VAL_F1 : 0.6778900107429149

EPOCH : 47 / 50
VAL_LOSS : 0.5928483504269805 
VAL_ACCURACY : 0.6802259887005649
VAL_F1 : 0.6816647914202053

EPOCH : 48 / 50
VAL_LOSS : 0.5912020057439804 
VAL_ACCURACY : 0.6813559322033899
VAL_F1 : 0.6824324319514398

EPOCH : 49 / 50
VAL_LOSS : 0.5881277972034046 
VAL_ACCURACY : 0.6836158192090396
VAL_F1 : 0.6839729114825196

EPOCH : 50 / 50
VAL_LOSS : 0.5882923709494727 
VAL_ACCURACY : 0.6870056497175141
VAL_F1 : 0.6862967152598742

# 5話-0
# 文: オススメの本教えて
正解 : 1 , 予測 : 0 / 元クラス : UNK
tensor([[-0.3303, -0.4041]], device='cuda:0')
# 5話-0
# 文: 僕ですか?
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[-0.0970, -0.0997]], device='cuda:0')
# 5話-0
# 文: あと、これも読んだよ
正解 : 1 , 予測 : 0 / 元クラス : 憤怒
tensor([[-0.0645, -0.5915]], device='cuda:0')
# 5話-1
# 文: これ読んだよ
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 0.3795, -0.2689]], device='cuda:0')
# 5話-1
# 文: ありがとうございます …それ、何読んでるんですか?
正解 : 1 , 予測 : 0 / 元クラス : 恐怖
tensor([[-0.3714, -0.4334]], device='cuda:0')
# 5話-1
# 文: オススメの本教えて
正解 : 1 , 予測 : 0 / 元クラス : UNK
tensor([[-0.3303, -0.4041]], device='cuda:0')
# 5話-1
# 文: 僕ですか?
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[-0.0970, -0.0997]], device='cuda:0')
# 5話-1
# 文: そうなんだ〜
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.3040, -0.2189]], device='cuda:0')
# 6話-0
# 文: 今日弁当なんですね
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[-0.0292, -0.1192]], device='cuda:0')
# 6話-0
# 文: どうぞどうぞ
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.1353, -0.0817]], device='cuda:0')
# 6話-0
# 文: キャー!
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[-0.1462, -0.3860]], device='cuda:0')
# 6話-0
# 文: ベタだなあ
正解 : 1 , 予測 : 0 / 元クラス : UNK
tensor([[ 0.0493, -0.6759]], device='cuda:0')
# 6話-1
# 文: キャー!
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[-0.1462, -0.3860]], device='cuda:0')
# 6話-1
# 文: ベタだなあ
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
tensor([[ 0.0493, -0.6759]], device='cuda:0')
# 6話-1
# 文: ええ…父の分と2つ作ったんだけど
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
tensor([[ 0.1470, -0.2857]], device='cuda:0')
# 6話-1
# 文: ほとんど冷凍食品詰めただけよ
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
tensor([[-0.1998, -0.6383]], device='cuda:0')
# 6話-1
# 文: 俺も今日弁当なんでおかず分けますよ
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.6098, -0.2970]], device='cuda:0')
# 7話-0
# 文: 本当はチョコが好きなんだけど…
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
tensor([[-0.2432, -0.3596]], device='cuda:0')
# 7話-0
# 文: 別に気にしませんが…
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 0.0362, -0.0332]], device='cuda:0')
# 7話-0
# 文: はんぶんこしよっか
正解 : 1 , 予測 : 0 / 元クラス : UNK
tensor([[-0.2428, -0.4473]], device='cuda:0')
# 7話-0
# 文: とか言い出すのかな…
正解 : 1 , 予測 : 0 / 元クラス : UNK
tensor([[ 0.0227, -0.0251]], device='cuda:0')
# 7話-0
# 文: ジャーン!パフェを作ってみました〜!
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.7539, -0.0093]], device='cuda:0')
# 7話-0
# 文: 器用だ!?
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[ 0.2020, -0.1721]], device='cuda:0')
# 7話-1
# 文: ジャーン!パフェを作ってみました〜!
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.7539, -0.0093]], device='cuda:0')
# 7話-1
# 文: 器用だ!?
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[ 0.2020, -0.1721]], device='cuda:0')
# 7話-1
# 文: こうやっていろんな食べ方をすれば飽きないですね
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.1351,  0.0032]], device='cuda:0')
# 7話-1
# 文: チョコ一つしかないね
正解 : 1 , 予測 : 0 / 元クラス : UNK
tensor([[-0.1783, -0.3177]], device='cuda:0')
# 7話-1
# 文: はんぶんこしよっか
正解 : 1 , 予測 : 0 / 元クラス : UNK
tensor([[-0.2428, -0.4473]], device='cuda:0')
# 7話-1
# 文: Aくんがいなければ独り占めできたのにな…
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
tensor([[-0.1999, -0.3238]], device='cuda:0')
# 9話-0
# 文: Bさん…あれ?
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
tensor([[ 0.0705, -0.2515]], device='cuda:0')
# 9話-0
# 文: Bさ…ちょっと!
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
tensor([[-0.2171, -0.4284]], device='cuda:0')
# 9話-0
# 文: ハッ
正解 : 1 , 予測 : 0 / 元クラス : UNK
tensor([[-0.1273, -0.7294]], device='cuda:0')
# 9話-0
# 文: ここはよその研究室…!?
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[ 0.0359, -0.0279]], device='cuda:0')
# 9話-0
# 文: ?
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[-0.1133, -0.4486]], device='cuda:0')
# 9話-0
# 文: 人違い!?
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[-0.1777, -0.3967]], device='cuda:0')
# 9話-1
# 文: ?
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[-0.1133, -0.4486]], device='cuda:0')
# 9話-1
# 文: 人違い!?
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[-0.1777, -0.3967]], device='cuda:0')
# 9話-1
# 文: ここは よその研究室…!?
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[-0.0907, -0.4889]], device='cuda:0')
# 9話-1
# 文: ハッ
正解 : 1 , 予測 : 0 / 元クラス : UNK
tensor([[-0.1273, -0.7294]], device='cuda:0')
# 9話-1
# 文: 恥ずかしい…
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
tensor([[ 0.0088, -0.6476]], device='cuda:0')
# 9話-1
# 文: ?
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[-0.1133, -0.4486]], device='cuda:0')
------------------------test acc------------------------
Test Acc : 0.4384
correct: 32, total: 73
------------------------------------------------
                  喜楽        その他  accuracy  macro avg  weighted avg
precision   0.313725   0.727273  0.438356   0.520499      0.602642
recall      0.727273   0.313725  0.438356   0.520499      0.438356
f1-score    0.438356   0.438356  0.438356   0.438356      0.438356
support    22.000000  51.000000  0.438356  73.000000     73.000000
正例のF1値 : 0.4383561639504597
class weight : tensor([0.6008, 0.3322])
best:lr 1.4664752492860872e-06
EPOCH : 1 / 50
VAL_LOSS : 0.712500702057566 
VAL_ACCURACY : 0.40225988700564974
VAL_F1 : 0.4366347173142071

EPOCH : 2 / 50
VAL_LOSS : 0.7047202193311283 
VAL_ACCURACY : 0.44519774011299434
VAL_F1 : 0.48800834155617434

EPOCH : 3 / 50
VAL_LOSS : 0.6954179129430226 
VAL_ACCURACY : 0.47570621468926555
VAL_F1 : 0.5284552840911081

EPOCH : 4 / 50
VAL_LOSS : 0.6869588771036693 
VAL_ACCURACY : 0.503954802259887
VAL_F1 : 0.5605605601018636

EPOCH : 5 / 50
VAL_LOSS : 0.6775598281196186 
VAL_ACCURACY : 0.5401129943502825
VAL_F1 : 0.5909547734097583

EPOCH : 6 / 50
VAL_LOSS : 0.6693092627184731 
VAL_ACCURACY : 0.5649717514124294
VAL_F1 : 0.6107178964046494

EPOCH : 7 / 50
VAL_LOSS : 0.6626067087054253 
VAL_ACCURACY : 0.584180790960452
VAL_F1 : 0.6275303639113574

EPOCH : 8 / 50
VAL_LOSS : 0.6532439408557755 
VAL_ACCURACY : 0.6033898305084746
VAL_F1 : 0.6429298062519639

EPOCH : 9 / 50
VAL_LOSS : 0.6463209252272334 
VAL_ACCURACY : 0.6169491525423729
VAL_F1 : 0.6544342503019137

EPOCH : 10 / 50
VAL_LOSS : 0.637584388256073 
VAL_ACCURACY : 0.6361581920903955
VAL_F1 : 0.6666666662009525

EPOCH : 11 / 50
VAL_LOSS : 0.6306661686726979 
VAL_ACCURACY : 0.6485875706214689
VAL_F1 : 0.6750261228344235

EPOCH : 12 / 50
VAL_LOSS : 0.6237354044403348 
VAL_ACCURACY : 0.6644067796610169
VAL_F1 : 0.6863780354332484

EPOCH : 13 / 50
VAL_LOSS : 0.6161974721721241 
VAL_ACCURACY : 0.6813559322033899
VAL_F1 : 0.6999999995289679

EPOCH : 14 / 50
VAL_LOSS : 0.6099026075431279 
VAL_ACCURACY : 0.6994350282485876
VAL_F1 : 0.7121212116469942

EPOCH : 15 / 50
VAL_LOSS : 0.6010548632059779 
VAL_ACCURACY : 0.7050847457627119
VAL_F1 : 0.7159956469676722

EPOCH : 16 / 50
VAL_LOSS : 0.5953496981944356 
VAL_ACCURACY : 0.7163841807909604
VAL_F1 : 0.7250821462925133

EPOCH : 17 / 50
VAL_LOSS : 0.589146304343428 
VAL_ACCURACY : 0.7197740112994351
VAL_F1 : 0.7274725269955657

EPOCH : 18 / 50
VAL_LOSS : 0.5841107357825551 
VAL_ACCURACY : 0.7322033898305085
VAL_F1 : 0.7357859526978148

EPOCH : 19 / 50
VAL_LOSS : 0.5782262842570033 
VAL_ACCURACY : 0.7480225988700565
VAL_F1 : 0.7474518681476179

EPOCH : 20 / 50
VAL_LOSS : 0.570956174816404 
VAL_ACCURACY : 0.7581920903954802
VAL_F1 : 0.7551487409350733

EPOCH : 21 / 50
VAL_LOSS : 0.5650627703538963 
VAL_ACCURACY : 0.7672316384180791
VAL_F1 : 0.7621247108312807

EPOCH : 22 / 50
VAL_LOSS : 0.559247901397092 
VAL_ACCURACY : 0.7762711864406779
VAL_F1 : 0.7692307687442581

EPOCH : 23 / 50
VAL_LOSS : 0.5544081734759467 
VAL_ACCURACY : 0.7819209039548023
VAL_F1 : 0.7737397415993866

EPOCH : 24 / 50
VAL_LOSS : 0.5479014930980546 
VAL_ACCURACY : 0.7875706214689265
VAL_F1 : 0.7783018863042455

EPOCH : 25 / 50
VAL_LOSS : 0.5438645700258868 
VAL_ACCURACY : 0.7898305084745763
VAL_F1 : 0.7790973866842097

EPOCH : 26 / 50
VAL_LOSS : 0.538787519293172 
VAL_ACCURACY : 0.7954802259887006
VAL_F1 : 0.7842669840156837

EPOCH : 27 / 50
VAL_LOSS : 0.5333885374878135 
VAL_ACCURACY : 0.8033898305084746
VAL_F1 : 0.7908653841245898

EPOCH : 28 / 50
VAL_LOSS : 0.528513108513185 
VAL_ACCURACY : 0.8067796610169492
VAL_F1 : 0.793727381897157

EPOCH : 29 / 50
VAL_LOSS : 0.5229798603270736 
VAL_ACCURACY : 0.8101694915254237
VAL_F1 : 0.7966101689998007

EPOCH : 30 / 50
VAL_LOSS : 0.518651969730854 
VAL_ACCURACY : 0.8169491525423729
VAL_F1 : 0.8029197075368604

EPOCH : 31 / 50
VAL_LOSS : 0.5144263213234288 
VAL_ACCURACY : 0.8203389830508474
VAL_F1 : 0.8053855564224729

EPOCH : 32 / 50
VAL_LOSS : 0.5118732053254332 
VAL_ACCURACY : 0.8214689265536723
VAL_F1 : 0.8058968054033047

EPOCH : 33 / 50
VAL_LOSS : 0.5070698804089001 
VAL_ACCURACY : 0.8248587570621468
VAL_F1 : 0.8088779279894242

EPOCH : 34 / 50
VAL_LOSS : 0.5021644373025212 
VAL_ACCURACY : 0.8282485875706215
VAL_F1 : 0.8114143915649318

EPOCH : 35 / 50
VAL_LOSS : 0.4972379702542509 
VAL_ACCURACY : 0.8293785310734463
VAL_F1 : 0.811485642451031

EPOCH : 36 / 50
VAL_LOSS : 0.49276106751390863 
VAL_ACCURACY : 0.831638418079096
VAL_F1 : 0.8135168956245996

EPOCH : 37 / 50
VAL_LOSS : 0.48792287334799767 
VAL_ACCURACY : 0.8350282485875706
VAL_F1 : 0.8165829140769236

EPOCH : 38 / 50
VAL_LOSS : 0.4848563224077225 
VAL_ACCURACY : 0.8361581920903954
VAL_F1 : 0.8176100623970127

EPOCH : 39 / 50
VAL_LOSS : 0.4814045892230102 
VAL_ACCURACY : 0.8372881355932204
VAL_F1 : 0.8181818176853766

EPOCH : 40 / 50
VAL_LOSS : 0.47632793709635735 
VAL_ACCURACY : 0.8361581920903954
VAL_F1 : 0.8171500625553862

EPOCH : 41 / 50
VAL_LOSS : 0.47685578518680166 
VAL_ACCURACY : 0.8372881355932204
VAL_F1 : 0.8181818176853766

EPOCH : 42 / 50
VAL_LOSS : 0.4700418545731476 
VAL_ACCURACY : 0.8372881355932204
VAL_F1 : 0.8186397979924687

EPOCH : 43 / 50
VAL_LOSS : 0.4665117471345833 
VAL_ACCURACY : 0.8372881355932204
VAL_F1 : 0.8186397979924687

EPOCH : 44 / 50
VAL_LOSS : 0.4651647997753961 
VAL_ACCURACY : 0.8361581920903954
VAL_F1 : 0.8176100623970127

EPOCH : 45 / 50
VAL_LOSS : 0.46037951165011953 
VAL_ACCURACY : 0.8406779661016949
VAL_F1 : 0.8217446265577891

EPOCH : 46 / 50
VAL_LOSS : 0.4589277489909104 
VAL_ACCURACY : 0.8440677966101695
VAL_F1 : 0.8248730959497603

EPOCH : 47 / 50
VAL_LOSS : 0.4553986420588834 
VAL_ACCURACY : 0.8440677966101695
VAL_F1 : 0.8248730959497603

EPOCH : 48 / 50
VAL_LOSS : 0.45217971077987124 
VAL_ACCURACY : 0.8451977401129943
VAL_F1 : 0.8254777065090771

EPOCH : 49 / 50
VAL_LOSS : 0.44882243339504513 
VAL_ACCURACY : 0.8463276836158192
VAL_F1 : 0.826530611747488

EPOCH : 50 / 50
VAL_LOSS : 0.4469414422554629 
VAL_ACCURACY : 0.847457627118644
VAL_F1 : 0.8275862063990254

# 5話-0
# 文: 何読んでるんですか?
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[0.5511, 0.1936]], device='cuda:0')
# 5話-0
# 文: オススメの本教えて
正解 : 1 , 予測 : 0 / 元クラス : UNK
tensor([[0.3545, 0.0554]], device='cuda:0')
# 5話-0
# 文: 僕ですか?
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[0.3050, 0.2519]], device='cuda:0')
# 5話-0
# 文: 少々マニアックだろうか…
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
tensor([[0.1974, 0.1813]], device='cuda:0')
# 5話-0
# 文: Bさん、苦手そうだよな…
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
tensor([[0.4299, 0.1046]], device='cuda:0')
# 5話-0
# 文: 適当に流そう
正解 : 1 , 予測 : 0 / 元クラス : 嫌悪
tensor([[0.2676, 0.2131]], device='cuda:0')
# 5話-0
# 文: そうなんだ〜
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 0.4840, -0.1084]], device='cuda:0')
# 5話-0
# 文: 適当に流したな
正解 : 1 , 予測 : 0 / 元クラス : 憤怒
tensor([[0.4373, 0.0967]], device='cuda:0')
# 5話-0
# 文: あと、これも読んだよ
正解 : 1 , 予測 : 0 / 元クラス : 憤怒
tensor([[ 0.7406, -0.2083]], device='cuda:0')
# 5話-1
# 文: これ読んだよ
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 0.8149, -0.2338]], device='cuda:0')
# 5話-1
# 文: オススメの本教えて
正解 : 1 , 予測 : 0 / 元クラス : UNK
tensor([[0.3545, 0.0554]], device='cuda:0')
# 5話-1
# 文: 僕ですか?
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[0.3050, 0.2519]], device='cuda:0')
# 6話-0
# 文: 手作りなんですか?
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[0.4254, 0.1878]], device='cuda:0')
# 6話-0
# 文: ほとんど冷凍食品詰めただけだよ
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.0809,  0.0086]], device='cuda:0')
# 6話-0
# 文: 見てもいいですか?
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.4367,  0.3334]], device='cuda:0')
# 6話-0
# 文: キャー!
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[ 0.0287, -0.0195]], device='cuda:0')
# 6話-0
# 文: ベタだなあ
正解 : 1 , 予測 : 0 / 元クラス : UNK
tensor([[ 0.6054, -0.0854]], device='cuda:0')
# 6話-1
# 文: キャー!
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[ 0.0287, -0.0195]], device='cuda:0')
# 6話-1
# 文: ベタだなあ
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
tensor([[ 0.6054, -0.0854]], device='cuda:0')
# 6話-1
# 文: ええ…父の分と2つ作ったんだけど
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
tensor([[0.1301, 0.0895]], device='cuda:0')
# 6話-1
# 文: 手作りなんですか?
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[0.4254, 0.1878]], device='cuda:0')
# 6話-1
# 文: 俺も今日弁当なんでおかず分けますよ
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.2254,  0.4510]], device='cuda:0')
# 7話-0
# 文: どれがいいですか?
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[0.5054, 0.2390]], device='cuda:0')
# 7話-0
# 文: 本当はチョコが好きなんだけど…
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
tensor([[0.1813, 0.1692]], device='cuda:0')
# 7話-0
# 文: はんぶんこしよっか
正解 : 1 , 予測 : 0 / 元クラス : UNK
tensor([[0.3494, 0.1316]], device='cuda:0')
# 7話-0
# 文: ジャーン!パフェを作ってみました〜!
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.3027,  0.2596]], device='cuda:0')
# 7話-0
# 文: 器用だ!?
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[ 0.0630, -0.0274]], device='cuda:0')
# 7話-1
# 文: ジャーン!パフェを作ってみました〜!
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.3027,  0.2596]], device='cuda:0')
# 7話-1
# 文: 器用だ!?
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[ 0.0630, -0.0274]], device='cuda:0')
# 7話-1
# 文: こうやっていろんな食べ方をすれば飽きないですね
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.1351,  0.3952]], device='cuda:0')
# 7話-1
# 文: チョコ一つしかないね
正解 : 1 , 予測 : 0 / 元クラス : UNK
tensor([[0.8606, 0.1987]], device='cuda:0')
# 7話-1
# 文: はんぶんこしよっか
正解 : 1 , 予測 : 0 / 元クラス : UNK
tensor([[0.3494, 0.1316]], device='cuda:0')
# 7話-1
# 文: とか言い出すのかと思った…
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.4985,  0.1054]], device='cuda:0')
# 7話-1
# 文: Aくんがいなければ独り占めできたのにな…
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
tensor([[ 0.4756, -0.0040]], device='cuda:0')
# 8話-0
# 文: 今日は良い実験結果が出たな
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.0945,  0.2697]], device='cuda:0')
# 8話-0
# 文: ここは日本 何も見ていない
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 0.0488, -0.0284]], device='cuda:0')
# 8話-1
# 文: ここは日本 何も見ていない
正解 : 1 , 予測 : 0 / 元クラス : 恐怖
tensor([[ 0.0488, -0.0284]], device='cuda:0')
# 9話-0
# 文: Bさん…あれ?
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
tensor([[0.0898, 0.0095]], device='cuda:0')
# 9話-0
# 文: Bさ…ちょっと!
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
tensor([[0.6061, 0.1579]], device='cuda:0')
# 9話-0
# 文: ハッ
正解 : 1 , 予測 : 0 / 元クラス : UNK
tensor([[ 0.3174, -0.0820]], device='cuda:0')
# 9話-0
# 文: ?
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[0.3946, 0.0010]], device='cuda:0')
# 9話-0
# 文: 人違い!?
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[ 0.0246, -0.0935]], device='cuda:0')
# 9話-1
# 文: ?
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[0.3946, 0.0010]], device='cuda:0')
# 9話-1
# 文: 人違い!?
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[ 0.0246, -0.0935]], device='cuda:0')
# 9話-1
# 文: ハッ
正解 : 1 , 予測 : 0 / 元クラス : UNK
tensor([[ 0.3174, -0.0820]], device='cuda:0')
# 9話-1
# 文: 恥ずかしい…
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
tensor([[ 0.4793, -0.1828]], device='cuda:0')
# 9話-1
# 文: ただいま〜
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.0266, -0.0217]], device='cuda:0')
# 9話-1
# 文: ?
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[0.3946, 0.0010]], device='cuda:0')
------------------------test acc------------------------
Test Acc : 0.3425
correct: 25, total: 73
------------------------------------------------
                  喜楽        その他  accuracy  macro avg  weighted avg
precision   0.250000   0.571429  0.342466   0.410714      0.474560
recall      0.590909   0.235294  0.342466   0.413102      0.342466
f1-score    0.351351   0.333333  0.342466   0.342342      0.338763
support    22.000000  51.000000  0.342466  73.000000     73.000000
正例のF1値 : 0.35135135092403214
class weight : tensor([0.6008, 0.3322])
best:lr 3.2987521878032375e-06
EPOCH : 1 / 50
VAL_LOSS : 0.6959716326424054 
VAL_ACCURACY : 0.535593220338983
VAL_F1 : 0.29502572850996656

EPOCH : 2 / 50
VAL_LOSS : 0.6704401852829116 
VAL_ACCURACY : 0.5853107344632769
VAL_F1 : 0.5006802716081559

EPOCH : 3 / 50
VAL_LOSS : 0.6518317705818585 
VAL_ACCURACY : 0.6271186440677966
VAL_F1 : 0.5955882348014165

EPOCH : 4 / 50
VAL_LOSS : 0.6353635255779538 
VAL_ACCURACY : 0.6610169491525424
VAL_F1 : 0.6535796761894991

EPOCH : 5 / 50
VAL_LOSS : 0.6228512983236995 
VAL_ACCURACY : 0.6768361581920904
VAL_F1 : 0.679372196829169

EPOCH : 6 / 50
VAL_LOSS : 0.6082335433789662 
VAL_ACCURACY : 0.6779661016949152
VAL_F1 : 0.6857772872844092

EPOCH : 7 / 50
VAL_LOSS : 0.5966135146362441 
VAL_ACCURACY : 0.6858757062146893
VAL_F1 : 0.6917960083907748

EPOCH : 8 / 50
VAL_LOSS : 0.5869323866707938 
VAL_ACCURACY : 0.6937853107344633
VAL_F1 : 0.6992230849819894

EPOCH : 9 / 50
VAL_LOSS : 0.574423325913293 
VAL_ACCURACY : 0.7050847457627119
VAL_F1 : 0.7083798877884013

EPOCH : 10 / 50
VAL_LOSS : 0.5622569450310299 
VAL_ACCURACY : 0.7084745762711865
VAL_F1 : 0.710112359069875

EPOCH : 11 / 50
VAL_LOSS : 0.5514144945357528 
VAL_ACCURACY : 0.7107344632768362
VAL_F1 : 0.7117117112306531

EPOCH : 12 / 50
VAL_LOSS : 0.544530347521816 
VAL_ACCURACY : 0.7209039548022599
VAL_F1 : 0.7189988618608592

EPOCH : 13 / 50
VAL_LOSS : 0.535730602485793 
VAL_ACCURACY : 0.727683615819209
VAL_F1 : 0.7226697348434626

EPOCH : 14 / 50
VAL_LOSS : 0.5253051535359451 
VAL_ACCURACY : 0.7333333333333333
VAL_F1 : 0.7255813948627691

EPOCH : 15 / 50
VAL_LOSS : 0.5202348764453616 
VAL_ACCURACY : 0.7468926553672316
VAL_F1 : 0.737704917545673

EPOCH : 16 / 50
VAL_LOSS : 0.5088147670030594 
VAL_ACCURACY : 0.7570621468926554
VAL_F1 : 0.7455621296888932

EPOCH : 17 / 50
VAL_LOSS : 0.5018011698765414 
VAL_ACCURACY : 0.7615819209039548
VAL_F1 : 0.7497034396059432

EPOCH : 18 / 50
VAL_LOSS : 0.49233275811587063 
VAL_ACCURACY : 0.7649717514124293
VAL_F1 : 0.7529691206510175

EPOCH : 19 / 50
VAL_LOSS : 0.48590696283749174 
VAL_ACCURACY : 0.7728813559322034
VAL_F1 : 0.759856630334434

EPOCH : 20 / 50
VAL_LOSS : 0.4778070476438318 
VAL_ACCURACY : 0.7785310734463277
VAL_F1 : 0.7638554211957093

EPOCH : 21 / 50
VAL_LOSS : 0.4714660607278347 
VAL_ACCURACY : 0.7807909604519774
VAL_F1 : 0.7657004826004398

EPOCH : 22 / 50
VAL_LOSS : 0.4636803812214306 
VAL_ACCURACY : 0.7830508474576271
VAL_F1 : 0.7681159415376321

EPOCH : 23 / 50
VAL_LOSS : 0.4571154809423855 
VAL_ACCURACY : 0.7909604519774012
VAL_F1 : 0.7735618110125142

EPOCH : 24 / 50
VAL_LOSS : 0.45490524971059393 
VAL_ACCURACY : 0.7954802259887006
VAL_F1 : 0.7784577718448155

EPOCH : 25 / 50
VAL_LOSS : 0.44880836457014084 
VAL_ACCURACY : 0.8011299435028248
VAL_F1 : 0.7827160488887122

EPOCH : 26 / 50
VAL_LOSS : 0.43750033607440336 
VAL_ACCURACY : 0.8090395480225989
VAL_F1 : 0.7911001231152317

EPOCH : 27 / 50
VAL_LOSS : 0.4342925819967474 
VAL_ACCURACY : 0.8214689265536723
VAL_F1 : 0.8015075371925393

EPOCH : 28 / 50
VAL_LOSS : 0.42716203523533686 
VAL_ACCURACY : 0.8259887005649718
VAL_F1 : 0.8055555550591458

EPOCH : 29 / 50
VAL_LOSS : 0.42163177845733507 
VAL_ACCURACY : 0.8305084745762712
VAL_F1 : 0.810126581781817

EPOCH : 30 / 50
VAL_LOSS : 0.4176658306803022 
VAL_ACCURACY : 0.8361581920903954
VAL_F1 : 0.8157560350811099

EPOCH : 31 / 50
VAL_LOSS : 0.4159152667437281 
VAL_ACCURACY : 0.8384180790960452
VAL_F1 : 0.8182973311420946

EPOCH : 32 / 50
VAL_LOSS : 0.40695464398179737 
VAL_ACCURACY : 0.8440677966101695
VAL_F1 : 0.8235294112670771

EPOCH : 33 / 50
VAL_LOSS : 0.40317933953234125 
VAL_ACCURACY : 0.8519774011299435
VAL_F1 : 0.8314028309046344

EPOCH : 34 / 50
VAL_LOSS : 0.4005425612309149 
VAL_ACCURACY : 0.8531073446327684
VAL_F1 : 0.8324742263058177

EPOCH : 35 / 50
VAL_LOSS : 0.3967044401381697 
VAL_ACCURACY : 0.8576271186440678
VAL_F1 : 0.8372093018270537

EPOCH : 36 / 50
VAL_LOSS : 0.391188201627561 
VAL_ACCURACY : 0.8587570621468926
VAL_F1 : 0.8378728918487657

EPOCH : 37 / 50
VAL_LOSS : 0.3858968461198466 
VAL_ACCURACY : 0.8632768361581921
VAL_F1 : 0.8430609592936289

EPOCH : 38 / 50
VAL_LOSS : 0.3820395608033453 
VAL_ACCURACY : 0.864406779661017
VAL_F1 : 0.8445595849934764

EPOCH : 39 / 50
VAL_LOSS : 0.37398213653692175 
VAL_ACCURACY : 0.8677966101694915
VAL_F1 : 0.847457626619393

EPOCH : 40 / 50
VAL_LOSS : 0.3711009629602943 
VAL_ACCURACY : 0.8711864406779661
VAL_F1 : 0.849999999500104

EPOCH : 41 / 50
VAL_LOSS : 0.3725957420787641 
VAL_ACCURACY : 0.8723163841807909
VAL_F1 : 0.8511198940981703

EPOCH : 42 / 50
VAL_LOSS : 0.3638575593275683 
VAL_ACCURACY : 0.8723163841807909
VAL_F1 : 0.850726551679504

EPOCH : 43 / 50
VAL_LOSS : 0.3617874788386481 
VAL_ACCURACY : 0.8745762711864407
VAL_F1 : 0.8529801319500093

EPOCH : 44 / 50
VAL_LOSS : 0.35828408252980026 
VAL_ACCURACY : 0.8790960451977401
VAL_F1 : 0.85790172592713

EPOCH : 45 / 50
VAL_LOSS : 0.3543139818523611 
VAL_ACCURACY : 0.8824858757062147
VAL_F1 : 0.8617021271589944

EPOCH : 46 / 50
VAL_LOSS : 0.3504570507045303 
VAL_ACCURACY : 0.8813559322033898
VAL_F1 : 0.8605577684238028

EPOCH : 47 / 50
VAL_LOSS : 0.3470149811889444 
VAL_ACCURACY : 0.8824858757062147
VAL_F1 : 0.8617021271589944

EPOCH : 48 / 50
VAL_LOSS : 0.3468709577407156 
VAL_ACCURACY : 0.8847457627118644
VAL_F1 : 0.863999999499264

EPOCH : 49 / 50
VAL_LOSS : 0.34016082489064764 
VAL_ACCURACY : 0.8858757062146893
VAL_F1 : 0.8655126492996006

EPOCH : 50 / 50
VAL_LOSS : 0.3379317865307842 
VAL_ACCURACY : 0.8858757062146893
VAL_F1 : 0.8655126492996006

# 5話-0
# 文: オススメの本教えて
正解 : 1 , 予測 : 0 / 元クラス : UNK
tensor([[ 0.6041, -0.6963]], device='cuda:0')
# 5話-0
# 文: 今ハマってる本はこの二冊…
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.1385, -0.0460]], device='cuda:0')
# 5話-0
# 文: Bさん、苦手そうだよな…
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
tensor([[ 0.6812, -0.5440]], device='cuda:0')
# 5話-0
# 文: そうなんだ〜
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 0.5148, -0.4606]], device='cuda:0')
# 5話-0
# 文: 適当に流したな
正解 : 1 , 予測 : 0 / 元クラス : 憤怒
tensor([[0.1970, 0.1705]], device='cuda:0')
# 5話-0
# 文: あと、これも読んだよ
正解 : 1 , 予測 : 0 / 元クラス : 憤怒
tensor([[ 0.3778, -0.4934]], device='cuda:0')
# 5話-1
# 文: これ読んだよ
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 0.8448, -0.6859]], device='cuda:0')
# 5話-1
# 文: オススメの本教えて
正解 : 1 , 予測 : 0 / 元クラス : UNK
tensor([[ 0.6041, -0.6963]], device='cuda:0')
# 6話-0
# 文: ほとんど冷凍食品詰めただけだよ
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[0.1585, 0.1945]], device='cuda:0')
# 6話-0
# 文: 見てもいいですか?
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[0.0596, 0.6125]], device='cuda:0')
# 6話-0
# 文: キャー!
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[ 0.1837, -0.0628]], device='cuda:0')
# 6話-0
# 文: ベタだなあ
正解 : 1 , 予測 : 0 / 元クラス : UNK
tensor([[ 0.1907, -0.1700]], device='cuda:0')
# 6話-1
# 文: キャー!
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[ 0.1837, -0.0628]], device='cuda:0')
# 6話-1
# 文: ベタだなあ
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
tensor([[ 0.1907, -0.1700]], device='cuda:0')
# 6話-1
# 文: 俺も今日弁当なんでおかず分けますよ
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.4745,  0.5761]], device='cuda:0')
# 7話-0
# 文: どれがいいですか?
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 0.1374, -0.1490]], device='cuda:0')
# 7話-0
# 文: チョコは一つしかないし悪いよ〜
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[ 0.2047, -0.2759]], device='cuda:0')
# 7話-0
# 文: ジャーン!パフェを作ってみました〜!
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.3194,  0.2403]], device='cuda:0')
# 7話-1
# 文: ジャーン!パフェを作ってみました〜!
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.3194,  0.2403]], device='cuda:0')
# 7話-1
# 文: こうやっていろんな食べ方をすれば飽きないですね
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.8814,  0.7959]], device='cuda:0')
# 7話-1
# 文: チョコ一つしかないね
正解 : 1 , 予測 : 0 / 元クラス : UNK
tensor([[ 0.2290, -0.7037]], device='cuda:0')
# 7話-1
# 文: とか言い出すのかと思った…
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.4971,  0.1964]], device='cuda:0')
# 7話-1
# 文: Aくんがいなければ独り占めできたのにな…
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
tensor([[ 0.3482, -0.4281]], device='cuda:0')
# 8話-0
# 文: 今日は良い実験結果が出たな
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.0902,  0.2970]], device='cuda:0')
# 8話-0
# 文: 国際会議でスペインにいるBさんからだ
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[0.0590, 0.0691]], device='cuda:0')
# 8話-0
# 文: ここは日本 何も見ていない
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 0.1906, -0.0030]], device='cuda:0')
# 8話-1
# 文: ここは日本 何も見ていない
正解 : 1 , 予測 : 0 / 元クラス : 恐怖
tensor([[ 0.1906, -0.0030]], device='cuda:0')
# 9話-0
# 文: Bさん…あれ?
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
tensor([[0.4658, 0.1130]], device='cuda:0')
# 9話-0
# 文: Bさ…ちょっと!
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
tensor([[ 0.5002, -0.1300]], device='cuda:0')
# 9話-1
# 文: ここは よその研究室…!?
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[ 0.0748, -0.3234]], device='cuda:0')
# 9話-1
# 文: 恥ずかしい…
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
tensor([[ 0.1300, -0.0939]], device='cuda:0')
# 9話-1
# 文: ただいま〜
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.1994,  0.0741]], device='cuda:0')
------------------------test acc------------------------
Test Acc : 0.5616
correct: 41, total: 73
------------------------------------------------
                  喜楽        その他  accuracy  macro avg  weighted avg
precision   0.343750   0.731707  0.561644   0.537729      0.614789
recall      0.500000   0.588235  0.561644   0.544118      0.561644
f1-score    0.407407   0.652174  0.561644   0.529791      0.578409
support    22.000000  51.000000  0.561644  73.000000     73.000000
正例のF1値 : 0.40740740690946503
