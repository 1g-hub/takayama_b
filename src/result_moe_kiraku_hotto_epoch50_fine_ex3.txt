class weight : tensor([0.5648, 0.3853])
best:lr 3.993507065042073e-07
EPOCH : 1 / 50
VAL_LOSS : 0.6602725707567655 
VAL_ACCURACY : 0.5366748166259169
VAL_F1 : 0.6323957318541509

EPOCH : 2 / 50
VAL_LOSS : 0.6143458617421297 
VAL_ACCURACY : 0.6515892420537898
VAL_F1 : 0.6945337615920019

EPOCH : 3 / 50
VAL_LOSS : 0.5794894987573991 
VAL_ACCURACY : 0.7408312958435208
VAL_F1 : 0.7488151653929719

EPOCH : 4 / 50
VAL_LOSS : 0.543802658525797 
VAL_ACCURACY : 0.8215158924205379
VAL_F1 : 0.8103896098937425

EPOCH : 5 / 50
VAL_LOSS : 0.5197719530417368 
VAL_ACCURACY : 0.8557457212713936
VAL_F1 : 0.8426666661682916

EPOCH : 6 / 50
VAL_LOSS : 0.4890205069230153 
VAL_ACCURACY : 0.8814180929095354
VAL_F1 : 0.8665749651114698

EPOCH : 7 / 50
VAL_LOSS : 0.47162291751458096 
VAL_ACCURACY : 0.8863080684596577
VAL_F1 : 0.8713692941048536

EPOCH : 8 / 50
VAL_LOSS : 0.4529592784551474 
VAL_ACCURACY : 0.8960880195599022
VAL_F1 : 0.8814504876436492

EPOCH : 9 / 50
VAL_LOSS : 0.4368583829357074 
VAL_ACCURACY : 0.9070904645476773
VAL_F1 : 0.8920454540433239

EPOCH : 10 / 50
VAL_LOSS : 0.42080327581900817 
VAL_ACCURACY : 0.9095354523227384
VAL_F1 : 0.8951841354752867

EPOCH : 11 / 50
VAL_LOSS : 0.40558520819132143 
VAL_ACCURACY : 0.91320293398533
VAL_F1 : 0.8990042669231276

EPOCH : 12 / 50
VAL_LOSS : 0.392164467045894 
VAL_ACCURACY : 0.9242053789731052
VAL_F1 : 0.9111747845978769

EPOCH : 13 / 50
VAL_LOSS : 0.3803776591443099 
VAL_ACCURACY : 0.9278728606356969
VAL_F1 : 0.9151079131665567

EPOCH : 14 / 50
VAL_LOSS : 0.3711453372469315 
VAL_ACCURACY : 0.9290953545232273
VAL_F1 : 0.9166666661641811

EPOCH : 15 / 50
VAL_LOSS : 0.35929979756474495 
VAL_ACCURACY : 0.9303178484107579
VAL_F1 : 0.9179856110082749

EPOCH : 16 / 50
VAL_LOSS : 0.3596826714391892 
VAL_ACCURACY : 0.9352078239608802
VAL_F1 : 0.9235209230183427

EPOCH : 17 / 50
VAL_LOSS : 0.34406812431720585 
VAL_ACCURACY : 0.9364303178484108
VAL_F1 : 0.9250720456069479

EPOCH : 18 / 50
VAL_LOSS : 0.3359178204375964 
VAL_ACCURACY : 0.9400977995110025
VAL_F1 : 0.9298998564360532

EPOCH : 19 / 50
VAL_LOSS : 0.3228494404600217 
VAL_ACCURACY : 0.9437652811735942
VAL_F1 : 0.9339080454744765

EPOCH : 20 / 50
VAL_LOSS : 0.31763671510494673 
VAL_ACCURACY : 0.9511002444987775
VAL_F1 : 0.943019942517585

EPOCH : 21 / 50
VAL_LOSS : 0.3080410355558762 
VAL_ACCURACY : 0.9535452322738386
VAL_F1 : 0.9458689453665798

EPOCH : 22 / 50
VAL_LOSS : 0.3152313710978398 
VAL_ACCURACY : 0.9547677261613692
VAL_F1 : 0.9473684205503016

EPOCH : 23 / 50
VAL_LOSS : 0.29433154887877977 
VAL_ACCURACY : 0.9559902200488998
VAL_F1 : 0.9490084980813664

EPOCH : 24 / 50
VAL_LOSS : 0.2845205469773366 
VAL_ACCURACY : 0.9572127139364304
VAL_F1 : 0.9503546094268256

EPOCH : 25 / 50
VAL_LOSS : 0.27918442539297617 
VAL_ACCURACY : 0.9572127139364304
VAL_F1 : 0.9503546094268256

EPOCH : 26 / 50
VAL_LOSS : 0.27016835602430195 
VAL_ACCURACY : 0.9572127139364304
VAL_F1 : 0.9503546094268256

EPOCH : 27 / 50
VAL_LOSS : 0.26490251390406716 
VAL_ACCURACY : 0.9559902200488998
VAL_F1 : 0.9490084980813664

EPOCH : 28 / 50
VAL_LOSS : 0.258508079756911 
VAL_ACCURACY : 0.9559902200488998
VAL_F1 : 0.9490084980813664

EPOCH : 29 / 50
VAL_LOSS : 0.2539420580634704 
VAL_ACCURACY : 0.9559902200488998
VAL_F1 : 0.9490084980813664

EPOCH : 30 / 50
VAL_LOSS : 0.2507201029131046 
VAL_ACCURACY : 0.9559902200488998
VAL_F1 : 0.9490084980813664

EPOCH : 31 / 50
VAL_LOSS : 0.2439601828272526 
VAL_ACCURACY : 0.9559902200488998
VAL_F1 : 0.9490084980813664

EPOCH : 32 / 50
VAL_LOSS : 0.23806141861356223 
VAL_ACCURACY : 0.9559902200488998
VAL_F1 : 0.9490084980813664

EPOCH : 33 / 50
VAL_LOSS : 0.2322601739030618 
VAL_ACCURACY : 0.9559902200488998
VAL_F1 : 0.9491525418707746

EPOCH : 34 / 50
VAL_LOSS : 0.22748247877909586 
VAL_ACCURACY : 0.9572127139364304
VAL_F1 : 0.9504950490027908

EPOCH : 35 / 50
VAL_LOSS : 0.22003418651337808 
VAL_ACCURACY : 0.9559902200488998
VAL_F1 : 0.9491525418707746

EPOCH : 36 / 50
VAL_LOSS : 0.21510241983028558 
VAL_ACCURACY : 0.9559902200488998
VAL_F1 : 0.9491525418707746

EPOCH : 37 / 50
VAL_LOSS : 0.20999714159048521 
VAL_ACCURACY : 0.9559902200488998
VAL_F1 : 0.9491525418707746

EPOCH : 38 / 50
VAL_LOSS : 0.2079051467948235 
VAL_ACCURACY : 0.9559902200488998
VAL_F1 : 0.9491525418707746

EPOCH : 39 / 50
VAL_LOSS : 0.20525324502243444 
VAL_ACCURACY : 0.9559902200488998
VAL_F1 : 0.9491525418707746

EPOCH : 40 / 50
VAL_LOSS : 0.20031586604622695 
VAL_ACCURACY : 0.9559902200488998
VAL_F1 : 0.9491525418707746

EPOCH : 41 / 50
VAL_LOSS : 0.19528145314409182 
VAL_ACCURACY : 0.9559902200488998
VAL_F1 : 0.9491525418707746

EPOCH : 42 / 50
VAL_LOSS : 0.18908443860709667 
VAL_ACCURACY : 0.9559902200488998
VAL_F1 : 0.9491525418707746

EPOCH : 43 / 50
VAL_LOSS : 0.18617041093798783 
VAL_ACCURACY : 0.9572127139364304
VAL_F1 : 0.9504950490027908

EPOCH : 44 / 50
VAL_LOSS : 0.1811944143130229 
VAL_ACCURACY : 0.9572127139364304
VAL_F1 : 0.9504950490027908

EPOCH : 45 / 50
VAL_LOSS : 0.17669726055688584 
VAL_ACCURACY : 0.9572127139364304
VAL_F1 : 0.9506346962539345

EPOCH : 46 / 50
VAL_LOSS : 0.17444497332550013 
VAL_ACCURACY : 0.9572127139364304
VAL_F1 : 0.9506346962539345

EPOCH : 47 / 50
VAL_LOSS : 0.17100996395143178 
VAL_ACCURACY : 0.9572127139364304
VAL_F1 : 0.9506346962539345

EPOCH : 48 / 50
VAL_LOSS : 0.17094246212106484 
VAL_ACCURACY : 0.9572127139364304
VAL_F1 : 0.9506346962539345

EPOCH : 49 / 50
VAL_LOSS : 0.1643495737360074 
VAL_ACCURACY : 0.9572127139364304
VAL_F1 : 0.9506346962539345

EPOCH : 50 / 50
VAL_LOSS : 0.16172913289987123 
VAL_ACCURACY : 0.9572127139364304
VAL_F1 : 0.9506346962539345

# 5話-0
# 文: 夏目漱石だよ〜 Aくんはどんな本を読むの
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.3256,  0.6394]], device='cuda:0')
# 5話-0
# 文: 少々マニアックだろうか…
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
tensor([[ 0.2831, -0.9580]], device='cuda:0')
# 5話-0
# 文: Bさん、苦手そうだよな…
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
tensor([[ 0.6690, -1.4931]], device='cuda:0')
# 5話-0
# 文: あと、これも読んだよ
正解 : 1 , 予測 : 0 / 元クラス : 憤怒
tensor([[ 0.3879, -0.8829]], device='cuda:0')
# 5話-1
# 文: これ読んだよ
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 0.3902, -0.7003]], device='cuda:0')
# 5話-1
# 文: 夏目漱石だよ〜 Aくんはどんな本を読むの
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[0.0030, 0.6898]], device='cuda:0')
# 5話-1
# 文: 小説はあまり読まないのですが 研究で利用している青空文庫の作品なら少々
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[-0.2145, -0.4804]], device='cuda:0')
# 6話-0
# 文: そうなんだ〜 父の分と2つ作ったの
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.3262,  0.8602]], device='cuda:0')
# 6話-0
# 文: ほとんど冷凍食品詰めただけだよ
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.1311,  0.1395]], device='cuda:0')
# 6話-0
# 文: 見てもいいですか?
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.4202,  1.1355]], device='cuda:0')
# 6話-0
# 文: どうぞどうぞ
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.4041,  0.7839]], device='cuda:0')
# 6話-0
# 文: キャー!
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[ 0.3913, -0.2835]], device='cuda:0')
# 6話-1
# 文: キャー!
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[ 0.5442, -1.3433]], device='cuda:0')
# 6話-1
# 文: ベタだなあ
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
tensor([[ 0.3998, -0.9499]], device='cuda:0')
# 6話-1
# 文: 俺も今日弁当なんでおかず分けますよ
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.3727,  0.2147]], device='cuda:0')
# 7話-0
# 文: じゃあチョコですね
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 0.0908, -0.3381]], device='cuda:0')
# 7話-0
# 文: チョコは一つしかないし悪いよ〜
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[ 0.3505, -0.7762]], device='cuda:0')
# 7話-0
# 文: 別に気にしませんが…
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 0.0616, -0.1034]], device='cuda:0')
# 7話-0
# 文: ジャーン!パフェを作ってみました〜!
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.2351,  0.1984]], device='cuda:0')
# 7話-1
# 文: こうやっていろんな食べ方をすれば飽きないですね
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.1441,  0.4616]], device='cuda:0')
# 7話-1
# 文: Aくんがいなければ独り占めできたのにな…
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
tensor([[ 0.8428, -1.7264]], device='cuda:0')
# 8話-0
# 文: 今日は良い実験結果が出たな
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.7247,  0.9833]], device='cuda:0')
# 8話-1
# 文: でもわざわざ国際会議から送ってくれたんだよな…
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.3127,  0.0362]], device='cuda:0')
# 8話-1
# 文: もう少し頑張るか
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.5941,  1.3588]], device='cuda:0')
# 9話-0
# 文: あれ?スペインからもう戻ってきたのか.
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.0867, -0.0427]], device='cuda:0')
# 9話-0
# 文: ?
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 0.0235, -0.2647]], device='cuda:0')
# 9話-1
# 文: 恥ずかしい…
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
tensor([[-0.0375, -0.4213]], device='cuda:0')
# 9話-1
# 文: ただいま〜
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.1592,  0.6064]], device='cuda:0')
------------------------test acc------------------------
Test Acc : 0.5625
correct: 36, total: 64
------------------------------------------------
                  喜楽        その他  accuracy  macro avg  weighted avg
precision   0.363636   0.666667    0.5625   0.515152        0.5625
recall      0.363636   0.666667    0.5625   0.515152        0.5625
f1-score    0.363636   0.666667    0.5625   0.515152        0.5625
support    22.000000  42.000000    0.5625  64.000000       64.0000
正例のF1値 : 0.3636363631198347
class weight : tensor([0.5648, 0.3853])
best:lr 1.520014186034404e-06
EPOCH : 1 / 50
VAL_LOSS : 0.5579771582896893 
VAL_ACCURACY : 0.7701711491442543
VAL_F1 : 0.7526315784503879

EPOCH : 2 / 50
VAL_LOSS : 0.4594249272575745 
VAL_ACCURACY : 0.843520782396088
VAL_F1 : 0.8274932609563503

EPOCH : 3 / 50
VAL_LOSS : 0.3951699429979691 
VAL_ACCURACY : 0.8887530562347188
VAL_F1 : 0.8705547647894961

EPOCH : 4 / 50
VAL_LOSS : 0.36526267803632295 
VAL_ACCURACY : 0.9254278728606357
VAL_F1 : 0.9119769114743644

EPOCH : 5 / 50
VAL_LOSS : 0.3371356576681137 
VAL_ACCURACY : 0.9400977995110025
VAL_F1 : 0.9292929287903319

EPOCH : 6 / 50
VAL_LOSS : 0.2935340883067021 
VAL_ACCURACY : 0.9474327628361858
VAL_F1 : 0.9381294959003034

EPOCH : 7 / 50
VAL_LOSS : 0.272921623232273 
VAL_ACCURACY : 0.9535452322738386
VAL_F1 : 0.9460227267704432

EPOCH : 8 / 50
VAL_LOSS : 0.25252250180794644 
VAL_ACCURACY : 0.9547677261613692
VAL_F1 : 0.9476661946887961

EPOCH : 9 / 50
VAL_LOSS : 0.2307111841554825 
VAL_ACCURACY : 0.9559902200488998
VAL_F1 : 0.9490084980813664

EPOCH : 10 / 50
VAL_LOSS : 0.21447710363337627 
VAL_ACCURACY : 0.9559902200488998
VAL_F1 : 0.9491525418707746

EPOCH : 11 / 50
VAL_LOSS : 0.1984227212289205 
VAL_ACCURACY : 0.9547677261613692
VAL_F1 : 0.9479606183447493

EPOCH : 12 / 50
VAL_LOSS : 0.18260800551909667 
VAL_ACCURACY : 0.9559902200488998
VAL_F1 : 0.9492957741458838

EPOCH : 13 / 50
VAL_LOSS : 0.1692002768126818 
VAL_ACCURACY : 0.960880195599022
VAL_F1 : 0.9546742204609538

EPOCH : 14 / 50
VAL_LOSS : 0.15761027456476137 
VAL_ACCURACY : 0.960880195599022
VAL_F1 : 0.9546742204609538

EPOCH : 15 / 50
VAL_LOSS : 0.14786891438640082 
VAL_ACCURACY : 0.9645476772616137
VAL_F1 : 0.9587482214037544

EPOCH : 16 / 50
VAL_LOSS : 0.13853585462157542 
VAL_ACCURACY : 0.9718826405867971
VAL_F1 : 0.9670014342176287

EPOCH : 17 / 50
VAL_LOSS : 0.13107190281152725 
VAL_ACCURACY : 0.9743276283618582
VAL_F1 : 0.969784172159205

EPOCH : 18 / 50
VAL_LOSS : 0.12536514550447464 
VAL_ACCURACY : 0.9792176039119804
VAL_F1 : 0.9753979734480241

EPOCH : 19 / 50
VAL_LOSS : 0.11564752860711171 
VAL_ACCURACY : 0.9828850855745721
VAL_F1 : 0.9796511622878669

EPOCH : 20 / 50
VAL_LOSS : 0.11239031652131906 
VAL_ACCURACY : 0.9828850855745721
VAL_F1 : 0.9796511622878669

EPOCH : 21 / 50
VAL_LOSS : 0.10871441311274584 
VAL_ACCURACY : 0.9841075794621027
VAL_F1 : 0.9810771465131651

EPOCH : 22 / 50
VAL_LOSS : 0.09985516750468658 
VAL_ACCURACY : 0.9853300733496333
VAL_F1 : 0.9825072881268774

EPOCH : 23 / 50
VAL_LOSS : 0.09530090884520458 
VAL_ACCURACY : 0.9877750611246944
VAL_F1 : 0.9854227400219125

EPOCH : 24 / 50
VAL_LOSS : 0.09295295615895437 
VAL_ACCURACY : 0.9865525672371638
VAL_F1 : 0.9839416053365443

EPOCH : 25 / 50
VAL_LOSS : 0.08688155303780849 
VAL_ACCURACY : 0.9877750611246944
VAL_F1 : 0.9854227400219125

EPOCH : 26 / 50
VAL_LOSS : 0.08373382945473377 
VAL_ACCURACY : 0.9902200488997555
VAL_F1 : 0.9883040930643616

EPOCH : 27 / 50
VAL_LOSS : 0.08006508927792311 
VAL_ACCURACY : 0.991442542787286
VAL_F1 : 0.9897810213949215

EPOCH : 28 / 50
VAL_LOSS : 0.07916185489067665 
VAL_ACCURACY : 0.9926650366748166
VAL_F1 : 0.9912536438119831

EPOCH : 29 / 50
VAL_LOSS : 0.07367055533597103 
VAL_ACCURACY : 0.9951100244498777
VAL_F1 : 0.9941690957070183

EPOCH : 30 / 50
VAL_LOSS : 0.07077525885632405 
VAL_ACCURACY : 0.9963325183374083
VAL_F1 : 0.9956204374532985

EPOCH : 31 / 50
VAL_LOSS : 0.06834664202940005 
VAL_ACCURACY : 0.9963325183374083
VAL_F1 : 0.9956204374532985

EPOCH : 32 / 50
VAL_LOSS : 0.06695782085164236 
VAL_ACCURACY : 0.9951100244498777
VAL_F1 : 0.994152046280719

EPOCH : 33 / 50
VAL_LOSS : 0.06365802927085987 
VAL_ACCURACY : 0.9951100244498777
VAL_F1 : 0.9941690957070183

EPOCH : 34 / 50
VAL_LOSS : 0.06147108470591215 
VAL_ACCURACY : 0.9951100244498777
VAL_F1 : 0.9941690957070183

EPOCH : 35 / 50
VAL_LOSS : 0.059380175080150366 
VAL_ACCURACY : 0.9963325183374083
VAL_F1 : 0.9956204374532985

EPOCH : 36 / 50
VAL_LOSS : 0.058231471213870324 
VAL_ACCURACY : 0.9963325183374083
VAL_F1 : 0.9956204374532985

EPOCH : 37 / 50
VAL_LOSS : 0.05639271427375766 
VAL_ACCURACY : 0.9963325183374083
VAL_F1 : 0.9956204374532985

EPOCH : 38 / 50
VAL_LOSS : 0.05482949681866627 
VAL_ACCURACY : 0.9951100244498777
VAL_F1 : 0.9941690957070183

EPOCH : 39 / 50
VAL_LOSS : 0.05331013405408997 
VAL_ACCURACY : 0.9963325183374083
VAL_F1 : 0.9956204374532985

EPOCH : 40 / 50
VAL_LOSS : 0.05185681330756499 
VAL_ACCURACY : 0.9963325183374083
VAL_F1 : 0.9956204374532985

EPOCH : 41 / 50
VAL_LOSS : 0.050060612901758686 
VAL_ACCURACY : 0.9975550122249389
VAL_F1 : 0.9970845476020536

EPOCH : 42 / 50
VAL_LOSS : 0.048688514659611076 
VAL_ACCURACY : 0.9963325183374083
VAL_F1 : 0.9956204374532985

EPOCH : 43 / 50
VAL_LOSS : 0.047997819617963754 
VAL_ACCURACY : 0.9963325183374083
VAL_F1 : 0.9956204374532985

EPOCH : 44 / 50
VAL_LOSS : 0.047173398869255416 
VAL_ACCURACY : 0.9951100244498777
VAL_F1 : 0.9941860460087547

EPOCH : 45 / 50
VAL_LOSS : 0.045949959518531196 
VAL_ACCURACY : 0.9963325183374083
VAL_F1 : 0.9956204374532985

EPOCH : 46 / 50
VAL_LOSS : 0.04477597432784163 
VAL_ACCURACY : 0.9951100244498777
VAL_F1 : 0.9941860460087547

EPOCH : 47 / 50
VAL_LOSS : 0.04495155718177557 
VAL_ACCURACY : 0.9975550122249389
VAL_F1 : 0.9970760228888975

EPOCH : 48 / 50
VAL_LOSS : 0.04216533666476607 
VAL_ACCURACY : 0.9987775061124694
VAL_F1 : 0.9985401454824872

EPOCH : 49 / 50
VAL_LOSS : 0.04101347274935016 
VAL_ACCURACY : 0.9987775061124694
VAL_F1 : 0.9985401454824872

EPOCH : 50 / 50
VAL_LOSS : 0.03975081250358086 
VAL_ACCURACY : 0.9987775061124694
VAL_F1 : 0.9985401454824872

# 5話-0
# 文: 夏目漱石だよ〜 Aくんはどんな本を読むの
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.4488,  0.0463]], device='cuda:0')
# 5話-0
# 文: Bさん、苦手そうだよな…
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
tensor([[ 2.1422, -1.6967]], device='cuda:0')
# 5話-0
# 文: あと、これも読んだよ
正解 : 1 , 予測 : 0 / 元クラス : 憤怒
tensor([[ 1.9654, -1.4853]], device='cuda:0')
# 5話-1
# 文: これ読んだよ
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 1.9421, -1.4248]], device='cuda:0')
# 5話-1
# 文: 夏目漱石だよ〜 Aくんはどんな本を読むの
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.3978,  0.1607]], device='cuda:0')
# 6話-0
# 文: そうなんだ〜 父の分と2つ作ったの
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.8458,  0.5403]], device='cuda:0')
# 6話-0
# 文: ほとんど冷凍食品詰めただけだよ
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-1.6767,  0.9851]], device='cuda:0')
# 6話-0
# 文: 見てもいいですか?
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-1.2395,  1.2896]], device='cuda:0')
# 6話-0
# 文: どうぞどうぞ
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.3904,  0.6704]], device='cuda:0')
# 6話-1
# 文: 俺も今日弁当なんでおかず分けますよ
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.2340,  0.4717]], device='cuda:0')
# 7話-0
# 文: チョコは一つしかないし悪いよ〜
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[ 0.9698, -0.7611]], device='cuda:0')
# 7話-0
# 文: 別に気にしませんが…
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 0.3001, -0.2763]], device='cuda:0')
# 7話-1
# 文: Aくんがいなければ独り占めできたのにな…
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
tensor([[ 2.2570, -1.6803]], device='cuda:0')
# 8話-0
# 文: 今日は良い実験結果が出たな
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-1.8358,  1.3611]], device='cuda:0')
# 8話-1
# 文: でもわざわざ国際会議から送ってくれたんだよな…
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.6296,  0.2572]], device='cuda:0')
# 8話-1
# 文: もう少し頑張るか
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-1.6724,  1.2325]], device='cuda:0')
# 9話-0
# 文: あれ?スペインからもう戻ってきたのか.
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-1.1416,  0.5667]], device='cuda:0')
# 9話-1
# 文: ただいま〜
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-1.8192,  1.1509]], device='cuda:0')
# 9話-1
# 文: おかえりなさい!
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-1.1306,  0.2951]], device='cuda:0')
------------------------test acc------------------------
Test Acc : 0.7031
correct: 45, total: 64
------------------------------------------------
                  喜楽        その他  accuracy  macro avg  weighted avg
precision   0.600000   0.734694  0.703125   0.667347      0.688393
recall      0.409091   0.857143  0.703125   0.633117      0.703125
f1-score    0.486486   0.791209  0.703125   0.638848      0.686460
support    22.000000  42.000000  0.703125  64.000000     64.000000
正例のF1値 : 0.4864864859780862
class weight : tensor([0.5648, 0.3853])
best:lr 3.3136089161843005e-06
EPOCH : 1 / 50
VAL_LOSS : 0.4431645394517825 
VAL_ACCURACY : 0.8704156479217604
VAL_F1 : 0.8445747795561785

EPOCH : 2 / 50
VAL_LOSS : 0.3526603734264007 
VAL_ACCURACY : 0.9119804400977995
VAL_F1 : 0.8985915487939139

EPOCH : 3 / 50
VAL_LOSS : 0.2932581463112281 
VAL_ACCURACY : 0.9462102689486552
VAL_F1 : 0.9367816086928591

EPOCH : 4 / 50
VAL_LOSS : 0.24107088119937822 
VAL_ACCURACY : 0.9572127139364304
VAL_F1 : 0.9503546094268256

EPOCH : 5 / 50
VAL_LOSS : 0.21842427379809892 
VAL_ACCURACY : 0.960880195599022
VAL_F1 : 0.9546742204609538

EPOCH : 6 / 50
VAL_LOSS : 0.1769609459890769 
VAL_ACCURACY : 0.960880195599022
VAL_F1 : 0.9546742204609538

EPOCH : 7 / 50
VAL_LOSS : 0.1572669016627165 
VAL_ACCURACY : 0.9584352078239609
VAL_F1 : 0.9519774006278289

EPOCH : 8 / 50
VAL_LOSS : 0.1427944258141976 
VAL_ACCURACY : 0.960880195599022
VAL_F1 : 0.9546742204609538

EPOCH : 9 / 50
VAL_LOSS : 0.12643043524943864 
VAL_ACCURACY : 0.9621026894865525
VAL_F1 : 0.9560283682920577

EPOCH : 10 / 50
VAL_LOSS : 0.11412381180203877 
VAL_ACCURACY : 0.9621026894865525
VAL_F1 : 0.9560283682920577

EPOCH : 11 / 50
VAL_LOSS : 0.10613262151869443 
VAL_ACCURACY : 0.9657701711491442
VAL_F1 : 0.9601139596115535

EPOCH : 12 / 50
VAL_LOSS : 0.09948381043684024 
VAL_ACCURACY : 0.969437652811736
VAL_F1 : 0.9643366614090977

EPOCH : 13 / 50
VAL_LOSS : 0.08801817277876231 
VAL_ACCURACY : 0.9816625916870416
VAL_F1 : 0.9782923294538044

EPOCH : 14 / 50
VAL_LOSS : 0.08042875333474232 
VAL_ACCURACY : 0.991442542787286
VAL_F1 : 0.9898107709672882

EPOCH : 15 / 50
VAL_LOSS : 0.0730131333693862 
VAL_ACCURACY : 0.9938875305623472
VAL_F1 : 0.99270072942411

EPOCH : 16 / 50
VAL_LOSS : 0.06717447169984762 
VAL_ACCURACY : 0.9951100244498777
VAL_F1 : 0.994152046280719

EPOCH : 17 / 50
VAL_LOSS : 0.06286834209011151 
VAL_ACCURACY : 0.9963325183374083
VAL_F1 : 0.9956204374532985

EPOCH : 18 / 50
VAL_LOSS : 0.05944692332727405 
VAL_ACCURACY : 0.9951100244498777
VAL_F1 : 0.9941690957070183

EPOCH : 19 / 50
VAL_LOSS : 0.05581222685913627 
VAL_ACCURACY : 0.9951100244498777
VAL_F1 : 0.9941690957070183

EPOCH : 20 / 50
VAL_LOSS : 0.050815581487348445 
VAL_ACCURACY : 0.9975550122249389
VAL_F1 : 0.9970760228888975

EPOCH : 21 / 50
VAL_LOSS : 0.04789792671083258 
VAL_ACCURACY : 0.9963325183374083
VAL_F1 : 0.9956204374532985

EPOCH : 22 / 50
VAL_LOSS : 0.045545431247983985 
VAL_ACCURACY : 0.9951100244498777
VAL_F1 : 0.994152046280719

EPOCH : 23 / 50
VAL_LOSS : 0.043365374637337833 
VAL_ACCURACY : 0.9963325183374083
VAL_F1 : 0.9956204374532985

EPOCH : 24 / 50
VAL_LOSS : 0.043105216875958904 
VAL_ACCURACY : 0.9963325183374083
VAL_F1 : 0.9956204374532985

EPOCH : 25 / 50
VAL_LOSS : 0.03971291967452718 
VAL_ACCURACY : 0.9951100244498777
VAL_F1 : 0.994152046280719

EPOCH : 26 / 50
VAL_LOSS : 0.040126139047340706 
VAL_ACCURACY : 0.9963325183374083
VAL_F1 : 0.9956204374532985

EPOCH : 27 / 50
VAL_LOSS : 0.03698545794647474 
VAL_ACCURACY : 0.9963325183374083
VAL_F1 : 0.9956076129670711

EPOCH : 28 / 50
VAL_LOSS : 0.034523702871340975 
VAL_ACCURACY : 0.9975550122249389
VAL_F1 : 0.9970760228888975

EPOCH : 29 / 50
VAL_LOSS : 0.033948432152660996 
VAL_ACCURACY : 0.9975550122249389
VAL_F1 : 0.9970845476020536

EPOCH : 30 / 50
VAL_LOSS : 0.03270908258855343 
VAL_ACCURACY : 0.9963325183374083
VAL_F1 : 0.9956076129670711

EPOCH : 31 / 50
VAL_LOSS : 0.03152880488106838 
VAL_ACCURACY : 0.9963325183374083
VAL_F1 : 0.9956204374532985

EPOCH : 32 / 50
VAL_LOSS : 0.03232945799111174 
VAL_ACCURACY : 0.9975550122249389
VAL_F1 : 0.9970760228888975

EPOCH : 33 / 50
VAL_LOSS : 0.02901841517394552 
VAL_ACCURACY : 0.9975550122249389
VAL_F1 : 0.9970760228888975

EPOCH : 34 / 50
VAL_LOSS : 0.028334175129062854 
VAL_ACCURACY : 0.9987775061124694
VAL_F1 : 0.9985401454824872

EPOCH : 35 / 50
VAL_LOSS : 0.027356408428973876 
VAL_ACCURACY : 0.9987775061124694
VAL_F1 : 0.9985401454824872

EPOCH : 36 / 50
VAL_LOSS : 0.02594599948049738 
VAL_ACCURACY : 0.9987775061124694
VAL_F1 : 0.9985401454824872

EPOCH : 37 / 50
VAL_LOSS : 0.025891522088876136 
VAL_ACCURACY : 0.9975550122249389
VAL_F1 : 0.9970760228888975

EPOCH : 38 / 50
VAL_LOSS : 0.026520454360601995 
VAL_ACCURACY : 0.9975550122249389
VAL_F1 : 0.9970674481774323

EPOCH : 39 / 50
VAL_LOSS : 0.02437810923975821 
VAL_ACCURACY : 0.9987775061124694
VAL_F1 : 0.9985401454824872

EPOCH : 40 / 50
VAL_LOSS : 0.023516713480393473 
VAL_ACCURACY : 0.9975550122249389
VAL_F1 : 0.9970760228888975

EPOCH : 41 / 50
VAL_LOSS : 0.02261916372495202 
VAL_ACCURACY : 0.9987775061124694
VAL_F1 : 0.9985358706537388

EPOCH : 42 / 50
VAL_LOSS : 0.021279576127059184 
VAL_ACCURACY : 0.9987775061124694
VAL_F1 : 0.9985401454824872

EPOCH : 43 / 50
VAL_LOSS : 0.020860176837931458 
VAL_ACCURACY : 0.9987775061124694
VAL_F1 : 0.9985401454824872

EPOCH : 44 / 50
VAL_LOSS : 0.019857353369633738 
VAL_ACCURACY : 0.9987775061124694
VAL_F1 : 0.9985401454824872

EPOCH : 45 / 50
VAL_LOSS : 0.01871785197335367 
VAL_ACCURACY : 0.9987775061124694
VAL_F1 : 0.9985401454824872

EPOCH : 46 / 50
VAL_LOSS : 0.01887666048983542 
VAL_ACCURACY : 0.9987775061124694
VAL_F1 : 0.9985401454824872

EPOCH : 47 / 50
VAL_LOSS : 0.01727300285934829 
VAL_ACCURACY : 0.9987775061124694
VAL_F1 : 0.9985401454824872

EPOCH : 48 / 50
VAL_LOSS : 0.017254083739736907 
VAL_ACCURACY : 0.9987775061124694
VAL_F1 : 0.9985401454824872

EPOCH : 49 / 50
VAL_LOSS : 0.01683580857486679 
VAL_ACCURACY : 1.0
VAL_F1 : 0.9999999994970761

EPOCH : 50 / 50
VAL_LOSS : 0.016427396098151803 
VAL_ACCURACY : 0.9987775061124694
VAL_F1 : 0.9985401454824872

# 5話-0
# 文: 今ハマってる本はこの二冊…
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.6737,  1.5579]], device='cuda:0')
# 5話-0
# 文: Bさん、苦手そうだよな…
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
tensor([[ 1.5613, -2.3101]], device='cuda:0')
# 5話-0
# 文: あと、これも読んだよ
正解 : 1 , 予測 : 0 / 元クラス : 憤怒
tensor([[ 1.4595, -2.4413]], device='cuda:0')
# 5話-1
# 文: これ読んだよ
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 1.4551, -2.6784]], device='cuda:0')
# 5話-1
# 文: 夏目漱石だよ〜 Aくんはどんな本を読むの
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.0193,  0.4749]], device='cuda:0')
# 6話-0
# 文: そうなんだ〜 父の分と2つ作ったの
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.7625,  0.9052]], device='cuda:0')
# 6話-0
# 文: ほとんど冷凍食品詰めただけだよ
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-1.7680,  2.2090]], device='cuda:0')
# 6話-0
# 文: 見てもいいですか?
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-1.5223,  1.6986]], device='cuda:0')
# 6話-0
# 文: どうぞどうぞ
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.8238,  0.3905]], device='cuda:0')
# 6話-1
# 文: 俺も今日弁当なんでおかず分けますよ
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.7901,  1.1694]], device='cuda:0')
# 7話-0
# 文: どれがいいですか?
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 0.8332, -0.9290]], device='cuda:0')
# 7話-0
# 文: じゃあチョコですね
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 1.1176, -1.0307]], device='cuda:0')
# 7話-0
# 文: チョコは一つしかないし悪いよ〜
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[ 1.2755, -1.5456]], device='cuda:0')
# 7話-0
# 文: 別に気にしませんが…
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 0.7765, -0.7512]], device='cuda:0')
# 7話-1
# 文: こうやっていろんな食べ方をすれば飽きないですね
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.1773,  1.1631]], device='cuda:0')
# 7話-1
# 文: Aくんがいなければ独り占めできたのにな…
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
tensor([[ 1.6608, -2.6020]], device='cuda:0')
# 8話-0
# 文: 今日は良い実験結果が出たな
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-1.9148,  2.4244]], device='cuda:0')
# 8話-1
# 文: でもわざわざ国際会議から送ってくれたんだよな…
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-1.3545,  0.9314]], device='cuda:0')
# 8話-1
# 文: もう少し頑張るか
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-1.9274,  2.3673]], device='cuda:0')
# 9話-0
# 文: あれ?スペインからもう戻ってきたのか.
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.8979,  1.1118]], device='cuda:0')
# 9話-0
# 文: Bさ…ちょっと!
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
tensor([[ 0.0119, -0.3984]], device='cuda:0')
# 9話-1
# 文: ここは よその研究室…!?
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[ 0.2334, -0.9456]], device='cuda:0')
# 9話-1
# 文: ただいま〜
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-1.5902,  2.2221]], device='cuda:0')
# 9話-1
# 文: おかえりなさい!
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.7935,  1.3078]], device='cuda:0')
------------------------test acc------------------------
Test Acc : 0.6250
correct: 40, total: 64
------------------------------------------------
                  喜楽        その他  accuracy  macro avg  weighted avg
precision   0.444444   0.695652     0.625   0.570048      0.609300
recall      0.363636   0.761905     0.625   0.562771      0.625000
f1-score    0.400000   0.727273     0.625   0.563636      0.614773
support    22.000000  42.000000     0.625  64.000000     64.000000
正例のF1値 : 0.399999999485
class weight : tensor([0.5648, 0.3853])
best:lr 5.72442391082136e-06
EPOCH : 1 / 50
VAL_LOSS : 0.3753521717511691 
VAL_ACCURACY : 0.8960880195599022
VAL_F1 : 0.8827586201888191

EPOCH : 2 / 50
VAL_LOSS : 0.25570674956991124 
VAL_ACCURACY : 0.9523227383863081
VAL_F1 : 0.9448373403748012

EPOCH : 3 / 50
VAL_LOSS : 0.17810986348642752 
VAL_ACCURACY : 0.9547677261613692
VAL_F1 : 0.9478138217828563

EPOCH : 4 / 50
VAL_LOSS : 0.13413196737663105 
VAL_ACCURACY : 0.9633251833740831
VAL_F1 : 0.9573863631340473

EPOCH : 5 / 50
VAL_LOSS : 0.10541012718413885 
VAL_ACCURACY : 0.9767726161369193
VAL_F1 : 0.97258297208025

EPOCH : 6 / 50
VAL_LOSS : 0.08903379910267316 
VAL_ACCURACY : 0.9841075794621027
VAL_F1 : 0.9812949635260785

EPOCH : 7 / 50
VAL_LOSS : 0.07098664318283017 
VAL_ACCURACY : 0.991442542787286
VAL_F1 : 0.9897510975937354

EPOCH : 8 / 50
VAL_LOSS : 0.06260682857380463 
VAL_ACCURACY : 0.988997555012225
VAL_F1 : 0.9869753974711455

EPOCH : 9 / 50
VAL_LOSS : 0.05410725340390435 
VAL_ACCURACY : 0.9926650366748166
VAL_F1 : 0.9912790692645772

EPOCH : 10 / 50
VAL_LOSS : 0.050516589293972805 
VAL_ACCURACY : 0.9963325183374083
VAL_F1 : 0.9956204374532985

EPOCH : 11 / 50
VAL_LOSS : 0.049857221687069304 
VAL_ACCURACY : 0.9951100244498777
VAL_F1 : 0.9941348968577929

EPOCH : 12 / 50
VAL_LOSS : 0.03704792483208271 
VAL_ACCURACY : 0.9975550122249389
VAL_F1 : 0.9970760228888975

EPOCH : 13 / 50
VAL_LOSS : 0.03394224188433817 
VAL_ACCURACY : 0.9975550122249389
VAL_F1 : 0.9970760228888975

EPOCH : 14 / 50
VAL_LOSS : 0.03229320912550275 
VAL_ACCURACY : 0.9987775061124694
VAL_F1 : 0.9985358706537388

EPOCH : 15 / 50
VAL_LOSS : 0.02860640909952613 
VAL_ACCURACY : 0.9987775061124694
VAL_F1 : 0.9985358706537388

EPOCH : 16 / 50
VAL_LOSS : 0.028408924063954216 
VAL_ACCURACY : 0.9951100244498777
VAL_F1 : 0.9941690957070183

EPOCH : 17 / 50
VAL_LOSS : 0.024469122057780623 
VAL_ACCURACY : 0.9975550122249389
VAL_F1 : 0.9970674481774323

EPOCH : 18 / 50
VAL_LOSS : 0.02235535833124931 
VAL_ACCURACY : 0.9987775061124694
VAL_F1 : 0.9985358706537388

EPOCH : 19 / 50
VAL_LOSS : 0.02078401644785817 
VAL_ACCURACY : 0.9975550122249389
VAL_F1 : 0.9970845476020536

EPOCH : 20 / 50
VAL_LOSS : 0.01924710154819947 
VAL_ACCURACY : 1.0
VAL_F1 : 0.9999999994970761

EPOCH : 21 / 50
VAL_LOSS : 0.019199997920972798 
VAL_ACCURACY : 1.0
VAL_F1 : 0.9999999994970761

EPOCH : 22 / 50
VAL_LOSS : 0.018597782786505725 
VAL_ACCURACY : 1.0
VAL_F1 : 0.9999999994970761

EPOCH : 23 / 50
VAL_LOSS : 0.01717169350013137 
VAL_ACCURACY : 1.0
VAL_F1 : 0.9999999994970761

EPOCH : 24 / 50
VAL_LOSS : 0.01609395002014935 
VAL_ACCURACY : 1.0
VAL_F1 : 0.9999999994970761

EPOCH : 25 / 50
VAL_LOSS : 0.014685622004505534 
VAL_ACCURACY : 1.0
VAL_F1 : 0.9999999994970761

EPOCH : 26 / 50
VAL_LOSS : 0.013450874087329093 
VAL_ACCURACY : 1.0
VAL_F1 : 0.9999999994970761

EPOCH : 27 / 50
VAL_LOSS : 0.012827819714752527 
VAL_ACCURACY : 1.0
VAL_F1 : 0.9999999994970761

EPOCH : 28 / 50
VAL_LOSS : 0.012175675678568391 
VAL_ACCURACY : 1.0
VAL_F1 : 0.9999999994970761

EPOCH : 29 / 50
VAL_LOSS : 0.012607584743259044 
VAL_ACCURACY : 1.0
VAL_F1 : 0.9999999994970761

EPOCH : 30 / 50
VAL_LOSS : 0.01124041980633942 
VAL_ACCURACY : 1.0
VAL_F1 : 0.9999999994970761

EPOCH : 31 / 50
VAL_LOSS : 0.011908079202000339 
VAL_ACCURACY : 0.9987775061124694
VAL_F1 : 0.9985401454824872

EPOCH : 32 / 50
VAL_LOSS : 0.010713012575601729 
VAL_ACCURACY : 1.0
VAL_F1 : 0.9999999994970761

EPOCH : 33 / 50
VAL_LOSS : 0.010383133561565326 
VAL_ACCURACY : 1.0
VAL_F1 : 0.9999999994970761

EPOCH : 34 / 50
VAL_LOSS : 0.009328513253981678 
VAL_ACCURACY : 1.0
VAL_F1 : 0.9999999994970761

EPOCH : 35 / 50
VAL_LOSS : 0.009284264067761026 
VAL_ACCURACY : 1.0
VAL_F1 : 0.9999999994970761

EPOCH : 36 / 50
VAL_LOSS : 0.00910319138963062 
VAL_ACCURACY : 1.0
VAL_F1 : 0.9999999994970761

EPOCH : 37 / 50
VAL_LOSS : 0.00986711431043939 
VAL_ACCURACY : 0.9975550122249389
VAL_F1 : 0.9970845476020536

EPOCH : 38 / 50
VAL_LOSS : 0.008776642829896165 
VAL_ACCURACY : 0.9987775061124694
VAL_F1 : 0.9985401454824872

EPOCH : 39 / 50
VAL_LOSS : 0.007798091812918966 
VAL_ACCURACY : 1.0
VAL_F1 : 0.9999999994970761

EPOCH : 40 / 50
VAL_LOSS : 0.007901423754027257 
VAL_ACCURACY : 0.9987775061124694
VAL_F1 : 0.9985401454824872

EPOCH : 41 / 50
VAL_LOSS : 0.006699503748677671 
VAL_ACCURACY : 1.0
VAL_F1 : 0.9999999994970761

EPOCH : 42 / 50
VAL_LOSS : 0.0062864151102705644 
VAL_ACCURACY : 1.0
VAL_F1 : 0.9999999994970761

EPOCH : 43 / 50
VAL_LOSS : 0.008266876603906544 
VAL_ACCURACY : 0.9975550122249389
VAL_F1 : 0.9970845476020536

EPOCH : 44 / 50
VAL_LOSS : 0.008393455977336718 
VAL_ACCURACY : 0.9975550122249389
VAL_F1 : 0.9970845476020536

EPOCH : 45 / 50
VAL_LOSS : 0.006984490731086295 
VAL_ACCURACY : 1.0
VAL_F1 : 0.9999999994970761

EPOCH : 46 / 50
VAL_LOSS : 0.0061015644415210075 
VAL_ACCURACY : 1.0
VAL_F1 : 0.9999999994970761

EPOCH : 47 / 50
VAL_LOSS : 0.008285892648228373 
VAL_ACCURACY : 0.9975550122249389
VAL_F1 : 0.9970845476020536

EPOCH : 48 / 50
VAL_LOSS : 0.005425606527401565 
VAL_ACCURACY : 1.0
VAL_F1 : 0.9999999994970761

EPOCH : 49 / 50
VAL_LOSS : 0.005015419742379051 
VAL_ACCURACY : 1.0
VAL_F1 : 0.9999999994970761

EPOCH : 50 / 50
VAL_LOSS : 0.004862249824397553 
VAL_ACCURACY : 1.0
VAL_F1 : 0.9999999994970761

# 5話-0
# 文: 夏目漱石だよ〜 Aくんはどんな本を読むの
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-1.4108,  0.6299]], device='cuda:0')
# 5話-0
# 文: 今ハマってる本はこの二冊…
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.6563,  0.4689]], device='cuda:0')
# 5話-0
# 文: Bさん、苦手そうだよな…
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
tensor([[ 1.8921, -0.7467]], device='cuda:0')
# 5話-0
# 文: あと、これも読んだよ
正解 : 1 , 予測 : 0 / 元クラス : 憤怒
tensor([[ 2.2311, -1.1272]], device='cuda:0')
# 5話-1
# 文: これ読んだよ
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 2.6669, -1.2630]], device='cuda:0')
# 5話-1
# 文: 夏目漱石だよ〜 Aくんはどんな本を読むの
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-1.3799,  0.7860]], device='cuda:0')
# 6話-0
# 文: そうなんだ〜 父の分と2つ作ったの
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-1.5435,  1.0465]], device='cuda:0')
# 6話-0
# 文: ほとんど冷凍食品詰めただけだよ
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-2.4870,  1.3479]], device='cuda:0')
# 6話-0
# 文: 見てもいいですか?
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-2.4236,  1.2786]], device='cuda:0')
# 6話-0
# 文: どうぞどうぞ
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-1.3986,  0.8497]], device='cuda:0')
# 6話-1
# 文: 俺も今日弁当なんでおかず分けますよ
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-1.6388,  0.9357]], device='cuda:0')
# 7話-0
# 文: チョコは一つしかないし悪いよ〜
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[0.5275, 0.5064]], device='cuda:0')
# 7話-0
# 文: ジャーン!パフェを作ってみました〜!
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.0941,  0.2661]], device='cuda:0')
# 7話-1
# 文: こうやっていろんな食べ方をすれば飽きないですね
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.7844,  0.4870]], device='cuda:0')
# 7話-1
# 文: Aくんがいなければ独り占めできたのにな…
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
tensor([[ 2.9070, -1.1509]], device='cuda:0')
# 8話-0
# 文: 今日は良い実験結果が出たな
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-2.7777,  1.4533]], device='cuda:0')
# 8話-1
# 文: でもわざわざ国際会議から送ってくれたんだよな…
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-2.1771,  0.5984]], device='cuda:0')
# 8話-1
# 文: もう少し頑張るか
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-2.5419,  1.2246]], device='cuda:0')
# 9話-0
# 文: あれ?スペインからもう戻ってきたのか.
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-1.8646,  0.8456]], device='cuda:0')
# 9話-1
# 文: ここは よその研究室…!?
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[ 0.2962, -0.3940]], device='cuda:0')
# 9話-1
# 文: ただいま〜
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-2.2637,  1.2639]], device='cuda:0')
# 9話-1
# 文: おかえりなさい!
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-1.4585,  1.0074]], device='cuda:0')
------------------------test acc------------------------
Test Acc : 0.6562
correct: 42, total: 64
------------------------------------------------
                  喜楽        その他  accuracy  macro avg  weighted avg
precision   0.500000   0.692308   0.65625   0.596154      0.626202
recall      0.272727   0.857143   0.65625   0.564935      0.656250
f1-score    0.352941   0.765957   0.65625   0.559449      0.623983
support    22.000000  42.000000   0.65625  64.000000     64.000000
正例のF1値 : 0.35294117599307956
