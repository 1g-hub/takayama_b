class weight : tensor([0.3485, 0.9347])
best:lr 3.951314221760114e-07
EPOCH : 1 / 50
VAL_LOSS : 0.6530774183133069 
VAL_ACCURACY : 0.7346437346437347
VAL_F1 : 0.7999999994987654

EPOCH : 2 / 50
VAL_LOSS : 0.6011621730000365 
VAL_ACCURACY : 0.6977886977886978
VAL_F1 : 0.7611650480447922

EPOCH : 3 / 50
VAL_LOSS : 0.5667888697455911 
VAL_ACCURACY : 0.7174447174447175
VAL_F1 : 0.7653061219554227

EPOCH : 4 / 50
VAL_LOSS : 0.5410035848617554 
VAL_ACCURACY : 0.7506142506142506
VAL_F1 : 0.7917948713020002

EPOCH : 5 / 50
VAL_LOSS : 0.517529654152253 
VAL_ACCURACY : 0.7628992628992629
VAL_F1 : 0.8036622578986162

EPOCH : 6 / 50
VAL_LOSS : 0.49769371222047243 
VAL_ACCURACY : 0.7751842751842751
VAL_F1 : 0.8157099692931243

EPOCH : 7 / 50
VAL_LOSS : 0.4813108134503458 
VAL_ACCURACY : 0.7764127764127764
VAL_F1 : 0.8169014079551838

EPOCH : 8 / 50
VAL_LOSS : 0.46360935066260545 
VAL_ACCURACY : 0.7825552825552825
VAL_F1 : 0.8228228223266991

EPOCH : 9 / 50
VAL_LOSS : 0.4497014780839284 
VAL_ACCURACY : 0.7874692874692875
VAL_F1 : 0.827517447160449

EPOCH : 10 / 50
VAL_LOSS : 0.4324694229107277 
VAL_ACCURACY : 0.7899262899262899
VAL_F1 : 0.8298507457718572

EPOCH : 11 / 50
VAL_LOSS : 0.4228554034934324 
VAL_ACCURACY : 0.7911547911547911
VAL_F1 : 0.8310139160040869

EPOCH : 12 / 50
VAL_LOSS : 0.41018638599152657 
VAL_ACCURACY : 0.7911547911547911
VAL_F1 : 0.8310139160040869

EPOCH : 13 / 50
VAL_LOSS : 0.3986760640845579 
VAL_ACCURACY : 0.7911547911547911
VAL_F1 : 0.8310139160040869

EPOCH : 14 / 50
VAL_LOSS : 0.38900090140454907 
VAL_ACCURACY : 0.7972972972972973
VAL_F1 : 0.8367952517280948

EPOCH : 15 / 50
VAL_LOSS : 0.3777461536959106 
VAL_ACCURACY : 0.8095823095823096
VAL_F1 : 0.8478900878236991

EPOCH : 16 / 50
VAL_LOSS : 0.3679700412002264 
VAL_ACCURACY : 0.8402948402948403
VAL_F1 : 0.873294346479745

EPOCH : 17 / 50
VAL_LOSS : 0.3596055805683136 
VAL_ACCURACY : 0.8660933660933661
VAL_F1 : 0.8956937794041857

EPOCH : 18 / 50
VAL_LOSS : 0.35103677505371617 
VAL_ACCURACY : 0.9115479115479116
VAL_F1 : 0.9334565614208473

EPOCH : 19 / 50
VAL_LOSS : 0.3447760159478468 
VAL_ACCURACY : 0.9213759213759214
VAL_F1 : 0.940850276762793

EPOCH : 20 / 50
VAL_LOSS : 0.33522480813895955 
VAL_ACCURACY : 0.9262899262899262
VAL_F1 : 0.9447513807138671

EPOCH : 21 / 50
VAL_LOSS : 0.3255184514849794 
VAL_ACCURACY : 0.9312039312039312
VAL_F1 : 0.9485294112630704

EPOCH : 22 / 50
VAL_LOSS : 0.3208085424175449 
VAL_ACCURACY : 0.9312039312039312
VAL_F1 : 0.9485294112630704

EPOCH : 23 / 50
VAL_LOSS : 0.3129652373346628 
VAL_ACCURACY : 0.9324324324324325
VAL_F1 : 0.9494020234174186

EPOCH : 24 / 50
VAL_LOSS : 0.3097435685933805 
VAL_ACCURACY : 0.9336609336609336
VAL_F1 : 0.95027624259231

EPOCH : 25 / 50
VAL_LOSS : 0.2994008619411319 
VAL_ACCURACY : 0.9324324324324325
VAL_F1 : 0.9494020234174186

EPOCH : 26 / 50
VAL_LOSS : 0.29641804186736836 
VAL_ACCURACY : 0.9324324324324325
VAL_F1 : 0.9494020234174186

EPOCH : 27 / 50
VAL_LOSS : 0.29222965970927595 
VAL_ACCURACY : 0.9324324324324325
VAL_F1 : 0.9494020234174186

EPOCH : 28 / 50
VAL_LOSS : 0.28176118988616794 
VAL_ACCURACY : 0.9324324324324325
VAL_F1 : 0.9494020234174186

EPOCH : 29 / 50
VAL_LOSS : 0.2810419610902375 
VAL_ACCURACY : 0.9348894348894349
VAL_F1 : 0.9511520732311188

EPOCH : 30 / 50
VAL_LOSS : 0.27567361675056756 
VAL_ACCURACY : 0.9348894348894349
VAL_F1 : 0.9511520732311188

EPOCH : 31 / 50
VAL_LOSS : 0.27224793591920066 
VAL_ACCURACY : 0.9348894348894349
VAL_F1 : 0.9511520732311188

EPOCH : 32 / 50
VAL_LOSS : 0.2640354171687481 
VAL_ACCURACY : 0.9336609336609336
VAL_F1 : 0.95027624259231

EPOCH : 33 / 50
VAL_LOSS : 0.2604627603409337 
VAL_ACCURACY : 0.9324324324324325
VAL_F1 : 0.9494020234174186

EPOCH : 34 / 50
VAL_LOSS : 0.2582332950596716 
VAL_ACCURACY : 0.9324324324324325
VAL_F1 : 0.9494020234174186

EPOCH : 35 / 50
VAL_LOSS : 0.2507220262698099 
VAL_ACCURACY : 0.9312039312039312
VAL_F1 : 0.9484346219661624

EPOCH : 36 / 50
VAL_LOSS : 0.24667475942303152 
VAL_ACCURACY : 0.9336609336609336
VAL_F1 : 0.95027624259231

EPOCH : 37 / 50
VAL_LOSS : 0.24285886173739152 
VAL_ACCURACY : 0.9324324324324325
VAL_F1 : 0.9493087552587722

EPOCH : 38 / 50
VAL_LOSS : 0.23916429704895206 
VAL_ACCURACY : 0.9324324324324325
VAL_F1 : 0.9493087552587722

EPOCH : 39 / 50
VAL_LOSS : 0.23586751710550458 
VAL_ACCURACY : 0.9324324324324325
VAL_F1 : 0.9493087552587722

EPOCH : 40 / 50
VAL_LOSS : 0.23112469940793282 
VAL_ACCURACY : 0.9348894348894349
VAL_F1 : 0.9511520732311188

EPOCH : 41 / 50
VAL_LOSS : 0.2270840904584118 
VAL_ACCURACY : 0.9348894348894349
VAL_F1 : 0.9511520732311188

EPOCH : 42 / 50
VAL_LOSS : 0.22228126520035313 
VAL_ACCURACY : 0.9348894348894349
VAL_F1 : 0.9510618646877206

EPOCH : 43 / 50
VAL_LOSS : 0.21986905821398192 
VAL_ACCURACY : 0.9348894348894349
VAL_F1 : 0.9509713223476807

EPOCH : 44 / 50
VAL_LOSS : 0.21483874481682683 
VAL_ACCURACY : 0.9385749385749386
VAL_F1 : 0.9539594838446052

EPOCH : 45 / 50
VAL_LOSS : 0.21265836103874095 
VAL_ACCURACY : 0.9398034398034398
VAL_F1 : 0.9547553088243713

EPOCH : 46 / 50
VAL_LOSS : 0.20722857263742708 
VAL_ACCURACY : 0.9398034398034398
VAL_F1 : 0.9547553088243713

EPOCH : 47 / 50
VAL_LOSS : 0.20650709084436006 
VAL_ACCURACY : 0.9385749385749386
VAL_F1 : 0.953789278611198

EPOCH : 48 / 50
VAL_LOSS : 0.20270520010415247 
VAL_ACCURACY : 0.9398034398034398
VAL_F1 : 0.9546715998684879

EPOCH : 49 / 50
VAL_LOSS : 0.20011605643758587 
VAL_ACCURACY : 0.9422604422604423
VAL_F1 : 0.9566820271481594

EPOCH : 50 / 50
VAL_LOSS : 0.19454284202234418 
VAL_ACCURACY : 0.9422604422604423
VAL_F1 : 0.9564411487107292

# 5話-0
# 文: 適当に流そう
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.4074,  0.4289]], device='cuda:0')
# 5話-0
# 文: そうなんだ〜
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 0.8857, -0.0607]], device='cuda:0')
# 5話-0
# 文: あと、これも読んだよ
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.1069,  0.7426]], device='cuda:0')
# 5話-1
# 文: これ読んだよ
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.2548,  0.6503]], device='cuda:0')
# 5話-1
# 文: 夏目漱石だよ〜 Aくんはどんな本を読むの
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.7680,  0.4124]], device='cuda:0')
# 5話-1
# 文: 僕ですか?
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-1.4211,  0.8381]], device='cuda:0')
# 5話-1
# 文: 本当に今ハマってる本はこの二冊…
正解 : 1 , 予測 : 0 / 元クラス : 恐怖
tensor([[ 0.5947, -0.1526]], device='cuda:0')
# 6話-0
# 文: 今日弁当なんですね
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[0.1580, 0.4369]], device='cuda:0')
# 6話-0
# 文: 手作りなんですか?
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.2288,  0.5595]], device='cuda:0')
# 6話-1
# 文: 今日弁当なの珍しいですね
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.5068,  0.6140]], device='cuda:0')
# 6話-1
# 文: ほとんど冷凍食品詰めただけよ…
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
tensor([[ 2.2047, -0.5306]], device='cuda:0')
# 7話-0
# 文: どれがいいですか?
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.1204,  0.3885]], device='cuda:0')
# 7話-0
# 文: じゃあチョコですね
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[0.4735, 0.5162]], device='cuda:0')
# 7話-0
# 文: チョコは一つしかないし、悪いよ〜
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
tensor([[0.8881, 0.2615]], device='cuda:0')
# 7話-0
# 文: ジャーン!パフェを作ってみました〜!
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.0023,  0.5559]], device='cuda:0')
# 7話-1
# 文: 器用だ!?
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[ 1.3736, -0.1500]], device='cuda:0')
# 7話-1
# 文: こうやっていろんな食べ方をすれば飽きないですね
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.9316,  0.7130]], device='cuda:0')
# 8話-1
# 文: もう少し頑張るか
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.0980,  0.3832]], device='cuda:0')
# 9話-0
# 文: Bさん…
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.6225,  0.4992]], device='cuda:0')
# 9話-0
# 文: ?
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[1.6617, 0.0971]], device='cuda:0')
# 9話-0
# 文: 人違い!?
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[1.7155, 0.1263]], device='cuda:0')
# 9話-1
# 文: 人違い!?
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[1.3235, 0.3643]], device='cuda:0')
# 9話-1
# 文: ?
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[0.5766, 0.2635]], device='cuda:0')
------------------------test acc------------------------
Test Acc : 0.6567
correct: 44, total: 67
------------------------------------------------
                  喜楽        その他  accuracy  macro avg  weighted avg
precision   0.727273   0.588235  0.656716   0.657754      0.667092
recall      0.631579   0.689655  0.656716   0.660617      0.656716
f1-score    0.676056   0.634921  0.656716   0.655488      0.658251
support    38.000000  29.000000  0.656716  67.000000     67.000000
正例のF1値 : 0.6760563375116049
class weight : tensor([0.3485, 0.9347])
best:lr 1.5985702277017555e-06
EPOCH : 1 / 50
VAL_LOSS : 0.4960033887741612 
VAL_ACCURACY : 0.7886977886977887
VAL_F1 : 0.8300395251941914

EPOCH : 2 / 50
VAL_LOSS : 0.4209761122862498 
VAL_ACCURACY : 0.8488943488943489
VAL_F1 : 0.8842897455009616

EPOCH : 3 / 50
VAL_LOSS : 0.3663717268728742 
VAL_ACCURACY : 0.8918918918918919
VAL_F1 : 0.9212880138097004

EPOCH : 4 / 50
VAL_LOSS : 0.3309033442946041 
VAL_ACCURACY : 0.9115479115479116
VAL_F1 : 0.9346642463222619

EPOCH : 5 / 50
VAL_LOSS : 0.305440011269906 
VAL_ACCURACY : 0.9262899262899262
VAL_F1 : 0.9449541279387157

EPOCH : 6 / 50
VAL_LOSS : 0.2801532840319708 
VAL_ACCURACY : 0.9287469287469288
VAL_F1 : 0.946886446384773

EPOCH : 7 / 50
VAL_LOSS : 0.2602074160879734 
VAL_ACCURACY : 0.9312039312039312
VAL_F1 : 0.9485294112630704

EPOCH : 8 / 50
VAL_LOSS : 0.23984077616649516 
VAL_ACCURACY : 0.9312039312039312
VAL_F1 : 0.9484346219661624

EPOCH : 9 / 50
VAL_LOSS : 0.2263342340787252 
VAL_ACCURACY : 0.9336609336609336
VAL_F1 : 0.9498141258926253

EPOCH : 10 / 50
VAL_LOSS : 0.21317580809780196 
VAL_ACCURACY : 0.9336609336609336
VAL_F1 : 0.9495327097791039

EPOCH : 11 / 50
VAL_LOSS : 0.19746199016477547 
VAL_ACCURACY : 0.941031941031941
VAL_F1 : 0.9554730978287593

EPOCH : 12 / 50
VAL_LOSS : 0.19033484905958176 
VAL_ACCURACY : 0.941031941031941
VAL_F1 : 0.9552238800956784

EPOCH : 13 / 50
VAL_LOSS : 0.17786534525015774 
VAL_ACCURACY : 0.941031941031941
VAL_F1 : 0.9552238800956784

EPOCH : 14 / 50
VAL_LOSS : 0.16316884179033486 
VAL_ACCURACY : 0.9533169533169533
VAL_F1 : 0.9649446489448843

EPOCH : 15 / 50
VAL_LOSS : 0.15241710330341376 
VAL_ACCURACY : 0.9508599508599509
VAL_F1 : 0.9629629624614267

EPOCH : 16 / 50
VAL_LOSS : 0.14518685573164156 
VAL_ACCURACY : 0.9533169533169533
VAL_F1 : 0.9647495356766087

EPOCH : 17 / 50
VAL_LOSS : 0.1334447908562188 
VAL_ACCURACY : 0.9557739557739557
VAL_F1 : 0.96654275042791

EPOCH : 18 / 50
VAL_LOSS : 0.1253330401491885 
VAL_ACCURACY : 0.9594594594594594
VAL_F1 : 0.9695852529545873

EPOCH : 19 / 50
VAL_LOSS : 0.11524968031866878 
VAL_ACCURACY : 0.9643734643734644
VAL_F1 : 0.9733210666556452

EPOCH : 20 / 50
VAL_LOSS : 0.11091037686256801 
VAL_ACCURACY : 0.961916461916462
VAL_F1 : 0.9713758074392991

EPOCH : 21 / 50
VAL_LOSS : 0.10326849464692321 
VAL_ACCURACY : 0.9643734643734644
VAL_F1 : 0.9733210666556452

EPOCH : 22 / 50
VAL_LOSS : 0.10045945688205607 
VAL_ACCURACY : 0.9680589680589681
VAL_F1 : 0.9760589313583766

EPOCH : 23 / 50
VAL_LOSS : 0.09653984663971499 
VAL_ACCURACY : 0.9717444717444718
VAL_F1 : 0.9788408458644666

EPOCH : 24 / 50
VAL_LOSS : 0.09010286158060327 
VAL_ACCURACY : 0.9717444717444718
VAL_F1 : 0.9789184229629878

EPOCH : 25 / 50
VAL_LOSS : 0.08649139982812545 
VAL_ACCURACY : 0.9742014742014742
VAL_F1 : 0.9808219173064615

EPOCH : 26 / 50
VAL_LOSS : 0.08181131780878001 
VAL_ACCURACY : 0.9766584766584766
VAL_F1 : 0.9826484013247231

EPOCH : 27 / 50
VAL_LOSS : 0.07598949523240912 
VAL_ACCURACY : 0.9828009828009828
VAL_F1 : 0.9872727267709388

EPOCH : 28 / 50
VAL_LOSS : 0.0756028714936738 
VAL_ACCURACY : 0.9828009828009828
VAL_F1 : 0.9872727267709388

EPOCH : 29 / 50
VAL_LOSS : 0.07299468271872576 
VAL_ACCURACY : 0.9815724815724816
VAL_F1 : 0.9863512278876603

EPOCH : 30 / 50
VAL_LOSS : 0.07008052255739183 
VAL_ACCURACY : 0.9815724815724816
VAL_F1 : 0.9863512278876603

EPOCH : 31 / 50
VAL_LOSS : 0.06987796395140536 
VAL_ACCURACY : 0.9828009828009828
VAL_F1 : 0.9872727267709388

EPOCH : 32 / 50
VAL_LOSS : 0.06356423147314903 
VAL_ACCURACY : 0.984029484029484
VAL_F1 : 0.9881925517234584

EPOCH : 33 / 50
VAL_LOSS : 0.06201560550606718 
VAL_ACCURACY : 0.9852579852579852
VAL_F1 : 0.9891107073021993

EPOCH : 34 / 50
VAL_LOSS : 0.05937415774108148 
VAL_ACCURACY : 0.9864864864864865
VAL_F1 : 0.990027198047616

EPOCH : 35 / 50
VAL_LOSS : 0.05813984777413163 
VAL_ACCURACY : 0.9864864864864865
VAL_F1 : 0.990027198047616

EPOCH : 36 / 50
VAL_LOSS : 0.055728085777338815 
VAL_ACCURACY : 0.9852579852579852
VAL_F1 : 0.9891107073021993

EPOCH : 37 / 50
VAL_LOSS : 0.05620209445409915 
VAL_ACCURACY : 0.9877149877149877
VAL_F1 : 0.990925589334864

EPOCH : 38 / 50
VAL_LOSS : 0.05236203409731388 
VAL_ACCURACY : 0.9889434889434889
VAL_F1 : 0.9918256125772211

EPOCH : 39 / 50
VAL_LOSS : 0.05026695029992683 
VAL_ACCURACY : 0.9889434889434889
VAL_F1 : 0.9918404346749926

EPOCH : 40 / 50
VAL_LOSS : 0.04957070687383998 
VAL_ACCURACY : 0.9901719901719902
VAL_F1 : 0.9927404713675285

EPOCH : 41 / 50
VAL_LOSS : 0.047339000720895974 
VAL_ACCURACY : 0.9901719901719902
VAL_F1 : 0.9927404713675285

EPOCH : 42 / 50
VAL_LOSS : 0.04621633149537386 
VAL_ACCURACY : 0.9901719901719902
VAL_F1 : 0.9927404713675285

EPOCH : 43 / 50
VAL_LOSS : 0.04627302100918457 
VAL_ACCURACY : 0.9901719901719902
VAL_F1 : 0.9927404713675285

EPOCH : 44 / 50
VAL_LOSS : 0.04653019430663656 
VAL_ACCURACY : 0.9901719901719902
VAL_F1 : 0.9927404713675285

EPOCH : 45 / 50
VAL_LOSS : 0.04430712270093899 
VAL_ACCURACY : 0.9914004914004914
VAL_F1 : 0.993653671302369

EPOCH : 46 / 50
VAL_LOSS : 0.04115522238334604 
VAL_ACCURACY : 0.9914004914004914
VAL_F1 : 0.993653671302369

EPOCH : 47 / 50
VAL_LOSS : 0.0414694872703038 
VAL_ACCURACY : 0.9901719901719902
VAL_F1 : 0.9927404713675285

EPOCH : 48 / 50
VAL_LOSS : 0.04163063788676963 
VAL_ACCURACY : 0.9914004914004914
VAL_F1 : 0.993653671302369

EPOCH : 49 / 50
VAL_LOSS : 0.040966858009935596 
VAL_ACCURACY : 0.9901719901719902
VAL_F1 : 0.9927404713675285

EPOCH : 50 / 50
VAL_LOSS : 0.03897124287836692 
VAL_ACCURACY : 0.9914004914004914
VAL_F1 : 0.993653671302369

# 5話-0
# 文: 適当に流そう
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.5835,  0.3916]], device='cuda:0')
# 5話-0
# 文: そうなんだ〜
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 1.1713, -2.2488]], device='cuda:0')
# 5話-0
# 文: あと、これも読んだよ
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.4965,  0.9130]], device='cuda:0')
# 5話-1
# 文: 僕ですか?
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-1.1953,  1.9390]], device='cuda:0')
# 5話-1
# 文: 本当に今ハマってる本はこの二冊…
正解 : 1 , 予測 : 0 / 元クラス : 恐怖
tensor([[0.4714, 0.0892]], device='cuda:0')
# 6話-0
# 文: 手作りなんですか?
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.8180,  1.4895]], device='cuda:0')
# 6話-1
# 文: 今日弁当なの珍しいですね
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.4552,  0.8117]], device='cuda:0')
# 6話-1
# 文: ほとんど冷凍食品詰めただけよ…
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
tensor([[ 1.6425, -2.8472]], device='cuda:0')
# 7話-0
# 文: どれがいいですか?
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[0.0379, 0.1069]], device='cuda:0')
# 7話-0
# 文: チョコは一つしかないし、悪いよ〜
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
tensor([[ 0.9478, -1.7409]], device='cuda:0')
# 7話-0
# 文: ジャーン!パフェを作ってみました〜!
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[0.0102, 1.1131]], device='cuda:0')
# 7話-1
# 文: 器用だ!?
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[ 1.3064, -1.7785]], device='cuda:0')
# 7話-1
# 文: こうやっていろんな食べ方をすれば飽きないですね
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.0117,  0.6846]], device='cuda:0')
# 8話-1
# 文: でも わざわざ国際会議から送ってくれたんだよな…
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
tensor([[ 0.3781, -0.9220]], device='cuda:0')
# 8話-1
# 文: もう少し頑張るか
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[0.0594, 0.1680]], device='cuda:0')
# 9話-0
# 文: Bさん…
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-1.2732,  2.4105]], device='cuda:0')
# 9話-0
# 文: ?
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 0.7355, -1.3103]], device='cuda:0')
# 9話-0
# 文: 人違い!?
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[ 0.8139, -1.3504]], device='cuda:0')
# 9話-1
# 文: 人違い!?
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[0.2637, 0.0774]], device='cuda:0')
# 9話-1
# 文: ?
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 0.3004, -0.3234]], device='cuda:0')
------------------------test acc------------------------
Test Acc : 0.7015
correct: 47, total: 67
------------------------------------------------
                  喜楽        その他  accuracy  macro avg  weighted avg
precision   0.736842   0.655172  0.701493   0.696007      0.701493
recall      0.736842   0.655172  0.701493   0.696007      0.701493
f1-score    0.736842   0.655172  0.701493   0.696007      0.701493
support    38.000000  29.000000  0.701493  67.000000     67.000000
正例のF1値 : 0.7368421047437672
class weight : tensor([0.3485, 0.9347])
best:lr 3.3204124577722935e-06
EPOCH : 1 / 50
VAL_LOSS : 0.46619007458873823 
VAL_ACCURACY : 0.7972972972972973
VAL_F1 : 0.8408871740424134

EPOCH : 2 / 50
VAL_LOSS : 0.3717121335805631 
VAL_ACCURACY : 0.8611793611793612
VAL_F1 : 0.8956602026379614

EPOCH : 3 / 50
VAL_LOSS : 0.3199298229872012 
VAL_ACCURACY : 0.9152334152334153
VAL_F1 : 0.9365225385968353

EPOCH : 4 / 50
VAL_LOSS : 0.2761787117696276 
VAL_ACCURACY : 0.9299754299754299
VAL_F1 : 0.9474654372864254

EPOCH : 5 / 50
VAL_LOSS : 0.24208069928720885 
VAL_ACCURACY : 0.9373464373464373
VAL_F1 : 0.9528214611080841

EPOCH : 6 / 50
VAL_LOSS : 0.216766497668098 
VAL_ACCURACY : 0.9434889434889435
VAL_F1 : 0.9574861362821708

EPOCH : 7 / 50
VAL_LOSS : 0.18721245185417287 
VAL_ACCURACY : 0.9545454545454546
VAL_F1 : 0.9658986170098935

EPOCH : 8 / 50
VAL_LOSS : 0.1647957436302129 
VAL_ACCURACY : 0.9594594594594594
VAL_F1 : 0.9696969691952837

EPOCH : 9 / 50
VAL_LOSS : 0.14859510958194733 
VAL_ACCURACY : 0.9582309582309583
VAL_F1 : 0.9686924488537862

EPOCH : 10 / 50
VAL_LOSS : 0.12918116838908664 
VAL_ACCURACY : 0.9656019656019657
VAL_F1 : 0.9743589738572501

EPOCH : 11 / 50
VAL_LOSS : 0.12189676503048223 
VAL_ACCURACY : 0.9668304668304668
VAL_F1 : 0.9752066110685518

EPOCH : 12 / 50
VAL_LOSS : 0.10699419998655132 
VAL_ACCURACY : 0.9766584766584766
VAL_F1 : 0.9827115554581856

EPOCH : 13 / 50
VAL_LOSS : 0.09784770019206346 
VAL_ACCURACY : 0.9828009828009828
VAL_F1 : 0.9872495441248105

EPOCH : 14 / 50
VAL_LOSS : 0.09086080362983778 
VAL_ACCURACY : 0.9864864864864865
VAL_F1 : 0.9900090821503399

EPOCH : 15 / 50
VAL_LOSS : 0.08334099603634254 
VAL_ACCURACY : 0.9901719901719902
VAL_F1 : 0.9927536226866074

EPOCH : 16 / 50
VAL_LOSS : 0.07648993502644931 
VAL_ACCURACY : 0.9914004914004914
VAL_F1 : 0.9936651578692427

EPOCH : 17 / 50
VAL_LOSS : 0.07232844522770714 
VAL_ACCURACY : 0.9901719901719902
VAL_F1 : 0.9927536226866074

EPOCH : 18 / 50
VAL_LOSS : 0.06831712714012932 
VAL_ACCURACY : 0.9914004914004914
VAL_F1 : 0.9936651578692427

EPOCH : 19 / 50
VAL_LOSS : 0.06518063040486738 
VAL_ACCURACY : 0.9914004914004914
VAL_F1 : 0.9936651578692427

EPOCH : 20 / 50
VAL_LOSS : 0.0617622219610448 
VAL_ACCURACY : 0.9914004914004914
VAL_F1 : 0.9936651578692427

EPOCH : 21 / 50
VAL_LOSS : 0.05980707591801297 
VAL_ACCURACY : 0.9914004914004914
VAL_F1 : 0.993653671302369

EPOCH : 22 / 50
VAL_LOSS : 0.055889503299897794 
VAL_ACCURACY : 0.9926289926289926
VAL_F1 : 0.9945652168895027

EPOCH : 23 / 50
VAL_LOSS : 0.053809012085491534 
VAL_ACCURACY : 0.9938574938574939
VAL_F1 : 0.9954751126203706

EPOCH : 24 / 50
VAL_LOSS : 0.05176990687408868 
VAL_ACCURACY : 0.9938574938574939
VAL_F1 : 0.9954751126203706

EPOCH : 25 / 50
VAL_LOSS : 0.05167065586383436 
VAL_ACCURACY : 0.9926289926289926
VAL_F1 : 0.9945652168895027

EPOCH : 26 / 50
VAL_LOSS : 0.04758591007660417 
VAL_ACCURACY : 0.9938574938574939
VAL_F1 : 0.9954751126203706

EPOCH : 27 / 50
VAL_LOSS : 0.04516524306553252 
VAL_ACCURACY : 0.9926289926289926
VAL_F1 : 0.9945652168895027

EPOCH : 28 / 50
VAL_LOSS : 0.04635288876791795 
VAL_ACCURACY : 0.9938574938574939
VAL_F1 : 0.9954751126203706

EPOCH : 29 / 50
VAL_LOSS : 0.04671734198927879 
VAL_ACCURACY : 0.995085995085995
VAL_F1 : 0.9963833629701709

EPOCH : 30 / 50
VAL_LOSS : 0.042644459425526506 
VAL_ACCURACY : 0.9938574938574939
VAL_F1 : 0.9954751126203706

EPOCH : 31 / 50
VAL_LOSS : 0.04167699945323607 
VAL_ACCURACY : 0.9938574938574939
VAL_F1 : 0.9954751126203706

EPOCH : 32 / 50
VAL_LOSS : 0.03943300380499339 
VAL_ACCURACY : 0.995085995085995
VAL_F1 : 0.9963833629701709

EPOCH : 33 / 50
VAL_LOSS : 0.03602583465330741 
VAL_ACCURACY : 0.9938574938574939
VAL_F1 : 0.9954751126203706

EPOCH : 34 / 50
VAL_LOSS : 0.03689434755520493 
VAL_ACCURACY : 0.9926289926289926
VAL_F1 : 0.9945553534001931

EPOCH : 35 / 50
VAL_LOSS : 0.035477397926882204 
VAL_ACCURACY : 0.995085995085995
VAL_F1 : 0.9963833629701709

EPOCH : 36 / 50
VAL_LOSS : 0.035196081589103916 
VAL_ACCURACY : 0.9914004914004914
VAL_F1 : 0.993653671302369

EPOCH : 37 / 50
VAL_LOSS : 0.03362267941017361 
VAL_ACCURACY : 0.995085995085995
VAL_F1 : 0.9963833629701709

EPOCH : 38 / 50
VAL_LOSS : 0.03339780783098118 
VAL_ACCURACY : 0.995085995085995
VAL_F1 : 0.9963833629701709

EPOCH : 39 / 50
VAL_LOSS : 0.032035025019271704 
VAL_ACCURACY : 0.995085995085995
VAL_F1 : 0.9963833629701709

EPOCH : 40 / 50
VAL_LOSS : 0.03176422512122229 
VAL_ACCURACY : 0.995085995085995
VAL_F1 : 0.9963833629701709

EPOCH : 41 / 50
VAL_LOSS : 0.030401506242068374 
VAL_ACCURACY : 0.9938574938574939
VAL_F1 : 0.9954751126203706

EPOCH : 42 / 50
VAL_LOSS : 0.029006792962843298 
VAL_ACCURACY : 0.9938574938574939
VAL_F1 : 0.9954751126203706

EPOCH : 43 / 50
VAL_LOSS : 0.030330067463949614 
VAL_ACCURACY : 0.9926289926289926
VAL_F1 : 0.9945553534001931

EPOCH : 44 / 50
VAL_LOSS : 0.029191950244792535 
VAL_ACCURACY : 0.995085995085995
VAL_F1 : 0.9963833629701709

EPOCH : 45 / 50
VAL_LOSS : 0.028180539443650666 
VAL_ACCURACY : 0.995085995085995
VAL_F1 : 0.9963833629701709

EPOCH : 46 / 50
VAL_LOSS : 0.02643254846699682 
VAL_ACCURACY : 0.9963144963144963
VAL_F1 : 0.9972850673714986

EPOCH : 47 / 50
VAL_LOSS : 0.02551966498368511 
VAL_ACCURACY : 0.995085995085995
VAL_F1 : 0.9963833629701709

EPOCH : 48 / 50
VAL_LOSS : 0.026768211987526977 
VAL_ACCURACY : 0.9963144963144963
VAL_F1 : 0.9972850673714986

EPOCH : 49 / 50
VAL_LOSS : 0.02373900370416688 
VAL_ACCURACY : 0.9963144963144963
VAL_F1 : 0.9972850673714986

EPOCH : 50 / 50
VAL_LOSS : 0.024990431708740254 
VAL_ACCURACY : 0.9963144963144963
VAL_F1 : 0.9972850673714986

# 5話-0
# 文: 適当に流そう
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.1778, -0.0479]], device='cuda:0')
# 5話-0
# 文: そうなんだ〜
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 1.7647, -1.9136]], device='cuda:0')
# 5話-0
# 文: あと、これも読んだよ
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.4551,  0.6101]], device='cuda:0')
# 5話-1
# 文: 僕ですか?
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-1.9932,  1.6895]], device='cuda:0')
# 5話-1
# 文: 本当に今ハマってる本はこの二冊…
正解 : 1 , 予測 : 0 / 元クラス : 恐怖
tensor([[-0.4193, -0.5924]], device='cuda:0')
# 6話-0
# 文: 手作りなんですか?
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.8169,  0.9110]], device='cuda:0')
# 6話-0
# 文: どうぞどうぞ
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[0.0013, 0.2101]], device='cuda:0')
# 6話-1
# 文: ほとんど冷凍食品詰めただけよ…
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
tensor([[ 2.0000, -2.1481]], device='cuda:0')
# 6話-1
# 文: 俺も今日弁当なんでおかず分けますよ
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.9535,  0.7165]], device='cuda:0')
# 6話-1
# 文: ありがとう…
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.6727,  0.6056]], device='cuda:0')
# 7話-0
# 文: チョコは一つしかないし、悪いよ〜
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
tensor([[ 0.8458, -1.2152]], device='cuda:0')
# 7話-1
# 文: 器用だ!?
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[ 1.3097, -1.5187]], device='cuda:0')
# 7話-1
# 文: こうやっていろんな食べ方をすれば飽きないですね
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.3647,  0.2467]], device='cuda:0')
# 8話-1
# 文: でも わざわざ国際会議から送ってくれたんだよな…
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
tensor([[ 1.7142, -1.4304]], device='cuda:0')
# 9話-0
# 文: Bさん…
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-2.3953,  2.3303]], device='cuda:0')
# 9話-0
# 文: ?
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 0.6019, -0.7524]], device='cuda:0')
# 9話-0
# 文: 人違い!?
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[ 0.2243, -0.4071]], device='cuda:0')
# 9話-1
# 文: ?
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[-0.3606, -0.3922]], device='cuda:0')
------------------------test acc------------------------
Test Acc : 0.7313
correct: 49, total: 67
------------------------------------------------
                  喜楽        その他  accuracy  macro avg  weighted avg
precision   0.763158   0.689655  0.731343   0.726407      0.731343
recall      0.763158   0.689655  0.731343   0.726407      0.731343
f1-score    0.763158   0.689655  0.731343   0.726407      0.731343
support    38.000000  29.000000  0.731343  67.000000     67.000000
正例のF1値 : 0.763157894216759
class weight : tensor([0.3485, 0.9347])
best:lr 6.252752211177988e-06
EPOCH : 1 / 50
VAL_LOSS : 0.3971949821593715 
VAL_ACCURACY : 0.8796068796068796
VAL_F1 : 0.9082396998733991

EPOCH : 2 / 50
VAL_LOSS : 0.2920653025309245 
VAL_ACCURACY : 0.9275184275184275
VAL_F1 : 0.9459211727339008

EPOCH : 3 / 50
VAL_LOSS : 0.23759529213694966 
VAL_ACCURACY : 0.9348894348894349
VAL_F1 : 0.9509713223476807

EPOCH : 4 / 50
VAL_LOSS : 0.19262132180087707 
VAL_ACCURACY : 0.952088452088452
VAL_F1 : 0.9641214346409428

EPOCH : 5 / 50
VAL_LOSS : 0.15249413865454056 
VAL_ACCURACY : 0.9606879606879607
VAL_F1 : 0.9706422013331639

EPOCH : 6 / 50
VAL_LOSS : 0.12474595631162326 
VAL_ACCURACY : 0.972972972972973
VAL_F1 : 0.9799635696257346

EPOCH : 7 / 50
VAL_LOSS : 0.10570154061504439 
VAL_ACCURACY : 0.9766584766584766
VAL_F1 : 0.982584784099553

EPOCH : 8 / 50
VAL_LOSS : 0.08032520487904549 
VAL_ACCURACY : 0.9877149877149877
VAL_F1 : 0.990925589334864

EPOCH : 9 / 50
VAL_LOSS : 0.07373714279018197 
VAL_ACCURACY : 0.9877149877149877
VAL_F1 : 0.990925589334864

EPOCH : 10 / 50
VAL_LOSS : 0.06590400190622199 
VAL_ACCURACY : 0.9901719901719902
VAL_F1 : 0.9927536226866074

EPOCH : 11 / 50
VAL_LOSS : 0.060535198296694195 
VAL_ACCURACY : 0.9926289926289926
VAL_F1 : 0.9945652168895027

EPOCH : 12 / 50
VAL_LOSS : 0.056307505158817064 
VAL_ACCURACY : 0.9926289926289926
VAL_F1 : 0.9945652168895027

EPOCH : 13 / 50
VAL_LOSS : 0.04994633567391658 
VAL_ACCURACY : 0.9914004914004914
VAL_F1 : 0.993653671302369

EPOCH : 14 / 50
VAL_LOSS : 0.048587848414100854 
VAL_ACCURACY : 0.9914004914004914
VAL_F1 : 0.9936421430041026

EPOCH : 15 / 50
VAL_LOSS : 0.04653485868053109 
VAL_ACCURACY : 0.9914004914004914
VAL_F1 : 0.9936421430041026

EPOCH : 16 / 50
VAL_LOSS : 0.04399736747876102 
VAL_ACCURACY : 0.9914004914004914
VAL_F1 : 0.9936421430041026

EPOCH : 17 / 50
VAL_LOSS : 0.04463809421833824 
VAL_ACCURACY : 0.9914004914004914
VAL_F1 : 0.993653671302369

EPOCH : 18 / 50
VAL_LOSS : 0.04085852841244025 
VAL_ACCURACY : 0.9926289926289926
VAL_F1 : 0.9945652168895027

EPOCH : 19 / 50
VAL_LOSS : 0.03882766379883476 
VAL_ACCURACY : 0.9914004914004914
VAL_F1 : 0.993653671302369

EPOCH : 20 / 50
VAL_LOSS : 0.03851125586558791 
VAL_ACCURACY : 0.9914004914004914
VAL_F1 : 0.993653671302369

EPOCH : 21 / 50
VAL_LOSS : 0.03512042282404853 
VAL_ACCURACY : 0.995085995085995
VAL_F1 : 0.9963833629701709

EPOCH : 22 / 50
VAL_LOSS : 0.03381090359214474 
VAL_ACCURACY : 0.9914004914004914
VAL_F1 : 0.9936421430041026

EPOCH : 23 / 50
VAL_LOSS : 0.03147357904954868 
VAL_ACCURACY : 0.9938574938574939
VAL_F1 : 0.9954751126203706

EPOCH : 24 / 50
VAL_LOSS : 0.03133595574135874 
VAL_ACCURACY : 0.9914004914004914
VAL_F1 : 0.993653671302369

EPOCH : 25 / 50
VAL_LOSS : 0.03015578081648724 
VAL_ACCURACY : 0.995085995085995
VAL_F1 : 0.9963833629701709

EPOCH : 26 / 50
VAL_LOSS : 0.028554976643884882 
VAL_ACCURACY : 0.995085995085995
VAL_F1 : 0.9963833629701709

EPOCH : 27 / 50
VAL_LOSS : 0.028000986897477917 
VAL_ACCURACY : 0.9926289926289926
VAL_F1 : 0.9945553534001931

EPOCH : 28 / 50
VAL_LOSS : 0.02621762029023147 
VAL_ACCURACY : 0.9938574938574939
VAL_F1 : 0.9954669079297457

EPOCH : 29 / 50
VAL_LOSS : 0.026039308119638293 
VAL_ACCURACY : 0.9938574938574939
VAL_F1 : 0.9954669079297457

EPOCH : 30 / 50
VAL_LOSS : 0.025403596625170288 
VAL_ACCURACY : 0.995085995085995
VAL_F1 : 0.9963768110923978

EPOCH : 31 / 50
VAL_LOSS : 0.025470514179152602 
VAL_ACCURACY : 0.9926289926289926
VAL_F1 : 0.9945553534001931

EPOCH : 32 / 50
VAL_LOSS : 0.023228508091586476 
VAL_ACCURACY : 0.9926289926289926
VAL_F1 : 0.9945553534001931

EPOCH : 33 / 50
VAL_LOSS : 0.02727128660269812 
VAL_ACCURACY : 0.9926289926289926
VAL_F1 : 0.9945553534001931

EPOCH : 34 / 50
VAL_LOSS : 0.024162150700302684 
VAL_ACCURACY : 0.995085995085995
VAL_F1 : 0.9963768110923978

EPOCH : 35 / 50
VAL_LOSS : 0.02264347068015851 
VAL_ACCURACY : 0.9938574938574939
VAL_F1 : 0.9954751126203706

EPOCH : 36 / 50
VAL_LOSS : 0.022748141695617462 
VAL_ACCURACY : 0.9938574938574939
VAL_F1 : 0.9954669079297457

EPOCH : 37 / 50
VAL_LOSS : 0.021387700539301422 
VAL_ACCURACY : 0.9938574938574939
VAL_F1 : 0.9954669079297457

EPOCH : 38 / 50
VAL_LOSS : 0.022552634507198546 
VAL_ACCURACY : 0.9926289926289926
VAL_F1 : 0.9945652168895027

EPOCH : 39 / 50
VAL_LOSS : 0.02226786772884867 
VAL_ACCURACY : 0.9926289926289926
VAL_F1 : 0.9945553534001931

EPOCH : 40 / 50
VAL_LOSS : 0.021248472315788854 
VAL_ACCURACY : 0.9938574938574939
VAL_F1 : 0.9954669079297457

EPOCH : 41 / 50
VAL_LOSS : 0.019653924768242764 
VAL_ACCURACY : 0.9963144963144963
VAL_F1 : 0.9972850673714986

EPOCH : 42 / 50
VAL_LOSS : 0.020242391811574206 
VAL_ACCURACY : 0.9926289926289926
VAL_F1 : 0.9945553534001931

EPOCH : 43 / 50
VAL_LOSS : 0.01619193163316916 
VAL_ACCURACY : 0.995085995085995
VAL_F1 : 0.9963702354328576

EPOCH : 44 / 50
VAL_LOSS : 0.017468416643347227 
VAL_ACCURACY : 0.995085995085995
VAL_F1 : 0.9963768110923978

EPOCH : 45 / 50
VAL_LOSS : 0.016748435923135747 
VAL_ACCURACY : 0.995085995085995
VAL_F1 : 0.9963768110923978

EPOCH : 46 / 50
VAL_LOSS : 0.016261815431290398 
VAL_ACCURACY : 0.995085995085995
VAL_F1 : 0.9963768110923978

EPOCH : 47 / 50
VAL_LOSS : 0.015031548125632838 
VAL_ACCURACY : 0.9963144963144963
VAL_F1 : 0.9972850673714986

EPOCH : 48 / 50
VAL_LOSS : 0.017649374144407464 
VAL_ACCURACY : 0.9975429975429976
VAL_F1 : 0.9981916812341821

EPOCH : 49 / 50
VAL_LOSS : 0.01739220866276061 
VAL_ACCURACY : 0.9963144963144963
VAL_F1 : 0.9972850673714986

EPOCH : 50 / 50
VAL_LOSS : 0.018048899805209802 
VAL_ACCURACY : 0.995085995085995
VAL_F1 : 0.9963833629701709

# 5話-0
# 文: そうなんだ〜
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 2.4424, -2.5948]], device='cuda:0')
# 5話-0
# 文: あと、これも読んだよ
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.9574,  1.0949]], device='cuda:0')
# 5話-1
# 文: ありがとうございます… それ、何読んでるんですか?
正解 : 1 , 予測 : 0 / 元クラス : 恐怖
tensor([[ 0.8297, -1.0061]], device='cuda:0')
# 5話-1
# 文: 僕ですか?
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-1.4675,  1.3414]], device='cuda:0')
# 5話-1
# 文: 本当に今ハマってる本はこの二冊…
正解 : 1 , 予測 : 0 / 元クラス : 恐怖
tensor([[ 0.7258, -1.1853]], device='cuda:0')
# 6話-0
# 文: 手作りなんですか?
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-1.4923,  1.0798]], device='cuda:0')
# 6話-0
# 文: どうぞどうぞ
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.4212, -0.0237]], device='cuda:0')
# 6話-1
# 文: ほとんど冷凍食品詰めただけよ…
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
tensor([[ 2.6992, -2.7357]], device='cuda:0')
# 6話-1
# 文: 俺も今日弁当なんでおかず分けますよ
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.4521,  0.2570]], device='cuda:0')
# 6話-1
# 文: ありがとう…
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.6936,  0.3796]], device='cuda:0')
# 7話-0
# 文: チョコは一つしかないし、悪いよ〜
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
tensor([[ 1.6790, -1.9945]], device='cuda:0')
# 7話-1
# 文: 器用だ!?
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[ 1.8396, -1.9810]], device='cuda:0')
# 8話-1
# 文: でも わざわざ国際会議から送ってくれたんだよな…
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
tensor([[ 2.4239, -2.6023]], device='cuda:0')
# 9話-0
# 文: Bさん…
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-2.6023,  2.7081]], device='cuda:0')
# 9話-0
# 文: ?
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 1.4374, -1.6045]], device='cuda:0')
# 9話-0
# 文: 人違い!?
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[ 1.4126, -1.6187]], device='cuda:0')
------------------------test acc------------------------
Test Acc : 0.7612
correct: 51, total: 67
------------------------------------------------
                  喜楽        その他  accuracy  macro avg  weighted avg
precision   0.775000   0.740741  0.761194   0.757870      0.760171
recall      0.815789   0.689655  0.761194   0.752722      0.761194
f1-score    0.794872   0.714286  0.761194   0.754579      0.759991
support    38.000000  29.000000  0.761194  67.000000     67.000000
正例のF1値 : 0.7948717943517423
