class weight : tensor([0.3988, 0.7537])
best:lr 3.5337676253638463e-07
EPOCH : 1 / 50
VAL_LOSS : 0.712365445281778 
VAL_ACCURACY : 0.44881889763779526
VAL_F1 : 0.3859649118386819

EPOCH : 2 / 50
VAL_LOSS : 0.7094782856958253 
VAL_ACCURACY : 0.45219347581552305
VAL_F1 : 0.38895859428879004

EPOCH : 3 / 50
VAL_LOSS : 0.7069159905825343 
VAL_ACCURACY : 0.45894263217097864
VAL_F1 : 0.3919089755418816

EPOCH : 4 / 50
VAL_LOSS : 0.7045298389026097 
VAL_ACCURACY : 0.4645669291338583
VAL_F1 : 0.3928571424236125

EPOCH : 5 / 50
VAL_LOSS : 0.7042470467942101 
VAL_ACCURACY : 0.46569178852643417
VAL_F1 : 0.39490445816455355

EPOCH : 6 / 50
VAL_LOSS : 0.6997921402965274 
VAL_ACCURACY : 0.4668166479190101
VAL_F1 : 0.3954081628317693

EPOCH : 7 / 50
VAL_LOSS : 0.6979073019964355 
VAL_ACCURACY : 0.46906636670416196
VAL_F1 : 0.39949109371276603

EPOCH : 8 / 50
VAL_LOSS : 0.6965027909193721 
VAL_ACCURACY : 0.47131608548931386
VAL_F1 : 0.4020356229748461

EPOCH : 9 / 50
VAL_LOSS : 0.6942245449338641 
VAL_ACCURACY : 0.47244094488188976
VAL_F1 : 0.40557667890423615

EPOCH : 10 / 50
VAL_LOSS : 0.6935911966221673 
VAL_ACCURACY : 0.4769403824521935
VAL_F1 : 0.409148665384099

EPOCH : 11 / 50
VAL_LOSS : 0.6903842581169946 
VAL_ACCURACY : 0.4746906636670416
VAL_F1 : 0.4050955409670753

EPOCH : 12 / 50
VAL_LOSS : 0.688028063092913 
VAL_ACCURACY : 0.4735658042744657
VAL_F1 : 0.40306122405623956

EPOCH : 13 / 50
VAL_LOSS : 0.6853552918348994 
VAL_ACCURACY : 0.47581552305961755
VAL_F1 : 0.4040920711789823

EPOCH : 14 / 50
VAL_LOSS : 0.6848126969167164 
VAL_ACCURACY : 0.47919010123734535
VAL_F1 : 0.4086845461826521

EPOCH : 15 / 50
VAL_LOSS : 0.6820275166204998 
VAL_ACCURACY : 0.47919010123734535
VAL_F1 : 0.4086845461826521

EPOCH : 16 / 50
VAL_LOSS : 0.6808273600680488 
VAL_ACCURACY : 0.48368953880764903
VAL_F1 : 0.4152866237695971

EPOCH : 17 / 50
VAL_LOSS : 0.6782111685190882 
VAL_ACCURACY : 0.48931383577052867
VAL_F1 : 0.4209183669133369

EPOCH : 18 / 50
VAL_LOSS : 0.6774190323693412 
VAL_ACCURACY : 0.48931383577052867
VAL_F1 : 0.4223918570714863

EPOCH : 19 / 50
VAL_LOSS : 0.6745159147041184 
VAL_ACCURACY : 0.49268841394825647
VAL_F1 : 0.4283903671171061

EPOCH : 20 / 50
VAL_LOSS : 0.6732502302953175 
VAL_ACCURACY : 0.49606299212598426
VAL_F1 : 0.43434343390483116

EPOCH : 21 / 50
VAL_LOSS : 0.6702712848782539 
VAL_ACCURACY : 0.4983127109111361
VAL_F1 : 0.43828715321258305

EPOCH : 22 / 50
VAL_LOSS : 0.6694083905645779 
VAL_ACCURACY : 0.5039370078740157
VAL_F1 : 0.44667503092603533

EPOCH : 23 / 50
VAL_LOSS : 0.6667577656252044 
VAL_ACCURACY : 0.5084364454443194
VAL_F1 : 0.4516938515031872

EPOCH : 24 / 50
VAL_LOSS : 0.6660768602575574 
VAL_ACCURACY : 0.5106861642294713
VAL_F1 : 0.45692883850740257

EPOCH : 25 / 50
VAL_LOSS : 0.6631987360971314 
VAL_ACCURACY : 0.5185601799775028
VAL_F1 : 0.46898262982624733

EPOCH : 26 / 50
VAL_LOSS : 0.6624220897044454 
VAL_ACCURACY : 0.5230596175478065
VAL_F1 : 0.4739454089825626

EPOCH : 27 / 50
VAL_LOSS : 0.6593851212944303 
VAL_ACCURACY : 0.5264341957255343
VAL_F1 : 0.4770186330941924

EPOCH : 28 / 50
VAL_LOSS : 0.6571888104081154 
VAL_ACCURACY : 0.5331833520809899
VAL_F1 : 0.4882860661350451

EPOCH : 29 / 50
VAL_LOSS : 0.6561683735677174 
VAL_ACCURACY : 0.5376827896512936
VAL_F1 : 0.4957055210208951

EPOCH : 30 / 50
VAL_LOSS : 0.655375308224133 
VAL_ACCURACY : 0.545556805399325
VAL_F1 : 0.5061124689846247

EPOCH : 31 / 50
VAL_LOSS : 0.6533428920166833 
VAL_ACCURACY : 0.547806524184477
VAL_F1 : 0.5097560971069542

EPOCH : 32 / 50
VAL_LOSS : 0.6508066867079053 
VAL_ACCURACY : 0.5556805399325084
VAL_F1 : 0.521212120755676

EPOCH : 33 / 50
VAL_LOSS : 0.647923326918057 
VAL_ACCURACY : 0.5613048368953881
VAL_F1 : 0.5289855067885191

EPOCH : 34 / 50
VAL_LOSS : 0.6467402077146939 
VAL_ACCURACY : 0.5658042744656918
VAL_F1 : 0.5349397585773611

EPOCH : 35 / 50
VAL_LOSS : 0.6448397295815604 
VAL_ACCURACY : 0.5669291338582677
VAL_F1 : 0.5355850417612104

EPOCH : 36 / 50
VAL_LOSS : 0.6432714611291885 
VAL_ACCURACY : 0.5759280089988752
VAL_F1 : 0.5485029935509427

EPOCH : 37 / 50
VAL_LOSS : 0.6421534589358738 
VAL_ACCURACY : 0.5793025871766029
VAL_F1 : 0.5536992835472114

EPOCH : 38 / 50
VAL_LOSS : 0.6397405756371362 
VAL_ACCURACY : 0.5883014623172104
VAL_F1 : 0.5653206646191006

EPOCH : 39 / 50
VAL_LOSS : 0.6367262229323387 
VAL_ACCURACY : 0.5984251968503937
VAL_F1 : 0.5734767020470047

EPOCH : 40 / 50
VAL_LOSS : 0.6364880938615117 
VAL_ACCURACY : 0.6017997750281214
VAL_F1 : 0.5765550234619113

EPOCH : 41 / 50
VAL_LOSS : 0.635874113866261 
VAL_ACCURACY : 0.6074240719910011
VAL_F1 : 0.5820359276825988

EPOCH : 42 / 50
VAL_LOSS : 0.6332839759332793 
VAL_ACCURACY : 0.6074240719910011
VAL_F1 : 0.5810324125049512

EPOCH : 43 / 50
VAL_LOSS : 0.6306710072926113 
VAL_ACCURACY : 0.6152980877390326
VAL_F1 : 0.5918854410650202

EPOCH : 44 / 50
VAL_LOSS : 0.6293193719216755 
VAL_ACCURACY : 0.6265466816647919
VAL_F1 : 0.6075650113545763

EPOCH : 45 / 50
VAL_LOSS : 0.6288478140320096 
VAL_ACCURACY : 0.6344206974128234
VAL_F1 : 0.6162927976448078

EPOCH : 46 / 50
VAL_LOSS : 0.6267675395522799 
VAL_ACCURACY : 0.641169853768279
VAL_F1 : 0.6242638393445681

EPOCH : 47 / 50
VAL_LOSS : 0.6248914290751729 
VAL_ACCURACY : 0.6467941507311586
VAL_F1 : 0.6323185007020607

EPOCH : 48 / 50
VAL_LOSS : 0.6231311314872333 
VAL_ACCURACY : 0.6524184476940382
VAL_F1 : 0.640279394174188

EPOCH : 49 / 50
VAL_LOSS : 0.6222098192998341 
VAL_ACCURACY : 0.655793025871766
VAL_F1 : 0.6441860460405139

EPOCH : 50 / 50
VAL_LOSS : 0.6200796685048512 
VAL_ACCURACY : 0.6591676040494938
VAL_F1 : 0.6480836232219026

# 5話-0
# 文: 何読んでるんですか?
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[0.1162, 0.3228]], device='cuda:0')
# 5話-0
# 文: 僕ですか?
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[0.1300, 0.4334]], device='cuda:0')
# 5話-0
# 文: 今ハマってる本はこの二冊…
正解 : 1 , 予測 : 0 / 元クラス : 恐怖
tensor([[-0.0605, -0.2303]], device='cuda:0')
# 5話-0
# 文: 適当に流そう
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.0815,  0.3073]], device='cuda:0')
# 5話-0
# 文: 小説はあまり読まないのですが、研究で利用している青空文庫の作品なら少々
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.0290,  0.1233]], device='cuda:0')
# 5話-0
# 文: そうなんだ〜
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[0.3317, 0.0082]], device='cuda:0')
# 5話-1
# 文: 僕ですか?
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[0.1300, 0.4334]], device='cuda:0')
# 5話-1
# 文: 本当に今ハマってる本はこの二冊…
正解 : 1 , 予測 : 0 / 元クラス : 恐怖
tensor([[ 0.1003, -0.0171]], device='cuda:0')
# 6話-0
# 文: 手作りなんですか?
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[0.1834, 0.3131]], device='cuda:0')
# 6話-0
# 文: どうぞどうぞ
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.1190,  0.2833]], device='cuda:0')
# 6話-0
# 文: キャー!
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[0.1587, 0.1028]], device='cuda:0')
# 6話-1
# 文: キャー!
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[0.1587, 0.1028]], device='cuda:0')
# 6話-1
# 文: 今日弁当なの珍しいですね
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[0.1618, 0.2304]], device='cuda:0')
# 6話-1
# 文: ええ… 父の分と2つ作ったんだけど
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
tensor([[0.1092, 0.0545]], device='cuda:0')
# 6話-1
# 文: 手作りなんですか?
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[0.1834, 0.3131]], device='cuda:0')
# 6話-1
# 文: ほとんど冷凍食品詰めただけよ…
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
tensor([[ 0.2832, -0.0431]], device='cuda:0')
# 7話-0
# 文: どれがいいですか?
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[0.1491, 0.2833]], device='cuda:0')
# 7話-0
# 文: 差し入れで沢山いただいてしまいました
正解 : 1 , 予測 : 0 / 元クラス : UNK
tensor([[-0.1617, -0.3077]], device='cuda:0')
# 7話-0
# 文: 別に気にしませんが…
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[0.0435, 0.3108]], device='cuda:0')
# 7話-0
# 文: はんぶんこしよっか
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.0246,  0.2717]], device='cuda:0')
# 7話-0
# 文: とか言い出すのかな…
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[0.0474, 0.3102]], device='cuda:0')
# 7話-0
# 文: ジャーン!パフェを作ってみました〜!
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.2569,  0.3435]], device='cuda:0')
# 7話-0
# 文: 器用だ!?
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[0.0797, 0.0442]], device='cuda:0')
# 7話-1
# 文: ジャーン!パフェを作ってみました〜!
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.2569,  0.3435]], device='cuda:0')
# 7話-1
# 文: 器用だ!?
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[0.0797, 0.0442]], device='cuda:0')
# 7話-1
# 文: てっきり
正解 : 1 , 予測 : 0 / 元クラス : UNK
tensor([[0.3895, 0.0272]], device='cuda:0')
# 7話-1
# 文: チョコ一つしかないね…はんぶんこしよっか
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.0045,  0.2113]], device='cuda:0')
# 7話-1
# 文: とか言い出すのかと思った…
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[0.0395, 0.3132]], device='cuda:0')
# 7話-1
# 文: Aくんがいなければ独り占めできたのにな…
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
tensor([[ 0.3709, -0.2737]], device='cuda:0')
# 8話-0
# 文: 国際会議でスペインにいるBさんからだ
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[0.0926, 0.1412]], device='cuda:0')
# 8話-0
# 文: ここは日本。何も見ていない
正解 : 1 , 予測 : 0 / 元クラス : 恐怖
tensor([[0.3709, 0.3334]], device='cuda:0')
# 8話-1
# 文: ここは日本。何も見ていない
正解 : 1 , 予測 : 0 / 元クラス : 恐怖
tensor([[0.3709, 0.3334]], device='cuda:0')
# 8話-1
# 文: でも わざわざ国際会議から送ってくれたんだよな…
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
tensor([[ 0.1702, -0.0573]], device='cuda:0')
# 9話-0
# 文: あれ?スペインからもう戻ってきたのか
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.0433,  0.0871]], device='cuda:0')
# 9話-0
# 文: Bさん…
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[0.1358, 0.1739]], device='cuda:0')
# 9話-0
# 文: あれ？
正解 : 1 , 予測 : 0 / 元クラス : UNK
tensor([[0.2166, 0.0723]], device='cuda:0')
# 9話-0
# 文: 人違い!?
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[0.2546, 0.0357]], device='cuda:0')
# 9話-1
# 文: 人違い!?
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[0.2546, 0.0357]], device='cuda:0')
# 9話-1
# 文: おかえりなさい!
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[0.0312, 0.2146]], device='cuda:0')
------------------------test acc------------------------
Test Acc : 0.4868
correct: 37, total: 76
------------------------------------------------
                  喜楽        その他  accuracy  macro avg  weighted avg
precision   0.485714   0.487805  0.486842   0.486760      0.486760
recall      0.447368   0.526316  0.486842   0.486842      0.486842
f1-score    0.465753   0.506329  0.486842   0.486041      0.486041
support    38.000000  38.000000  0.486842  76.000000     76.000000
正例のF1値 : 0.4657534241456182
class weight : tensor([0.3988, 0.7537])
best:lr 1.5417134737100756e-06
EPOCH : 1 / 50
VAL_LOSS : 0.6956107137458665 
VAL_ACCURACY : 0.5849268841394826
VAL_F1 : 0.6901763219219686

EPOCH : 2 / 50
VAL_LOSS : 0.683013627571719 
VAL_ACCURACY : 0.5995500562429696
VAL_F1 : 0.6882661991504107

EPOCH : 3 / 50
VAL_LOSS : 0.6715105399489403 
VAL_ACCURACY : 0.6209223847019123
VAL_F1 : 0.6888273309853907

EPOCH : 4 / 50
VAL_LOSS : 0.6638640825237546 
VAL_ACCURACY : 0.6321709786276716
VAL_F1 : 0.683446272490677

EPOCH : 5 / 50
VAL_LOSS : 0.653515392116138 
VAL_ACCURACY : 0.6479190101237345
VAL_F1 : 0.6847935543859748

EPOCH : 6 / 50
VAL_LOSS : 0.646239385008812 
VAL_ACCURACY : 0.6501687289088864
VAL_F1 : 0.679050567099707

EPOCH : 7 / 50
VAL_LOSS : 0.6384900680610112 
VAL_ACCURACY : 0.6602924634420697
VAL_F1 : 0.6821052626647047

EPOCH : 8 / 50
VAL_LOSS : 0.6317413949540683 
VAL_ACCURACY : 0.6614173228346457
VAL_F1 : 0.6752966553899566

EPOCH : 9 / 50
VAL_LOSS : 0.6244140416383743 
VAL_ACCURACY : 0.6659167604049494
VAL_F1 : 0.678223184776999

EPOCH : 10 / 50
VAL_LOSS : 0.6182471471173423 
VAL_ACCURACY : 0.6704161979752531
VAL_F1 : 0.6790799557020667

EPOCH : 11 / 50
VAL_LOSS : 0.61330617751394 
VAL_ACCURACY : 0.6771653543307087
VAL_F1 : 0.6821705421516613

EPOCH : 12 / 50
VAL_LOSS : 0.6058277455823762 
VAL_ACCURACY : 0.6782902137232846
VAL_F1 : 0.6815144761319537

EPOCH : 13 / 50
VAL_LOSS : 0.5997253656387329 
VAL_ACCURACY : 0.688413948256468
VAL_F1 : 0.6925638174964949

EPOCH : 14 / 50
VAL_LOSS : 0.5942223976765361 
VAL_ACCURACY : 0.6996625421822272
VAL_F1 : 0.7049723752060756

EPOCH : 15 / 50
VAL_LOSS : 0.5888140414442334 
VAL_ACCURACY : 0.7086614173228346
VAL_F1 : 0.7150715066652192

EPOCH : 16 / 50
VAL_LOSS : 0.5834492333233356 
VAL_ACCURACY : 0.7052868391451068
VAL_F1 : 0.7114537440081362

EPOCH : 17 / 50
VAL_LOSS : 0.5781226339084762 
VAL_ACCURACY : 0.7120359955005624
VAL_F1 : 0.7192982451278472

EPOCH : 18 / 50
VAL_LOSS : 0.5738503618964127 
VAL_ACCURACY : 0.7154105736782902
VAL_F1 : 0.7228915657786411

EPOCH : 19 / 50
VAL_LOSS : 0.5686176754534245 
VAL_ACCURACY : 0.7244094488188977
VAL_F1 : 0.7339847986432252

EPOCH : 20 / 50
VAL_LOSS : 0.5626922813909394 
VAL_ACCURACY : 0.7255343082114736
VAL_F1 : 0.7353579170821379

EPOCH : 21 / 50
VAL_LOSS : 0.5583664700388908 
VAL_ACCURACY : 0.7277840269966255
VAL_F1 : 0.7352297588131138

EPOCH : 22 / 50
VAL_LOSS : 0.5538969923342977 
VAL_ACCURACY : 0.734533183352081
VAL_F1 : 0.742919389490666

EPOCH : 23 / 50
VAL_LOSS : 0.5492370235068458 
VAL_ACCURACY : 0.7390326209223848
VAL_F1 : 0.7483731014638884

EPOCH : 24 / 50
VAL_LOSS : 0.5435742006770202 
VAL_ACCURACY : 0.7424071991001124
VAL_F1 : 0.7529665583024103

EPOCH : 25 / 50
VAL_LOSS : 0.5404346116951534 
VAL_ACCURACY : 0.7469066366704162
VAL_F1 : 0.7583243818943723

EPOCH : 26 / 50
VAL_LOSS : 0.5364129181419101 
VAL_ACCURACY : 0.749156355455568
VAL_F1 : 0.760986065961771

EPOCH : 27 / 50
VAL_LOSS : 0.5321918954806668 
VAL_ACCURACY : 0.7547806524184477
VAL_F1 : 0.7675906178454545

EPOCH : 28 / 50
VAL_LOSS : 0.5266352689691952 
VAL_ACCURACY : 0.7547806524184477
VAL_F1 : 0.7675906178454545

EPOCH : 29 / 50
VAL_LOSS : 0.5224081948399544 
VAL_ACCURACY : 0.7559055118110236
VAL_F1 : 0.768409818078643

EPOCH : 30 / 50
VAL_LOSS : 0.5187341671969209 
VAL_ACCURACY : 0.7592800899887514
VAL_F1 : 0.7728237787010878

EPOCH : 31 / 50
VAL_LOSS : 0.5149195476302079 
VAL_ACCURACY : 0.7637795275590551
VAL_F1 : 0.7780126844966545

EPOCH : 32 / 50
VAL_LOSS : 0.5121479800769261 
VAL_ACCURACY : 0.7626546681664792
VAL_F1 : 0.7776606949756752

EPOCH : 33 / 50
VAL_LOSS : 0.5068212263286114 
VAL_ACCURACY : 0.7637795275590551
VAL_F1 : 0.7784810121651401

EPOCH : 34 / 50
VAL_LOSS : 0.5034842464540686 
VAL_ACCURACY : 0.7649043869516311
VAL_F1 : 0.7797681765352071

EPOCH : 35 / 50
VAL_LOSS : 0.49865569546818733 
VAL_ACCURACY : 0.7671541057367829
VAL_F1 : 0.7823343843644932

EPOCH : 36 / 50
VAL_LOSS : 0.4964711628854275 
VAL_ACCURACY : 0.7705286839145107
VAL_F1 : 0.7861635215185802

EPOCH : 37 / 50
VAL_LOSS : 0.49485661036201883 
VAL_ACCURACY : 0.7705286839145107
VAL_F1 : 0.7861635215185802

EPOCH : 38 / 50
VAL_LOSS : 0.4884305867765631 
VAL_ACCURACY : 0.7705286839145107
VAL_F1 : 0.7861635215185802

EPOCH : 39 / 50
VAL_LOSS : 0.48455873717154774 
VAL_ACCURACY : 0.7716535433070866
VAL_F1 : 0.7874345544796778

EPOCH : 40 / 50
VAL_LOSS : 0.48190248917256084 
VAL_ACCURACY : 0.7716535433070866
VAL_F1 : 0.7874345544796778

EPOCH : 41 / 50
VAL_LOSS : 0.47844451665878296 
VAL_ACCURACY : 0.7739032620922385
VAL_F1 : 0.7895287953173696

EPOCH : 42 / 50
VAL_LOSS : 0.475260177893298 
VAL_ACCURACY : 0.7750281214848144
VAL_F1 : 0.7912317322820464

EPOCH : 43 / 50
VAL_LOSS : 0.47382273099252153 
VAL_ACCURACY : 0.7750281214848144
VAL_F1 : 0.790794978585205

EPOCH : 44 / 50
VAL_LOSS : 0.46927364223769735 
VAL_ACCURACY : 0.7761529808773904
VAL_F1 : 0.7916230361550615

EPOCH : 45 / 50
VAL_LOSS : 0.46588488508548054 
VAL_ACCURACY : 0.7761529808773904
VAL_F1 : 0.7916230361550615

EPOCH : 46 / 50
VAL_LOSS : 0.4635439185159547 
VAL_ACCURACY : 0.7795275590551181
VAL_F1 : 0.7958333328384809

EPOCH : 47 / 50
VAL_LOSS : 0.4599999939756734 
VAL_ACCURACY : 0.7795275590551181
VAL_F1 : 0.7958333328384809

EPOCH : 48 / 50
VAL_LOSS : 0.4583637352500643 
VAL_ACCURACY : 0.7795275590551181
VAL_F1 : 0.7958333328384809

EPOCH : 49 / 50
VAL_LOSS : 0.45558427966066767 
VAL_ACCURACY : 0.7806524184476941
VAL_F1 : 0.797086367871297

EPOCH : 50 / 50
VAL_LOSS : 0.45260043548686163 
VAL_ACCURACY : 0.7795275590551181
VAL_F1 : 0.7958333328384809

# 5話-0
# 文: 何読んでるんですか?
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[0.0960, 0.1295]], device='cuda:0')
# 5話-0
# 文: オススメの本教えて
正解 : 1 , 予測 : 0 / 元クラス : UNK
tensor([[ 0.1714, -0.1899]], device='cuda:0')
# 5話-0
# 文: 僕ですか?
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.0171,  0.5986]], device='cuda:0')
# 5話-0
# 文: Bさん、苦手そうだよな…
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
tensor([[0.3677, 0.1160]], device='cuda:0')
# 5話-0
# 文: 適当に流そう
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.1854,  0.6989]], device='cuda:0')
# 5話-0
# 文: 小説はあまり読まないのですが、研究で利用している青空文庫の作品なら少々
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[0.0125, 0.5391]], device='cuda:0')
# 5話-0
# 文: そうなんだ〜
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 0.6159, -0.3453]], device='cuda:0')
# 5話-1
# 文: 僕ですか?
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.0171,  0.5986]], device='cuda:0')
# 5話-1
# 文: 小説はあまり読まないのですが 研究で利用している青空文庫の作品なら少々
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.0538,  0.2817]], device='cuda:0')
# 5話-1
# 文: 本当に今ハマってる本はこの二冊…
正解 : 1 , 予測 : 0 / 元クラス : 恐怖
tensor([[ 0.2478, -0.1348]], device='cuda:0')
# 6話-0
# 文: 手作りなんですか?
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.2406,  0.3517]], device='cuda:0')
# 6話-0
# 文: 見てもいいですか?
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.0446,  0.1290]], device='cuda:0')
# 6話-0
# 文: キャー!
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[ 0.3499, -0.3069]], device='cuda:0')
# 6話-0
# 文: ベタだなあ
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[0.2969, 0.2250]], device='cuda:0')
# 6話-1
# 文: キャー!
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[ 0.3499, -0.3069]], device='cuda:0')
# 6話-1
# 文: ベタだなあ
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[0.2969, 0.2250]], device='cuda:0')
# 6話-1
# 文: 今日弁当なの珍しいですね
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.1153,  0.4387]], device='cuda:0')
# 6話-1
# 文: ええ… 父の分と2つ作ったんだけど
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
tensor([[ 0.1114, -0.0583]], device='cuda:0')
# 6話-1
# 文: 手作りなんですか?
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.2406,  0.3517]], device='cuda:0')
# 6話-1
# 文: ほとんど冷凍食品詰めただけよ…
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
tensor([[ 0.2184, -0.8894]], device='cuda:0')
# 7話-0
# 文: どれがいいですか?
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.3339,  0.0887]], device='cuda:0')
# 7話-0
# 文: 差し入れで沢山いただいてしまいました
正解 : 1 , 予測 : 0 / 元クラス : UNK
tensor([[0.4957, 0.2065]], device='cuda:0')
# 7話-0
# 文: じゃあチョコですね
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.4785,  0.0882]], device='cuda:0')
# 7話-0
# 文: 別に気にしませんが…
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.4355, -0.0084]], device='cuda:0')
# 7話-0
# 文: とか言い出すのかな…
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.4293, -0.0072]], device='cuda:0')
# 7話-0
# 文: 器用だ!?
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[ 0.4555, -0.1396]], device='cuda:0')
# 7話-1
# 文: 器用だ!?
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[ 0.4555, -0.1396]], device='cuda:0')
# 7話-1
# 文: てっきり
正解 : 1 , 予測 : 0 / 元クラス : UNK
tensor([[ 0.4061, -0.6546]], device='cuda:0')
# 7話-1
# 文: とか言い出すのかと思った…
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.4337,  0.0027]], device='cuda:0')
# 7話-1
# 文: Aくんがいなければ独り占めできたのにな…
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
tensor([[ 0.3511, -0.4091]], device='cuda:0')
# 8話-1
# 文: でも わざわざ国際会議から送ってくれたんだよな…
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
tensor([[ 0.2870, -0.1871]], device='cuda:0')
# 8話-1
# 文: もう少し頑張るか
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[0.2370, 0.5034]], device='cuda:0')
# 9話-0
# 文: Bさん…
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[0.1965, 0.5201]], device='cuda:0')
# 9話-0
# 文: あれ？
正解 : 1 , 予測 : 0 / 元クラス : UNK
tensor([[0.5082, 0.1261]], device='cuda:0')
# 9話-0
# 文: Bさ…ちょっと!
正解 : 1 , 予測 : 0 / 元クラス : 憤怒
tensor([[0.1098, 0.1039]], device='cuda:0')
# 9話-0
# 文: ハッ
正解 : 1 , 予測 : 0 / 元クラス : UNK
tensor([[ 0.4615, -0.2559]], device='cuda:0')
# 9話-0
# 文: 人違い!?
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[ 0.5033, -0.1492]], device='cuda:0')
# 9話-1
# 文: 人違い!?
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[ 0.5033, -0.1492]], device='cuda:0')
# 9話-1
# 文: ハッ
正解 : 1 , 予測 : 0 / 元クラス : UNK
tensor([[ 0.4615, -0.2559]], device='cuda:0')
------------------------test acc------------------------
Test Acc : 0.4868
correct: 37, total: 76
------------------------------------------------
                  喜楽        その他  accuracy  macro avg  weighted avg
precision   0.488372   0.484848  0.486842   0.486610      0.486610
recall      0.552632   0.421053  0.486842   0.486842      0.486842
f1-score    0.518519   0.450704  0.486842   0.484611      0.484611
support    38.000000  38.000000  0.486842  76.000000     76.000000
正例のF1値 : 0.5185185180076208
class weight : tensor([0.3988, 0.7537])
best:lr 3.1511881250859125e-06
EPOCH : 1 / 50
VAL_LOSS : 0.7361633437020438 
VAL_ACCURACY : 0.6062992125984252
VAL_F1 : 0.7503566329075155

EPOCH : 2 / 50
VAL_LOSS : 0.6948009420718465 
VAL_ACCURACY : 0.6276715410573678
VAL_F1 : 0.7486712219914892

EPOCH : 3 / 50
VAL_LOSS : 0.6696724306259837 
VAL_ACCURACY : 0.6681664791901012
VAL_F1 : 0.747647561520983

EPOCH : 4 / 50
VAL_LOSS : 0.6490116268396378 
VAL_ACCURACY : 0.6940382452193475
VAL_F1 : 0.7384615379605918

EPOCH : 5 / 50
VAL_LOSS : 0.6338947245052883 
VAL_ACCURACY : 0.7075365579302587
VAL_F1 : 0.7341513287464715

EPOCH : 6 / 50
VAL_LOSS : 0.6195683905056545 
VAL_ACCURACY : 0.7154105736782902
VAL_F1 : 0.7299893271502297

EPOCH : 7 / 50
VAL_LOSS : 0.6068024539521762 
VAL_ACCURACY : 0.7232845894263217
VAL_F1 : 0.7354838704778172

EPOCH : 8 / 50
VAL_LOSS : 0.5934162533708981 
VAL_ACCURACY : 0.7322834645669292
VAL_F1 : 0.7446351926427315

EPOCH : 9 / 50
VAL_LOSS : 0.5808538869023323 
VAL_ACCURACY : 0.735658042744657
VAL_F1 : 0.747583243333708

EPOCH : 10 / 50
VAL_LOSS : 0.5697090827992984 
VAL_ACCURACY : 0.7570303712035995
VAL_F1 : 0.7707006364505614

EPOCH : 11 / 50
VAL_LOSS : 0.5618654814149652 
VAL_ACCURACY : 0.7615298087739033
VAL_F1 : 0.7763713075237942

EPOCH : 12 / 50
VAL_LOSS : 0.5484087403331485 
VAL_ACCURACY : 0.7649043869516311
VAL_F1 : 0.7797681765352071

EPOCH : 13 / 50
VAL_LOSS : 0.5391865143818515 
VAL_ACCURACY : 0.7727784026996626
VAL_F1 : 0.7878151255567095

EPOCH : 14 / 50
VAL_LOSS : 0.5309411558721747 
VAL_ACCURACY : 0.7750281214848144
VAL_F1 : 0.7903563936359718

EPOCH : 15 / 50
VAL_LOSS : 0.521363982132503 
VAL_ACCURACY : 0.7784026996625422
VAL_F1 : 0.7941483798608374

EPOCH : 16 / 50
VAL_LOSS : 0.5133551364498479 
VAL_ACCURACY : 0.7896512935883014
VAL_F1 : 0.8066184069499354

EPOCH : 17 / 50
VAL_LOSS : 0.5050990278167384 
VAL_ACCURACY : 0.7896512935883014
VAL_F1 : 0.8066184069499354

EPOCH : 18 / 50
VAL_LOSS : 0.496594533856426 
VAL_ACCURACY : 0.7919010123734533
VAL_F1 : 0.8090815268517606

EPOCH : 19 / 50
VAL_LOSS : 0.48796775032367024 
VAL_ACCURACY : 0.7919010123734533
VAL_F1 : 0.8094747677838661

EPOCH : 20 / 50
VAL_LOSS : 0.48117828741669655 
VAL_ACCURACY : 0.7941507311586051
VAL_F1 : 0.811921890562089

EPOCH : 21 / 50
VAL_LOSS : 0.47333074307867457 
VAL_ACCURACY : 0.7930258717660292
VAL_F1 : 0.8103092778543736

EPOCH : 22 / 50
VAL_LOSS : 0.46835561628852573 
VAL_ACCURACY : 0.7941507311586051
VAL_F1 : 0.8115345000186713

EPOCH : 23 / 50
VAL_LOSS : 0.4612900247531278 
VAL_ACCURACY : 0.7975253093363329
VAL_F1 : 0.8151950713719711

EPOCH : 24 / 50
VAL_LOSS : 0.4564845838717052 
VAL_ACCURACY : 0.7986501687289089
VAL_F1 : 0.8167860793392889

EPOCH : 25 / 50
VAL_LOSS : 0.450724759804351 
VAL_ACCURACY : 0.7986501687289089
VAL_F1 : 0.8167860793392889

EPOCH : 26 / 50
VAL_LOSS : 0.44320958267365185 
VAL_ACCURACY : 0.8020247469066367
VAL_F1 : 0.820040899298443

EPOCH : 27 / 50
VAL_LOSS : 0.43628730305603575 
VAL_ACCURACY : 0.8020247469066367
VAL_F1 : 0.820040899298443

EPOCH : 28 / 50
VAL_LOSS : 0.4317970222660473 
VAL_ACCURACY : 0.8042744656917885
VAL_F1 : 0.8224489790945648

EPOCH : 29 / 50
VAL_LOSS : 0.42840736731886864 
VAL_ACCURACY : 0.8065241844769404
VAL_F1 : 0.8244897954210912

EPOCH : 30 / 50
VAL_LOSS : 0.4240099878183433 
VAL_ACCURACY : 0.8110236220472441
VAL_F1 : 0.8296146039645956

EPOCH : 31 / 50
VAL_LOSS : 0.419943206012249 
VAL_ACCURACY : 0.81214848143982
VAL_F1 : 0.8308004047705152

EPOCH : 32 / 50
VAL_LOSS : 0.4128033055790833 
VAL_ACCURACY : 0.8098987626546682
VAL_F1 : 0.8284263954413048

EPOCH : 33 / 50
VAL_LOSS : 0.4104544903550829 
VAL_ACCURACY : 0.8087739032620922
VAL_F1 : 0.8272357718600413

EPOCH : 34 / 50
VAL_LOSS : 0.40601897558995653 
VAL_ACCURACY : 0.81214848143982
VAL_F1 : 0.830111901842186

EPOCH : 35 / 50
VAL_LOSS : 0.39978545744504246 
VAL_ACCURACY : 0.81214848143982
VAL_F1 : 0.8311425677525991

EPOCH : 36 / 50
VAL_LOSS : 0.39705138759953634 
VAL_ACCURACY : 0.8155230596175478
VAL_F1 : 0.8346774188564077

EPOCH : 37 / 50
VAL_LOSS : 0.39322281362754957 
VAL_ACCURACY : 0.8188976377952756
VAL_F1 : 0.8378650548891912

EPOCH : 38 / 50
VAL_LOSS : 0.3898960727133921 
VAL_ACCURACY : 0.8188976377952756
VAL_F1 : 0.8378650548891912

EPOCH : 39 / 50
VAL_LOSS : 0.3864165089492287 
VAL_ACCURACY : 0.8188976377952756
VAL_F1 : 0.8381909542751789

EPOCH : 40 / 50
VAL_LOSS : 0.38250008624579224 
VAL_ACCURACY : 0.8200224971878515
VAL_F1 : 0.8393574292201013

EPOCH : 41 / 50
VAL_LOSS : 0.3795858398079872 
VAL_ACCURACY : 0.8200224971878515
VAL_F1 : 0.8393574292201013

EPOCH : 42 / 50
VAL_LOSS : 0.37857541761228014 
VAL_ACCURACY : 0.8188976377952756
VAL_F1 : 0.8381909542751789

EPOCH : 43 / 50
VAL_LOSS : 0.372761177697352 
VAL_ACCURACY : 0.8188976377952756
VAL_F1 : 0.8381909542751789

EPOCH : 44 / 50
VAL_LOSS : 0.3709832025425775 
VAL_ACCURACY : 0.8188976377952756
VAL_F1 : 0.8381909542751789

EPOCH : 45 / 50
VAL_LOSS : 0.36965867078730036 
VAL_ACCURACY : 0.8200224971878515
VAL_F1 : 0.8393574292201013

EPOCH : 46 / 50
VAL_LOSS : 0.3653145155736378 
VAL_ACCURACY : 0.8211473565804275
VAL_F1 : 0.8405215641952257

EPOCH : 47 / 50
VAL_LOSS : 0.3622211002345596 
VAL_ACCURACY : 0.8278965129358831
VAL_F1 : 0.8474576266193207

EPOCH : 48 / 50
VAL_LOSS : 0.359435485675931 
VAL_ACCURACY : 0.829021372328459
VAL_F1 : 0.8486055771898461

EPOCH : 49 / 50
VAL_LOSS : 0.35714937693306376 
VAL_ACCURACY : 0.8301462317210349
VAL_F1 : 0.8497512432816258

EPOCH : 50 / 50
VAL_LOSS : 0.3556926513889006 
VAL_ACCURACY : 0.8312710911136107
VAL_F1 : 0.85089463170722

# 5話-0
# 文: オススメの本教えて
正解 : 1 , 予測 : 0 / 元クラス : UNK
tensor([[ 0.8431, -0.5671]], device='cuda:0')
# 5話-0
# 文: 僕ですか?
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.2849,  0.3239]], device='cuda:0')
# 5話-0
# 文: Bさん、苦手そうだよな…
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
tensor([[ 0.3997, -0.1480]], device='cuda:0')
# 5話-0
# 文: 適当に流そう
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.5136,  0.4473]], device='cuda:0')
# 5話-0
# 文: 小説はあまり読まないのですが、研究で利用している青空文庫の作品なら少々
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.5094,  0.2097]], device='cuda:0')
# 5話-0
# 文: そうなんだ〜
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 0.8940, -1.2081]], device='cuda:0')
# 5話-1
# 文: ありがとうございます… それ、何読んでるんですか?
正解 : 1 , 予測 : 0 / 元クラス : 恐怖
tensor([[ 0.4840, -0.2834]], device='cuda:0')
# 5話-1
# 文: 僕ですか?
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.2849,  0.3239]], device='cuda:0')
# 5話-1
# 文: 本当に今ハマってる本はこの二冊…
正解 : 1 , 予測 : 0 / 元クラス : 恐怖
tensor([[ 0.3280, -0.4662]], device='cuda:0')
# 6話-0
# 文: 手作りなんですか?
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.1495,  0.3681]], device='cuda:0')
# 6話-0
# 文: 見てもいいですか?
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.2857,  0.1288]], device='cuda:0')
# 6話-0
# 文: キャー!
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[ 0.5034, -0.9218]], device='cuda:0')
# 6話-0
# 文: ベタだなあ
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[0.0908, 0.0409]], device='cuda:0')
# 6話-1
# 文: キャー!
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[ 0.5034, -0.9218]], device='cuda:0')
# 6話-1
# 文: ベタだなあ
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[0.0908, 0.0409]], device='cuda:0')
# 6話-1
# 文: 今日弁当なの珍しいですね
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.2447, -0.2259]], device='cuda:0')
# 6話-1
# 文: ええ… 父の分と2つ作ったんだけど
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
tensor([[ 0.4911, -0.4885]], device='cuda:0')
# 6話-1
# 文: 手作りなんですか?
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.1495,  0.3681]], device='cuda:0')
# 6話-1
# 文: ほとんど冷凍食品詰めただけよ…
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
tensor([[ 0.3238, -0.3579]], device='cuda:0')
# 7話-0
# 文: どれがいいですか?
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.0453,  0.1768]], device='cuda:0')
# 7話-0
# 文: じゃあチョコですね
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.4334,  0.2081]], device='cuda:0')
# 7話-0
# 文: 別に気にしませんが…
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.6057,  0.5732]], device='cuda:0')
# 7話-0
# 文: とか言い出すのかな…
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.6101,  0.5801]], device='cuda:0')
# 7話-0
# 文: 器用だ!?
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[ 0.7215, -0.9308]], device='cuda:0')
# 7話-1
# 文: 器用だ!?
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[ 0.7215, -0.9308]], device='cuda:0')
# 7話-1
# 文: こうやっていろんな食べ方をすれば飽きないですね
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.2455, -0.1997]], device='cuda:0')
# 7話-1
# 文: てっきり
正解 : 1 , 予測 : 0 / 元クラス : UNK
tensor([[ 0.6827, -0.5763]], device='cuda:0')
# 7話-1
# 文: とか言い出すのかと思った…
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.6083,  0.5821]], device='cuda:0')
# 7話-1
# 文: Aくんがいなければ独り占めできたのにな…
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
tensor([[ 0.3769, -0.1853]], device='cuda:0')
# 8話-1
# 文: でも わざわざ国際会議から送ってくれたんだよな…
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
tensor([[ 0.8874, -0.5107]], device='cuda:0')
# 9話-0
# 文: Bさん…
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.1132,  0.4517]], device='cuda:0')
# 9話-0
# 文: あれ？
正解 : 1 , 予測 : 0 / 元クラス : UNK
tensor([[ 0.4318, -0.2062]], device='cuda:0')
# 9話-0
# 文: ハッ
正解 : 1 , 予測 : 0 / 元クラス : UNK
tensor([[ 0.6187, -0.8260]], device='cuda:0')
# 9話-0
# 文: 人違い!?
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[ 0.6738, -0.8189]], device='cuda:0')
# 9話-1
# 文: 人違い!?
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[ 0.6738, -0.8189]], device='cuda:0')
# 9話-1
# 文: ハッ
正解 : 1 , 予測 : 0 / 元クラス : UNK
tensor([[ 0.6187, -0.8260]], device='cuda:0')
------------------------test acc------------------------
Test Acc : 0.5263
correct: 40, total: 76
------------------------------------------------
                  喜楽        その他  accuracy  macro avg  weighted avg
precision   0.522727   0.531250  0.526316   0.526989      0.526989
recall      0.605263   0.447368  0.526316   0.526316      0.526316
f1-score    0.560976   0.485714  0.526316   0.523345      0.523345
support    38.000000  38.000000  0.526316  76.000000     76.000000
正例のF1値 : 0.5609756092450923
