class weight : tensor([0.7635, 0.1549])
best:lr 3.5081997961892887e-07
EPOCH : 1 / 50
VAL_LOSS : 0.7067235451118619 
VAL_ACCURACY : 0.23383084577114427
VAL_F1 : 0.32307692275886

EPOCH : 2 / 50
VAL_LOSS : 0.665960103857751 
VAL_ACCURACY : 0.2537313432835821
VAL_F1 : 0.3749999996945313

EPOCH : 3 / 50
VAL_LOSS : 0.6256499863138386 
VAL_ACCURACY : 0.35074626865671643
VAL_F1 : 0.40816326498033234

EPOCH : 4 / 50
VAL_LOSS : 0.5953099190020094 
VAL_ACCURACY : 0.4465174129353234
VAL_F1 : 0.4458281441093471

EPOCH : 5 / 50
VAL_LOSS : 0.5667437729882259 
VAL_ACCURACY : 0.5099502487562189
VAL_F1 : 0.4774535805371178

EPOCH : 6 / 50
VAL_LOSS : 0.5292842031693926 
VAL_ACCURACY : 0.6194029850746269
VAL_F1 : 0.5391566261092048

EPOCH : 7 / 50
VAL_LOSS : 0.5046817794734356 
VAL_ACCURACY : 0.7189054726368159
VAL_F1 : 0.6130136982015973

EPOCH : 8 / 50
VAL_LOSS : 0.47869393755407896 
VAL_ACCURACY : 0.7599502487562189
VAL_F1 : 0.650994574603756

EPOCH : 9 / 50
VAL_LOSS : 0.4566870448636074 
VAL_ACCURACY : 0.7736318407960199
VAL_F1 : 0.6642066416203483

EPOCH : 10 / 50
VAL_LOSS : 0.4325915025729759 
VAL_ACCURACY : 0.8345771144278606
VAL_F1 : 0.7302231232656791

EPOCH : 11 / 50
VAL_LOSS : 0.416273749926511 
VAL_ACCURACY : 0.8619402985074627
VAL_F1 : 0.7643312097156072

EPOCH : 12 / 50
VAL_LOSS : 0.39681508085306955 
VAL_ACCURACY : 0.8893034825870647
VAL_F1 : 0.8017817367098378

EPOCH : 13 / 50
VAL_LOSS : 0.3775743847968532 
VAL_ACCURACY : 0.8893034825870647
VAL_F1 : 0.8017817367098378

EPOCH : 14 / 50
VAL_LOSS : 0.3620070704058105 
VAL_ACCURACY : 0.8992537313432836
VAL_F1 : 0.8163265301254108

EPOCH : 15 / 50
VAL_LOSS : 0.3467610449183221 
VAL_ACCURACY : 0.9079601990049752
VAL_F1 : 0.8294930870683175

EPOCH : 16 / 50
VAL_LOSS : 0.33063745732400934 
VAL_ACCURACY : 0.9203980099502488
VAL_F1 : 0.8490566032809719

EPOCH : 17 / 50
VAL_LOSS : 0.3160964422950558 
VAL_ACCURACY : 0.9191542288557214
VAL_F1 : 0.8470588230371212

EPOCH : 18 / 50
VAL_LOSS : 0.3049775879172718 
VAL_ACCURACY : 0.9216417910447762
VAL_F1 : 0.8510638292943011

EPOCH : 19 / 50
VAL_LOSS : 0.2952318171075746 
VAL_ACCURACY : 0.9266169154228856
VAL_F1 : 0.8591885436585576

EPOCH : 20 / 50
VAL_LOSS : 0.2782585398823607 
VAL_ACCURACY : 0.9440298507462687
VAL_F1 : 0.8888888883906723

EPOCH : 21 / 50
VAL_LOSS : 0.26392824626436423 
VAL_ACCURACY : 0.9378109452736318
VAL_F1 : 0.8780487799909579

EPOCH : 22 / 50
VAL_LOSS : 0.2558528462461397 
VAL_ACCURACY : 0.9427860696517413
VAL_F1 : 0.8866995068912131

EPOCH : 23 / 50
VAL_LOSS : 0.250694113034828 
VAL_ACCURACY : 0.9577114427860697
VAL_F1 : 0.9137055832554305

EPOCH : 24 / 50
VAL_LOSS : 0.23882861581503176 
VAL_ACCURACY : 0.9589552238805971
VAL_F1 : 0.9160305338500089

EPOCH : 25 / 50
VAL_LOSS : 0.2281966711960587 
VAL_ACCURACY : 0.9527363184079602
VAL_F1 : 0.9045226125653393

EPOCH : 26 / 50
VAL_LOSS : 0.21582181517984353 
VAL_ACCURACY : 0.9614427860696517
VAL_F1 : 0.9207161120304029

EPOCH : 27 / 50
VAL_LOSS : 0.21671880138855354 
VAL_ACCURACY : 0.9738805970149254
VAL_F1 : 0.9448818892603386

EPOCH : 28 / 50
VAL_LOSS : 0.19949450446110145 
VAL_ACCURACY : 0.9776119402985075
VAL_F1 : 0.9523809518770472

EPOCH : 29 / 50
VAL_LOSS : 0.19014385926957225 
VAL_ACCURACY : 0.9825870646766169
VAL_F1 : 0.9625668444153394

EPOCH : 30 / 50
VAL_LOSS : 0.18203414173102847 
VAL_ACCURACY : 0.9825870646766169
VAL_F1 : 0.9625668444153394

EPOCH : 31 / 50
VAL_LOSS : 0.17622818344948338 
VAL_ACCURACY : 0.9875621890547264
VAL_F1 : 0.972972972468079

EPOCH : 32 / 50
VAL_LOSS : 0.17162830002752005 
VAL_ACCURACY : 0.9900497512437811
VAL_F1 : 0.9782608690601371

EPOCH : 33 / 50
VAL_LOSS : 0.16633606935833015 
VAL_ACCURACY : 0.9888059701492538
VAL_F1 : 0.9756097555925706

EPOCH : 34 / 50
VAL_LOSS : 0.15660990350971035 
VAL_ACCURACY : 0.9925373134328358
VAL_F1 : 0.9836065568718088

EPOCH : 35 / 50
VAL_LOSS : 0.1541642530583868 
VAL_ACCURACY : 0.9925373134328358
VAL_F1 : 0.9836065568718088

EPOCH : 36 / 50
VAL_LOSS : 0.14908680743446537 
VAL_ACCURACY : 0.9912935323383084
VAL_F1 : 0.9809264300125475

EPOCH : 37 / 50
VAL_LOSS : 0.1452589084704717 
VAL_ACCURACY : 0.9937810945273632
VAL_F1 : 0.9863013693577032

EPOCH : 38 / 50
VAL_LOSS : 0.13742901019605935 
VAL_ACCURACY : 0.9925373134328358
VAL_F1 : 0.9836065568718088

EPOCH : 39 / 50
VAL_LOSS : 0.12966737319149224 
VAL_ACCURACY : 0.9937810945273632
VAL_F1 : 0.9863013693577032

EPOCH : 40 / 50
VAL_LOSS : 0.1255988304813703 
VAL_ACCURACY : 0.9925373134328358
VAL_F1 : 0.9836065568718088

EPOCH : 41 / 50
VAL_LOSS : 0.11932123620428291 
VAL_ACCURACY : 0.9925373134328358
VAL_F1 : 0.9836065568718088

EPOCH : 42 / 50
VAL_LOSS : 0.11638318002223969 
VAL_ACCURACY : 0.9925373134328358
VAL_F1 : 0.9836065568718088

EPOCH : 43 / 50
VAL_LOSS : 0.11392905409721767 
VAL_ACCURACY : 0.9925373134328358
VAL_F1 : 0.9836065568718088

EPOCH : 44 / 50
VAL_LOSS : 0.10928443191098232 
VAL_ACCURACY : 0.9937810945273632
VAL_F1 : 0.9863013693577032

EPOCH : 45 / 50
VAL_LOSS : 0.10498044179642901 
VAL_ACCURACY : 0.9925373134328358
VAL_F1 : 0.9836065568718088

EPOCH : 46 / 50
VAL_LOSS : 0.10226399451494217 
VAL_ACCURACY : 0.9937810945273632
VAL_F1 : 0.9863013693577032

EPOCH : 47 / 50
VAL_LOSS : 0.09850207665095143 
VAL_ACCURACY : 0.9925373134328358
VAL_F1 : 0.9836065568718088

EPOCH : 48 / 50
VAL_LOSS : 0.09464785018387963 
VAL_ACCURACY : 0.9925373134328358
VAL_F1 : 0.9836065568718088

EPOCH : 49 / 50
VAL_LOSS : 0.0932347754053041 
VAL_ACCURACY : 0.9912935323383084
VAL_F1 : 0.9809264300125475

EPOCH : 50 / 50
VAL_LOSS : 0.09311243840584568 
VAL_ACCURACY : 0.9925373134328358
VAL_F1 : 0.9836065568718088

# 5話-0
# 文: 夏目漱石だよ〜 Aくんはどんな本を読むの
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.6812,  1.2445]], device='cuda:0')
# 5話-0
# 文: 今ハマってる本はこの二冊…
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 0.0848, -0.2126]], device='cuda:0')
# 5話-0
# 文: そうなんだ〜
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.4437,  0.7654]], device='cuda:0')
# 5話-0
# 文: あと、これも読んだよ
正解 : 1 , 予測 : 0 / 元クラス : 憤怒
tensor([[ 0.7543, -0.5469]], device='cuda:0')
# 5話-1
# 文: これ読んだよ
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 0.7500, -0.4117]], device='cuda:0')
# 5話-1
# 文: 夏目漱石だよ〜 Aくんはどんな本を読むの
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.8945,  1.2978]], device='cuda:0')
# 5話-1
# 文: 小説はあまり読まないのですが 研究で利用している青空文庫の作品なら少々
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 0.3297, -0.3308]], device='cuda:0')
# 5話-1
# 文: そうなんだ〜
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 0.5981, -0.4539]], device='cuda:0')
# 6話-0
# 文: 手作りなんですか?
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 0.4037, -0.3369]], device='cuda:0')
# 6話-0
# 文: ほとんど冷凍食品詰めただけだよ
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 0.3911, -0.5211]], device='cuda:0')
# 6話-0
# 文: 見てもいいですか?
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[-0.0403, -0.1825]], device='cuda:0')
# 6話-0
# 文: どうぞどうぞ
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 0.0373, -0.3267]], device='cuda:0')
# 6話-0
# 文: キャー!
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[ 0.6971, -0.2369]], device='cuda:0')
# 6話-0
# 文: ベタだなあ
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
tensor([[0.2812, 0.1845]], device='cuda:0')
# 6話-1
# 文: キャー!
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[0.6024, 0.0270]], device='cuda:0')
# 6話-1
# 文: 手作りなんですか?
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 0.4921, -0.3643]], device='cuda:0')
# 6話-1
# 文: ほとんど冷凍食品詰めただけよ…
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
tensor([[ 0.5701, -0.4809]], device='cuda:0')
# 6話-1
# 文: 俺も今日弁当なんでおかず分けますよ
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.4016,  0.1348]], device='cuda:0')
# 7話-0
# 文: チョコは一つしかないし、悪いよ〜
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 0.1244, -0.0589]], device='cuda:0')
# 7話-0
# 文: 器用だ!?
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[ 0.2810, -0.0322]], device='cuda:0')
# 7話-1
# 文: 器用だ!?
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[ 0.2856, -0.0444]], device='cuda:0')
# 7話-1
# 文: チョコ一つしかないね はんぶんこしよっか
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 0.8952, -0.5295]], device='cuda:0')
# 7話-1
# 文: とか言い出すのかと思った…
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[0.1363, 0.0535]], device='cuda:0')
# 7話-1
# 文: Aくんがいなければ独り占めできたのにな…
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
tensor([[0.3144, 0.0203]], device='cuda:0')
# 8話-0
# 文: 国際会議でスペインにいるBさんからだ
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[0.4027, 0.1423]], device='cuda:0')
# 9話-0
# 文: あれ?スペインからもう戻ってきたのか。
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 1.0437, -0.8196]], device='cuda:0')
# 9話-0
# 文: Bさ…ちょっと!
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 0.3203, -0.2032]], device='cuda:0')
# 9話-0
# 文: 人違い!?
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[ 0.4812, -0.0664]], device='cuda:0')
# 9話-1
# 文: Bさ… 人違い!?
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[0.2874, 0.1138]], device='cuda:0')
# 9話-1
# 文: ここは よその研究室…!?
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[ 0.6574, -0.5094]], device='cuda:0')
# 9話-1
# 文: 恥ずかしい…
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
tensor([[ 0.3101, -0.0889]], device='cuda:0')
------------------------test acc------------------------
Test Acc : 0.5156
correct: 33, total: 64
------------------------------------------------
                  喜楽        その他  accuracy  macro avg  weighted avg
precision   0.228571   0.862069  0.515625   0.545320      0.743288
recall      0.666667   0.480769  0.515625   0.573718      0.515625
f1-score    0.340426   0.617284  0.515625   0.478855      0.565373
support    12.000000  52.000000  0.515625  64.000000     64.000000
正例のF1値 : 0.3404255315201449
class weight : tensor([0.7635, 0.1549])
best:lr 1.411994057393608e-06
EPOCH : 1 / 50
VAL_LOSS : 0.5433126115331463 
VAL_ACCURACY : 0.5385572139303483
VAL_F1 : 0.4868603039123829

EPOCH : 2 / 50
VAL_LOSS : 0.4588238719631644 
VAL_ACCURACY : 0.753731343283582
VAL_F1 : 0.6399999995573421

EPOCH : 3 / 50
VAL_LOSS : 0.3914314823992112 
VAL_ACCURACY : 0.8383084577114428
VAL_F1 : 0.7302904559605379

EPOCH : 4 / 50
VAL_LOSS : 0.3400876770416896 
VAL_ACCURACY : 0.8706467661691543
VAL_F1 : 0.7729257637116569

EPOCH : 5 / 50
VAL_LOSS : 0.2960227228262845 
VAL_ACCURACY : 0.9079601990049752
VAL_F1 : 0.8279069762535858

EPOCH : 6 / 50
VAL_LOSS : 0.2524820802842869 
VAL_ACCURACY : 0.9328358208955224
VAL_F1 : 0.8695652168956101

EPOCH : 7 / 50
VAL_LOSS : 0.2201461347879148 
VAL_ACCURACY : 0.9626865671641791
VAL_F1 : 0.923076922575148

EPOCH : 8 / 50
VAL_LOSS : 0.18911214114404193 
VAL_ACCURACY : 0.9838308457711443
VAL_F1 : 0.9651474525785424

EPOCH : 9 / 50
VAL_LOSS : 0.17230086905114791 
VAL_ACCURACY : 0.9850746268656716
VAL_F1 : 0.9677419349791884

EPOCH : 10 / 50
VAL_LOSS : 0.14907750209756926 
VAL_ACCURACY : 0.9912935323383084
VAL_F1 : 0.9809264300125475

EPOCH : 11 / 50
VAL_LOSS : 0.13167325670228286 
VAL_ACCURACY : 0.9912935323383084
VAL_F1 : 0.9809264300125475

EPOCH : 12 / 50
VAL_LOSS : 0.11931660778674424 
VAL_ACCURACY : 0.9912935323383084
VAL_F1 : 0.9809264300125475

EPOCH : 13 / 50
VAL_LOSS : 0.10798899931650535 
VAL_ACCURACY : 0.9912935323383084
VAL_F1 : 0.9809264300125475

EPOCH : 14 / 50
VAL_LOSS : 0.09704241711719364 
VAL_ACCURACY : 0.9912935323383084
VAL_F1 : 0.9809264300125475

EPOCH : 15 / 50
VAL_LOSS : 0.08985463968094658 
VAL_ACCURACY : 0.9912935323383084
VAL_F1 : 0.9809264300125475

EPOCH : 16 / 50
VAL_LOSS : 0.07996120778661148 
VAL_ACCURACY : 0.9912935323383084
VAL_F1 : 0.9809264300125475

EPOCH : 17 / 50
VAL_LOSS : 0.07470829178597413 
VAL_ACCURACY : 0.9925373134328358
VAL_F1 : 0.9836065568718088

EPOCH : 18 / 50
VAL_LOSS : 0.06976919811145932 
VAL_ACCURACY : 0.9925373134328358
VAL_F1 : 0.9836065568718088

EPOCH : 19 / 50
VAL_LOSS : 0.06462639767457456 
VAL_ACCURACY : 0.9925373134328358
VAL_F1 : 0.9836065568718088

EPOCH : 20 / 50
VAL_LOSS : 0.0600646183479066 
VAL_ACCURACY : 0.9925373134328358
VAL_F1 : 0.9836065568718088

EPOCH : 21 / 50
VAL_LOSS : 0.058086816440610325 
VAL_ACCURACY : 0.9950248756218906
VAL_F1 : 0.9890109885056154

EPOCH : 22 / 50
VAL_LOSS : 0.054904424092348886 
VAL_ACCURACY : 0.9950248756218906
VAL_F1 : 0.9890109885056154

EPOCH : 23 / 50
VAL_LOSS : 0.05169171419944249 
VAL_ACCURACY : 0.9950248756218906
VAL_F1 : 0.9890109885056154

EPOCH : 24 / 50
VAL_LOSS : 0.04824294259443002 
VAL_ACCURACY : 0.9950248756218906
VAL_F1 : 0.9890109885056154

EPOCH : 25 / 50
VAL_LOSS : 0.04555006233938769 
VAL_ACCURACY : 0.9950248756218906
VAL_F1 : 0.9890109885056154

EPOCH : 26 / 50
VAL_LOSS : 0.04443546541619534 
VAL_ACCURACY : 0.9950248756218906
VAL_F1 : 0.9890109885056154

EPOCH : 27 / 50
VAL_LOSS : 0.042165448414344414 
VAL_ACCURACY : 0.9950248756218906
VAL_F1 : 0.9890109885056154

EPOCH : 28 / 50
VAL_LOSS : 0.0405362053756036 
VAL_ACCURACY : 0.9950248756218906
VAL_F1 : 0.9890109885056154

EPOCH : 29 / 50
VAL_LOSS : 0.03885530570850653 
VAL_ACCURACY : 0.9950248756218906
VAL_F1 : 0.9890109885056154

EPOCH : 30 / 50
VAL_LOSS : 0.037548993915027265 
VAL_ACCURACY : 0.9950248756218906
VAL_F1 : 0.9890109885056154

EPOCH : 31 / 50
VAL_LOSS : 0.03858382561627556 
VAL_ACCURACY : 0.9950248756218906
VAL_F1 : 0.9890109885056154

EPOCH : 32 / 50
VAL_LOSS : 0.03599304965167653 
VAL_ACCURACY : 0.9950248756218906
VAL_F1 : 0.9890109885056154

EPOCH : 33 / 50
VAL_LOSS : 0.03430153078892652 
VAL_ACCURACY : 0.9950248756218906
VAL_F1 : 0.9890109885056154

EPOCH : 34 / 50
VAL_LOSS : 0.0326020029537818 
VAL_ACCURACY : 0.996268656716418
VAL_F1 : 0.9917355366846528

EPOCH : 35 / 50
VAL_LOSS : 0.03247803913465902 
VAL_ACCURACY : 0.996268656716418
VAL_F1 : 0.9917355366846528

EPOCH : 36 / 50
VAL_LOSS : 0.03209770262679633 
VAL_ACCURACY : 0.996268656716418
VAL_F1 : 0.9917355366846528

EPOCH : 37 / 50
VAL_LOSS : 0.030783614728088472 
VAL_ACCURACY : 0.9950248756218906
VAL_F1 : 0.9890109885056154

EPOCH : 38 / 50
VAL_LOSS : 0.030211241660164853 
VAL_ACCURACY : 0.996268656716418
VAL_F1 : 0.9917355366846528

EPOCH : 39 / 50
VAL_LOSS : 0.028876043235262234 
VAL_ACCURACY : 0.996268656716418
VAL_F1 : 0.9917355366846528

EPOCH : 40 / 50
VAL_LOSS : 0.028402057531125405 
VAL_ACCURACY : 0.996268656716418
VAL_F1 : 0.9917355366846528

EPOCH : 41 / 50
VAL_LOSS : 0.02794813930842222 
VAL_ACCURACY : 0.996268656716418
VAL_F1 : 0.9917355366846528

EPOCH : 42 / 50
VAL_LOSS : 0.026537606821340674 
VAL_ACCURACY : 0.996268656716418
VAL_F1 : 0.9917355366846528

EPOCH : 43 / 50
VAL_LOSS : 0.026733374770949867 
VAL_ACCURACY : 0.996268656716418
VAL_F1 : 0.9917355366846528

EPOCH : 44 / 50
VAL_LOSS : 0.02516740334092402 
VAL_ACCURACY : 0.996268656716418
VAL_F1 : 0.9917355366846528

EPOCH : 45 / 50
VAL_LOSS : 0.02539812912251435 
VAL_ACCURACY : 0.996268656716418
VAL_F1 : 0.9917355366846528

EPOCH : 46 / 50
VAL_LOSS : 0.024377139175639433 
VAL_ACCURACY : 0.996268656716418
VAL_F1 : 0.9917355366846528

EPOCH : 47 / 50
VAL_LOSS : 0.02378906861093699 
VAL_ACCURACY : 0.9975124378109452
VAL_F1 : 0.994475137616068

EPOCH : 48 / 50
VAL_LOSS : 0.02258182448499343 
VAL_ACCURACY : 0.9975124378109452
VAL_F1 : 0.994475137616068

EPOCH : 49 / 50
VAL_LOSS : 0.023031487513114426 
VAL_ACCURACY : 0.9975124378109452
VAL_F1 : 0.994475137616068

EPOCH : 50 / 50
VAL_LOSS : 0.022742641724500003 
VAL_ACCURACY : 0.9975124378109452
VAL_F1 : 0.994475137616068

# 5話-0
# 文: 夏目漱石だよ〜 Aくんはどんな本を読むの
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-1.8918,  1.9846]], device='cuda:0')
# 5話-0
# 文: そうなんだ〜
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-1.2908,  1.5550]], device='cuda:0')
# 5話-0
# 文: あと、これも読んだよ
正解 : 1 , 予測 : 0 / 元クラス : 憤怒
tensor([[ 0.9742, -1.3147]], device='cuda:0')
# 5話-1
# 文: これ読んだよ
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 1.7565, -1.8344]], device='cuda:0')
# 5話-1
# 文: 夏目漱石だよ〜 Aくんはどんな本を読むの
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-1.8856,  2.0157]], device='cuda:0')
# 5話-1
# 文: 小説はあまり読まないのですが 研究で利用している青空文庫の作品なら少々
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 0.0019, -0.3626]], device='cuda:0')
# 5話-1
# 文: そうなんだ〜
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 0.5367, -0.6877]], device='cuda:0')
# 6話-0
# 文: 手作りなんですか?
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 0.4036, -0.3649]], device='cuda:0')
# 6話-0
# 文: 見てもいいですか?
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 0.7875, -0.5253]], device='cuda:0')
# 6話-0
# 文: キャー!
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[ 0.6460, -0.8950]], device='cuda:0')
# 6話-1
# 文: キャー!
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[ 0.5608, -0.5257]], device='cuda:0')
# 6話-1
# 文: 手作りなんですか?
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 0.6921, -0.6006]], device='cuda:0')
# 6話-1
# 文: 俺も今日弁当なんでおかず分けますよ
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.9766,  1.1131]], device='cuda:0')
# 7話-0
# 文: 別に気にしませんが…
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[ 0.1780, -0.2110]], device='cuda:0')
# 7話-0
# 文: ジャーン!パフェを作ってみました〜!
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.5465,  0.2374]], device='cuda:0')
# 7話-1
# 文: ジャーン!パフェを作ってみました〜!
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.3440,  0.4851]], device='cuda:0')
# 7話-1
# 文: こうやっていろんな食べ方をすれば飽きないですね
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.5229,  0.6952]], device='cuda:0')
# 7話-1
# 文: チョコ一つしかないね はんぶんこしよっか
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 1.8120, -1.8899]], device='cuda:0')
# 7話-1
# 文: とか言い出すのかと思った…
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 0.7979, -1.0858]], device='cuda:0')
# 8話-0
# 文: 今日は良い実験結果が出たな
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-1.1454,  0.8639]], device='cuda:0')
# 8話-1
# 文: でもわざわざ国際会議から送ってくれたんだよな…
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
tensor([[ 0.7163, -0.9219]], device='cuda:0')
# 9話-0
# 文: あれ?スペインからもう戻ってきたのか。
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 0.9068, -1.2907]], device='cuda:0')
# 9話-0
# 文: ここはよその研究室…!?
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[ 0.9111, -0.8746]], device='cuda:0')
# 9話-1
# 文: ここは よその研究室…!?
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[ 0.9238, -1.0232]], device='cuda:0')
# 9話-1
# 文: ただいま〜
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.3382,  0.4634]], device='cuda:0')
------------------------test acc------------------------
Test Acc : 0.6094
correct: 39, total: 64
------------------------------------------------
                  喜楽        その他  accuracy  macro avg  weighted avg
precision   0.157895   0.800000  0.609375   0.478947      0.679605
recall      0.250000   0.692308  0.609375   0.471154      0.609375
f1-score    0.193548   0.742268  0.609375   0.467908      0.639383
support    12.000000  52.000000  0.609375  64.000000     64.000000
正例のF1値 : 0.19354838660978146
class weight : tensor([0.7635, 0.1549])
best:lr 3.361973627568092e-06
EPOCH : 1 / 50
VAL_LOSS : 0.48712165624487636 
VAL_ACCURACY : 0.6231343283582089
VAL_F1 : 0.5331278886575957

EPOCH : 2 / 50
VAL_LOSS : 0.3761822037837085 
VAL_ACCURACY : 0.8159203980099502
VAL_F1 : 0.7063492058872197

EPOCH : 3 / 50
VAL_LOSS : 0.28940602961708517 
VAL_ACCURACY : 0.9564676616915423
VAL_F1 : 0.9100257064389742

EPOCH : 4 / 50
VAL_LOSS : 0.227232929538278 
VAL_ACCURACY : 0.9813432835820896
VAL_F1 : 0.9597855222836649

EPOCH : 5 / 50
VAL_LOSS : 0.1850726242158927 
VAL_ACCURACY : 0.986318407960199
VAL_F1 : 0.9703504038078771

EPOCH : 6 / 50
VAL_LOSS : 0.15043609676992192 
VAL_ACCURACY : 0.9900497512437811
VAL_F1 : 0.9782608690601371

EPOCH : 7 / 50
VAL_LOSS : 0.12590035284851112 
VAL_ACCURACY : 0.9912935323383084
VAL_F1 : 0.9809264300125475

EPOCH : 8 / 50
VAL_LOSS : 0.11243192311011109 
VAL_ACCURACY : 0.9912935323383084
VAL_F1 : 0.9809264300125475

EPOCH : 9 / 50
VAL_LOSS : 0.0999252163604194 
VAL_ACCURACY : 0.9925373134328358
VAL_F1 : 0.9836065568718088

EPOCH : 10 / 50
VAL_LOSS : 0.0898657860416992 
VAL_ACCURACY : 0.9937810945273632
VAL_F1 : 0.9863013693577032

EPOCH : 11 / 50
VAL_LOSS : 0.08394037632673394 
VAL_ACCURACY : 0.9900497512437811
VAL_F1 : 0.9782608690601371

EPOCH : 12 / 50
VAL_LOSS : 0.07770393292109172 
VAL_ACCURACY : 0.9900497512437811
VAL_F1 : 0.9782608690601371

EPOCH : 13 / 50
VAL_LOSS : 0.07318673414342544 
VAL_ACCURACY : 0.9937810945273632
VAL_F1 : 0.9863013693577032

EPOCH : 14 / 50
VAL_LOSS : 0.06825924883870517 
VAL_ACCURACY : 0.9925373134328358
VAL_F1 : 0.9836065568718088

EPOCH : 15 / 50
VAL_LOSS : 0.06606166335005387 
VAL_ACCURACY : 0.9925373134328358
VAL_F1 : 0.9836065568718088

EPOCH : 16 / 50
VAL_LOSS : 0.0646691751100269 
VAL_ACCURACY : 0.9925373134328358
VAL_F1 : 0.9836065568718088

EPOCH : 17 / 50
VAL_LOSS : 0.05923660194464758 
VAL_ACCURACY : 0.9937810945273632
VAL_F1 : 0.9863013693577032

EPOCH : 18 / 50
VAL_LOSS : 0.05754408656674273 
VAL_ACCURACY : 0.9937810945273632
VAL_F1 : 0.9863013693577032

EPOCH : 19 / 50
VAL_LOSS : 0.05483415971199671 
VAL_ACCURACY : 0.9950248756218906
VAL_F1 : 0.9890109885056154

EPOCH : 20 / 50
VAL_LOSS : 0.05381683552382039 
VAL_ACCURACY : 0.9937810945273632
VAL_F1 : 0.9863013693577032

EPOCH : 21 / 50
VAL_LOSS : 0.05261326172188217 
VAL_ACCURACY : 0.996268656716418
VAL_F1 : 0.9917355366846528

EPOCH : 22 / 50
VAL_LOSS : 0.04955864171771442 
VAL_ACCURACY : 0.996268656716418
VAL_F1 : 0.9917355366846528

EPOCH : 23 / 50
VAL_LOSS : 0.04708809310606882 
VAL_ACCURACY : 0.996268656716418
VAL_F1 : 0.9917355366846528

EPOCH : 24 / 50
VAL_LOSS : 0.045272617509552075 
VAL_ACCURACY : 0.996268656716418
VAL_F1 : 0.9917355366846528

EPOCH : 25 / 50
VAL_LOSS : 0.04436943869964749 
VAL_ACCURACY : 0.996268656716418
VAL_F1 : 0.9917355366846528

EPOCH : 26 / 50
VAL_LOSS : 0.042054893120246774 
VAL_ACCURACY : 0.996268656716418
VAL_F1 : 0.9917355366846528

EPOCH : 27 / 50
VAL_LOSS : 0.04012048149517938 
VAL_ACCURACY : 0.9987562189054726
VAL_F1 : 0.997229916391986

EPOCH : 28 / 50
VAL_LOSS : 0.0399509914511559 
VAL_ACCURACY : 0.9975124378109452
VAL_F1 : 0.994475137616068

EPOCH : 29 / 50
VAL_LOSS : 0.03762218856490126 
VAL_ACCURACY : 0.9975124378109452
VAL_F1 : 0.994475137616068

EPOCH : 30 / 50
VAL_LOSS : 0.037248450495740944 
VAL_ACCURACY : 0.9975124378109452
VAL_F1 : 0.994475137616068

EPOCH : 31 / 50
VAL_LOSS : 0.035415355225696284 
VAL_ACCURACY : 0.9975124378109452
VAL_F1 : 0.994475137616068

EPOCH : 32 / 50
VAL_LOSS : 0.0343099818291033 
VAL_ACCURACY : 0.9987562189054726
VAL_F1 : 0.997229916391986

EPOCH : 33 / 50
VAL_LOSS : 0.032930545654951356 
VAL_ACCURACY : 0.9975124378109452
VAL_F1 : 0.994475137616068

EPOCH : 34 / 50
VAL_LOSS : 0.03226714741949942 
VAL_ACCURACY : 0.9975124378109452
VAL_F1 : 0.994475137616068

EPOCH : 35 / 50
VAL_LOSS : 0.031431921593406624 
VAL_ACCURACY : 0.9975124378109452
VAL_F1 : 0.994475137616068

EPOCH : 36 / 50
VAL_LOSS : 0.03111165761947632 
VAL_ACCURACY : 0.9975124378109452
VAL_F1 : 0.994475137616068

EPOCH : 37 / 50
VAL_LOSS : 0.030140893241646243 
VAL_ACCURACY : 0.9975124378109452
VAL_F1 : 0.994475137616068

EPOCH : 38 / 50
VAL_LOSS : 0.027847395187207295 
VAL_ACCURACY : 0.9987562189054726
VAL_F1 : 0.997229916391986

EPOCH : 39 / 50
VAL_LOSS : 0.026972442134922624 
VAL_ACCURACY : 1.0
VAL_F1 : 0.9999999994944446

EPOCH : 40 / 50
VAL_LOSS : 0.02695593676146339 
VAL_ACCURACY : 0.9975124378109452
VAL_F1 : 0.994475137616068

EPOCH : 41 / 50
VAL_LOSS : 0.0261120859022234 
VAL_ACCURACY : 0.9975124378109452
VAL_F1 : 0.994475137616068

EPOCH : 42 / 50
VAL_LOSS : 0.025298392546235348 
VAL_ACCURACY : 0.9987562189054726
VAL_F1 : 0.997229916391986

EPOCH : 43 / 50
VAL_LOSS : 0.02450836877174237 
VAL_ACCURACY : 0.9987562189054726
VAL_F1 : 0.997229916391986

EPOCH : 44 / 50
VAL_LOSS : 0.02375112948756592 
VAL_ACCURACY : 0.9987562189054726
VAL_F1 : 0.997229916391986

EPOCH : 45 / 50
VAL_LOSS : 0.022708218252541972 
VAL_ACCURACY : 0.9987562189054726
VAL_F1 : 0.997229916391986

EPOCH : 46 / 50
VAL_LOSS : 0.0232053641960317 
VAL_ACCURACY : 0.9987562189054726
VAL_F1 : 0.997229916391986

EPOCH : 47 / 50
VAL_LOSS : 0.021731581904140172 
VAL_ACCURACY : 0.9987562189054726
VAL_F1 : 0.997229916391986

EPOCH : 48 / 50
VAL_LOSS : 0.02177294497104252 
VAL_ACCURACY : 0.9987562189054726
VAL_F1 : 0.997229916391986

EPOCH : 49 / 50
VAL_LOSS : 0.020360623906348265 
VAL_ACCURACY : 0.9987562189054726
VAL_F1 : 0.997229916391986

EPOCH : 50 / 50
VAL_LOSS : 0.020750438356224227 
VAL_ACCURACY : 0.9987562189054726
VAL_F1 : 0.997229916391986

# 5話-0
# 文: 夏目漱石だよ〜 Aくんはどんな本を読むの
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-1.5993,  2.2645]], device='cuda:0')
# 5話-0
# 文: そうなんだ〜
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-1.5222,  2.0348]], device='cuda:0')
# 5話-1
# 文: これ読んだよ
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 1.5234, -1.7534]], device='cuda:0')
# 5話-1
# 文: 夏目漱石だよ〜 Aくんはどんな本を読むの
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-1.6002,  2.2661]], device='cuda:0')
# 5話-1
# 文: 小説はあまり読まないのですが 研究で利用している青空文庫の作品なら少々
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 0.4105, -0.7433]], device='cuda:0')
# 5話-1
# 文: そうなんだ〜
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 0.3374, -0.5961]], device='cuda:0')
# 6話-0
# 文: 手作りなんですか?
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 0.0112, -0.1043]], device='cuda:0')
# 6話-0
# 文: 見てもいいですか?
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 0.6724, -0.7088]], device='cuda:0')
# 6話-0
# 文: キャー!
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[ 0.6719, -0.3470]], device='cuda:0')
# 6話-1
# 文: キャー!
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[0.2806, 0.0182]], device='cuda:0')
# 6話-1
# 文: 手作りなんですか?
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 0.2793, -0.4617]], device='cuda:0')
# 6話-1
# 文: 俺も今日弁当なんでおかず分けますよ
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-1.3598,  1.9233]], device='cuda:0')
# 7話-0
# 文: 別に気にしませんが…
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[ 0.2808, -0.1420]], device='cuda:0')
# 7話-0
# 文: ジャーン!パフェを作ってみました〜!
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[0.0143, 0.4857]], device='cuda:0')
# 7話-1
# 文: ジャーン!パフェを作ってみました〜!
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[0.0836, 0.4355]], device='cuda:0')
# 7話-1
# 文: こうやっていろんな食べ方をすれば飽きないですね
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.4744,  0.7167]], device='cuda:0')
# 7話-1
# 文: チョコ一つしかないね はんぶんこしよっか
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 1.5355, -1.8951]], device='cuda:0')
# 7話-1
# 文: とか言い出すのかと思った…
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 0.9019, -0.7199]], device='cuda:0')
# 8話-0
# 文: 今日は良い実験結果が出たな
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-1.0006,  1.4995]], device='cuda:0')
# 8話-1
# 文: でもわざわざ国際会議から送ってくれたんだよな…
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
tensor([[ 1.0577, -1.2889]], device='cuda:0')
# 9話-0
# 文: あれ?スペインからもう戻ってきたのか。
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 1.0971, -1.6153]], device='cuda:0')
# 9話-0
# 文: ここはよその研究室…!?
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[ 0.9556, -0.7916]], device='cuda:0')
# 9話-1
# 文: ここは よその研究室…!?
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[ 1.1657, -1.4373]], device='cuda:0')
# 9話-1
# 文: ただいま〜
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.6585,  0.9657]], device='cuda:0')
------------------------test acc------------------------
Test Acc : 0.6250
correct: 40, total: 64
------------------------------------------------
                  喜楽        その他  accuracy  macro avg  weighted avg
precision   0.166667   0.804348     0.625   0.485507      0.684783
recall      0.250000   0.711538     0.625   0.480769      0.625000
f1-score    0.200000   0.755102     0.625   0.477551      0.651020
support    12.000000  52.000000     0.625  64.000000     64.000000
正例のF1値 : 0.19999999950666664
class weight : tensor([0.7635, 0.1549])
best:lr 5.922352952066885e-06
EPOCH : 1 / 50
VAL_LOSS : 0.30199019231048285 
VAL_ACCURACY : 0.9390547263681592
VAL_F1 : 0.8801955985248773

EPOCH : 2 / 50
VAL_LOSS : 0.16762525047741683 
VAL_ACCURACY : 0.9751243781094527
VAL_F1 : 0.9473684205490306

EPOCH : 3 / 50
VAL_LOSS : 0.09835474083528799 
VAL_ACCURACY : 0.9925373134328358
VAL_F1 : 0.9836065568718088

EPOCH : 4 / 50
VAL_LOSS : 0.06424120901262059 
VAL_ACCURACY : 0.9925373134328358
VAL_F1 : 0.9836065568718088

EPOCH : 5 / 50
VAL_LOSS : 0.04774568719314594 
VAL_ACCURACY : 0.9912935323383084
VAL_F1 : 0.9809264300125475

EPOCH : 6 / 50
VAL_LOSS : 0.03979996686764792 
VAL_ACCURACY : 0.9912935323383084
VAL_F1 : 0.9809264300125475

EPOCH : 7 / 50
VAL_LOSS : 0.03138495904996114 
VAL_ACCURACY : 0.9937810945273632
VAL_F1 : 0.9863013693577032

EPOCH : 8 / 50
VAL_LOSS : 0.025782734867842758 
VAL_ACCURACY : 0.996268656716418
VAL_F1 : 0.9917355366846528

EPOCH : 9 / 50
VAL_LOSS : 0.02624524832137075 
VAL_ACCURACY : 0.996268656716418
VAL_F1 : 0.9917355366846528

EPOCH : 10 / 50
VAL_LOSS : 0.02157161439604619 
VAL_ACCURACY : 0.996268656716418
VAL_F1 : 0.9917355366846528

EPOCH : 11 / 50
VAL_LOSS : 0.021406185521068526 
VAL_ACCURACY : 0.9950248756218906
VAL_F1 : 0.9890109885056154

EPOCH : 12 / 50
VAL_LOSS : 0.019392008747101997 
VAL_ACCURACY : 0.9950248756218906
VAL_F1 : 0.9890109885056154

EPOCH : 13 / 50
VAL_LOSS : 0.01617198205534734 
VAL_ACCURACY : 0.996268656716418
VAL_F1 : 0.9917355366846528

EPOCH : 14 / 50
VAL_LOSS : 0.014861857555076187 
VAL_ACCURACY : 0.9975124378109452
VAL_F1 : 0.994475137616068

EPOCH : 15 / 50
VAL_LOSS : 0.01442987669040175 
VAL_ACCURACY : 0.9975124378109452
VAL_F1 : 0.994475137616068

EPOCH : 16 / 50
VAL_LOSS : 0.014162041119062434 
VAL_ACCURACY : 0.9975124378109452
VAL_F1 : 0.994475137616068

EPOCH : 17 / 50
VAL_LOSS : 0.015817444479348613 
VAL_ACCURACY : 0.9950248756218906
VAL_F1 : 0.9890109885056154

EPOCH : 18 / 50
VAL_LOSS : 0.015227406851801217 
VAL_ACCURACY : 0.996268656716418
VAL_F1 : 0.9917355366846528

EPOCH : 19 / 50
VAL_LOSS : 0.01076157599249307 
VAL_ACCURACY : 1.0
VAL_F1 : 0.9999999994944446

EPOCH : 20 / 50
VAL_LOSS : 0.011977905736250035 
VAL_ACCURACY : 0.9975124378109452
VAL_F1 : 0.994475137616068

EPOCH : 21 / 50
VAL_LOSS : 0.011341203278040184 
VAL_ACCURACY : 0.9975124378109452
VAL_F1 : 0.994475137616068

EPOCH : 22 / 50
VAL_LOSS : 0.01080419908405519 
VAL_ACCURACY : 0.9975124378109452
VAL_F1 : 0.994475137616068

EPOCH : 23 / 50
VAL_LOSS : 0.009504593780958186 
VAL_ACCURACY : 0.9987562189054726
VAL_F1 : 0.997229916391986

EPOCH : 24 / 50
VAL_LOSS : 0.008953508455306292 
VAL_ACCURACY : 0.9987562189054726
VAL_F1 : 0.997229916391986

EPOCH : 25 / 50
VAL_LOSS : 0.008326848320589931 
VAL_ACCURACY : 0.9987562189054726
VAL_F1 : 0.997229916391986

EPOCH : 26 / 50
VAL_LOSS : 0.008436368239641773 
VAL_ACCURACY : 0.9987562189054726
VAL_F1 : 0.997229916391986

EPOCH : 27 / 50
VAL_LOSS : 0.009062266041177745 
VAL_ACCURACY : 0.9987562189054726
VAL_F1 : 0.997229916391986

EPOCH : 28 / 50
VAL_LOSS : 0.007157589044129732 
VAL_ACCURACY : 0.9987562189054726
VAL_F1 : 0.997229916391986

EPOCH : 29 / 50
VAL_LOSS : 0.006496628527255619 
VAL_ACCURACY : 1.0
VAL_F1 : 0.9999999994944446

EPOCH : 30 / 50
VAL_LOSS : 0.006687282584607601 
VAL_ACCURACY : 1.0
VAL_F1 : 0.9999999994944446

EPOCH : 31 / 50
VAL_LOSS : 0.007869432725961887 
VAL_ACCURACY : 0.9987562189054726
VAL_F1 : 0.997229916391986

EPOCH : 32 / 50
VAL_LOSS : 0.005957597821001329 
VAL_ACCURACY : 1.0
VAL_F1 : 0.9999999994944446

EPOCH : 33 / 50
VAL_LOSS : 0.006375917333963455 
VAL_ACCURACY : 1.0
VAL_F1 : 0.9999999994944446

EPOCH : 34 / 50
VAL_LOSS : 0.005722246068876748 
VAL_ACCURACY : 0.9987562189054726
VAL_F1 : 0.997229916391986

EPOCH : 35 / 50
VAL_LOSS : 0.006086198896096617 
VAL_ACCURACY : 0.9987562189054726
VAL_F1 : 0.997229916391986

EPOCH : 36 / 50
VAL_LOSS : 0.007562822685120445 
VAL_ACCURACY : 0.9975124378109452
VAL_F1 : 0.994475137616068

EPOCH : 37 / 50
VAL_LOSS : 0.005673489807283177 
VAL_ACCURACY : 0.9987562189054726
VAL_F1 : 0.997229916391986

EPOCH : 38 / 50
VAL_LOSS : 0.005124575727820105 
VAL_ACCURACY : 1.0
VAL_F1 : 0.9999999994944446

EPOCH : 39 / 50
VAL_LOSS : 0.004480112417071473 
VAL_ACCURACY : 1.0
VAL_F1 : 0.9999999994944446

EPOCH : 40 / 50
VAL_LOSS : 0.004514150385397906 
VAL_ACCURACY : 1.0
VAL_F1 : 0.9999999994944446

EPOCH : 41 / 50
VAL_LOSS : 0.004657770835739725 
VAL_ACCURACY : 0.9987562189054726
VAL_F1 : 0.997229916391986

EPOCH : 42 / 50
VAL_LOSS : 0.004967401831356042 
VAL_ACCURACY : 0.9987562189054726
VAL_F1 : 0.997229916391986

EPOCH : 43 / 50
VAL_LOSS : 0.006087075298031171 
VAL_ACCURACY : 0.9987562189054726
VAL_F1 : 0.997229916391986

EPOCH : 44 / 50
VAL_LOSS : 0.005465966169996297 
VAL_ACCURACY : 0.9987562189054726
VAL_F1 : 0.997229916391986

EPOCH : 45 / 50
VAL_LOSS : 0.00350857372213082 
VAL_ACCURACY : 1.0
VAL_F1 : 0.9999999994944446

EPOCH : 46 / 50
VAL_LOSS : 0.00463491313013376 
VAL_ACCURACY : 0.9987562189054726
VAL_F1 : 0.997229916391986

EPOCH : 47 / 50
VAL_LOSS : 0.0046645069047443425 
VAL_ACCURACY : 0.9987562189054726
VAL_F1 : 0.997229916391986

EPOCH : 48 / 50
VAL_LOSS : 0.005499133447586906 
VAL_ACCURACY : 0.9987562189054726
VAL_F1 : 0.997229916391986

EPOCH : 49 / 50
VAL_LOSS : 0.0045715846285662234 
VAL_ACCURACY : 0.9987562189054726
VAL_F1 : 0.997229916391986

EPOCH : 50 / 50
VAL_LOSS : 0.0041284460218294575 
VAL_ACCURACY : 0.9987562189054726
VAL_F1 : 0.997229916391986

# 5話-0
# 文: 夏目漱石だよ〜 Aくんはどんな本を読むの
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-2.5533,  2.1635]], device='cuda:0')
# 5話-0
# 文: そうなんだ〜
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-2.3429,  1.9869]], device='cuda:0')
# 5話-0
# 文: あと、これも読んだよ
正解 : 1 , 予測 : 0 / 元クラス : 憤怒
tensor([[ 0.7553, -0.6499]], device='cuda:0')
# 5話-1
# 文: これ読んだよ
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 2.1671, -1.7068]], device='cuda:0')
# 5話-1
# 文: 夏目漱石だよ〜 Aくんはどんな本を読むの
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-2.5577,  2.1636]], device='cuda:0')
# 5話-1
# 文: 小説はあまり読まないのですが 研究で利用している青空文庫の作品なら少々
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[-0.0303, -0.1587]], device='cuda:0')
# 6話-0
# 文: 手作りなんですか?
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 0.0965, -0.2683]], device='cuda:0')
# 6話-0
# 文: 見てもいいですか?
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 1.1735, -1.0889]], device='cuda:0')
# 6話-0
# 文: どうぞどうぞ
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 0.0534, -0.2847]], device='cuda:0')
# 6話-0
# 文: キャー!
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[ 0.2179, -0.0136]], device='cuda:0')
# 6話-1
# 文: 手作りなんですか?
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 0.4562, -0.6336]], device='cuda:0')
# 6話-1
# 文: 俺も今日弁当なんでおかず分けますよ
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-1.7564,  1.4053]], device='cuda:0')
# 7話-0
# 文: 別に気にしませんが…
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[ 0.0031, -0.1321]], device='cuda:0')
# 7話-0
# 文: ジャーン!パフェを作ってみました〜!
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.5706,  0.2510]], device='cuda:0')
# 7話-1
# 文: ジャーン!パフェを作ってみました〜!
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.5964,  0.3495]], device='cuda:0')
# 7話-1
# 文: こうやっていろんな食べ方をすれば飽きないですね
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.9612,  0.9844]], device='cuda:0')
# 7話-1
# 文: チョコ一つしかないね はんぶんこしよっか
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 2.2396, -1.7642]], device='cuda:0')
# 7話-1
# 文: とか言い出すのかと思った…
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 0.9213, -0.8559]], device='cuda:0')
# 8話-0
# 文: 今日は良い実験結果が出たな
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-1.6313,  1.3949]], device='cuda:0')
# 8話-1
# 文: でもわざわざ国際会議から送ってくれたんだよな…
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
tensor([[ 1.0076, -0.6603]], device='cuda:0')
# 9話-0
# 文: あれ?スペインからもう戻ってきたのか。
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 0.6252, -0.6426]], device='cuda:0')
# 9話-0
# 文: ここはよその研究室…!?
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[ 0.7589, -0.8174]], device='cuda:0')
# 9話-1
# 文: ここは よその研究室…!?
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[ 0.3739, -0.6366]], device='cuda:0')
# 9話-1
# 文: ただいま〜
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.8293,  0.8073]], device='cuda:0')
------------------------test acc------------------------
Test Acc : 0.6250
correct: 40, total: 64
------------------------------------------------
                  喜楽        その他  accuracy  macro avg  weighted avg
precision   0.166667   0.804348     0.625   0.485507      0.684783
recall      0.250000   0.711538     0.625   0.480769      0.625000
f1-score    0.200000   0.755102     0.625   0.477551      0.651020
support    12.000000  52.000000     0.625  64.000000     64.000000
正例のF1値 : 0.19999999950666664
