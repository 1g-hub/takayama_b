class weight : tensor([0.7065, 0.2077])
best:lr 3.5541242654906284e-07
class weight : tensor([0.7065, 0.2077])
best:lr 3.7417347642381154e-07
EPOCH : 1 / 50
VAL_LOSS : 0.6992016982059089 
VAL_ACCURACY : 0.2754182754182754
VAL_F1 : 0.3846994532045842

EPOCH : 2 / 50
VAL_LOSS : 0.6488506149272529 
VAL_ACCURACY : 0.44787644787644787
VAL_F1 : 0.43921568588225046

EPOCH : 3 / 50
VAL_LOSS : 0.6127618514761632 
VAL_ACCURACY : 0.5868725868725869
VAL_F1 : 0.49765258172340887

EPOCH : 4 / 50
VAL_LOSS : 0.577417794539004 
VAL_ACCURACY : 0.6756756756756757
VAL_F1 : 0.5483870963083594

EPOCH : 5 / 50
VAL_LOSS : 0.5476709646838052 
VAL_ACCURACY : 0.7503217503217503
VAL_F1 : 0.6072874489054075

EPOCH : 6 / 50
VAL_LOSS : 0.5255736015280899 
VAL_ACCURACY : 0.7657657657657657
VAL_F1 : 0.625514402802486

EPOCH : 7 / 50
VAL_LOSS : 0.5027654426438468 
VAL_ACCURACY : 0.803088803088803
VAL_F1 : 0.6778947363491988

EPOCH : 8 / 50
VAL_LOSS : 0.48455495493752615 
VAL_ACCURACY : 0.8442728442728443
VAL_F1 : 0.7340659335680425

EPOCH : 9 / 50
VAL_LOSS : 0.4660268419859361 
VAL_ACCURACY : 0.8584298584298584
VAL_F1 : 0.7533632281998031

EPOCH : 10 / 50
VAL_LOSS : 0.447932349175823 
VAL_ACCURACY : 0.8687258687258688
VAL_F1 : 0.7671232871700757

EPOCH : 11 / 50
VAL_LOSS : 0.4291259907946295 
VAL_ACCURACY : 0.8738738738738738
VAL_F1 : 0.7741935478853237

EPOCH : 12 / 50
VAL_LOSS : 0.41184763519131407 
VAL_ACCURACY : 0.8893178893178894
VAL_F1 : 0.7981220652248453

EPOCH : 13 / 50
VAL_LOSS : 0.39783982020251607 
VAL_ACCURACY : 0.8970398970398971
VAL_F1 : 0.8095238090203628

EPOCH : 14 / 50
VAL_LOSS : 0.38124368385392793 
VAL_ACCURACY : 0.9009009009009009
VAL_F1 : 0.8153477213188643

EPOCH : 15 / 50
VAL_LOSS : 0.37005966293568515 
VAL_ACCURACY : 0.9137709137709138
VAL_F1 : 0.834567900730474

EPOCH : 16 / 50
VAL_LOSS : 0.36043086739218966 
VAL_ACCURACY : 0.9279279279279279
VAL_F1 : 0.8647342990128358

EPOCH : 17 / 50
VAL_LOSS : 0.34763527920051496 
VAL_ACCURACY : 0.9382239382239382
VAL_F1 : 0.8829268287639978

EPOCH : 18 / 50
VAL_LOSS : 0.3434026667049953 
VAL_ACCURACY : 0.9446589446589446
VAL_F1 : 0.8948655251679988

EPOCH : 19 / 50
VAL_LOSS : 0.3281543525506039 
VAL_ACCURACY : 0.9498069498069498
VAL_F1 : 0.9041769036724642

EPOCH : 20 / 50
VAL_LOSS : 0.32183172295288165 
VAL_ACCURACY : 0.9523809523809523
VAL_F1 : 0.9095354518182939

EPOCH : 21 / 50
VAL_LOSS : 0.31429327203302965 
VAL_ACCURACY : 0.9498069498069498
VAL_F1 : 0.9051094885467172

EPOCH : 22 / 50
VAL_LOSS : 0.3013523500792834 
VAL_ACCURACY : 0.9510939510939511
VAL_F1 : 0.9073170726663179

EPOCH : 23 / 50
VAL_LOSS : 0.29450197609103457 
VAL_ACCURACY : 0.9498069498069498
VAL_F1 : 0.9051094885467172

EPOCH : 24 / 50
VAL_LOSS : 0.28897266637305824 
VAL_ACCURACY : 0.9498069498069498
VAL_F1 : 0.9051094885467172

EPOCH : 25 / 50
VAL_LOSS : 0.28138323797255144 
VAL_ACCURACY : 0.9536679536679536
VAL_F1 : 0.9130434777565638

EPOCH : 26 / 50
VAL_LOSS : 0.2714565822056362 
VAL_ACCURACY : 0.9562419562419563
VAL_F1 : 0.9174757276509333

EPOCH : 27 / 50
VAL_LOSS : 0.26846722923979466 
VAL_ACCURACY : 0.9575289575289575
VAL_F1 : 0.9200968517958596

EPOCH : 28 / 50
VAL_LOSS : 0.26112254572157956 
VAL_ACCURACY : 0.9575289575289575
VAL_F1 : 0.9204819272065496

EPOCH : 29 / 50
VAL_LOSS : 0.258457820938558 
VAL_ACCURACY : 0.9626769626769627
VAL_F1 : 0.9304556349873772

EPOCH : 30 / 50
VAL_LOSS : 0.25128093939654683 
VAL_ACCURACY : 0.9613899613899614
VAL_F1 : 0.928571428067415

EPOCH : 31 / 50
VAL_LOSS : 0.24416495342643893 
VAL_ACCURACY : 0.963963963963964
VAL_F1 : 0.9330143535628076

EPOCH : 32 / 50
VAL_LOSS : 0.2408669098299377 
VAL_ACCURACY : 0.9626769626769627
VAL_F1 : 0.9307875889947084

EPOCH : 33 / 50
VAL_LOSS : 0.23485267770533658 
VAL_ACCURACY : 0.963963963963964
VAL_F1 : 0.9333333328292971

EPOCH : 34 / 50
VAL_LOSS : 0.22913582957520776 
VAL_ACCURACY : 0.963963963963964
VAL_F1 : 0.9333333328292971

EPOCH : 35 / 50
VAL_LOSS : 0.22153955302676376 
VAL_ACCURACY : 0.963963963963964
VAL_F1 : 0.9333333328292971

EPOCH : 36 / 50
VAL_LOSS : 0.21966659627398666 
VAL_ACCURACY : 0.9626769626769627
VAL_F1 : 0.9311163890447471

EPOCH : 37 / 50
VAL_LOSS : 0.21315741493385665 
VAL_ACCURACY : 0.9678249678249679
VAL_F1 : 0.9400479611264198

EPOCH : 38 / 50
VAL_LOSS : 0.20984776743820735 
VAL_ACCURACY : 0.9691119691119691
VAL_F1 : 0.9428571423530613

EPOCH : 39 / 50
VAL_LOSS : 0.20670254224417162 
VAL_ACCURACY : 0.9716859716859717
VAL_F1 : 0.947368420548385

EPOCH : 40 / 50
VAL_LOSS : 0.20121386920919224 
VAL_ACCURACY : 0.9716859716859717
VAL_F1 : 0.947368420548385

EPOCH : 41 / 50
VAL_LOSS : 0.19865185463306856 
VAL_ACCURACY : 0.9716859716859717
VAL_F1 : 0.947368420548385

EPOCH : 42 / 50
VAL_LOSS : 0.194964700815629 
VAL_ACCURACY : 0.972972972972973
VAL_F1 : 0.9498806677535672

EPOCH : 43 / 50
VAL_LOSS : 0.19105793368451449 
VAL_ACCURACY : 0.972972972972973
VAL_F1 : 0.9501187643415689

EPOCH : 44 / 50
VAL_LOSS : 0.18608094645398005 
VAL_ACCURACY : 0.972972972972973
VAL_F1 : 0.9501187643415689

EPOCH : 45 / 50
VAL_LOSS : 0.1834135821887425 
VAL_ACCURACY : 0.9755469755469756
VAL_F1 : 0.9548693581657743

EPOCH : 46 / 50
VAL_LOSS : 0.17820817475416223 
VAL_ACCURACY : 0.9768339768339769
VAL_F1 : 0.9571428566387076

EPOCH : 47 / 50
VAL_LOSS : 0.1759674616005956 
VAL_ACCURACY : 0.9781209781209781
VAL_F1 : 0.9596199519899797

EPOCH : 48 / 50
VAL_LOSS : 0.17328395892162712 
VAL_ACCURACY : 0.9845559845559846
VAL_F1 : 0.9711538456493621

EPOCH : 49 / 50
VAL_LOSS : 0.16861570413623536 
VAL_ACCURACY : 0.9858429858429858
VAL_F1 : 0.9734939753990653

EPOCH : 50 / 50
VAL_LOSS : 0.16801478348824442 
VAL_ACCURACY : 0.9858429858429858
VAL_F1 : 0.9734939753990653

# 5話-0
# 文: あと、これも読んだよ
正解 : 1 , 予測 : 0 / 元クラス : 憤怒
tensor([[0.2503, 0.1653]], device='cuda:0')
# 6話-0
# 文: そうなんだ?
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.3094,  0.9600]], device='cuda:0')
# 6話-0
# 文: どうぞどうぞ
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[0.0310, 1.2794]], device='cuda:0')
# 6話-0
# 文: キャー!
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[0.5279, 0.4685]], device='cuda:0')
# 6話-1
# 文: キャー!
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[0.3502, 0.2408]], device='cuda:0')
# 7話-0
# 文: はんぶんこしよっか
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.0280,  0.6379]], device='cuda:0')
# 7話-0
# 文: とか言い出すのかな…
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.2918,  1.3740]], device='cuda:0')
# 7話-0
# 文: ジャーン!パフェを作ってみました?!
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[0.0227, 0.4612]], device='cuda:0')
# 7話-1
# 文: ジャーン!パフェを作ってみました?!
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[0.0319, 0.5805]], device='cuda:0')
# 8話-0
# 文: 今日は良い実験結果が出たな
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[0.0240, 0.9005]], device='cuda:0')
# 8話-0
# 文: ここは日本… 何も見ていない
正解 : 1 , 予測 : 0 / 元クラス : 恐怖
tensor([[ 0.0501, -0.0559]], device='cuda:0')
# 8話-1
# 文: でもわざわざ国際会議から送ってくれたんだよな…
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
tensor([[ 0.4261, -0.1908]], device='cuda:0')
# 9話-0
# 文: あれ?スペインからもう戻ってきたのか
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[ 0.6693, -0.4441]], device='cuda:0')
# 9話-0
# 文: Bさ…ちょっと!
正解 : 1 , 予測 : 0 / 元クラス : 憤怒
tensor([[ 0.5228, -1.3492]], device='cuda:0')
# 9話-0
# 文: ここはよその研究室…!?
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[ 0.4808, -1.0392]], device='cuda:0')
# 9話-1
# 文: ここは よその研究室…!?
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[ 0.4501, -1.0050]], device='cuda:0')
# 9話-1
# 文: 恥ずかしい…
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
tensor([[0.1494, 0.0662]], device='cuda:0')
# 9話-1
# 文: おかえりなさい!
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[0.3592, 0.5161]], device='cuda:0')
------------------------test acc------------------------
Test Acc : 0.7273
correct: 48, total: 66
------------------------------------------------
                  喜楽        その他  accuracy  macro avg  weighted avg
precision   0.166667   0.851852  0.727273   0.509259      0.748036
recall      0.200000   0.821429  0.727273   0.510714      0.727273
f1-score    0.181818   0.836364  0.727273   0.509091      0.737190
support    10.000000  56.000000  0.727273  66.000000     66.000000
正例のF1値 : 0.18181818130578511
class weight : tensor([0.7065, 0.2077])
best:lr 1.489916310728016e-06
EPOCH : 1 / 50
VAL_LOSS : 0.4955562979591136 
VAL_ACCURACY : 0.8674388674388674
VAL_F1 : 0.7736263731283083

EPOCH : 2 / 50
VAL_LOSS : 0.4169025050134075 
VAL_ACCURACY : 0.8957528957528957
VAL_F1 : 0.8057553951798216

EPOCH : 3 / 50
VAL_LOSS : 0.3668627155070402 
VAL_ACCURACY : 0.9099099099099099
VAL_F1 : 0.8333333328297733

EPOCH : 4 / 50
VAL_LOSS : 0.32769007676718187 
VAL_ACCURACY : 0.9407979407979408
VAL_F1 : 0.8935185180159252

EPOCH : 5 / 50
VAL_LOSS : 0.2976811117663675 
VAL_ACCURACY : 0.9485199485199485
VAL_F1 : 0.9069767436831369

EPOCH : 6 / 50
VAL_LOSS : 0.2715900446079215 
VAL_ACCURACY : 0.9498069498069498
VAL_F1 : 0.9099307154327988

EPOCH : 7 / 50
VAL_LOSS : 0.24650816893091007 
VAL_ACCURACY : 0.954954954954955
VAL_F1 : 0.9180327863819361

EPOCH : 8 / 50
VAL_LOSS : 0.224513051157095 
VAL_ACCURACY : 0.9562419562419563
VAL_F1 : 0.9205607471603416

EPOCH : 9 / 50
VAL_LOSS : 0.2082841279251235 
VAL_ACCURACY : 0.9601029601029601
VAL_F1 : 0.9270588230258491

EPOCH : 10 / 50
VAL_LOSS : 0.19023745050843882 
VAL_ACCURACY : 0.9626769626769627
VAL_F1 : 0.9320843086301137

EPOCH : 11 / 50
VAL_LOSS : 0.17373672735934353 
VAL_ACCURACY : 0.963963963963964
VAL_F1 : 0.9348837204271931

EPOCH : 12 / 50
VAL_LOSS : 0.16140482863601374 
VAL_ACCURACY : 0.9613899613899614
VAL_F1 : 0.9308755755343712

EPOCH : 13 / 50
VAL_LOSS : 0.1516100542277706 
VAL_ACCURACY : 0.9626769626769627
VAL_F1 : 0.9333333328309686

EPOCH : 14 / 50
VAL_LOSS : 0.1351148020095971 
VAL_ACCURACY : 0.9755469755469756
VAL_F1 : 0.955082741812898

EPOCH : 15 / 50
VAL_LOSS : 0.12886250923786843 
VAL_ACCURACY : 0.9845559845559846
VAL_F1 : 0.9711538456493621

EPOCH : 16 / 50
VAL_LOSS : 0.11884029080369035 
VAL_ACCURACY : 0.9845559845559846
VAL_F1 : 0.9711538456493621

EPOCH : 17 / 50
VAL_LOSS : 0.11164263924773858 
VAL_ACCURACY : 0.9858429858429858
VAL_F1 : 0.9734939753990653

EPOCH : 18 / 50
VAL_LOSS : 0.1044218655751676 
VAL_ACCURACY : 0.9871299871299871
VAL_F1 : 0.9760765545195393

EPOCH : 19 / 50
VAL_LOSS : 0.0966135393448022 
VAL_ACCURACY : 0.9884169884169884
VAL_F1 : 0.9784172656825906

EPOCH : 20 / 50
VAL_LOSS : 0.09244969433971814 
VAL_ACCURACY : 0.9897039897039897
VAL_F1 : 0.9807692302647005

EPOCH : 21 / 50
VAL_LOSS : 0.08837007959278262 
VAL_ACCURACY : 0.990990990990991
VAL_F1 : 0.9831325296158863

EPOCH : 22 / 50
VAL_LOSS : 0.08471431917681986 
VAL_ACCURACY : 0.990990990990991
VAL_F1 : 0.9831325296158863

EPOCH : 23 / 50
VAL_LOSS : 0.07862761358217317 
VAL_ACCURACY : 0.9922779922779923
VAL_F1 : 0.9855072458721558

EPOCH : 24 / 50
VAL_LOSS : 0.07485404070846889 
VAL_ACCURACY : 0.9922779922779923
VAL_F1 : 0.9855072458721558

EPOCH : 25 / 50
VAL_LOSS : 0.07174954000784427 
VAL_ACCURACY : 0.990990990990991
VAL_F1 : 0.9831325296158863

EPOCH : 26 / 50
VAL_LOSS : 0.0693768218007623 
VAL_ACCURACY : 0.9922779922779923
VAL_F1 : 0.9855072458721558

EPOCH : 27 / 50
VAL_LOSS : 0.06729137186645245 
VAL_ACCURACY : 0.9922779922779923
VAL_F1 : 0.9855072458721558

EPOCH : 28 / 50
VAL_LOSS : 0.06158264182812097 
VAL_ACCURACY : 0.9935649935649936
VAL_F1 : 0.987893461965023

EPOCH : 29 / 50
VAL_LOSS : 0.06148637401662311 
VAL_ACCURACY : 0.9922779922779923
VAL_F1 : 0.9855072458721558

EPOCH : 30 / 50
VAL_LOSS : 0.057543293934087365 
VAL_ACCURACY : 0.9922779922779923
VAL_F1 : 0.9855072458721558

EPOCH : 31 / 50
VAL_LOSS : 0.05434980756622188 
VAL_ACCURACY : 0.9935649935649936
VAL_F1 : 0.987893461965023

EPOCH : 32 / 50
VAL_LOSS : 0.05232257757107822 
VAL_ACCURACY : 0.9922779922779923
VAL_F1 : 0.9855072458721558

EPOCH : 33 / 50
VAL_LOSS : 0.05124293537620379 
VAL_ACCURACY : 0.9948519948519948
VAL_F1 : 0.9902912616311623

EPOCH : 34 / 50
VAL_LOSS : 0.05092479250564867 
VAL_ACCURACY : 0.990990990990991
VAL_F1 : 0.9831325296158863

EPOCH : 35 / 50
VAL_LOSS : 0.04726638314219154 
VAL_ACCURACY : 0.9948519948519948
VAL_F1 : 0.9902912616311623

EPOCH : 36 / 50
VAL_LOSS : 0.04647579523069518 
VAL_ACCURACY : 0.9935649935649936
VAL_F1 : 0.987893461965023

EPOCH : 37 / 50
VAL_LOSS : 0.044895497245752085 
VAL_ACCURACY : 0.9948519948519948
VAL_F1 : 0.9902912616311623

EPOCH : 38 / 50
VAL_LOSS : 0.04196728507474977 
VAL_ACCURACY : 0.9974259974259975
VAL_F1 : 0.99512195071467

EPOCH : 39 / 50
VAL_LOSS : 0.04222104899889352 
VAL_ACCURACY : 0.9961389961389961
VAL_F1 : 0.9927007294222033

EPOCH : 40 / 50
VAL_LOSS : 0.04142389952072075 
VAL_ACCURACY : 0.9961389961389961
VAL_F1 : 0.9927007294222033

EPOCH : 41 / 50
VAL_LOSS : 0.03977556845971516 
VAL_ACCURACY : 0.9961389961389961
VAL_F1 : 0.9927007294222033

EPOCH : 42 / 50
VAL_LOSS : 0.03742123239350562 
VAL_ACCURACY : 0.9961389961389961
VAL_F1 : 0.9927007294222033

EPOCH : 43 / 50
VAL_LOSS : 0.03616656872386835 
VAL_ACCURACY : 0.9961389961389961
VAL_F1 : 0.9927007294222033

EPOCH : 44 / 50
VAL_LOSS : 0.03483506731156792 
VAL_ACCURACY : 0.9961389961389961
VAL_F1 : 0.9927007294222033

EPOCH : 45 / 50
VAL_LOSS : 0.03328127163101216 
VAL_ACCURACY : 0.9961389961389961
VAL_F1 : 0.9927007294222033

EPOCH : 46 / 50
VAL_LOSS : 0.03287003877363643 
VAL_ACCURACY : 0.9961389961389961
VAL_F1 : 0.9927007294222033

EPOCH : 47 / 50
VAL_LOSS : 0.03298429274285326 
VAL_ACCURACY : 0.9961389961389961
VAL_F1 : 0.9927007294222033

EPOCH : 48 / 50
VAL_LOSS : 0.0308508928104931 
VAL_ACCURACY : 0.9961389961389961
VAL_F1 : 0.9927007294222033

EPOCH : 49 / 50
VAL_LOSS : 0.030778161459127252 
VAL_ACCURACY : 0.9961389961389961
VAL_F1 : 0.9927007294222033

EPOCH : 50 / 50
VAL_LOSS : 0.029797929966328095 
VAL_ACCURACY : 0.9974259974259975
VAL_F1 : 0.99512195071467

# 5話-0
# 文: 適当に流したな
正解 : 1 , 予測 : 0 / 元クラス : 憤怒
tensor([[ 0.0469, -0.2018]], device='cuda:0')
# 6話-0
# 文: そうなんだ?
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.8372,  1.0097]], device='cuda:0')
# 6話-0
# 文: どうぞどうぞ
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.8249,  0.7326]], device='cuda:0')
# 7話-0
# 文: とか言い出すのかな…
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.9102,  0.8747]], device='cuda:0')
# 7話-1
# 文: ジャーン!パフェを作ってみました?!
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.1566,  0.1045]], device='cuda:0')
# 8話-0
# 文: 今日は良い実験結果が出たな
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-1.6524,  1.2696]], device='cuda:0')
# 8話-1
# 文: でもわざわざ国際会議から送ってくれたんだよな…
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
tensor([[ 0.1043, -0.7016]], device='cuda:0')
# 8話-1
# 文: もう少し頑張るか
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.8112,  0.1412]], device='cuda:0')
# 9話-0
# 文: あれ?スペインからもう戻ってきたのか
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[ 0.5096, -1.1801]], device='cuda:0')
# 9話-0
# 文: Bさ…ちょっと!
正解 : 1 , 予測 : 0 / 元クラス : 憤怒
tensor([[ 2.3875, -1.5986]], device='cuda:0')
# 9話-0
# 文: ここはよその研究室…!?
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[ 2.0124, -1.1964]], device='cuda:0')
# 9話-1
# 文: ここは よその研究室…!?
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[ 1.8102, -1.1231]], device='cuda:0')
------------------------test acc------------------------
Test Acc : 0.8182
correct: 54, total: 66
------------------------------------------------
             喜楽        その他  accuracy  macro avg  weighted avg
precision   0.4   0.892857  0.818182   0.646429      0.818182
recall      0.4   0.892857  0.818182   0.646429      0.818182
f1-score    0.4   0.892857  0.818182   0.646429      0.818182
support    10.0  56.000000  0.818182  66.000000     66.000000
正例のF1値 : 0.39999999946
class weight : tensor([0.7065, 0.2077])
best:lr 3.2851520933480764e-06
EPOCH : 1 / 50
VAL_LOSS : 0.4515395882178326 
VAL_ACCURACY : 0.8918918918918919
VAL_F1 : 0.8028169009055744

EPOCH : 2 / 50
VAL_LOSS : 0.33648965158024613 
VAL_ACCURACY : 0.9253539253539254
VAL_F1 : 0.8549999994959251

EPOCH : 3 / 50
VAL_LOSS : 0.26747622690638717 
VAL_ACCURACY : 0.9472329472329473
VAL_F1 : 0.904428903925886

EPOCH : 4 / 50
VAL_LOSS : 0.22373877556956545 
VAL_ACCURACY : 0.9510939510939511
VAL_F1 : 0.9095238090198866

EPOCH : 5 / 50
VAL_LOSS : 0.19256734194196 
VAL_ACCURACY : 0.9601029601029601
VAL_F1 : 0.9284064660100806

EPOCH : 6 / 50
VAL_LOSS : 0.15885894198198708 
VAL_ACCURACY : 0.9678249678249679
VAL_F1 : 0.9411764700846064

EPOCH : 7 / 50
VAL_LOSS : 0.13757168288741792 
VAL_ACCURACY : 0.9781209781209781
VAL_F1 : 0.9596199519899797

EPOCH : 8 / 50
VAL_LOSS : 0.12465778829491868 
VAL_ACCURACY : 0.9794079794079794
VAL_F1 : 0.9619047614005896

EPOCH : 9 / 50
VAL_LOSS : 0.10866374355189655 
VAL_ACCURACY : 0.9871299871299871
VAL_F1 : 0.9758454101234102

EPOCH : 10 / 50
VAL_LOSS : 0.09731482220243434 
VAL_ACCURACY : 0.9884169884169884
VAL_F1 : 0.9782082319408568

EPOCH : 11 / 50
VAL_LOSS : 0.09003234031249066 
VAL_ACCURACY : 0.9884169884169884
VAL_F1 : 0.9783132525074758

EPOCH : 12 / 50
VAL_LOSS : 0.08389888141228229 
VAL_ACCURACY : 0.9897039897039897
VAL_F1 : 0.980676327997783

EPOCH : 13 / 50
VAL_LOSS : 0.07870721779003435 
VAL_ACCURACY : 0.9884169884169884
VAL_F1 : 0.9784172656825906

EPOCH : 14 / 50
VAL_LOSS : 0.0720832892978678 
VAL_ACCURACY : 0.9884169884169884
VAL_F1 : 0.9784172656825906

EPOCH : 15 / 50
VAL_LOSS : 0.06607090571553123 
VAL_ACCURACY : 0.9922779922779923
VAL_F1 : 0.9855072458721558

EPOCH : 16 / 50
VAL_LOSS : 0.06357210159909968 
VAL_ACCURACY : 0.9922779922779923
VAL_F1 : 0.9855072458721558

EPOCH : 17 / 50
VAL_LOSS : 0.05740218183823994 
VAL_ACCURACY : 0.9948519948519948
VAL_F1 : 0.9902439019342059

EPOCH : 18 / 50
VAL_LOSS : 0.05497612899207339 
VAL_ACCURACY : 0.9935649935649936
VAL_F1 : 0.9878345493735653

EPOCH : 19 / 50
VAL_LOSS : 0.05215798059896547 
VAL_ACCURACY : 0.9961389961389961
VAL_F1 : 0.9927007294222033

EPOCH : 20 / 50
VAL_LOSS : 0.04960081718710004 
VAL_ACCURACY : 0.9948519948519948
VAL_F1 : 0.9902439019342059

EPOCH : 21 / 50
VAL_LOSS : 0.0467321299092502 
VAL_ACCURACY : 0.9961389961389961
VAL_F1 : 0.9927007294222033

EPOCH : 22 / 50
VAL_LOSS : 0.04445190518638309 
VAL_ACCURACY : 0.9974259974259975
VAL_F1 : 0.99512195071467

EPOCH : 23 / 50
VAL_LOSS : 0.042376769896672696 
VAL_ACCURACY : 0.9974259974259975
VAL_F1 : 0.99512195071467

EPOCH : 24 / 50
VAL_LOSS : 0.040963398824845045 
VAL_ACCURACY : 0.9974259974259975
VAL_F1 : 0.99512195071467

EPOCH : 25 / 50
VAL_LOSS : 0.03870143011516454 
VAL_ACCURACY : 0.9987129987129987
VAL_F1 : 0.9975550117200639

EPOCH : 26 / 50
VAL_LOSS : 0.03756112187188499 
VAL_ACCURACY : 0.9987129987129987
VAL_F1 : 0.9975550117200639

EPOCH : 27 / 50
VAL_LOSS : 0.03606838303409061 
VAL_ACCURACY : 0.9987129987129987
VAL_F1 : 0.9975550117200639

EPOCH : 28 / 50
VAL_LOSS : 0.033544412909113634 
VAL_ACCURACY : 0.9987129987129987
VAL_F1 : 0.9975550117200639

EPOCH : 29 / 50
VAL_LOSS : 0.031189408096275767 
VAL_ACCURACY : 0.9987129987129987
VAL_F1 : 0.9975550117200639

EPOCH : 30 / 50
VAL_LOSS : 0.028888095816483304 
VAL_ACCURACY : 0.9987129987129987
VAL_F1 : 0.9975550117200639

EPOCH : 31 / 50
VAL_LOSS : 0.028755030309667393 
VAL_ACCURACY : 0.9987129987129987
VAL_F1 : 0.9975550117200639

EPOCH : 32 / 50
VAL_LOSS : 0.027406843721258397 
VAL_ACCURACY : 0.9987129987129987
VAL_F1 : 0.9975550117200639

EPOCH : 33 / 50
VAL_LOSS : 0.025901384366562172 
VAL_ACCURACY : 0.9987129987129987
VAL_F1 : 0.9975550117200639

EPOCH : 34 / 50
VAL_LOSS : 0.02408220331963836 
VAL_ACCURACY : 0.9987129987129987
VAL_F1 : 0.9975550117200639

EPOCH : 35 / 50
VAL_LOSS : 0.02213450372979349 
VAL_ACCURACY : 0.9987129987129987
VAL_F1 : 0.9975550117200639

EPOCH : 36 / 50
VAL_LOSS : 0.021354497049231917 
VAL_ACCURACY : 0.9987129987129987
VAL_F1 : 0.9975550117200639

EPOCH : 37 / 50
VAL_LOSS : 0.02080354214246784 
VAL_ACCURACY : 0.9987129987129987
VAL_F1 : 0.9975550117200639

EPOCH : 38 / 50
VAL_LOSS : 0.019942727187002192 
VAL_ACCURACY : 0.9987129987129987
VAL_F1 : 0.9975550117200639

EPOCH : 39 / 50
VAL_LOSS : 0.018805018474100803 
VAL_ACCURACY : 0.9987129987129987
VAL_F1 : 0.9975550117200639

EPOCH : 40 / 50
VAL_LOSS : 0.018638082114713534 
VAL_ACCURACY : 0.9987129987129987
VAL_F1 : 0.9975550117200639

EPOCH : 41 / 50
VAL_LOSS : 0.018075576546240826 
VAL_ACCURACY : 0.9987129987129987
VAL_F1 : 0.9975550117200639

EPOCH : 42 / 50
VAL_LOSS : 0.01744768200252129 
VAL_ACCURACY : 0.9987129987129987
VAL_F1 : 0.9975550117200639

EPOCH : 43 / 50
VAL_LOSS : 0.017063968130672465 
VAL_ACCURACY : 0.9987129987129987
VAL_F1 : 0.9975550117200639

EPOCH : 44 / 50
VAL_LOSS : 0.01663166065985451 
VAL_ACCURACY : 0.9987129987129987
VAL_F1 : 0.9975550117200639

EPOCH : 45 / 50
VAL_LOSS : 0.015868196720067337 
VAL_ACCURACY : 0.9987129987129987
VAL_F1 : 0.9975550117200639

EPOCH : 46 / 50
VAL_LOSS : 0.015750630359564508 
VAL_ACCURACY : 0.9987129987129987
VAL_F1 : 0.9975550117200639

EPOCH : 47 / 50
VAL_LOSS : 0.01547953847567646 
VAL_ACCURACY : 0.9987129987129987
VAL_F1 : 0.9975550117200639

EPOCH : 48 / 50
VAL_LOSS : 0.01478797052891887 
VAL_ACCURACY : 0.9987129987129987
VAL_F1 : 0.9975550117200639

EPOCH : 49 / 50
VAL_LOSS : 0.01451572171431415 
VAL_ACCURACY : 0.9987129987129987
VAL_F1 : 0.9975550117200639

EPOCH : 50 / 50
VAL_LOSS : 0.014354068842925588 
VAL_ACCURACY : 0.9987129987129987
VAL_F1 : 0.9975550117200639

# 5話-0
# 文: 適当に流したな
正解 : 1 , 予測 : 0 / 元クラス : 憤怒
tensor([[ 0.2284, -0.2549]], device='cuda:0')
# 6話-0
# 文: そうなんだ?
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-1.1311,  1.4889]], device='cuda:0')
# 6話-0
# 文: どうぞどうぞ
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.6984,  0.6507]], device='cuda:0')
# 7話-0
# 文: とか言い出すのかな…
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.7843,  0.9162]], device='cuda:0')
# 7話-0
# 文: ジャーン!パフェを作ってみました?!
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.6505,  0.4357]], device='cuda:0')
# 7話-1
# 文: ジャーン!パフェを作ってみました?!
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.8360,  0.5734]], device='cuda:0')
# 8話-0
# 文: 今日は良い実験結果が出たな
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-1.8730,  1.6921]], device='cuda:0')
# 8話-1
# 文: もう少し頑張るか
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.5875, -0.1297]], device='cuda:0')
# 9話-0
# 文: あれ?スペインからもう戻ってきたのか
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[ 0.7627, -0.5948]], device='cuda:0')
# 9話-0
# 文: Bさ…ちょっと!
正解 : 1 , 予測 : 0 / 元クラス : 憤怒
tensor([[ 1.8604, -1.7109]], device='cuda:0')
# 9話-0
# 文: ここはよその研究室…!?
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[ 1.5896, -1.4340]], device='cuda:0')
# 9話-1
# 文: ここは よその研究室…!?
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[ 1.4191, -1.1162]], device='cuda:0')
# 9話-1
# 文: おかえりなさい!
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[0.0460, 0.3649]], device='cuda:0')
------------------------test acc------------------------
Test Acc : 0.8030
correct: 53, total: 66
------------------------------------------------
                  喜楽        その他  accuracy  macro avg  weighted avg
precision   0.285714   0.864407   0.80303   0.575061      0.776726
recall      0.200000   0.910714   0.80303   0.555357      0.803030
f1-score    0.235294   0.886957   0.80303   0.561125      0.788220
support    10.000000  56.000000   0.80303  66.000000     66.000000
正例のF1値 : 0.2352941171349481
class weight : tensor([0.7065, 0.2077])
best:lr 5.9421424114796485e-06
EPOCH : 1 / 50
VAL_LOSS : 0.3755268034886341 
VAL_ACCURACY : 0.9227799227799228
VAL_F1 : 0.8492462306518269

EPOCH : 2 / 50
VAL_LOSS : 0.26725145991967647 
VAL_ACCURACY : 0.9536679536679536
VAL_F1 : 0.9142857137817688

EPOCH : 3 / 50
VAL_LOSS : 0.20607364177703857 
VAL_ACCURACY : 0.9601029601029601
VAL_F1 : 0.9274004678807212

EPOCH : 4 / 50
VAL_LOSS : 0.16163395421237362 
VAL_ACCURACY : 0.9665379665379665
VAL_F1 : 0.9395348832178692

EPOCH : 5 / 50
VAL_LOSS : 0.1304537666087248 
VAL_ACCURACY : 0.9781209781209781
VAL_F1 : 0.9596199519899797

EPOCH : 6 / 50
VAL_LOSS : 0.10797454355930795 
VAL_ACCURACY : 0.9794079794079794
VAL_F1 : 0.9619047614005896

EPOCH : 7 / 50
VAL_LOSS : 0.09424935798255765 
VAL_ACCURACY : 0.9897039897039897
VAL_F1 : 0.9807692302647005

EPOCH : 8 / 50
VAL_LOSS : 0.08107610563842618 
VAL_ACCURACY : 0.990990990990991
VAL_F1 : 0.9831325296158863

EPOCH : 9 / 50
VAL_LOSS : 0.07231986218569231 
VAL_ACCURACY : 0.9922779922779923
VAL_F1 : 0.985436892699147

EPOCH : 10 / 50
VAL_LOSS : 0.06549159483033784 
VAL_ACCURACY : 0.9961389961389961
VAL_F1 : 0.9927007294222033

EPOCH : 11 / 50
VAL_LOSS : 0.05940442076142954 
VAL_ACCURACY : 0.9961389961389961
VAL_F1 : 0.9927007294222033

EPOCH : 12 / 50
VAL_LOSS : 0.05533336270220426 
VAL_ACCURACY : 0.9961389961389961
VAL_F1 : 0.9927007294222033

EPOCH : 13 / 50
VAL_LOSS : 0.05038244729595525 
VAL_ACCURACY : 0.9987129987129987
VAL_F1 : 0.9975550117200639

EPOCH : 14 / 50
VAL_LOSS : 0.04806497765286845 
VAL_ACCURACY : 0.9987129987129987
VAL_F1 : 0.9975550117200639

EPOCH : 15 / 50
VAL_LOSS : 0.04375557700286106 
VAL_ACCURACY : 0.9987129987129987
VAL_F1 : 0.9975550117200639

EPOCH : 16 / 50
VAL_LOSS : 0.04090261919309898 
VAL_ACCURACY : 0.9987129987129987
VAL_F1 : 0.9975550117200639

EPOCH : 17 / 50
VAL_LOSS : 0.03850434005868678 
VAL_ACCURACY : 0.9987129987129987
VAL_F1 : 0.9975550117200639

EPOCH : 18 / 50
VAL_LOSS : 0.03500583752685664 
VAL_ACCURACY : 0.9987129987129987
VAL_F1 : 0.9975550117200639

EPOCH : 19 / 50
VAL_LOSS : 0.03358540976686137 
VAL_ACCURACY : 0.9987129987129987
VAL_F1 : 0.9975550117200639

EPOCH : 20 / 50
VAL_LOSS : 0.031700439713135055 
VAL_ACCURACY : 0.9987129987129987
VAL_F1 : 0.9975550117200639

EPOCH : 21 / 50
VAL_LOSS : 0.030055812008830965 
VAL_ACCURACY : 0.9987129987129987
VAL_F1 : 0.9975550117200639

EPOCH : 22 / 50
VAL_LOSS : 0.02767890497890054 
VAL_ACCURACY : 0.9987129987129987
VAL_F1 : 0.9975550117200639

EPOCH : 23 / 50
VAL_LOSS : 0.026332619428938747 
VAL_ACCURACY : 0.9987129987129987
VAL_F1 : 0.9975550117200639

EPOCH : 24 / 50
VAL_LOSS : 0.025045893440137103 
VAL_ACCURACY : 0.9987129987129987
VAL_F1 : 0.9975550117200639

EPOCH : 25 / 50
VAL_LOSS : 0.023879120354445612 
VAL_ACCURACY : 0.9987129987129987
VAL_F1 : 0.9975550117200639

EPOCH : 26 / 50
VAL_LOSS : 0.022536023120794977 
VAL_ACCURACY : 0.9987129987129987
VAL_F1 : 0.9975550117200639

EPOCH : 27 / 50
VAL_LOSS : 0.021932758695008804 
VAL_ACCURACY : 1.0
VAL_F1 : 0.9999999994950981

EPOCH : 28 / 50
VAL_LOSS : 0.02092544958755678 
VAL_ACCURACY : 0.9987129987129987
VAL_F1 : 0.9975550117200639

EPOCH : 29 / 50
VAL_LOSS : 0.019895974717730164 
VAL_ACCURACY : 1.0
VAL_F1 : 0.9999999994950981

EPOCH : 30 / 50
VAL_LOSS : 0.018355300650000572 
VAL_ACCURACY : 1.0
VAL_F1 : 0.9999999994950981

EPOCH : 31 / 50
VAL_LOSS : 0.017454601482165103 
VAL_ACCURACY : 1.0
VAL_F1 : 0.9999999994950981

EPOCH : 32 / 50
VAL_LOSS : 0.017139444393771037 
VAL_ACCURACY : 1.0
VAL_F1 : 0.9999999994950981

EPOCH : 33 / 50
VAL_LOSS : 0.015802537889352868 
VAL_ACCURACY : 1.0
VAL_F1 : 0.9999999994950981

EPOCH : 34 / 50
VAL_LOSS : 0.015219761438819826 
VAL_ACCURACY : 1.0
VAL_F1 : 0.9999999994950981

EPOCH : 35 / 50
VAL_LOSS : 0.01452444480465991 
VAL_ACCURACY : 1.0
VAL_F1 : 0.9999999994950981

EPOCH : 36 / 50
VAL_LOSS : 0.013768237806400475 
VAL_ACCURACY : 1.0
VAL_F1 : 0.9999999994950981

EPOCH : 37 / 50
VAL_LOSS : 0.013193893493438254 
VAL_ACCURACY : 1.0
VAL_F1 : 0.9999999994950981

EPOCH : 38 / 50
VAL_LOSS : 0.013473513498142058 
VAL_ACCURACY : 1.0
VAL_F1 : 0.9999999994950981

EPOCH : 39 / 50
VAL_LOSS : 0.012170261722438189 
VAL_ACCURACY : 1.0
VAL_F1 : 0.9999999994950981

EPOCH : 40 / 50
VAL_LOSS : 0.011770109493969654 
VAL_ACCURACY : 1.0
VAL_F1 : 0.9999999994950981

EPOCH : 41 / 50
VAL_LOSS : 0.01150524308334808 
VAL_ACCURACY : 1.0
VAL_F1 : 0.9999999994950981

EPOCH : 42 / 50
VAL_LOSS : 0.010849092174701544 
VAL_ACCURACY : 1.0
VAL_F1 : 0.9999999994950981

EPOCH : 43 / 50
VAL_LOSS : 0.010566353037649271 
VAL_ACCURACY : 1.0
VAL_F1 : 0.9999999994950981

EPOCH : 44 / 50
VAL_LOSS : 0.009878795641493432 
VAL_ACCURACY : 1.0
VAL_F1 : 0.9999999994950981

EPOCH : 45 / 50
VAL_LOSS : 0.010566966513133779 
VAL_ACCURACY : 1.0
VAL_F1 : 0.9999999994950981

EPOCH : 46 / 50
VAL_LOSS : 0.009102539463462879 
VAL_ACCURACY : 1.0
VAL_F1 : 0.9999999994950981

EPOCH : 47 / 50
VAL_LOSS : 0.008917678119044523 
VAL_ACCURACY : 1.0
VAL_F1 : 0.9999999994950981

EPOCH : 48 / 50
VAL_LOSS : 0.008347608453156997 
VAL_ACCURACY : 1.0
VAL_F1 : 0.9999999994950981

EPOCH : 49 / 50
VAL_LOSS : 0.008093398606062544 
VAL_ACCURACY : 1.0
VAL_F1 : 0.9999999994950981

EPOCH : 50 / 50
VAL_LOSS : 0.007936022320420158 
VAL_ACCURACY : 1.0
VAL_F1 : 0.9999999994950981

# 5話-0
# 文: 適当に流したな
正解 : 1 , 予測 : 0 / 元クラス : 憤怒
tensor([[ 0.5949, -1.2442]], device='cuda:0')
# 6話-0
# 文: そうなんだ?
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-1.6605,  1.8783]], device='cuda:0')
# 6話-0
# 文: どうぞどうぞ
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.8900,  0.4418]], device='cuda:0')
# 7話-0
# 文: どれがいいですか?
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[-0.1719, -0.5857]], device='cuda:0')
# 7話-0
# 文: とか言い出すのかな…
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.4008,  0.7442]], device='cuda:0')
# 7話-0
# 文: ジャーン!パフェを作ってみました?!
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-1.4531,  0.8173]], device='cuda:0')
# 7話-1
# 文: ジャーン!パフェを作ってみました?!
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-1.3343,  1.1410]], device='cuda:0')
# 7話-1
# 文: チョコ一つしかないね はんぶんこしよっか
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 0.7735, -1.0954]], device='cuda:0')
# 8話-0
# 文: 今日は良い実験結果が出たな
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-1.6913,  1.9294]], device='cuda:0')
# 8話-1
# 文: でもわざわざ国際会議から送ってくれたんだよな…
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
tensor([[ 0.5269, -0.6816]], device='cuda:0')
# 8話-1
# 文: もう少し頑張るか
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.6612,  1.0362]], device='cuda:0')
# 9話-0
# 文: あれ?スペインからもう戻ってきたのか
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[ 0.9218, -0.3493]], device='cuda:0')
# 9話-0
# 文: Bさ…ちょっと!
正解 : 1 , 予測 : 0 / 元クラス : 憤怒
tensor([[ 1.9821, -2.3641]], device='cuda:0')
# 9話-0
# 文: ここはよその研究室…!?
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[ 1.8104, -2.2438]], device='cuda:0')
# 9話-1
# 文: ここは よその研究室…!?
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[ 1.4559, -2.0840]], device='cuda:0')
# 9話-1
# 文: おかえりなさい!
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-1.2606,  1.2171]], device='cuda:0')
------------------------test acc------------------------
Test Acc : 0.7576
correct: 50, total: 66
------------------------------------------------
             喜楽        その他  accuracy  macro avg  weighted avg
precision   0.2   0.857143  0.757576   0.528571      0.757576
recall      0.2   0.857143  0.757576   0.528571      0.757576
f1-score    0.2   0.857143  0.757576   0.528571      0.757576
support    10.0  56.000000  0.757576  66.000000     66.000000
正例のF1値 : 0.19999999948000002
