class weight : tensor([0.3988, 0.7537])
best:lr 3.8052987822358415e-07
EPOCH : 1 / 5
VAL_LOSS : 0.6964383316891534 
VAL_ACCURACY : 0.43532058492688414
VAL_F1 : 0.2766570601662666

EPOCH : 2 / 5
VAL_LOSS : 0.6769325541598457 
VAL_ACCURACY : 0.4701912260967379
VAL_F1 : 0.3394109393172518

EPOCH : 3 / 5
VAL_LOSS : 0.6597232307706561 
VAL_ACCURACY : 0.5106861642294713
VAL_F1 : 0.40329218067954115

EPOCH : 4 / 5
VAL_LOSS : 0.6436317414045334 
VAL_ACCURACY : 0.5534308211473565
VAL_F1 : 0.47556142626959996

EPOCH : 5 / 5
VAL_LOSS : 0.6284081563353539 
VAL_ACCURACY : 0.5883014623172104
VAL_F1 : 0.5307692303379422

# 5話-0
# 文: 何読んでるんですか?
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.5602, -0.0350]], device='cuda:0')
# 5話-0
# 文: 夏目漱石だよ〜 Aくんはどんな本を読むの
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.5053, -0.3987]], device='cuda:0')
# 5話-0
# 文: オススメの本教えて
正解 : 1 , 予測 : 0 / 元クラス : UNK
tensor([[-0.3826, -0.5274]], device='cuda:0')
# 5話-0
# 文: 僕ですか?
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.3365,  0.0141]], device='cuda:0')
# 5話-0
# 文: 適当に流そう
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.6259,  0.0991]], device='cuda:0')
# 5話-0
# 文: 小説はあまり読まないのですが、研究で利用している青空文庫の作品なら少々
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.5536, -0.1104]], device='cuda:0')
# 5話-0
# 文: そうなんだ〜
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 0.1493, -0.8111]], device='cuda:0')
# 5話-0
# 文: あと、これも読んだよ
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.7160, -0.4474]], device='cuda:0')
# 5話-1
# 文: 夏目漱石だよ〜 Aくんはどんな本を読むの
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.5053, -0.3987]], device='cuda:0')
# 5話-1
# 文: 僕ですか?
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.3365,  0.0141]], device='cuda:0')
# 5話-1
# 文: 小説はあまり読まないのですが 研究で利用している青空文庫の作品なら少々
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.3869, -0.2553]], device='cuda:0')
# 6話-0
# 文: 今日弁当なんですね
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.3092, -0.1755]], device='cuda:0')
# 6話-0
# 文: そうなんだ〜 父の分と2つ作ったの
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.5216, -0.2845]], device='cuda:0')
# 6話-0
# 文: 手作りなんですか?
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.4228,  0.0022]], device='cuda:0')
# 6話-0
# 文: 見てもいいですか?
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.4559, -0.0416]], device='cuda:0')
# 6話-0
# 文: キャー!
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[-0.2414, -0.3882]], device='cuda:0')
# 6話-1
# 文: キャー!
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[-0.2414, -0.3882]], device='cuda:0')
# 6話-1
# 文: 今日弁当なの珍しいですね
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.2976, -0.0634]], device='cuda:0')
# 6話-1
# 文: 手作りなんですか?
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.4228,  0.0022]], device='cuda:0')
# 6話-1
# 文: ほとんど冷凍食品詰めただけよ…
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
tensor([[-0.1691, -0.6551]], device='cuda:0')
# 6話-1
# 文: 俺も今日弁当なんでおかず分けますよ
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.4252, -0.2413]], device='cuda:0')
# 7話-0
# 文: どれがいいですか?
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.4162,  0.0359]], device='cuda:0')
# 7話-0
# 文: じゃあチョコですね
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.3633,  0.0538]], device='cuda:0')
# 7話-0
# 文: 別に気にしませんが…
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.2198,  0.2402]], device='cuda:0')
# 7話-0
# 文: はんぶんこしよっか
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.3379, -0.1540]], device='cuda:0')
# 7話-0
# 文: とか言い出すのかな…
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.2277,  0.2322]], device='cuda:0')
# 7話-1
# 文: こうやっていろんな食べ方をすれば飽きないですね
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.3606, -0.2635]], device='cuda:0')
# 7話-1
# 文: チョコ一つしかないね…はんぶんこしよっか
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.2766, -0.1529]], device='cuda:0')
# 7話-1
# 文: とか言い出すのかと思った…
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.2281,  0.2387]], device='cuda:0')
# 8話-0
# 文: 今日は良い実験結果が出たな
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.2356, -0.2349]], device='cuda:0')
# 9話-0
# 文: Bさん…
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.4633, -0.1542]], device='cuda:0')
# 9話-0
# 文: あれ？
正解 : 1 , 予測 : 0 / 元クラス : UNK
tensor([[-0.0046, -0.3382]], device='cuda:0')
# 9話-0
# 文: ハッ
正解 : 1 , 予測 : 0 / 元クラス : UNK
tensor([[-0.3303, -0.3748]], device='cuda:0')
# 9話-0
# 文: 人違い!?
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[-0.1165, -0.3249]], device='cuda:0')
# 9話-1
# 文: 人違い!?
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[-0.1165, -0.3249]], device='cuda:0')
# 9話-1
# 文: ハッ
正解 : 1 , 予測 : 0 / 元クラス : UNK
tensor([[-0.3303, -0.3748]], device='cuda:0')
# 9話-1
# 文: おかえりなさい!
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.4063, -0.3869]], device='cuda:0')
------------------------test acc------------------------
Test Acc : 0.5132
correct: 39, total: 76
------------------------------------------------
                  喜楽        その他  accuracy  macro avg  weighted avg
precision   0.523810   0.509091  0.513158   0.516450      0.516450
recall      0.289474   0.736842  0.513158   0.513158      0.513158
f1-score    0.372881   0.602151  0.513158   0.487516      0.487516
support    38.000000  38.000000  0.513158  76.000000     76.000000
正例のF1値 : 0.3728813554610743
class weight : tensor([0.3485, 0.9347])
best:lr 3.921734801069288e-07
EPOCH : 1 / 50
VAL_LOSS : 0.6921649364864125 
VAL_ACCURACY : 0.3882063882063882
VAL_F1 : 0.3306451609064993

EPOCH : 2 / 50
VAL_LOSS : 0.675912594093996 
VAL_ACCURACY : 0.43243243243243246
VAL_F1 : 0.37398373945936064

EPOCH : 3 / 50
VAL_LOSS : 0.6597232129059586 
VAL_ACCURACY : 0.47788697788697787
VAL_F1 : 0.4201909955341725

EPOCH : 4 / 50
VAL_LOSS : 0.643667877889147 
VAL_ACCURACY : 0.515970515970516
VAL_F1 : 0.47043010714268274

EPOCH : 5 / 50
VAL_LOSS : 0.6292225040641486 
VAL_ACCURACY : 0.5577395577395577
VAL_F1 : 0.5275590547174449

EPOCH : 6 / 50
VAL_LOSS : 0.6150348350113514 
VAL_ACCURACY : 0.601965601965602
VAL_F1 : 0.5939849619780466

EPOCH : 7 / 50
VAL_LOSS : 0.5989836840068593 
VAL_ACCURACY : 0.6265356265356266
VAL_F1 : 0.6256157631099153

EPOCH : 8 / 50
VAL_LOSS : 0.5883599987217024 
VAL_ACCURACY : 0.6461916461916462
VAL_F1 : 0.6521739125974585

EPOCH : 9 / 50
VAL_LOSS : 0.5740471359561471 
VAL_ACCURACY : 0.6670761670761671
VAL_F1 : 0.6792899403737684

EPOCH : 10 / 50
VAL_LOSS : 0.5609555402222801 
VAL_ACCURACY : 0.6855036855036855
VAL_F1 : 0.7030162408370809

EPOCH : 11 / 50
VAL_LOSS : 0.5461612822962743 
VAL_ACCURACY : 0.7014742014742015
VAL_F1 : 0.7222857138183105

EPOCH : 12 / 50
VAL_LOSS : 0.5343896992066327 
VAL_ACCURACY : 0.7174447174447175
VAL_F1 : 0.7421524658942921

EPOCH : 13 / 50
VAL_LOSS : 0.521940153019101 
VAL_ACCURACY : 0.7248157248157249
VAL_F1 : 0.7511111106351308

EPOCH : 14 / 50
VAL_LOSS : 0.5127801988639084 
VAL_ACCURACY : 0.730958230958231
VAL_F1 : 0.758544652223128

EPOCH : 15 / 50
VAL_LOSS : 0.5019021677035912 
VAL_ACCURACY : 0.7444717444717445
VAL_F1 : 0.7734204788216734

EPOCH : 16 / 50
VAL_LOSS : 0.49079769791341293 
VAL_ACCURACY : 0.7530712530712531
VAL_F1 : 0.7827027022197343

EPOCH : 17 / 50
VAL_LOSS : 0.4791637203272651 
VAL_ACCURACY : 0.7592137592137592
VAL_F1 : 0.7892473113437624

EPOCH : 18 / 50
VAL_LOSS : 0.4725828720074074 
VAL_ACCURACY : 0.7653562653562653
VAL_F1 : 0.7961579504213339

EPOCH : 19 / 50
VAL_LOSS : 0.46200570814749775 
VAL_ACCURACY : 0.7665847665847666
VAL_F1 : 0.797441364119503

EPOCH : 20 / 50
VAL_LOSS : 0.4542674019056208 
VAL_ACCURACY : 0.7727272727272727
VAL_F1 : 0.8038176029062951

EPOCH : 21 / 50
VAL_LOSS : 0.4450271567877601 
VAL_ACCURACY : 0.7727272727272727
VAL_F1 : 0.8042328037452569

EPOCH : 22 / 50
VAL_LOSS : 0.4352742316676121 
VAL_ACCURACY : 0.7788697788697788
VAL_F1 : 0.8105263153009064

EPOCH : 23 / 50
VAL_LOSS : 0.4284201539030262 
VAL_ACCURACY : 0.7837837837837838
VAL_F1 : 0.815513626345033

EPOCH : 24 / 50
VAL_LOSS : 0.42293067188823924 
VAL_ACCURACY : 0.785012285012285
VAL_F1 : 0.8167539262120314

EPOCH : 25 / 50
VAL_LOSS : 0.41323216084171743 
VAL_ACCURACY : 0.7960687960687961
VAL_F1 : 0.827800829384347

EPOCH : 26 / 50
VAL_LOSS : 0.40696002192357006 
VAL_ACCURACY : 0.7985257985257985
VAL_F1 : 0.8305785119048477

EPOCH : 27 / 50
VAL_LOSS : 0.4006991748716317 
VAL_ACCURACY : 0.800982800982801
VAL_F1 : 0.8329896902294739

EPOCH : 28 / 50
VAL_LOSS : 0.3956701124415678 
VAL_ACCURACY : 0.8058968058968059
VAL_F1 : 0.8377823403696097

EPOCH : 29 / 50
VAL_LOSS : 0.39264266251348984 
VAL_ACCURACY : 0.8083538083538083
VAL_F1 : 0.8401639339331077

EPOCH : 30 / 50
VAL_LOSS : 0.3857162504219541 
VAL_ACCURACY : 0.8144963144963145
VAL_F1 : 0.8463886058130767

EPOCH : 31 / 50
VAL_LOSS : 0.3790762050479066 
VAL_ACCURACY : 0.8144963144963145
VAL_F1 : 0.8463886058130767

EPOCH : 32 / 50
VAL_LOSS : 0.3758174280325572 
VAL_ACCURACY : 0.8157248157248157
VAL_F1 : 0.8475609751154695

EPOCH : 33 / 50
VAL_LOSS : 0.37042394280433655 
VAL_ACCURACY : 0.8157248157248157
VAL_F1 : 0.8475609751154695

EPOCH : 34 / 50
VAL_LOSS : 0.36677611458535286 
VAL_ACCURACY : 0.8181818181818182
VAL_F1 : 0.8502024286549689

EPOCH : 35 / 50
VAL_LOSS : 0.3626626294617559 
VAL_ACCURACY : 0.8194103194103194
VAL_F1 : 0.8513650146718739

EPOCH : 36 / 50
VAL_LOSS : 0.3576150928057876 
VAL_ACCURACY : 0.8194103194103194
VAL_F1 : 0.8513650146718739

EPOCH : 37 / 50
VAL_LOSS : 0.35703153879034755 
VAL_ACCURACY : 0.8206388206388207
VAL_F1 : 0.8525252520301602

EPOCH : 38 / 50
VAL_LOSS : 0.3510480511422251 
VAL_ACCURACY : 0.8230958230958231
VAL_F1 : 0.8548387091820695

EPOCH : 39 / 50
VAL_LOSS : 0.3479872752054065 
VAL_ACCURACY : 0.8267813267813268
VAL_F1 : 0.858006041800592

EPOCH : 40 / 50
VAL_LOSS : 0.34789050618807477 
VAL_ACCURACY : 0.8304668304668305
VAL_F1 : 0.861167001516463

EPOCH : 41 / 50
VAL_LOSS : 0.3420325532263401 
VAL_ACCURACY : 0.8341523341523341
VAL_F1 : 0.8645937808480567

EPOCH : 42 / 50
VAL_LOSS : 0.3365383881564234 
VAL_ACCURACY : 0.8316953316953317
VAL_F1 : 0.8625877627938983

EPOCH : 43 / 50
VAL_LOSS : 0.34004675377817717 
VAL_ACCURACY : 0.8353808353808354
VAL_F1 : 0.8659999995036759

EPOCH : 44 / 50
VAL_LOSS : 0.33269401712744845 
VAL_ACCURACY : 0.8378378378378378
VAL_F1 : 0.8682634725573404

EPOCH : 45 / 50
VAL_LOSS : 0.3300853453430475 
VAL_ACCURACY : 0.8390663390663391
VAL_F1 : 0.8693918240297571

EPOCH : 46 / 50
VAL_LOSS : 0.32906842757673826 
VAL_ACCURACY : 0.8378378378378378
VAL_F1 : 0.8682634725573404

EPOCH : 47 / 50
VAL_LOSS : 0.32539670286225336 
VAL_ACCURACY : 0.8439803439803439
VAL_F1 : 0.8738828197610965

EPOCH : 48 / 50
VAL_LOSS : 0.322689675525123 
VAL_ACCURACY : 0.8439803439803439
VAL_F1 : 0.874132804259885

EPOCH : 49 / 50
VAL_LOSS : 0.3211240572672264 
VAL_ACCURACY : 0.8452088452088452
VAL_F1 : 0.8752475242550731

EPOCH : 50 / 50
VAL_LOSS : 0.3177071622773713 
VAL_ACCURACY : 0.8439803439803439
VAL_F1 : 0.874132804259885

# 5話-0
# 文: 何読んでるんですか?
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.2756,  0.1772]], device='cuda:0')
# 5話-0
# 文: 僕ですか?
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.5145,  0.2385]], device='cuda:0')
# 5話-0
# 文: 適当に流そう
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.6872,  0.4476]], device='cuda:0')
# 5話-0
# 文: そうなんだ〜
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 1.7630, -0.0463]], device='cuda:0')
# 5話-1
# 文: ありがとうございます… それ、何読んでるんですか?
正解 : 1 , 予測 : 0 / 元クラス : 恐怖
tensor([[0.6639, 0.0121]], device='cuda:0')
# 5話-1
# 文: 僕ですか?
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.5145,  0.2385]], device='cuda:0')
# 5話-1
# 文: 本当に今ハマってる本はこの二冊…
正解 : 1 , 予測 : 0 / 元クラス : 恐怖
tensor([[0.8555, 0.0788]], device='cuda:0')
# 6話-0
# 文: 手作りなんですか?
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.2530,  0.1910]], device='cuda:0')
# 6話-0
# 文: 見てもいいですか?
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.0403,  0.1359]], device='cuda:0')
# 6話-0
# 文: キャー!
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[1.2250, 0.1697]], device='cuda:0')
# 6話-1
# 文: キャー!
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[1.2250, 0.1697]], device='cuda:0')
# 6話-1
# 文: 今日弁当なの珍しいですね
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.2408,  0.3053]], device='cuda:0')
# 6話-1
# 文: ええ… 父の分と2つ作ったんだけど
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
tensor([[0.5090, 0.2859]], device='cuda:0')
# 6話-1
# 文: 手作りなんですか?
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.2530,  0.1910]], device='cuda:0')
# 6話-1
# 文: ほとんど冷凍食品詰めただけよ…
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
tensor([[ 0.5813, -0.0257]], device='cuda:0')
# 7話-0
# 文: どれがいいですか?
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.3290,  0.3700]], device='cuda:0')
# 7話-0
# 文: じゃあチョコですね
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.3570,  0.1512]], device='cuda:0')
# 7話-0
# 文: 別に気にしませんが…
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.9134,  0.0541]], device='cuda:0')
# 7話-0
# 文: とか言い出すのかな…
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.9358,  0.0534]], device='cuda:0')
# 7話-0
# 文: 器用だ!?
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[ 0.4075, -0.2351]], device='cuda:0')
# 7話-1
# 文: 器用だ!?
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[ 0.4075, -0.2351]], device='cuda:0')
# 7話-1
# 文: とか言い出すのかと思った…
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.9193,  0.0527]], device='cuda:0')
# 7話-1
# 文: Aくんがいなければ独り占めできたのにな…
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
tensor([[0.4848, 0.1738]], device='cuda:0')
# 8話-1
# 文: でも わざわざ国際会議から送ってくれたんだよな…
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
tensor([[ 1.0958, -0.1297]], device='cuda:0')
# 8話-1
# 文: もう少し頑張るか
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.0593,  0.4120]], device='cuda:0')
# 9話-0
# 文: Bさん…
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.2605,  0.0807]], device='cuda:0')
# 9話-0
# 文: 人違い!?
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[ 0.3539, -0.1366]], device='cuda:0')
# 9話-1
# 文: 人違い!?
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[ 0.3539, -0.1366]], device='cuda:0')
------------------------test acc------------------------
Test Acc : 0.5821
correct: 39, total: 67
------------------------------------------------
                  喜楽        その他  accuracy  macro avg  weighted avg
precision   0.638889   0.516129   0.58209   0.577509      0.585754
recall      0.605263   0.551724   0.58209   0.578494      0.582090
f1-score    0.621622   0.533333   0.58209   0.577477      0.583407
support    38.000000  29.000000   0.58209  67.000000     67.000000
正例のF1値 : 0.6216216211051862
class weight : tensor([0.3485, 0.9347])
best:lr 1.5846107822430984e-06
EPOCH : 1 / 50
VAL_LOSS : 0.6342690750664356 
VAL_ACCURACY : 0.5257985257985258
VAL_F1 : 0.5012919892536774

EPOCH : 2 / 50
VAL_LOSS : 0.5733398421137941 
VAL_ACCURACY : 0.64004914004914
VAL_F1 : 0.6474127552684094

EPOCH : 3 / 50
VAL_LOSS : 0.5208435000157824 
VAL_ACCURACY : 0.7076167076167076
VAL_F1 : 0.7313769746979195

EPOCH : 4 / 50
VAL_LOSS : 0.48064498048202664 
VAL_ACCURACY : 0.7604422604422605
VAL_F1 : 0.7918890069848434

EPOCH : 5 / 50
VAL_LOSS : 0.4431939253620073 
VAL_ACCURACY : 0.773955773955774
VAL_F1 : 0.8067226885866816

EPOCH : 6 / 50
VAL_LOSS : 0.4113038363409977 
VAL_ACCURACY : 0.8022113022113022
VAL_F1 : 0.8341915546054999

EPOCH : 7 / 50
VAL_LOSS : 0.3882499509582333 
VAL_ACCURACY : 0.8095823095823096
VAL_F1 : 0.8413510742252525

EPOCH : 8 / 50
VAL_LOSS : 0.3696565864717259 
VAL_ACCURACY : 0.8218673218673219
VAL_F1 : 0.8530901717444059

EPOCH : 9 / 50
VAL_LOSS : 0.3500538456673716 
VAL_ACCURACY : 0.828009828009828
VAL_F1 : 0.8588709672465775

EPOCH : 10 / 50
VAL_LOSS : 0.3368046169771868 
VAL_ACCURACY : 0.8329238329238329
VAL_F1 : 0.8634538147651892

EPOCH : 11 / 50
VAL_LOSS : 0.32600613698071124 
VAL_ACCURACY : 0.8378378378378378
VAL_F1 : 0.8679999995036719

EPOCH : 12 / 50
VAL_LOSS : 0.3188665553050883 
VAL_ACCURACY : 0.8427518427518428
VAL_F1 : 0.871999999503664

EPOCH : 13 / 50
VAL_LOSS : 0.3052319691461675 
VAL_ACCURACY : 0.8488943488943489
VAL_F1 : 0.8773678958143875

EPOCH : 14 / 50
VAL_LOSS : 0.29682280298541575 
VAL_ACCURACY : 0.8488943488943489
VAL_F1 : 0.8778550143986258

EPOCH : 15 / 50
VAL_LOSS : 0.2880040654072575 
VAL_ACCURACY : 0.855036855036855
VAL_F1 : 0.8836291908236951

EPOCH : 16 / 50
VAL_LOSS : 0.2800714718360527 
VAL_ACCURACY : 0.8624078624078624
VAL_F1 : 0.8899803531363976

EPOCH : 17 / 50
VAL_LOSS : 0.27171578623500525 
VAL_ACCURACY : 0.8685503685503686
VAL_F1 : 0.895405669100602

EPOCH : 18 / 50
VAL_LOSS : 0.26546881216413837 
VAL_ACCURACY : 0.8746928746928747
VAL_F1 : 0.9007782096177118

EPOCH : 19 / 50
VAL_LOSS : 0.25412516062166174 
VAL_ACCURACY : 0.8796068796068796
VAL_F1 : 0.9052224366378714

EPOCH : 20 / 50
VAL_LOSS : 0.2542993156056778 
VAL_ACCURACY : 0.8820638820638821
VAL_F1 : 0.9069767436867225

EPOCH : 21 / 50
VAL_LOSS : 0.2451635865019817 
VAL_ACCURACY : 0.8845208845208845
VAL_F1 : 0.9089147281828428

EPOCH : 22 / 50
VAL_LOSS : 0.2393961047717169 
VAL_ACCURACY : 0.8857493857493858
VAL_F1 : 0.9099709578742691

EPOCH : 23 / 50
VAL_LOSS : 0.23491625867637933 
VAL_ACCURACY : 0.8918918918918919
VAL_F1 : 0.9150579145583027

EPOCH : 24 / 50
VAL_LOSS : 0.2304858413397097 
VAL_ACCURACY : 0.8918918918918919
VAL_F1 : 0.9148936165217986

EPOCH : 25 / 50
VAL_LOSS : 0.22356018511688008 
VAL_ACCURACY : 0.898034398034398
VAL_F1 : 0.9202689716422342

EPOCH : 26 / 50
VAL_LOSS : 0.21872957284544028 
VAL_ACCURACY : 0.9004914004914005
VAL_F1 : 0.9223394050608238

EPOCH : 27 / 50
VAL_LOSS : 0.21267838396278083 
VAL_ACCURACY : 0.9017199017199017
VAL_F1 : 0.9233716470094611

EPOCH : 28 / 50
VAL_LOSS : 0.21133329339471518 
VAL_ACCURACY : 0.9078624078624079
VAL_F1 : 0.928503336010567

EPOCH : 29 / 50
VAL_LOSS : 0.20587768778204918 
VAL_ACCURACY : 0.9090909090909091
VAL_F1 : 0.9296577941762604

EPOCH : 30 / 50
VAL_LOSS : 0.20272408601115732 
VAL_ACCURACY : 0.9103194103194103
VAL_F1 : 0.9306742635070027

EPOCH : 31 / 50
VAL_LOSS : 0.1984985875440579 
VAL_ACCURACY : 0.9115479115479116
VAL_F1 : 0.9315589348606673

EPOCH : 32 / 50
VAL_LOSS : 0.19591737056479736 
VAL_ACCURACY : 0.9115479115479116
VAL_F1 : 0.9315589348606673

EPOCH : 33 / 50
VAL_LOSS : 0.19752912252557045 
VAL_ACCURACY : 0.9152334152334153
VAL_F1 : 0.9344729339723324

EPOCH : 34 / 50
VAL_LOSS : 0.1923455840670595 
VAL_ACCURACY : 0.9176904176904177
VAL_F1 : 0.936492890494564

EPOCH : 35 / 50
VAL_LOSS : 0.18596362249523984 
VAL_ACCURACY : 0.918918918918919
VAL_F1 : 0.9373814036739195

EPOCH : 36 / 50
VAL_LOSS : 0.18660357141611622 
VAL_ACCURACY : 0.9201474201474201
VAL_F1 : 0.9383886250917168

EPOCH : 37 / 50
VAL_LOSS : 0.17980349838149315 
VAL_ACCURACY : 0.9238329238329238
VAL_F1 : 0.9413988652836647

EPOCH : 38 / 50
VAL_LOSS : 0.17956518425660975 
VAL_ACCURACY : 0.9238329238329238
VAL_F1 : 0.9413988652836647

EPOCH : 39 / 50
VAL_LOSS : 0.17571158027824232 
VAL_ACCURACY : 0.9262899262899262
VAL_F1 : 0.9432892244519031

EPOCH : 40 / 50
VAL_LOSS : 0.17440014420186772 
VAL_ACCURACY : 0.9238329238329238
VAL_F1 : 0.9412878782871292

EPOCH : 41 / 50
VAL_LOSS : 0.1708505369868933 
VAL_ACCURACY : 0.9275184275184275
VAL_F1 : 0.9442870627663528

EPOCH : 42 / 50
VAL_LOSS : 0.17253799984852472 
VAL_ACCURACY : 0.9287469287469288
VAL_F1 : 0.9452830183670026

EPOCH : 43 / 50
VAL_LOSS : 0.170095855698866 
VAL_ACCURACY : 0.9299754299754299
VAL_F1 : 0.9462770965772657

EPOCH : 44 / 50
VAL_LOSS : 0.17239704633168146 
VAL_ACCURACY : 0.9299754299754299
VAL_F1 : 0.9462770965772657

EPOCH : 45 / 50
VAL_LOSS : 0.1699006000131953 
VAL_ACCURACY : 0.9299754299754299
VAL_F1 : 0.9462770965772657

EPOCH : 46 / 50
VAL_LOSS : 0.16235377142826715 
VAL_ACCURACY : 0.9312039312039312
VAL_F1 : 0.9472693027005047

EPOCH : 47 / 50
VAL_LOSS : 0.16613769764993705 
VAL_ACCURACY : 0.9312039312039312
VAL_F1 : 0.9472693027005047

EPOCH : 48 / 50
VAL_LOSS : 0.1621785241306997 
VAL_ACCURACY : 0.9312039312039312
VAL_F1 : 0.9472693027005047

EPOCH : 49 / 50
VAL_LOSS : 0.16142321882002494 
VAL_ACCURACY : 0.9312039312039312
VAL_F1 : 0.9472693027005047

EPOCH : 50 / 50
VAL_LOSS : 0.15905065177118077 
VAL_ACCURACY : 0.9312039312039312
VAL_F1 : 0.9472693027005047

# 5話-0
# 文: 適当に流そう
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-1.1088,  0.1669]], device='cuda:0')
# 5話-0
# 文: そうなんだ〜
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 1.4313, -1.2173]], device='cuda:0')
# 5話-1
# 文: ありがとうございます… それ、何読んでるんですか?
正解 : 1 , 予測 : 0 / 元クラス : 恐怖
tensor([[ 1.4530, -1.4806]], device='cuda:0')
# 5話-1
# 文: 本当に今ハマってる本はこの二冊…
正解 : 1 , 予測 : 0 / 元クラス : 恐怖
tensor([[ 0.9187, -0.9778]], device='cuda:0')
# 6話-0
# 文: キャー!
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[ 0.2225, -0.7026]], device='cuda:0')
# 6話-0
# 文: ベタだなあ
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[-0.1643, -0.4378]], device='cuda:0')
# 6話-1
# 文: キャー!
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[ 0.2225, -0.7026]], device='cuda:0')
# 6話-1
# 文: ベタだなあ
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[-0.1643, -0.4378]], device='cuda:0')
# 6話-1
# 文: 今日弁当なの珍しいですね
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.4550,  0.1551]], device='cuda:0')
# 6話-1
# 文: ええ… 父の分と2つ作ったんだけど
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
tensor([[-0.1293, -0.4960]], device='cuda:0')
# 6話-1
# 文: ほとんど冷凍食品詰めただけよ…
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
tensor([[ 0.8982, -0.2930]], device='cuda:0')
# 7話-0
# 文: 別に気にしませんが…
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.4735,  0.2362]], device='cuda:0')
# 7話-0
# 文: とか言い出すのかな…
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.5009,  0.2612]], device='cuda:0')
# 7話-0
# 文: 器用だ!?
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[ 0.2973, -0.8252]], device='cuda:0')
# 7話-1
# 文: 器用だ!?
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[ 0.2973, -0.8252]], device='cuda:0')
# 7話-1
# 文: とか言い出すのかと思った…
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.4758,  0.2433]], device='cuda:0')
# 8話-0
# 文: ここは日本。何も見ていない
正解 : 1 , 予測 : 0 / 元クラス : 恐怖
tensor([[ 0.6439, -0.5645]], device='cuda:0')
# 8話-1
# 文: ここは日本。何も見ていない
正解 : 1 , 予測 : 0 / 元クラス : 恐怖
tensor([[ 0.6439, -0.5645]], device='cuda:0')
# 8話-1
# 文: でも わざわざ国際会議から送ってくれたんだよな…
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
tensor([[ 1.5918, -1.0683]], device='cuda:0')
# 9話-0
# 文: Bさん…
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-1.4953,  0.4117]], device='cuda:0')
# 9話-0
# 文: 無視!?
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[ 0.3214, -0.5165]], device='cuda:0')
# 9話-0
# 文: ?
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 0.8892, -0.9718]], device='cuda:0')
# 9話-1
# 文: ここは よその研究室…!?
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[ 0.9931, -0.8089]], device='cuda:0')
# 9話-1
# 文: ただいま〜
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.5645,  0.1523]], device='cuda:0')
# 9話-1
# 文: ?
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 0.8892, -0.9718]], device='cuda:0')
------------------------test acc------------------------
Test Acc : 0.6269
correct: 42, total: 67
------------------------------------------------
                  喜楽        その他  accuracy  macro avg  weighted avg
precision   0.632653   0.611111  0.626866   0.621882      0.623329
recall      0.815789   0.379310  0.626866   0.597550      0.626866
f1-score    0.712644   0.468085  0.626866   0.590364      0.606790
support    38.000000  29.000000  0.626866  67.000000     67.000000
正例のF1値 : 0.7126436776525299
class weight : tensor([0.3485, 0.9347])
best:lr 3.1900426083779308e-06
EPOCH : 1 / 50
VAL_LOSS : 0.5815520146313835 
VAL_ACCURACY : 0.6363636363636364
VAL_F1 : 0.640776698585305

EPOCH : 2 / 50
VAL_LOSS : 0.490940860673493 
VAL_ACCURACY : 0.757985257985258
VAL_F1 : 0.7883995698700289

EPOCH : 3 / 50
VAL_LOSS : 0.41861752084657256 
VAL_ACCURACY : 0.7825552825552825
VAL_F1 : 0.8134878814926566

EPOCH : 4 / 50
VAL_LOSS : 0.36892851778105196 
VAL_ACCURACY : 0.8132678132678133
VAL_F1 : 0.8448979586899542

EPOCH : 5 / 50
VAL_LOSS : 0.34003611434908476 
VAL_ACCURACY : 0.828009828009828
VAL_F1 : 0.8591549290818594

EPOCH : 6 / 50
VAL_LOSS : 0.3154354793768303 
VAL_ACCURACY : 0.8427518427518428
VAL_F1 : 0.8725099596625847

EPOCH : 7 / 50
VAL_LOSS : 0.3019496101666899 
VAL_ACCURACY : 0.8488943488943489
VAL_F1 : 0.8780971253698872

EPOCH : 8 / 50
VAL_LOSS : 0.28350889390590145 
VAL_ACCURACY : 0.8685503685503686
VAL_F1 : 0.8958130472128482

EPOCH : 9 / 50
VAL_LOSS : 0.2685529461093977 
VAL_ACCURACY : 0.8796068796068796
VAL_F1 : 0.9054054049058117

EPOCH : 10 / 50
VAL_LOSS : 0.26007886011810866 
VAL_ACCURACY : 0.8869778869778869
VAL_F1 : 0.9115384610386021

EPOCH : 11 / 50
VAL_LOSS : 0.24393378154319875 
VAL_ACCURACY : 0.8968058968058968
VAL_F1 : 0.9198473277439471

EPOCH : 12 / 50
VAL_LOSS : 0.23643790068579654 
VAL_ACCURACY : 0.9054054054054054
VAL_F1 : 0.9267364409838086

EPOCH : 13 / 50
VAL_LOSS : 0.22608673806283988 
VAL_ACCURACY : 0.9127764127764127
VAL_F1 : 0.9328287601425537

EPOCH : 14 / 50
VAL_LOSS : 0.22093621831314236 
VAL_ACCURACY : 0.9152334152334153
VAL_F1 : 0.934720907730062

EPOCH : 15 / 50
VAL_LOSS : 0.20986884759337293 
VAL_ACCURACY : 0.9201474201474201
VAL_F1 : 0.9387370400268557

EPOCH : 16 / 50
VAL_LOSS : 0.20362664006796538 
VAL_ACCURACY : 0.9226044226044227
VAL_F1 : 0.9406220541644582

EPOCH : 17 / 50
VAL_LOSS : 0.19979017505458757 
VAL_ACCURACY : 0.9238329238329238
VAL_F1 : 0.9416195851863911

EPOCH : 18 / 50
VAL_LOSS : 0.1906557561574029 
VAL_ACCURACY : 0.9336609336609336
VAL_F1 : 0.9495327097791039

EPOCH : 19 / 50
VAL_LOSS : 0.18453153938639397 
VAL_ACCURACY : 0.9324324324324325
VAL_F1 : 0.9484536077462462

EPOCH : 20 / 50
VAL_LOSS : 0.1837480412248303 
VAL_ACCURACY : 0.9312039312039312
VAL_F1 : 0.9474671664782199

EPOCH : 21 / 50
VAL_LOSS : 0.1806287264414862 
VAL_ACCURACY : 0.9336609336609336
VAL_F1 : 0.9494382017459811

EPOCH : 22 / 50
VAL_LOSS : 0.17453432879319378 
VAL_ACCURACY : 0.9312039312039312
VAL_F1 : 0.9474671664782199

EPOCH : 23 / 50
VAL_LOSS : 0.17350576496591755 
VAL_ACCURACY : 0.9348894348894349
VAL_F1 : 0.9504209536615268

EPOCH : 24 / 50
VAL_LOSS : 0.17004449979639522 
VAL_ACCURACY : 0.9361179361179361
VAL_F1 : 0.9514018686576051

EPOCH : 25 / 50
VAL_LOSS : 0.16489771556328325 
VAL_ACCURACY : 0.9348894348894349
VAL_F1 : 0.9503280219917909

EPOCH : 26 / 50
VAL_LOSS : 0.16144390469964812 
VAL_ACCURACY : 0.9373464373464373
VAL_F1 : 0.9522918610516075

EPOCH : 27 / 50
VAL_LOSS : 0.15685078326393576 
VAL_ACCURACY : 0.9373464373464373
VAL_F1 : 0.9521126755552206

EPOCH : 28 / 50
VAL_LOSS : 0.15460061815147305 
VAL_ACCURACY : 0.9385749385749386
VAL_F1 : 0.9530075182959078

EPOCH : 29 / 50
VAL_LOSS : 0.15402991485361958 
VAL_ACCURACY : 0.9398034398034398
VAL_F1 : 0.9539906098275176

EPOCH : 30 / 50
VAL_LOSS : 0.14911995105007114 
VAL_ACCURACY : 0.941031941031941
VAL_F1 : 0.9549718569097255

EPOCH : 31 / 50
VAL_LOSS : 0.1486168668842783 
VAL_ACCURACY : 0.9398034398034398
VAL_F1 : 0.9539906098275176

EPOCH : 32 / 50
VAL_LOSS : 0.1485656678822695 
VAL_ACCURACY : 0.9422604422604423
VAL_F1 : 0.9559512647284252

EPOCH : 33 / 50
VAL_LOSS : 0.14331203637023768 
VAL_ACCURACY : 0.941031941031941
VAL_F1 : 0.9549718569097255

EPOCH : 34 / 50
VAL_LOSS : 0.1425724060950326 
VAL_ACCURACY : 0.9385749385749386
VAL_F1 : 0.9530075182959078

EPOCH : 35 / 50
VAL_LOSS : 0.13962560161656024 
VAL_ACCURACY : 0.941031941031941
VAL_F1 : 0.9549718569097255

EPOCH : 36 / 50
VAL_LOSS : 0.14090683994193873 
VAL_ACCURACY : 0.9422604422604423
VAL_F1 : 0.9559512647284252

EPOCH : 37 / 50
VAL_LOSS : 0.13560636619142458 
VAL_ACCURACY : 0.9422604422604423
VAL_F1 : 0.9559512647284252

EPOCH : 38 / 50
VAL_LOSS : 0.13842935246579788 
VAL_ACCURACY : 0.941031941031941
VAL_F1 : 0.9549718569097255

EPOCH : 39 / 50
VAL_LOSS : 0.1329664199375639 
VAL_ACCURACY : 0.941031941031941
VAL_F1 : 0.9549718569097255

EPOCH : 40 / 50
VAL_LOSS : 0.13638805857329978 
VAL_ACCURACY : 0.9422604422604423
VAL_F1 : 0.9559512647284252

EPOCH : 41 / 50
VAL_LOSS : 0.13707758146612084 
VAL_ACCURACY : 0.941031941031941
VAL_F1 : 0.9549718569097255

EPOCH : 42 / 50
VAL_LOSS : 0.13159121660625234 
VAL_ACCURACY : 0.941031941031941
VAL_F1 : 0.9549718569097255

EPOCH : 43 / 50
VAL_LOSS : 0.13111120601202927 
VAL_ACCURACY : 0.941031941031941
VAL_F1 : 0.9549718569097255

EPOCH : 44 / 50
VAL_LOSS : 0.1284676379725045 
VAL_ACCURACY : 0.941031941031941
VAL_F1 : 0.9549718569097255

EPOCH : 45 / 50
VAL_LOSS : 0.12627332836535632 
VAL_ACCURACY : 0.941031941031941
VAL_F1 : 0.9549718569097255

EPOCH : 46 / 50
VAL_LOSS : 0.12397750470714242 
VAL_ACCURACY : 0.941031941031941
VAL_F1 : 0.9549718569097255

EPOCH : 47 / 50
VAL_LOSS : 0.12426277859976478 
VAL_ACCURACY : 0.941031941031941
VAL_F1 : 0.9549718569097255

EPOCH : 48 / 50
VAL_LOSS : 0.12326128309702172 
VAL_ACCURACY : 0.941031941031941
VAL_F1 : 0.9549718569097255

EPOCH : 49 / 50
VAL_LOSS : 0.12283627181222626 
VAL_ACCURACY : 0.941031941031941
VAL_F1 : 0.9549718569097255

EPOCH : 50 / 50
VAL_LOSS : 0.12255672745260537 
VAL_ACCURACY : 0.9422604422604423
VAL_F1 : 0.9558685440998145

# 5話-0
# 文: 適当に流そう
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.2522,  0.2394]], device='cuda:0')
# 5話-0
# 文: そうなんだ〜
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 1.8458, -0.9758]], device='cuda:0')
# 5話-1
# 文: ありがとうございます… それ、何読んでるんですか?
正解 : 1 , 予測 : 0 / 元クラス : 恐怖
tensor([[ 1.9621, -1.0692]], device='cuda:0')
# 5話-1
# 文: 本当に今ハマってる本はこの二冊…
正解 : 1 , 予測 : 0 / 元クラス : 恐怖
tensor([[ 1.7734, -0.4945]], device='cuda:0')
# 6話-0
# 文: キャー!
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[0.7095, 0.0250]], device='cuda:0')
# 6話-0
# 文: ベタだなあ
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 0.5969, -0.3076]], device='cuda:0')
# 6話-1
# 文: キャー!
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[0.7095, 0.0250]], device='cuda:0')
# 6話-1
# 文: ベタだなあ
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 0.5969, -0.3076]], device='cuda:0')
# 6話-1
# 文: 今日弁当なの珍しいですね
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.3909,  0.0505]], device='cuda:0')
# 6話-1
# 文: ええ… 父の分と2つ作ったんだけど
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
tensor([[-0.0122, -0.4852]], device='cuda:0')
# 6話-1
# 文: ほとんど冷凍食品詰めただけよ…
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
tensor([[ 0.5078, -0.4477]], device='cuda:0')
# 6話-1
# 文: 俺も今日弁当なんでおかず分けますよ
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.8034,  0.3566]], device='cuda:0')
# 7話-0
# 文: 別に気にしませんが…
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.1081,  0.4626]], device='cuda:0')
# 7話-0
# 文: とか言い出すのかな…
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.1312,  0.4701]], device='cuda:0')
# 7話-0
# 文: 器用だ!?
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[ 0.6818, -0.1200]], device='cuda:0')
# 7話-1
# 文: 器用だ!?
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[ 0.6818, -0.1200]], device='cuda:0')
# 7話-1
# 文: とか言い出すのかと思った…
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.0989,  0.4503]], device='cuda:0')
# 8話-0
# 文: ここは日本。何も見ていない
正解 : 1 , 予測 : 0 / 元クラス : 恐怖
tensor([[ 0.8509, -0.2866]], device='cuda:0')
# 8話-1
# 文: ここは日本。何も見ていない
正解 : 1 , 予測 : 0 / 元クラス : 恐怖
tensor([[ 0.8509, -0.2866]], device='cuda:0')
# 8話-1
# 文: でも わざわざ国際会議から送ってくれたんだよな…
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
tensor([[ 1.7707, -1.0209]], device='cuda:0')
# 9話-0
# 文: Bさん…
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-1.8810,  1.1913]], device='cuda:0')
# 9話-0
# 文: 無視!?
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[ 0.7355, -0.5615]], device='cuda:0')
# 9話-0
# 文: ?
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 1.0554, -0.7970]], device='cuda:0')
# 9話-1
# 文: ここは よその研究室…!?
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[ 1.4863, -0.9019]], device='cuda:0')
# 9話-1
# 文: ただいま〜
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.2712,  0.5284]], device='cuda:0')
# 9話-1
# 文: ?
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 1.0554, -0.7970]], device='cuda:0')
------------------------test acc------------------------
Test Acc : 0.6119
correct: 41, total: 67
------------------------------------------------
                  喜楽        その他  accuracy  macro avg  weighted avg
precision   0.625000   0.578947   0.61194   0.601974      0.605067
recall      0.789474   0.379310   0.61194   0.584392      0.611940
f1-score    0.697674   0.458333   0.61194   0.578004      0.594079
support    38.000000  29.000000   0.61194  67.000000     67.000000
正例のF1値 : 0.6976744180951866
class weight : tensor([0.3485, 0.9347])
best:lr 3.551220464811655e-05
EPOCH : 1 / 50
VAL_LOSS : 0.24233225265554353 
VAL_ACCURACY : 0.8771498771498771
VAL_F1 : 0.9029126208600509

EPOCH : 2 / 50
VAL_LOSS : 0.17205474372295773 
VAL_ACCURACY : 0.9262899262899262
VAL_F1 : 0.9430740032944022

EPOCH : 3 / 50
VAL_LOSS : 0.15524817663518822 
VAL_ACCURACY : 0.9287469287469288
VAL_F1 : 0.9449715365012296

EPOCH : 4 / 50
VAL_LOSS : 0.13119872243088834 
VAL_ACCURACY : 0.9373464373464373
VAL_F1 : 0.9521126755552206

EPOCH : 5 / 50
VAL_LOSS : 0.11942408317882641 
VAL_ACCURACY : 0.9434889434889435
VAL_F1 : 0.9568480295176021

EPOCH : 6 / 50
VAL_LOSS : 0.11181483845062115 
VAL_ACCURACY : 0.9434889434889435
VAL_F1 : 0.9570093452931085

EPOCH : 7 / 50
VAL_LOSS : 0.10757161729841255 
VAL_ACCURACY : 0.9398034398034398
VAL_F1 : 0.9538171531276757

EPOCH : 8 / 50
VAL_LOSS : 0.10476961795825 
VAL_ACCURACY : 0.9459459459459459
VAL_F1 : 0.9588785041716097

EPOCH : 9 / 50
VAL_LOSS : 0.10439770869618538 
VAL_ACCURACY : 0.9459459459459459
VAL_F1 : 0.9588014976261134

EPOCH : 10 / 50
VAL_LOSS : 0.09964782098198638 
VAL_ACCURACY : 0.9447174447174447
VAL_F1 : 0.9576669797435328

EPOCH : 11 / 50
VAL_LOSS : 0.11005839278154514 
VAL_ACCURACY : 0.9422604422604423
VAL_F1 : 0.956197576385867

EPOCH : 12 / 50
VAL_LOSS : 0.10287247850176166 
VAL_ACCURACY : 0.9471744471744472
VAL_F1 : 0.9596244126444083

EPOCH : 13 / 50
VAL_LOSS : 0.10010020020326563 
VAL_ACCURACY : 0.941031941031941
VAL_F1 : 0.9546313794613335

EPOCH : 14 / 50
VAL_LOSS : 0.10166076702230117 
VAL_ACCURACY : 0.9459459459459459
VAL_F1 : 0.9591078061900058

EPOCH : 15 / 50
VAL_LOSS : 0.09566347578576967 
VAL_ACCURACY : 0.9434889434889435
VAL_F1 : 0.9566854985573607

EPOCH : 16 / 50
VAL_LOSS : 0.09287838720004349 
VAL_ACCURACY : 0.9496314496314496
VAL_F1 : 0.9615745074650595

EPOCH : 17 / 50
VAL_LOSS : 0.09975645321366541 
VAL_ACCURACY : 0.9447174447174447
VAL_F1 : 0.9575871814028806

EPOCH : 18 / 50
VAL_LOSS : 0.09593502540762226 
VAL_ACCURACY : 0.9447174447174447
VAL_F1 : 0.9575871814028806

EPOCH : 19 / 50
VAL_LOSS : 0.0903349878522111 
VAL_ACCURACY : 0.9471744471744472
VAL_F1 : 0.9595484472882142

EPOCH : 20 / 50
VAL_LOSS : 0.08747283467913375 
VAL_ACCURACY : 0.9508599508599509
VAL_F1 : 0.9625468159781664

EPOCH : 21 / 50
VAL_LOSS : 0.09049166213976693 
VAL_ACCURACY : 0.9508599508599509
VAL_F1 : 0.9625468159781664

EPOCH : 22 / 50
VAL_LOSS : 0.09020415898960303 
VAL_ACCURACY : 0.9496314496314496
VAL_F1 : 0.9615023469167052

EPOCH : 23 / 50
VAL_LOSS : 0.08838130684350343 
VAL_ACCURACY : 0.9496314496314496
VAL_F1 : 0.9616463980020109

EPOCH : 24 / 50
VAL_LOSS : 0.08259954578334502 
VAL_ACCURACY : 0.9508599508599509
VAL_F1 : 0.9624765473412311

EPOCH : 25 / 50
VAL_LOSS : 0.08012847837937229 
VAL_ACCURACY : 0.952088452088452
VAL_F1 : 0.9634489217106041

EPOCH : 26 / 50
VAL_LOSS : 0.08966355102465433 
VAL_ACCURACY : 0.9496314496314496
VAL_F1 : 0.9616463980020109

EPOCH : 27 / 50
VAL_LOSS : 0.08271344402330179 
VAL_ACCURACY : 0.952088452088452
VAL_F1 : 0.9634489217106041

EPOCH : 28 / 50
VAL_LOSS : 0.08161681317998205 
VAL_ACCURACY : 0.9471744471744472
VAL_F1 : 0.9594721955404829

EPOCH : 29 / 50
VAL_LOSS : 0.08480803344362214 
VAL_ACCURACY : 0.9496314496314496
VAL_F1 : 0.9615023469167052

EPOCH : 30 / 50
VAL_LOSS : 0.08198097019511111 
VAL_ACCURACY : 0.9496314496314496
VAL_F1 : 0.9616463980020109

EPOCH : 31 / 50
VAL_LOSS : 0.09072485641010251 
VAL_ACCURACY : 0.9496314496314496
VAL_F1 : 0.9615745074650595

EPOCH : 32 / 50
VAL_LOSS : 0.09008421298737328 
VAL_ACCURACY : 0.9496314496314496
VAL_F1 : 0.9615023469167052

EPOCH : 33 / 50
VAL_LOSS : 0.0864735968666626 
VAL_ACCURACY : 0.9508599508599509
VAL_F1 : 0.9625468159781664

EPOCH : 34 / 50
VAL_LOSS : 0.08599929999121848 
VAL_ACCURACY : 0.9508599508599509
VAL_F1 : 0.9625468159781664

EPOCH : 35 / 50
VAL_LOSS : 0.09079488375972883 
VAL_ACCURACY : 0.9484029484029484
VAL_F1 : 0.9606003747333547

EPOCH : 36 / 50
VAL_LOSS : 0.08768468656047594 
VAL_ACCURACY : 0.9447174447174447
VAL_F1 : 0.9575871814028806

EPOCH : 37 / 50
VAL_LOSS : 0.08528503649594153 
VAL_ACCURACY : 0.9508599508599509
VAL_F1 : 0.9624765473412311

EPOCH : 38 / 50
VAL_LOSS : 0.08429815898667656 
VAL_ACCURACY : 0.9508599508599509
VAL_F1 : 0.9624765473412311

EPOCH : 39 / 50
VAL_LOSS : 0.08977379586876315 
VAL_ACCURACY : 0.9508599508599509
VAL_F1 : 0.9625468159781664

EPOCH : 40 / 50
VAL_LOSS : 0.08869088416480843 
VAL_ACCURACY : 0.9496314496314496
VAL_F1 : 0.9615023469167052

EPOCH : 41 / 50
VAL_LOSS : 0.08507247092932754 
VAL_ACCURACY : 0.952088452088452
VAL_F1 : 0.9634489217106041

EPOCH : 42 / 50
VAL_LOSS : 0.0854124392464976 
VAL_ACCURACY : 0.952088452088452
VAL_F1 : 0.9634489217106041

EPOCH : 43 / 50
VAL_LOSS : 0.08818629549304936 
VAL_ACCURACY : 0.952088452088452
VAL_F1 : 0.9634489217106041

EPOCH : 44 / 50
VAL_LOSS : 0.0919289890649345 
VAL_ACCURACY : 0.9508599508599509
VAL_F1 : 0.9624765473412311

EPOCH : 45 / 50
VAL_LOSS : 0.08471417864419374 
VAL_ACCURACY : 0.952088452088452
VAL_F1 : 0.9634489217106041

EPOCH : 46 / 50
VAL_LOSS : 0.09319174295181737 
VAL_ACCURACY : 0.9496314496314496
VAL_F1 : 0.9615745074650595

EPOCH : 47 / 50
VAL_LOSS : 0.09227149297629356 
VAL_ACCURACY : 0.9496314496314496
VAL_F1 : 0.9615023469167052

EPOCH : 48 / 50
VAL_LOSS : 0.08322646647381286 
VAL_ACCURACY : 0.9496314496314496
VAL_F1 : 0.9615023469167052

EPOCH : 49 / 50
VAL_LOSS : 0.08383705236437712 
VAL_ACCURACY : 0.9508599508599509
VAL_F1 : 0.9625468159781664

EPOCH : 50 / 50
VAL_LOSS : 0.08105625060624351 
VAL_ACCURACY : 0.9422604422604423
VAL_F1 : 0.9565217386288916

# 5話-0
# 文: 今ハマってる本はこの二冊…
正解 : 1 , 予測 : 0 / 元クラス : 恐怖
tensor([[ 0.5016, -0.6665]], device='cuda:0')
# 5話-0
# 文: そうなんだ〜
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 1.2382, -1.4718]], device='cuda:0')
# 5話-1
# 文: ありがとうございます… それ、何読んでるんですか?
正解 : 1 , 予測 : 0 / 元クラス : 恐怖
tensor([[ 2.2164, -2.7627]], device='cuda:0')
# 5話-1
# 文: 本当に今ハマってる本はこの二冊…
正解 : 1 , 予測 : 0 / 元クラス : 恐怖
tensor([[ 2.2066, -2.7277]], device='cuda:0')
# 6話-0
# 文: 今日弁当なんですね
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-1.6074,  1.7348]], device='cuda:0')
# 6話-0
# 文: ベタだなあ
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 1.1070, -1.2082]], device='cuda:0')
# 6話-1
# 文: ベタだなあ
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 1.1070, -1.2082]], device='cuda:0')
# 6話-1
# 文: ええ… 父の分と2つ作ったんだけど
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
tensor([[ 0.0327, -0.4915]], device='cuda:0')
# 6話-1
# 文: ほとんど冷凍食品詰めただけよ…
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
tensor([[ 2.0062, -2.4848]], device='cuda:0')
# 6話-1
# 文: 俺も今日弁当なんでおかず分けますよ
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-1.4127,  1.6827]], device='cuda:0')
# 7話-0
# 文: チョコは一つしかないし、悪いよ〜
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
tensor([[ 1.3089, -1.9837]], device='cuda:0')
# 7話-0
# 文: 別に気にしませんが…
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.5699,  0.2930]], device='cuda:0')
# 7話-0
# 文: とか言い出すのかな…
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.5723,  0.2949]], device='cuda:0')
# 7話-0
# 文: 器用だ!?
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[ 1.0177, -1.4209]], device='cuda:0')
# 7話-1
# 文: 器用だ!?
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[ 1.0177, -1.4209]], device='cuda:0')
# 7話-1
# 文: とか言い出すのかと思った…
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.5666,  0.2867]], device='cuda:0')
# 8話-1
# 文: でも わざわざ国際会議から送ってくれたんだよな…
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
tensor([[ 2.2145, -2.7505]], device='cuda:0')
# 9話-0
# 文: Bさん…
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-2.3929,  2.6464]], device='cuda:0')
# 9話-0
# 文: 無視!?
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[ 1.4746, -1.6086]], device='cuda:0')
# 9話-0
# 文: ?
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 2.0514, -2.4847]], device='cuda:0')
# 9話-0
# 文: 人違い!?
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[ 0.8807, -1.2036]], device='cuda:0')
# 9話-1
# 文: 人違い!?
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[ 0.8807, -1.2036]], device='cuda:0')
# 9話-1
# 文: ここは よその研究室…!?
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[ 2.2082, -2.7227]], device='cuda:0')
# 9話-1
# 文: ただいま〜
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-1.0554,  0.9859]], device='cuda:0')
# 9話-1
# 文: ?
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 2.0514, -2.4847]], device='cuda:0')
------------------------test acc------------------------
Test Acc : 0.6269
correct: 42, total: 67
------------------------------------------------
                  喜楽        その他  accuracy  macro avg  weighted avg
precision   0.632653   0.611111  0.626866   0.621882      0.623329
recall      0.815789   0.379310  0.626866   0.597550      0.626866
f1-score    0.712644   0.468085  0.626866   0.590364      0.606790
support    38.000000  29.000000  0.626866  67.000000     67.000000
正例のF1値 : 0.7126436776525299
class weight : tensor([0.3485, 0.9347])
best:lr 0.00014879302573756766
EPOCH : 1 / 50
VAL_LOSS : 0.15340327098965645 
VAL_ACCURACY : 0.9287469287469288
VAL_F1 : 0.9462962957947908

EPOCH : 2 / 50
VAL_LOSS : 0.1388264153444884 
VAL_ACCURACY : 0.9250614250614251
VAL_F1 : 0.9416267937581649

EPOCH : 3 / 50
VAL_LOSS : 0.11294109975079111 
VAL_ACCURACY : 0.9447174447174447
VAL_F1 : 0.95782567897397

EPOCH : 4 / 50
VAL_LOSS : 0.1008645367315587 
VAL_ACCURACY : 0.9471744471744472
VAL_F1 : 0.9597754906119302

EPOCH : 5 / 50
VAL_LOSS : 0.12433970151651724 
VAL_ACCURACY : 0.9398034398034398
VAL_F1 : 0.9540768504828804

EPOCH : 6 / 50
VAL_LOSS : 0.10529581793383055 
VAL_ACCURACY : 0.9336609336609336
VAL_F1 : 0.9488636358628724

EPOCH : 7 / 50
VAL_LOSS : 0.10307223624641113 
VAL_ACCURACY : 0.941031941031941
VAL_F1 : 0.9547169806311356

EPOCH : 8 / 50
VAL_LOSS : 0.09410884409375928 
VAL_ACCURACY : 0.9471744471744472
VAL_F1 : 0.9596244126444083

EPOCH : 9 / 50
VAL_LOSS : 0.09729962281919285 
VAL_ACCURACY : 0.9471744471744472
VAL_F1 : 0.9597000932195147

EPOCH : 10 / 50
VAL_LOSS : 0.09221182617486692 
VAL_ACCURACY : 0.9484029484029484
VAL_F1 : 0.9606003747333547

EPOCH : 11 / 50
VAL_LOSS : 0.08977145737256198 
VAL_ACCURACY : 0.9471744471744472
VAL_F1 : 0.9597754906119302

EPOCH : 12 / 50
VAL_LOSS : 0.0975434749898519 
VAL_ACCURACY : 0.9336609336609336
VAL_F1 : 0.9488636358628724

EPOCH : 13 / 50
VAL_LOSS : 0.09048237484496306 
VAL_ACCURACY : 0.9484029484029484
VAL_F1 : 0.9606003747333547

EPOCH : 14 / 50
VAL_LOSS : 0.08644118337143286 
VAL_ACCURACY : 0.9484029484029484
VAL_F1 : 0.9606741568021399

EPOCH : 15 / 50
VAL_LOSS : 0.09400068384175207 
VAL_ACCURACY : 0.9398034398034398
VAL_F1 : 0.9537299333990074

EPOCH : 16 / 50
VAL_LOSS : 0.09267974203890737 
VAL_ACCURACY : 0.9471744471744472
VAL_F1 : 0.9595484472882142

EPOCH : 17 / 50
VAL_LOSS : 0.08349402512734135 
VAL_ACCURACY : 0.9508599508599509
VAL_F1 : 0.9624765473412311

EPOCH : 18 / 50
VAL_LOSS : 0.08986937832635115 
VAL_ACCURACY : 0.941031941031941
VAL_F1 : 0.9547169806311356

EPOCH : 19 / 50
VAL_LOSS : 0.08692600011971652 
VAL_ACCURACY : 0.9496314496314496
VAL_F1 : 0.9616463980020109

EPOCH : 20 / 50
VAL_LOSS : 0.08360000364665016 
VAL_ACCURACY : 0.9471744471744472
VAL_F1 : 0.9595484472882142

EPOCH : 21 / 50
VAL_LOSS : 0.0817986848563248 
VAL_ACCURACY : 0.9496314496314496
VAL_F1 : 0.9615023469167052

EPOCH : 22 / 50
VAL_LOSS : 0.0853744265806003 
VAL_ACCURACY : 0.9484029484029484
VAL_F1 : 0.9606741568021399

EPOCH : 23 / 50
VAL_LOSS : 0.0850013705773973 
VAL_ACCURACY : 0.9508599508599509
VAL_F1 : 0.9625468159781664

EPOCH : 24 / 50
VAL_LOSS : 0.08761185126415655 
VAL_ACCURACY : 0.9471744471744472
VAL_F1 : 0.9597000932195147

EPOCH : 25 / 50
VAL_LOSS : 0.09391760213446676 
VAL_ACCURACY : 0.9422604422604423
VAL_F1 : 0.9556185075255381

EPOCH : 26 / 50
VAL_LOSS : 0.07981027288398906 
VAL_ACCURACY : 0.9496314496314496
VAL_F1 : 0.9615023469167052

EPOCH : 27 / 50
VAL_LOSS : 0.08199254956607725 
VAL_ACCURACY : 0.9508599508599509
VAL_F1 : 0.9625468159781664

EPOCH : 28 / 50
VAL_LOSS : 0.08226938231610785 
VAL_ACCURACY : 0.941031941031941
VAL_F1 : 0.9545454540446798

EPOCH : 29 / 50
VAL_LOSS : 0.08493134503563245 
VAL_ACCURACY : 0.9484029484029484
VAL_F1 : 0.9605263152883748

EPOCH : 30 / 50
VAL_LOSS : 0.08389785385453234 
VAL_ACCURACY : 0.9447174447174447
VAL_F1 : 0.9575871814028806

EPOCH : 31 / 50
VAL_LOSS : 0.08653676883299269 
VAL_ACCURACY : 0.9471744471744472
VAL_F1 : 0.9595484472882142

EPOCH : 32 / 50
VAL_LOSS : 0.08690441879169906 
VAL_ACCURACY : 0.9484029484029484
VAL_F1 : 0.9606003747333547

EPOCH : 33 / 50
VAL_LOSS : 0.0875411337131963 
VAL_ACCURACY : 0.9484029484029484
VAL_F1 : 0.9606741568021399

EPOCH : 34 / 50
VAL_LOSS : 0.08742382816568602 
VAL_ACCURACY : 0.9471744471744472
VAL_F1 : 0.9595484472882142

EPOCH : 35 / 50
VAL_LOSS : 0.08843410652423021 
VAL_ACCURACY : 0.9434889434889435
VAL_F1 : 0.9566037730839623

EPOCH : 36 / 50
VAL_LOSS : 0.08744713432137288 
VAL_ACCURACY : 0.9508599508599509
VAL_F1 : 0.9625468159781664

EPOCH : 37 / 50
VAL_LOSS : 0.08069388800318919 
VAL_ACCURACY : 0.9508599508599509
VAL_F1 : 0.9624765473412311

EPOCH : 38 / 50
VAL_LOSS : 0.07805881480339404 
VAL_ACCURACY : 0.9496314496314496
VAL_F1 : 0.9615745074650595

EPOCH : 39 / 50
VAL_LOSS : 0.07962989175290454 
VAL_ACCURACY : 0.9508599508599509
VAL_F1 : 0.9624765473412311

EPOCH : 40 / 50
VAL_LOSS : 0.07906445917472535 
VAL_ACCURACY : 0.9484029484029484
VAL_F1 : 0.9605263152883748

EPOCH : 41 / 50
VAL_LOSS : 0.08832490926279742 
VAL_ACCURACY : 0.9434889434889435
VAL_F1 : 0.9566854985573607

EPOCH : 42 / 50
VAL_LOSS : 0.08119237110676135 
VAL_ACCURACY : 0.9484029484029484
VAL_F1 : 0.9605263152883748

EPOCH : 43 / 50
VAL_LOSS : 0.08410302553709377 
VAL_ACCURACY : 0.9484029484029484
VAL_F1 : 0.9605263152883748

EPOCH : 44 / 50
VAL_LOSS : 0.10010031803383254 
VAL_ACCURACY : 0.9459459459459459
VAL_F1 : 0.9588785041716097

EPOCH : 45 / 50
VAL_LOSS : 0.08338830600876142 
VAL_ACCURACY : 0.9471744471744472
VAL_F1 : 0.9595484472882142

EPOCH : 46 / 50
VAL_LOSS : 0.09542364055546475 
VAL_ACCURACY : 0.9459459459459459
VAL_F1 : 0.9587242021254783

EPOCH : 47 / 50
VAL_LOSS : 0.0923725800022629 
VAL_ACCURACY : 0.9447174447174447
VAL_F1 : 0.9576669797435328

EPOCH : 48 / 50
VAL_LOSS : 0.08087414220048517 
VAL_ACCURACY : 0.9447174447174447
VAL_F1 : 0.9575871814028806

EPOCH : 49 / 50
VAL_LOSS : 0.08650080960554381 
VAL_ACCURACY : 0.9496314496314496
VAL_F1 : 0.9615745074650595

EPOCH : 50 / 50
VAL_LOSS : 0.0919544643028548 
VAL_ACCURACY : 0.9484029484029484
VAL_F1 : 0.9606003747333547

# 5話-0
# 文: そうなんだ〜
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 2.2881, -2.7774]], device='cuda:0')
# 5話-1
# 文: ありがとうございます… それ、何読んでるんですか?
正解 : 1 , 予測 : 0 / 元クラス : 恐怖
tensor([[ 2.3649, -3.0163]], device='cuda:0')
# 5話-1
# 文: 本当に今ハマってる本はこの二冊…
正解 : 1 , 予測 : 0 / 元クラス : 恐怖
tensor([[ 2.3836, -3.0239]], device='cuda:0')
# 6話-0
# 文: キャー!
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[ 0.9576, -1.6070]], device='cuda:0')
# 6話-0
# 文: ベタだなあ
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 0.7402, -1.1984]], device='cuda:0')
# 6話-1
# 文: キャー!
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[ 0.9576, -1.6070]], device='cuda:0')
# 6話-1
# 文: ベタだなあ
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 0.7402, -1.1984]], device='cuda:0')
# 6話-1
# 文: 今日弁当なの珍しいですね
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.5333,  0.2866]], device='cuda:0')
# 6話-1
# 文: ええ… 父の分と2つ作ったんだけど
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
tensor([[ 1.2380, -1.8381]], device='cuda:0')
# 6話-1
# 文: ほとんど冷凍食品詰めただけよ…
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
tensor([[ 0.7993, -1.5614]], device='cuda:0')
# 6話-1
# 文: 俺も今日弁当なんでおかず分けますよ
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-2.4383,  2.9134]], device='cuda:0')
# 7話-0
# 文: チョコは一つしかないし、悪いよ〜
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
tensor([[ 1.8730, -2.4075]], device='cuda:0')
# 7話-0
# 文: 別に気にしませんが…
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.7008,  0.1855]], device='cuda:0')
# 7話-0
# 文: とか言い出すのかな…
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.7073,  0.1963]], device='cuda:0')
# 7話-0
# 文: 器用だ!?
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[ 0.6949, -0.7239]], device='cuda:0')
# 7話-1
# 文: 器用だ!?
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[ 0.6949, -0.7239]], device='cuda:0')
# 7話-1
# 文: とか言い出すのかと思った…
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.7037,  0.1890]], device='cuda:0')
# 8話-0
# 文: ここは日本。何も見ていない
正解 : 1 , 予測 : 0 / 元クラス : 恐怖
tensor([[ 1.9339, -2.6455]], device='cuda:0')
# 8話-1
# 文: ここは日本。何も見ていない
正解 : 1 , 予測 : 0 / 元クラス : 恐怖
tensor([[ 1.9339, -2.6455]], device='cuda:0')
# 8話-1
# 文: でも わざわざ国際会議から送ってくれたんだよな…
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
tensor([[ 2.3702, -3.0039]], device='cuda:0')
# 9話-0
# 文: Bさん…
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-2.5115,  2.8925]], device='cuda:0')
# 9話-0
# 文: 無視!?
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[ 1.9677, -2.7110]], device='cuda:0')
# 9話-0
# 文: ?
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 1.8627, -2.9086]], device='cuda:0')
# 9話-0
# 文: 人違い!?
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[ 0.7189, -0.4916]], device='cuda:0')
# 9話-1
# 文: 人違い!?
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[ 0.7189, -0.4916]], device='cuda:0')
# 9話-1
# 文: ここは よその研究室…!?
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[ 2.3678, -3.0375]], device='cuda:0')
# 9話-1
# 文: ただいま〜
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.1450,  1.2513]], device='cuda:0')
# 9話-1
# 文: ?
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 1.8627, -2.9086]], device='cuda:0')
------------------------test acc------------------------
Test Acc : 0.5821
correct: 39, total: 67
------------------------------------------------
                  喜楽        その他  accuracy  macro avg  weighted avg
precision   0.596154   0.533333   0.58209   0.564744      0.568963
recall      0.815789   0.275862   0.58209   0.545826      0.582090
f1-score    0.688889   0.363636   0.58209   0.526263      0.548108
support    38.000000  29.000000   0.58209  67.000000     67.000000
正例のF1値 : 0.688888888385679
class weight : tensor([0.3485, 0.9347])
best:lr 0.0003336194739806972
EPOCH : 1 / 50
VAL_LOSS : 0.14603384525752536 
VAL_ACCURACY : 0.9275184275184275
VAL_F1 : 0.9442870627663528

EPOCH : 2 / 50
VAL_LOSS : 0.18891544541453614 
VAL_ACCURACY : 0.9262899262899262
VAL_F1 : 0.9445471344337658

EPOCH : 3 / 50
VAL_LOSS : 0.1169185410527622 
VAL_ACCURACY : 0.9422604422604423
VAL_F1 : 0.9557855121988516

EPOCH : 4 / 50
VAL_LOSS : 0.11408313570142377 
VAL_ACCURACY : 0.9336609336609336
VAL_F1 : 0.949056603272656

EPOCH : 5 / 50
VAL_LOSS : 0.12616234877165042 
VAL_ACCURACY : 0.9336609336609336
VAL_F1 : 0.949056603272656

EPOCH : 6 / 50
VAL_LOSS : 0.122771260821644 
VAL_ACCURACY : 0.9385749385749386
VAL_F1 : 0.9535315980115774

EPOCH : 7 / 50
VAL_LOSS : 0.11365102089064963 
VAL_ACCURACY : 0.9385749385749386
VAL_F1 : 0.9530075182959078

EPOCH : 8 / 50
VAL_LOSS : 0.09728621160976735 
VAL_ACCURACY : 0.9459459459459459
VAL_F1 : 0.9588014976261134

EPOCH : 9 / 50
VAL_LOSS : 0.09785958412377273 
VAL_ACCURACY : 0.9422604422604423
VAL_F1 : 0.9558685440998145

EPOCH : 10 / 50
VAL_LOSS : 0.14457589684638614 
VAL_ACCURACY : 0.9226044226044227
VAL_F1 : 0.9407337718414011

EPOCH : 11 / 50
VAL_LOSS : 0.10392215649834742 
VAL_ACCURACY : 0.9312039312039312
VAL_F1 : 0.9466666661661859

EPOCH : 12 / 50
VAL_LOSS : 0.09261384337921352 
VAL_ACCURACY : 0.9348894348894349
VAL_F1 : 0.9496676158336522

EPOCH : 13 / 50
VAL_LOSS : 0.10235972017707194 
VAL_ACCURACY : 0.9348894348894349
VAL_F1 : 0.9497630326746337

EPOCH : 14 / 50
VAL_LOSS : 0.10189880242607757 
VAL_ACCURACY : 0.9385749385749386
VAL_F1 : 0.952651514650744

EPOCH : 15 / 50
VAL_LOSS : 0.09965382927261732 
VAL_ACCURACY : 0.9447174447174447
VAL_F1 : 0.9576669797435328

EPOCH : 16 / 50
VAL_LOSS : 0.10786402559674838 
VAL_ACCURACY : 0.9398034398034398
VAL_F1 : 0.9541627684416881

EPOCH : 17 / 50
VAL_LOSS : 0.09212163445886735 
VAL_ACCURACY : 0.9398034398034398
VAL_F1 : 0.9536423836051443

EPOCH : 18 / 50
VAL_LOSS : 0.09863300054498456 
VAL_ACCURACY : 0.9459459459459459
VAL_F1 : 0.9586466160402581

EPOCH : 19 / 50
VAL_LOSS : 0.10368997837398566 
VAL_ACCURACY : 0.9361179361179361
VAL_F1 : 0.9507575752568082

EPOCH : 20 / 50
VAL_LOSS : 0.1055553378354685 
VAL_ACCURACY : 0.941031941031941
VAL_F1 : 0.9552238800956784

EPOCH : 21 / 50
VAL_LOSS : 0.08547925213169233 
VAL_ACCURACY : 0.9459459459459459
VAL_F1 : 0.9588014976261134

EPOCH : 22 / 50
VAL_LOSS : 0.09924388910625495 
VAL_ACCURACY : 0.9324324324324325
VAL_F1 : 0.9477682806009872

EPOCH : 23 / 50
VAL_LOSS : 0.09327804528213307 
VAL_ACCURACY : 0.9434889434889435
VAL_F1 : 0.9566854985573607

EPOCH : 24 / 50
VAL_LOSS : 0.0882110037457417 
VAL_ACCURACY : 0.9484029484029484
VAL_F1 : 0.9606003747333547

EPOCH : 25 / 50
VAL_LOSS : 0.08669652819962186 
VAL_ACCURACY : 0.9496314496314496
VAL_F1 : 0.9615745074650595

EPOCH : 26 / 50
VAL_LOSS : 0.09211512473320552 
VAL_ACCURACY : 0.9471744471744472
VAL_F1 : 0.9597754906119302

EPOCH : 27 / 50
VAL_LOSS : 0.08632353241281475 
VAL_ACCURACY : 0.9459459459459459
VAL_F1 : 0.9590316568542839

EPOCH : 28 / 50
VAL_LOSS : 0.09016570297307243 
VAL_ACCURACY : 0.9434889434889435
VAL_F1 : 0.9570895517374659

EPOCH : 29 / 50
VAL_LOSS : 0.08587817736335245 
VAL_ACCURACY : 0.9471744471744472
VAL_F1 : 0.9595484472882142

EPOCH : 30 / 50
VAL_LOSS : 0.11164464106710226 
VAL_ACCURACY : 0.9336609336609336
VAL_F1 : 0.9487666029148848

EPOCH : 31 / 50
VAL_LOSS : 0.0838503934278646 
VAL_ACCURACY : 0.9508599508599509
VAL_F1 : 0.9625468159781664

EPOCH : 32 / 50
VAL_LOSS : 0.10915090092549137 
VAL_ACCURACY : 0.9447174447174447
VAL_F1 : 0.9577464783721114

EPOCH : 33 / 50
VAL_LOSS : 0.08759216714979094 
VAL_ACCURACY : 0.9496314496314496
VAL_F1 : 0.9615023469167052

EPOCH : 34 / 50
VAL_LOSS : 0.08597780568707808 
VAL_ACCURACY : 0.9484029484029484
VAL_F1 : 0.9606741568021399

EPOCH : 35 / 50
VAL_LOSS : 0.09632673191235346 
VAL_ACCURACY : 0.9508599508599509
VAL_F1 : 0.9624765473412311

EPOCH : 36 / 50
VAL_LOSS : 0.0898103128716934 
VAL_ACCURACY : 0.9471744471744472
VAL_F1 : 0.9595484472882142

EPOCH : 37 / 50
VAL_LOSS : 0.08815710789834459 
VAL_ACCURACY : 0.9459459459459459
VAL_F1 : 0.9586466160402581

EPOCH : 38 / 50
VAL_LOSS : 0.09321883119934914 
VAL_ACCURACY : 0.9459459459459459
VAL_F1 : 0.958568737728732

EPOCH : 39 / 50
VAL_LOSS : 0.08647674855356123 
VAL_ACCURACY : 0.9484029484029484
VAL_F1 : 0.9605263152883748

EPOCH : 40 / 50
VAL_LOSS : 0.0868646321617359 
VAL_ACCURACY : 0.9508599508599509
VAL_F1 : 0.9624765473412311

EPOCH : 41 / 50
VAL_LOSS : 0.09211234473532029 
VAL_ACCURACY : 0.9447174447174447
VAL_F1 : 0.9575871814028806

EPOCH : 42 / 50
VAL_LOSS : 0.08520497776129667 
VAL_ACCURACY : 0.9496314496314496
VAL_F1 : 0.9615745074650595

EPOCH : 43 / 50
VAL_LOSS : 0.08901107849954974 
VAL_ACCURACY : 0.9422604422604423
VAL_F1 : 0.9556185075255381

EPOCH : 44 / 50
VAL_LOSS : 0.10103678012120665 
VAL_ACCURACY : 0.9471744471744472
VAL_F1 : 0.9598506064081128

EPOCH : 45 / 50
VAL_LOSS : 0.07648731257729963 
VAL_ACCURACY : 0.9471744471744472
VAL_F1 : 0.9595484472882142

EPOCH : 46 / 50
VAL_LOSS : 0.08007476655948981 
VAL_ACCURACY : 0.9496314496314496
VAL_F1 : 0.9615745074650595

EPOCH : 47 / 50
VAL_LOSS : 0.10120666366727914 
VAL_ACCURACY : 0.9361179361179361
VAL_F1 : 0.9506641361217121

EPOCH : 48 / 50
VAL_LOSS : 0.10601847790473816 
VAL_ACCURACY : 0.9336609336609336
VAL_F1 : 0.9486692010203306

EPOCH : 49 / 50
VAL_LOSS : 0.09133089276249795 
VAL_ACCURACY : 0.9434889434889435
VAL_F1 : 0.9566854985573607

EPOCH : 50 / 50
VAL_LOSS : 0.09798675884182255 
VAL_ACCURACY : 0.9471744471744472
VAL_F1 : 0.9597754906119302

# 5話-0
# 文: 適当に流そう
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.2912,  0.6738]], device='cuda:0')
# 5話-0
# 文: そうなんだ〜
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 2.8386, -2.3712]], device='cuda:0')
# 5話-1
# 文: ありがとうございます… それ、何読んでるんですか?
正解 : 1 , 予測 : 0 / 元クラス : 恐怖
tensor([[ 2.9491, -2.4438]], device='cuda:0')
# 5話-1
# 文: 本当に今ハマってる本はこの二冊…
正解 : 1 , 予測 : 0 / 元クラス : 恐怖
tensor([[ 2.9494, -2.4443]], device='cuda:0')
# 6話-0
# 文: キャー!
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[ 2.4053, -2.2273]], device='cuda:0')
# 6話-0
# 文: ベタだなあ
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 1.1882, -0.7397]], device='cuda:0')
# 6話-1
# 文: キャー!
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[ 2.4053, -2.2273]], device='cuda:0')
# 6話-1
# 文: ベタだなあ
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 1.1882, -0.7397]], device='cuda:0')
# 6話-1
# 文: 今日弁当なの珍しいですね
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-2.3012,  1.5101]], device='cuda:0')
# 6話-1
# 文: ほとんど冷凍食品詰めただけよ…
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
tensor([[ 0.2965, -0.4125]], device='cuda:0')
# 6話-1
# 文: 俺も今日弁当なんでおかず分けますよ
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-2.8937,  2.4517]], device='cuda:0')
# 7話-0
# 文: チョコは一つしかないし、悪いよ〜
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
tensor([[ 2.5132, -2.1946]], device='cuda:0')
# 7話-0
# 文: 別に気にしませんが…
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.3043,  0.6806]], device='cuda:0')
# 7話-0
# 文: とか言い出すのかな…
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.3042,  0.6802]], device='cuda:0')
# 7話-0
# 文: 器用だ!?
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[ 2.8375, -2.3326]], device='cuda:0')
# 7話-1
# 文: 器用だ!?
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[ 2.8375, -2.3326]], device='cuda:0')
# 7話-1
# 文: とか言い出すのかと思った…
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.3042,  0.6797]], device='cuda:0')
# 8話-0
# 文: ここは日本。何も見ていない
正解 : 1 , 予測 : 0 / 元クラス : 恐怖
tensor([[ 2.9496, -2.4445]], device='cuda:0')
# 8話-1
# 文: ここは日本。何も見ていない
正解 : 1 , 予測 : 0 / 元クラス : 恐怖
tensor([[ 2.9496, -2.4445]], device='cuda:0')
# 8話-1
# 文: でも わざわざ国際会議から送ってくれたんだよな…
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
tensor([[ 2.4118, -1.8555]], device='cuda:0')
# 9話-0
# 文: Bさん…
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-2.7518,  2.0723]], device='cuda:0')
# 9話-0
# 文: 無視!?
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[ 2.9481, -2.4434]], device='cuda:0')
# 9話-0
# 文: ?
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 2.9492, -2.4441]], device='cuda:0')
# 9話-0
# 文: 人違い!?
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[ 2.9486, -2.4436]], device='cuda:0')
# 9話-1
# 文: 人違い!?
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[ 2.9486, -2.4436]], device='cuda:0')
# 9話-1
# 文: ここは よその研究室…!?
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[ 2.9476, -2.4424]], device='cuda:0')
# 9話-1
# 文: ?
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 2.9492, -2.4441]], device='cuda:0')
------------------------test acc------------------------
Test Acc : 0.5970
correct: 40, total: 67
------------------------------------------------
                  喜楽        その他  accuracy  macro avg  weighted avg
precision   0.607843   0.562500  0.597015   0.585172      0.588217
recall      0.815789   0.310345  0.597015   0.563067      0.597015
f1-score    0.696629   0.400000  0.597015   0.548315      0.568237
support    38.000000  29.000000  0.597015  67.000000     67.000000
正例のF1値 : 0.6966292129781594
