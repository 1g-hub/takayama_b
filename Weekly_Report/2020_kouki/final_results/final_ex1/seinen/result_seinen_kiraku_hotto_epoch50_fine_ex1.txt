class weight : tensor([0.7576, 0.1600])
best:lr 3.7368637292084644e-07
EPOCH : 1 / 5
VAL_LOSS : 0.6840368486800283 
VAL_ACCURACY : 0.24285714285714285
VAL_F1 : 0.3614457828293193

EPOCH : 2 / 5
VAL_LOSS : 0.6695686162642713 
VAL_ACCURACY : 0.25833333333333336
VAL_F1 : 0.3700707782593238

EPOCH : 3 / 5
VAL_LOSS : 0.6518385421554997 
VAL_ACCURACY : 0.2773809523809524
VAL_F1 : 0.37615621757409784

EPOCH : 4 / 5
VAL_LOSS : 0.6304551351745173 
VAL_ACCURACY : 0.30952380952380953
VAL_F1 : 0.38689217727440117

EPOCH : 5 / 5
VAL_LOSS : 0.6155134304514471 
VAL_ACCURACY : 0.3761904761904762
VAL_F1 : 0.4099099095791256

# 5話-0
# 文: 何読んでるんですか?
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 0.4195, -0.2120]], device='cuda:0')
# 5話-0
# 文: 僕ですか?
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[0.3210, 0.0063]], device='cuda:0')
# 5話-0
# 文: 今ハマってる本はこの二冊…
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[0.4312, 0.2012]], device='cuda:0')
# 5話-0
# 文: 少々マニアックだろうか…
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[0.3281, 0.1884]], device='cuda:0')
# 5話-0
# 文: Bさん、苦手そうだよな…
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
tensor([[0.2295, 0.0721]], device='cuda:0')
# 5話-0
# 文: 適当に流そう
正解 : 1 , 予測 : 0 / 元クラス : UNK
tensor([[ 0.2949, -0.0398]], device='cuda:0')
# 5話-0
# 文: 小説はあまり読まないのですが、研究で利用している青空文庫の作品なら少々
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[0.2444, 0.2310]], device='cuda:0')
# 5話-0
# 文: そうなんだ〜
正解 : 1 , 予測 : 0 / 元クラス : 憤怒
tensor([[ 0.4584, -0.0096]], device='cuda:0')
# 5話-0
# 文: 適当に流したな
正解 : 1 , 予測 : 0 / 元クラス : UNK
tensor([[ 0.4285, -0.0273]], device='cuda:0')
# 5話-1
# 文: これ読んだよ
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[0.4946, 0.1509]], device='cuda:0')
# 5話-1
# 文: ありがとうございます… それ、何読んでるんですか?
正解 : 1 , 予測 : 0 / 元クラス : 恐怖
tensor([[0.8380, 0.2158]], device='cuda:0')
# 5話-1
# 文: 僕ですか?
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[0.3210, 0.0063]], device='cuda:0')
# 5話-1
# 文: そうなんだ〜
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[ 0.4584, -0.0096]], device='cuda:0')
# 5話-1
# 文: 本当に今ハマってる本はこの二冊…
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[0.4945, 0.1189]], device='cuda:0')
# 6話-0
# 文: 今日は弁当なんですね
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[ 0.0495, -0.0750]], device='cuda:0')
# 6話-0
# 文: 手作りなんですか?
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 0.3250, -0.1641]], device='cuda:0')
# 6話-0
# 文: ほとんど冷凍食品詰めただけだよ
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 0.6091, -0.1472]], device='cuda:0')
# 6話-0
# 文: キャー!
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[ 0.5770, -0.1458]], device='cuda:0')
# 6話-0
# 文: ベタだなあ
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
tensor([[ 0.3092, -0.2852]], device='cuda:0')
# 6話-1
# 文: キャー!
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[ 0.5770, -0.1458]], device='cuda:0')
# 6話-1
# 文: ベタだなあ
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
tensor([[ 0.3092, -0.2852]], device='cuda:0')
# 6話-1
# 文: 弁当なの珍しいですね
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
tensor([[ 0.2688, -0.4000]], device='cuda:0')
# 6話-1
# 文: ええ…父の分と2つ作ったんだけど
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
tensor([[0.5019, 0.1343]], device='cuda:0')
# 6話-1
# 文: 手作りなんですか?
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 0.3250, -0.1641]], device='cuda:0')
# 6話-1
# 文: ほとんど冷凍食品詰めただけよ…
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
tensor([[0.2367, 0.0169]], device='cuda:0')
# 6話-1
# 文: 俺も今日弁当なんでおかず分けますよ
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
tensor([[ 0.3394, -0.3161]], device='cuda:0')
# 6話-1
# 文: ありがとう…
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
tensor([[0.5709, 0.1282]], device='cuda:0')
# 7話-0
# 文: 差し入れで沢山いただいてしまいました
正解 : 1 , 予測 : 0 / 元クラス : UNK
tensor([[-0.1046, -0.1101]], device='cuda:0')
# 7話-0
# 文: じゃあチョコですね
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[0.1018, 0.0147]], device='cuda:0')
# 7話-0
# 文: チョコは一つしかないし、悪いよ〜
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
tensor([[0.2295, 0.0567]], device='cuda:0')
# 7話-0
# 文: 別に気にしませんが…
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 0.0516, -0.0767]], device='cuda:0')
# 7話-0
# 文: はんぶんこしよっか
正解 : 1 , 予測 : 0 / 元クラス : UNK
tensor([[ 0.6676, -0.3666]], device='cuda:0')
# 7話-0
# 文: とか言い出すのかな…
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 0.0462, -0.0782]], device='cuda:0')
# 7話-0
# 文: 器用だ!?
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[0.3220, 0.2255]], device='cuda:0')
# 7話-1
# 文: 器用だ!?
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[0.3220, 0.2255]], device='cuda:0')
# 7話-1
# 文: てっきり
正解 : 1 , 予測 : 0 / 元クラス : UNK
tensor([[ 0.4819, -0.1991]], device='cuda:0')
# 7話-1
# 文: チョコ一つしかないねはんぶんこしよっか
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 0.4428, -0.0889]], device='cuda:0')
# 7話-1
# 文: とか言い出すのかと思った…
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 0.0548, -0.0847]], device='cuda:0')
# 7話-1
# 文: Aくんがいなければ独り占めできたのにな…
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
tensor([[-0.0684, -0.1450]], device='cuda:0')
# 8話-0
# 文: 国際会議でスペインにいるBさんからだ
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[0.3000, 0.2155]], device='cuda:0')
# 8話-0
# 文: ここは日本…何も見ていない
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[0.1991, 0.1068]], device='cuda:0')
# 8話-1
# 文: ここは日本…何も見ていない
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[0.1991, 0.1068]], device='cuda:0')
# 8話-1
# 文: スペインから…
正解 : 1 , 予測 : 0 / 元クラス : UNK
tensor([[0.4063, 0.3308]], device='cuda:0')
# 9話-0
# 文: あれ?スペインからもう戻ってきたのか
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[ 0.2114, -0.2432]], device='cuda:0')
# 9話-0
# 文: Bさん… あれ?
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[0.0717, 0.0182]], device='cuda:0')
# 9話-0
# 文: 無視!?
正解 : 1 , 予測 : 0 / 元クラス : UNK
tensor([[ 0.3929, -0.3900]], device='cuda:0')
# 9話-0
# 文: Bさ…ちょっと!
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
tensor([[0.3230, 0.0910]], device='cuda:0')
# 9話-0
# 文: ここはよその研究室…!?
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[ 0.0496, -0.0794]], device='cuda:0')
# 9話-0
# 文: ?
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[ 0.1329, -0.2687]], device='cuda:0')
# 9話-0
# 文: 人違い!?
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[ 0.2202, -0.1267]], device='cuda:0')
# 9話-1
# 文: Bさ…
正解 : 1 , 予測 : 0 / 元クラス : UNK
tensor([[0.3499, 0.1159]], device='cuda:0')
# 9話-1
# 文: ?
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[ 0.1329, -0.2687]], device='cuda:0')
# 9話-1
# 文: 人違い!?
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[ 0.2202, -0.1267]], device='cuda:0')
# 9話-1
# 文: ここは よその研究室…!?
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[ 0.5896, -0.0018]], device='cuda:0')
# 9話-1
# 文: 恥ずかしい…
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
tensor([[ 0.3793, -0.3010]], device='cuda:0')
# 9話-1
# 文: ?
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[ 0.1329, -0.2687]], device='cuda:0')
------------------------test acc------------------------
Test Acc : 0.2329
correct: 17, total: 73
------------------------------------------------
                  喜楽        その他  accuracy  macro avg  weighted avg
precision   0.200000   1.000000  0.232877   0.600000      0.846575
recall      1.000000   0.050847  0.232877   0.525424      0.232877
f1-score    0.333333   0.096774  0.232877   0.215054      0.142142
support    14.000000  59.000000  0.232877  73.000000     73.000000
正例のF1値 : 0.33333333304761903
class weight : tensor([0.7557, 0.1616])
best:lr 3.98447540941762e-07
EPOCH : 1 / 50
VAL_LOSS : 0.7143910309443107 
VAL_ACCURACY : 0.25331724969843183
VAL_F1 : 0.37411526763750086

EPOCH : 2 / 50
VAL_LOSS : 0.6876540814454739 
VAL_ACCURACY : 0.25331724969843183
VAL_F1 : 0.3753784053414128

EPOCH : 3 / 50
VAL_LOSS : 0.6692326240814649 
VAL_ACCURACY : 0.2545235223160434
VAL_F1 : 0.3770161287230485

EPOCH : 4 / 50
VAL_LOSS : 0.6680425411233535 
VAL_ACCURACY : 0.25814234016887816
VAL_F1 : 0.37941473228388695

EPOCH : 5 / 50
VAL_LOSS : 0.6465173501234788 
VAL_ACCURACY : 0.2689987937273824
VAL_F1 : 0.3828920567148531

EPOCH : 6 / 50
VAL_LOSS : 0.6263969093561172 
VAL_ACCURACY : 0.3039806996381182
VAL_F1 : 0.39454354637584077

EPOCH : 7 / 50
VAL_LOSS : 0.6229678237667451 
VAL_ACCURACY : 0.36550060313630883
VAL_F1 : 0.4168514409095013

EPOCH : 8 / 50
VAL_LOSS : 0.6047467738389969 
VAL_ACCURACY : 0.40651387213510254
VAL_F1 : 0.4331797231606453

EPOCH : 9 / 50
VAL_LOSS : 0.5922053387531867 
VAL_ACCURACY : 0.45235223160434257
VAL_F1 : 0.4516908209026319

EPOCH : 10 / 50
VAL_LOSS : 0.5807024985551834 
VAL_ACCURACY : 0.4957780458383595
VAL_F1 : 0.47088607558416606

EPOCH : 11 / 50
VAL_LOSS : 0.5696355431125715 
VAL_ACCURACY : 0.5452352231604343
VAL_F1 : 0.4966622159097328

EPOCH : 12 / 50
VAL_LOSS : 0.559156745672226 
VAL_ACCURACY : 0.5790108564535585
VAL_F1 : 0.5159500689598551

EPOCH : 13 / 50
VAL_LOSS : 0.5477285001140374 
VAL_ACCURACY : 0.6151990349819059
VAL_F1 : 0.5383502166777318

EPOCH : 14 / 50
VAL_LOSS : 0.5379580866832 
VAL_ACCURACY : 0.6453558504221955
VAL_F1 : 0.5585585581503801

EPOCH : 15 / 50
VAL_LOSS : 0.532579212807692 
VAL_ACCURACY : 0.6718938480096501
VAL_F1 : 0.5776397511363036

EPOCH : 16 / 50
VAL_LOSS : 0.5181627072967016 
VAL_ACCURACY : 0.6972255729794934
VAL_F1 : 0.5971107539895344

EPOCH : 17 / 50
VAL_LOSS : 0.507397762284829 
VAL_ACCURACY : 0.715319662243667
VAL_F1 : 0.6118421048326967

EPOCH : 18 / 50
VAL_LOSS : 0.4969719442037436 
VAL_ACCURACY : 0.7346200241254524
VAL_F1 : 0.6283783779415917

EPOCH : 19 / 50
VAL_LOSS : 0.4874001517891884 
VAL_ACCURACY : 0.7394451145958987
VAL_F1 : 0.6326530607861135

EPOCH : 20 / 50
VAL_LOSS : 0.47790654691366047 
VAL_ACCURACY : 0.7490952955367913
VAL_F1 : 0.641379309903264

EPOCH : 21 / 50
VAL_LOSS : 0.47191617867121327 
VAL_ACCURACY : 0.7503015681544029
VAL_F1 : 0.6412478331794347

EPOCH : 22 / 50
VAL_LOSS : 0.45727597119716495 
VAL_ACCURACY : 0.7599517490952955
VAL_F1 : 0.6502636199406971

EPOCH : 23 / 50
VAL_LOSS : 0.452834784411467 
VAL_ACCURACY : 0.7683956574185766
VAL_F1 : 0.6583629888750966

EPOCH : 24 / 50
VAL_LOSS : 0.4396860020665022 
VAL_ACCURACY : 0.773220747889023
VAL_F1 : 0.6630824368256383

EPOCH : 25 / 50
VAL_LOSS : 0.431878177019266 
VAL_ACCURACY : 0.7780458383594693
VAL_F1 : 0.6678700356491352

EPOCH : 26 / 50
VAL_LOSS : 0.4276043554911247 
VAL_ACCURACY : 0.7828709288299156
VAL_F1 : 0.6727272722737256

EPOCH : 27 / 50
VAL_LOSS : 0.4183244980298556 
VAL_ACCURACY : 0.7901085645355851
VAL_F1 : 0.6801470583675863

EPOCH : 28 / 50
VAL_LOSS : 0.40867818490817 
VAL_ACCURACY : 0.7937273823884198
VAL_F1 : 0.6839186686740992

EPOCH : 29 / 50
VAL_LOSS : 0.4004795064146702 
VAL_ACCURACY : 0.7961399276236429
VAL_F1 : 0.6864564002841791

EPOCH : 30 / 50
VAL_LOSS : 0.39309002688297856 
VAL_ACCURACY : 0.8021712907117008
VAL_F1 : 0.6928838946711625

EPOCH : 31 / 50
VAL_LOSS : 0.39014628816109437 
VAL_ACCURACY : 0.8033775633293124
VAL_F1 : 0.6941838644552517

EPOCH : 32 / 50
VAL_LOSS : 0.3797698083978433 
VAL_ACCURACY : 0.8069963811821471
VAL_F1 : 0.6981132070856604

EPOCH : 33 / 50
VAL_LOSS : 0.3712178190740255 
VAL_ACCURACY : 0.8130277442702051
VAL_F1 : 0.7047619042984201

EPOCH : 34 / 50
VAL_LOSS : 0.3656001500785351 
VAL_ACCURACY : 0.8166465621230398
VAL_F1 : 0.7088122600717327

EPOCH : 35 / 50
VAL_LOSS : 0.3606139111977357 
VAL_ACCURACY : 0.8202653799758746
VAL_F1 : 0.7129094407672975

EPOCH : 36 / 50
VAL_LOSS : 0.3522968544409825 
VAL_ACCURACY : 0.8166465621230398
VAL_F1 : 0.7088122600717327

EPOCH : 37 / 50
VAL_LOSS : 0.34661512965193164 
VAL_ACCURACY : 0.827503015681544
VAL_F1 : 0.7212475628846408

EPOCH : 38 / 50
VAL_LOSS : 0.3390563236406216 
VAL_ACCURACY : 0.8299155609167672
VAL_F1 : 0.7240704496288848

EPOCH : 39 / 50
VAL_LOSS : 0.3377194923277085 
VAL_ACCURACY : 0.8323281061519904
VAL_F1 : 0.7269155201589464

EPOCH : 40 / 50
VAL_LOSS : 0.32928786197533977 
VAL_ACCURACY : 0.8335343787696019
VAL_F1 : 0.7283464562227898

EPOCH : 41 / 50
VAL_LOSS : 0.3218011549459054 
VAL_ACCURACY : 0.8359469240048251
VAL_F1 : 0.7312252959717931

EPOCH : 42 / 50
VAL_LOSS : 0.31505206513863343 
VAL_ACCURACY : 0.8395657418576599
VAL_F1 : 0.7366336628950417

EPOCH : 43 / 50
VAL_LOSS : 0.311790523907313 
VAL_ACCURACY : 0.8468033775633294
VAL_F1 : 0.7454909814903394

EPOCH : 44 / 50
VAL_LOSS : 0.3080419230346496 
VAL_ACCURACY : 0.8492159227985525
VAL_F1 : 0.7484909451996972

EPOCH : 45 / 50
VAL_LOSS : 0.30444289772556377 
VAL_ACCURACY : 0.8492159227985525
VAL_F1 : 0.7484909451996972

EPOCH : 46 / 50
VAL_LOSS : 0.2996226895887118 
VAL_ACCURACY : 0.850422195416164
VAL_F1 : 0.7499999995252747

EPOCH : 47 / 50
VAL_LOSS : 0.2940034241630481 
VAL_ACCURACY : 0.850422195416164
VAL_F1 : 0.7499999995252747

EPOCH : 48 / 50
VAL_LOSS : 0.2923054253825775 
VAL_ACCURACY : 0.8588661037394452
VAL_F1 : 0.7607361958416701

EPOCH : 49 / 50
VAL_LOSS : 0.28507623019126743 
VAL_ACCURACY : 0.8588661037394452
VAL_F1 : 0.7607361958416701

EPOCH : 50 / 50
VAL_LOSS : 0.2835137795370359 
VAL_ACCURACY : 0.8624849215922799
VAL_F1 : 0.7654320982869737

# 5話-0
# 文: 夏目漱石だよ〜 Aくんはどんな本を読むの?
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.2458, -0.1167]], device='cuda:0')
# 5話-0
# 文: そうなんだ〜
正解 : 1 , 予測 : 0 / 元クラス : 憤怒
tensor([[ 0.1285, -0.7533]], device='cuda:0')
# 5話-1
# 文: これ読んだよ
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 0.6669, -1.1194]], device='cuda:0')
# 5話-1
# 文: ありがとうございます… それ、何読んでるんですか?
正解 : 1 , 予測 : 0 / 元クラス : 恐怖
tensor([[ 0.5477, -0.6453]], device='cuda:0')
# 5話-1
# 文: 夏目漱石だよ〜 Aくんはどんな本を読むの?
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.2458, -0.1167]], device='cuda:0')
# 5話-1
# 文: そうなんだ〜
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[ 0.1285, -0.7533]], device='cuda:0')
# 5話-1
# 文: 本当に今ハマってる本はこの二冊…
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 0.2737, -0.2862]], device='cuda:0')
# 6話-0
# 文: 手作りなんですか?
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[-0.1316, -0.2671]], device='cuda:0')
# 6話-0
# 文: キャー!
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[ 0.2693, -0.8776]], device='cuda:0')
# 6話-1
# 文: キャー!
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[ 0.2693, -0.8776]], device='cuda:0')
# 6話-1
# 文: 弁当なの珍しいですね
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
tensor([[-0.1892, -0.4814]], device='cuda:0')
# 6話-1
# 文: 手作りなんですか?
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[-0.1316, -0.2671]], device='cuda:0')
# 6話-1
# 文: ありがとう…
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
tensor([[ 0.1182, -0.5854]], device='cuda:0')
# 7話-0
# 文: どれがいいですか?
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.2947,  0.0656]], device='cuda:0')
# 7話-1
# 文: チョコ一つしかないねはんぶんこしよっか
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 0.1902, -0.3238]], device='cuda:0')
# 8話-0
# 文: 今日は良い実験結果が出たな
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.2128,  0.4448]], device='cuda:0')
# 8話-0
# 文: 国際会議でスペインにいるBさんからだ
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[-0.1913, -0.4773]], device='cuda:0')
# 9話-0
# 文: Bさ…ちょっと!
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
tensor([[ 0.1246, -0.5248]], device='cuda:0')
# 9話-1
# 文: ここは よその研究室…!?
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[ 0.3164, -0.6191]], device='cuda:0')
# 9話-1
# 文: 恥ずかしい…
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
tensor([[-0.1830, -0.3705]], device='cuda:0')
------------------------test acc------------------------
Test Acc : 0.6923
correct: 45, total: 65
------------------------------------------------
                  喜楽        その他  accuracy  macro avg  weighted avg
precision   0.384615   0.897436  0.692308   0.641026      0.786982
recall      0.714286   0.686275  0.692308   0.700280      0.692308
f1-score    0.500000   0.777778  0.692308   0.638889      0.717949
support    14.000000  51.000000  0.692308  65.000000     65.000000
正例のF1値 : 0.49999999952
class weight : tensor([0.7557, 0.1616])
best:lr 1.4020992133993518e-06
EPOCH : 1 / 50
VAL_LOSS : 0.6224738921110446 
VAL_ACCURACY : 0.7744270205066345
VAL_F1 : 0.5908096275211085

EPOCH : 2 / 50
VAL_LOSS : 0.582769125699997 
VAL_ACCURACY : 0.729794933655006
VAL_F1 : 0.6028368789848662

EPOCH : 3 / 50
VAL_LOSS : 0.550168133698977 
VAL_ACCURACY : 0.7322074788902292
VAL_F1 : 0.6145833328902814

EPOCH : 4 / 50
VAL_LOSS : 0.5194225632227384 
VAL_ACCURACY : 0.744270205066345
VAL_F1 : 0.6280701749931241

EPOCH : 5 / 50
VAL_LOSS : 0.4903215788877927 
VAL_ACCURACY : 0.7659831121833535
VAL_F1 : 0.6510791362395516

EPOCH : 6 / 50
VAL_LOSS : 0.4644259919340794 
VAL_ACCURACY : 0.781664656212304
VAL_F1 : 0.6703096534622778

EPOCH : 7 / 50
VAL_LOSS : 0.43499750070847 
VAL_ACCURACY : 0.7864897466827503
VAL_F1 : 0.6775956279613405

EPOCH : 8 / 50
VAL_LOSS : 0.4161879993402041 
VAL_ACCURACY : 0.7949336550060314
VAL_F1 : 0.6863468630118804

EPOCH : 9 / 50
VAL_LOSS : 0.3917283988915957 
VAL_ACCURACY : 0.8094089264173703
VAL_F1 : 0.7018867919913065

EPOCH : 10 / 50
VAL_LOSS : 0.36984069330187946 
VAL_ACCURACY : 0.8130277442702051
VAL_F1 : 0.7058823524784664

EPOCH : 11 / 50
VAL_LOSS : 0.3516466858295294 
VAL_ACCURACY : 0.8130277442702051
VAL_F1 : 0.7047619042984201

EPOCH : 12 / 50
VAL_LOSS : 0.3332668448296877 
VAL_ACCURACY : 0.8202653799758746
VAL_F1 : 0.7117988389918029

EPOCH : 13 / 50
VAL_LOSS : 0.31482504652096677 
VAL_ACCURACY : 0.827503015681544
VAL_F1 : 0.7201565553040469

EPOCH : 14 / 50
VAL_LOSS : 0.30294181549778354 
VAL_ACCURACY : 0.8371531966224367
VAL_F1 : 0.7326732668554535

EPOCH : 15 / 50
VAL_LOSS : 0.2876142681791232 
VAL_ACCURACY : 0.8431845597104946
VAL_F1 : 0.739999999526808

EPOCH : 16 / 50
VAL_LOSS : 0.2770895026624203 
VAL_ACCURACY : 0.8576598311218335
VAL_F1 : 0.7581967208337729

EPOCH : 17 / 50
VAL_LOSS : 0.26633350493816227 
VAL_ACCURACY : 0.864897466827503
VAL_F1 : 0.7676348542918771

EPOCH : 18 / 50
VAL_LOSS : 0.24875472486019135 
VAL_ACCURACY : 0.8709288299155609
VAL_F1 : 0.7756813412373632

EPOCH : 19 / 50
VAL_LOSS : 0.24393968756955403 
VAL_ACCURACY : 0.8854041013268998
VAL_F1 : 0.7965738753177465

EPOCH : 20 / 50
VAL_LOSS : 0.22825891237992507 
VAL_ACCURACY : 0.893848009650181
VAL_F1 : 0.8086956516862855

EPOCH : 21 / 50
VAL_LOSS : 0.22073892446664664 
VAL_ACCURACY : 0.9010856453558505
VAL_F1 : 0.8193832594222962

EPOCH : 22 / 50
VAL_LOSS : 0.20923458498257858 
VAL_ACCURACY : 0.9119420989143546
VAL_F1 : 0.8352144464595896

EPOCH : 23 / 50
VAL_LOSS : 0.20389520907058165 
VAL_ACCURACY : 0.9252110977080821
VAL_F1 : 0.8558139529917037

EPOCH : 24 / 50
VAL_LOSS : 0.19585462401692683 
VAL_ACCURACY : 0.9324487334137516
VAL_F1 : 0.867924527803678

EPOCH : 25 / 50
VAL_LOSS : 0.1932434492672865 
VAL_ACCURACY : 0.9384800965018094
VAL_F1 : 0.8782816224122899

EPOCH : 26 / 50
VAL_LOSS : 0.18239908020656842 
VAL_ACCURACY : 0.9396863691194209
VAL_F1 : 0.8803827746199836

EPOCH : 27 / 50
VAL_LOSS : 0.17314563104166433 
VAL_ACCURACY : 0.9433051869722557
VAL_F1 : 0.8867469874515084

EPOCH : 28 / 50
VAL_LOSS : 0.17319078027055815 
VAL_ACCURACY : 0.9433051869722557
VAL_F1 : 0.8861985467147959

EPOCH : 29 / 50
VAL_LOSS : 0.1708535304149756 
VAL_ACCURACY : 0.9481302774427021
VAL_F1 : 0.8948655251708681

EPOCH : 30 / 50
VAL_LOSS : 0.16424367662805778 
VAL_ACCURACY : 0.9384800965018094
VAL_F1 : 0.8776978412267827

EPOCH : 31 / 50
VAL_LOSS : 0.15433678360512623 
VAL_ACCURACY : 0.9396863691194209
VAL_F1 : 0.8798076918076346

EPOCH : 32 / 50
VAL_LOSS : 0.15359847605801547 
VAL_ACCURACY : 0.9541616405307599
VAL_F1 : 0.905940593556992

EPOCH : 33 / 50
VAL_LOSS : 0.14643681278595558 
VAL_ACCURACY : 0.9493365500603136
VAL_F1 : 0.8970588230277177

EPOCH : 34 / 50
VAL_LOSS : 0.14422489810161865 
VAL_ACCURACY : 0.9589867310012062
VAL_F1 : 0.9154228850693672

EPOCH : 35 / 50
VAL_LOSS : 0.13902536407113075 
VAL_ACCURACY : 0.9565741857659831
VAL_F1 : 0.9108910886064725

EPOCH : 36 / 50
VAL_LOSS : 0.13283078981420168 
VAL_ACCURACY : 0.9613992762364294
VAL_F1 : 0.9199999994969127

EPOCH : 37 / 50
VAL_LOSS : 0.13804122934547755 
VAL_ACCURACY : 0.962605548854041
VAL_F1 : 0.9223057639077895

EPOCH : 38 / 50
VAL_LOSS : 0.13043360111231989 
VAL_ACCURACY : 0.962605548854041
VAL_F1 : 0.9223057639077895

EPOCH : 39 / 50
VAL_LOSS : 0.12612342476271665 
VAL_ACCURACY : 0.9577804583835947
VAL_F1 : 0.9131513642616604

EPOCH : 40 / 50
VAL_LOSS : 0.12257478192735177 
VAL_ACCURACY : 0.9638118214716526
VAL_F1 : 0.9246231150745058

EPOCH : 41 / 50
VAL_LOSS : 0.11820655051045693 
VAL_ACCURACY : 0.9650180940892642
VAL_F1 : 0.9273182952360853

EPOCH : 42 / 50
VAL_LOSS : 0.1202752418242968 
VAL_ACCURACY : 0.9686369119420989
VAL_F1 : 0.9343434338397486

EPOCH : 43 / 50
VAL_LOSS : 0.11299190949648619 
VAL_ACCURACY : 0.9698431845597105
VAL_F1 : 0.936708860255677

EPOCH : 44 / 50
VAL_LOSS : 0.114105253910216 
VAL_ACCURACY : 0.9698431845597105
VAL_F1 : 0.936708860255677

EPOCH : 45 / 50
VAL_LOSS : 0.11072802629608375 
VAL_ACCURACY : 0.9698431845597105
VAL_F1 : 0.9370277073049889

EPOCH : 46 / 50
VAL_LOSS : 0.10896632161277992 
VAL_ACCURACY : 0.9553679131483716
VAL_F1 : 0.9090909085889803

EPOCH : 47 / 50
VAL_LOSS : 0.10762707724307592 
VAL_ACCURACY : 0.9722557297949337
VAL_F1 : 0.9417721513948918

EPOCH : 48 / 50
VAL_LOSS : 0.10158191420711003 
VAL_ACCURACY : 0.9698431845597105
VAL_F1 : 0.9370277073049889

EPOCH : 49 / 50
VAL_LOSS : 0.09935012029913756 
VAL_ACCURACY : 0.962605548854041
VAL_F1 : 0.9230769225742663

EPOCH : 50 / 50
VAL_LOSS : 0.10009512219291467 
VAL_ACCURACY : 0.9746682750301568
VAL_F1 : 0.9465648849920945

# 5話-0
# 文: 夏目漱石だよ〜 Aくんはどんな本を読むの?
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.7579,  2.2501]], device='cuda:0')
# 5話-0
# 文: そうなんだ〜
正解 : 1 , 予測 : 0 / 元クラス : 憤怒
tensor([[ 0.1538, -0.2015]], device='cuda:0')
# 5話-1
# 文: これ読んだよ
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 1.0015, -2.0336]], device='cuda:0')
# 5話-1
# 文: ありがとうございます… それ、何読んでるんですか?
正解 : 1 , 予測 : 0 / 元クラス : 恐怖
tensor([[ 0.9026, -1.8427]], device='cuda:0')
# 5話-1
# 文: 夏目漱石だよ〜 Aくんはどんな本を読むの?
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.7579,  2.2501]], device='cuda:0')
# 5話-1
# 文: そうなんだ〜
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[ 0.1538, -0.2015]], device='cuda:0')
# 5話-1
# 文: 本当に今ハマってる本はこの二冊…
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 0.3803, -0.7984]], device='cuda:0')
# 6話-0
# 文: キャー!
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[ 0.4435, -0.6327]], device='cuda:0')
# 6話-1
# 文: キャー!
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[ 0.4435, -0.6327]], device='cuda:0')
# 6話-1
# 文: ありがとう…
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
tensor([[ 0.7211, -1.2612]], device='cuda:0')
# 7話-0
# 文: どれがいいですか?
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.8419,  1.8532]], device='cuda:0')
# 7話-0
# 文: ジャーン!パフェを作ってみました〜!
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.1363,  0.5931]], device='cuda:0')
# 7話-1
# 文: ジャーン!パフェを作ってみました〜!
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.1363,  0.5931]], device='cuda:0')
# 7話-1
# 文: チョコ一つしかないねはんぶんこしよっか
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 0.3248, -0.9129]], device='cuda:0')
# 8話-0
# 文: 今日は良い実験結果が出たな
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-1.0919,  2.1253]], device='cuda:0')
# 8話-0
# 文: 国際会議でスペインにいるBさんからだ
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[ 0.1786, -0.5955]], device='cuda:0')
# 8話-1
# 文: もう少し頑張るか
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.1151,  0.4789]], device='cuda:0')
# 9話-1
# 文: ここは よその研究室…!?
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[ 0.5766, -1.6069]], device='cuda:0')
# 9話-1
# 文: おかえりなさい!
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.8427,  1.4535]], device='cuda:0')
------------------------test acc------------------------
Test Acc : 0.7077
correct: 46, total: 65
------------------------------------------------
                  喜楽        その他  accuracy  macro avg  weighted avg
precision   0.352941   0.833333  0.707692   0.593137      0.729864
recall      0.428571   0.784314  0.707692   0.606443      0.707692
f1-score    0.387097   0.808081  0.707692   0.597589      0.717407
support    14.000000  51.000000  0.707692  65.000000     65.000000
正例のF1値 : 0.387096773673257
class weight : tensor([0.7557, 0.1616])
best:lr 3.3248757989921634e-06
EPOCH : 1 / 50
VAL_LOSS : 0.6009738135796326 
VAL_ACCURACY : 0.5886610373944512
VAL_F1 : 0.516312056343693

EPOCH : 2 / 50
VAL_LOSS : 0.5097705996953524 
VAL_ACCURACY : 0.7044632086851629
VAL_F1 : 0.6016260158324596

EPOCH : 3 / 50
VAL_LOSS : 0.44255801290273666 
VAL_ACCURACY : 0.7696019300361882
VAL_F1 : 0.659536541440336

EPOCH : 4 / 50
VAL_LOSS : 0.3781714943739084 
VAL_ACCURACY : 0.7997587454764777
VAL_F1 : 0.6891385763191167

EPOCH : 5 / 50
VAL_LOSS : 0.3320036501838611 
VAL_ACCURACY : 0.8287092882991556
VAL_F1 : 0.7215686269816455

EPOCH : 6 / 50
VAL_LOSS : 0.2939813409287196 
VAL_ACCURACY : 0.8540410132689988
VAL_F1 : 0.7525562367414992

EPOCH : 7 / 50
VAL_LOSS : 0.2618679144921211 
VAL_ACCURACY : 0.8697225572979493
VAL_F1 : 0.7731092432154245

EPOCH : 8 / 50
VAL_LOSS : 0.23249994375957891 
VAL_ACCURACY : 0.887816646562123
VAL_F1 : 0.7982646415951743

EPOCH : 9 / 50
VAL_LOSS : 0.2120627497251217 
VAL_ACCURACY : 0.9071170084439083
VAL_F1 : 0.8285077946090347

EPOCH : 10 / 50
VAL_LOSS : 0.18884583591268614 
VAL_ACCURACY : 0.9300361881785284
VAL_F1 : 0.8619047614056577

EPOCH : 11 / 50
VAL_LOSS : 0.17469061968418267 
VAL_ACCURACY : 0.9336550060313631
VAL_F1 : 0.8693586693348154

EPOCH : 12 / 50
VAL_LOSS : 0.15461139309291655 
VAL_ACCURACY : 0.9553679131483716
VAL_F1 : 0.9086419748063771

EPOCH : 13 / 50
VAL_LOSS : 0.14828297037344712 
VAL_ACCURACY : 0.9553679131483716
VAL_F1 : 0.9086419748063771

EPOCH : 14 / 50
VAL_LOSS : 0.13565241917967796 
VAL_ACCURACY : 0.9613992762364294
VAL_F1 : 0.9195979894463903

EPOCH : 15 / 50
VAL_LOSS : 0.1299833171069622 
VAL_ACCURACY : 0.9674306393244874
VAL_F1 : 0.9312977094196531

EPOCH : 16 / 50
VAL_LOSS : 0.1212851472485524 
VAL_ACCURACY : 0.9698431845597105
VAL_F1 : 0.936708860255677

EPOCH : 17 / 50
VAL_LOSS : 0.11212495248764753 
VAL_ACCURACY : 0.962605548854041
VAL_F1 : 0.9226932663299607

EPOCH : 18 / 50
VAL_LOSS : 0.10982867702841759 
VAL_ACCURACY : 0.9746682750301568
VAL_F1 : 0.9462915595980143

EPOCH : 19 / 50
VAL_LOSS : 0.09970781035148181 
VAL_ACCURACY : 0.9650180940892642
VAL_F1 : 0.9273182952360853

EPOCH : 20 / 50
VAL_LOSS : 0.09711737343325065 
VAL_ACCURACY : 0.9638118214716526
VAL_F1 : 0.9249999994968875

EPOCH : 21 / 50
VAL_LOSS : 0.09172680035520059 
VAL_ACCURACY : 0.9782870928829915
VAL_F1 : 0.9538461533417357

EPOCH : 22 / 50
VAL_LOSS : 0.08981588375396453 
VAL_ACCURACY : 0.9674306393244874
VAL_F1 : 0.9323308265643809

EPOCH : 23 / 50
VAL_LOSS : 0.08378337037104827 
VAL_ACCURACY : 0.9806996381182147
VAL_F1 : 0.9587628860933283

EPOCH : 24 / 50
VAL_LOSS : 0.0831700460268901 
VAL_ACCURACY : 0.9819059107358263
VAL_F1 : 0.9614395881844027

EPOCH : 25 / 50
VAL_LOSS : 0.0774564057445297 
VAL_ACCURACY : 0.9686369119420989
VAL_F1 : 0.9349999994968377

EPOCH : 26 / 50
VAL_LOSS : 0.07378769845056993 
VAL_ACCURACY : 0.9686369119420989
VAL_F1 : 0.9353233825817059

EPOCH : 27 / 50
VAL_LOSS : 0.07378566046603598 
VAL_ACCURACY : 0.9722557297949337
VAL_F1 : 0.9420654906802785

EPOCH : 28 / 50
VAL_LOSS : 0.07621417749816409 
VAL_ACCURACY : 0.9686369119420989
VAL_F1 : 0.9353233825817059

EPOCH : 29 / 50
VAL_LOSS : 0.06768740341067314 
VAL_ACCURACY : 0.9722557297949337
VAL_F1 : 0.9423558892209724

EPOCH : 30 / 50
VAL_LOSS : 0.07000710242069684 
VAL_ACCURACY : 0.9843184559710495
VAL_F1 : 0.9665809763591836

EPOCH : 31 / 50
VAL_LOSS : 0.06610882224944922 
VAL_ACCURACY : 0.9806996381182147
VAL_F1 : 0.9591836729651319

EPOCH : 32 / 50
VAL_LOSS : 0.061840620142622635 
VAL_ACCURACY : 0.9879372738238842
VAL_F1 : 0.9740932637438724

EPOCH : 33 / 50
VAL_LOSS : 0.062028614696688376 
VAL_ACCURACY : 0.985524728588661
VAL_F1 : 0.9690721644437906

EPOCH : 34 / 50
VAL_LOSS : 0.06310757912265566 
VAL_ACCURACY : 0.9867310012062727
VAL_F1 : 0.9715762268854303

EPOCH : 35 / 50
VAL_LOSS : 0.06141101844752064 
VAL_ACCURACY : 0.9674306393244874
VAL_F1 : 0.9330024808868721

EPOCH : 36 / 50
VAL_LOSS : 0.060409330834562965 
VAL_ACCURACY : 0.9867310012062727
VAL_F1 : 0.9715762268854303

EPOCH : 37 / 50
VAL_LOSS : 0.0594879354421909 
VAL_ACCURACY : 0.971049457177322
VAL_F1 : 0.9399999994968126

EPOCH : 38 / 50
VAL_LOSS : 0.06014758083396233 
VAL_ACCURACY : 0.9879372738238842
VAL_F1 : 0.9740932637438724

EPOCH : 39 / 50
VAL_LOSS : 0.058760818774597004 
VAL_ACCURACY : 0.9879372738238842
VAL_F1 : 0.9740932637438724

EPOCH : 40 / 50
VAL_LOSS : 0.05728824529796839 
VAL_ACCURACY : 0.9746682750301568
VAL_F1 : 0.9471032740555679

EPOCH : 41 / 50
VAL_LOSS : 0.05483658282229534 
VAL_ACCURACY : 0.9879372738238842
VAL_F1 : 0.9740932637438724

EPOCH : 42 / 50
VAL_LOSS : 0.05560051108925389 
VAL_ACCURACY : 0.9867310012062727
VAL_F1 : 0.9715762268854303

EPOCH : 43 / 50
VAL_LOSS : 0.06023867019953636 
VAL_ACCURACY : 0.9891435464414958
VAL_F1 : 0.9766233761184686

EPOCH : 44 / 50
VAL_LOSS : 0.05376546446663829 
VAL_ACCURACY : 0.9879372738238842
VAL_F1 : 0.9740932637438724

EPOCH : 45 / 50
VAL_LOSS : 0.057506597672517486 
VAL_ACCURACY : 0.9843184559710495
VAL_F1 : 0.9665809763591836

EPOCH : 46 / 50
VAL_LOSS : 0.053063978226138994 
VAL_ACCURACY : 0.9867310012062727
VAL_F1 : 0.9715762268854303

EPOCH : 47 / 50
VAL_LOSS : 0.053785572903087504 
VAL_ACCURACY : 0.9746682750301568
VAL_F1 : 0.9471032740555679

EPOCH : 48 / 50
VAL_LOSS : 0.0495304584574814 
VAL_ACCURACY : 0.9806996381182147
VAL_F1 : 0.9591836729651319

EPOCH : 49 / 50
VAL_LOSS : 0.04901244158211809 
VAL_ACCURACY : 0.9903498190591074
VAL_F1 : 0.979166666161689

EPOCH : 50 / 50
VAL_LOSS : 0.04586452652270404 
VAL_ACCURACY : 0.9903498190591074
VAL_F1 : 0.979166666161689

# 5話-0
# 文: 夏目漱石だよ〜 Aくんはどんな本を読むの?
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-2.1040,  1.7930]], device='cuda:0')
# 5話-1
# 文: これ読んだよ
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 2.0367, -2.0592]], device='cuda:0')
# 5話-1
# 文: ありがとうございます… それ、何読んでるんですか?
正解 : 1 , 予測 : 0 / 元クラス : 恐怖
tensor([[ 1.6724, -1.8691]], device='cuda:0')
# 5話-1
# 文: 夏目漱石だよ〜 Aくんはどんな本を読むの?
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-2.1040,  1.7930]], device='cuda:0')
# 6話-0
# 文: どうぞどうぞ
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.8728,  0.6148]], device='cuda:0')
# 6話-1
# 文: ありがとう…
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
tensor([[ 1.3619, -1.5689]], device='cuda:0')
# 7話-0
# 文: どれがいいですか?
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-1.9661,  1.6393]], device='cuda:0')
# 7話-1
# 文: こうやっていろんな食べ方をすれば飽きないですね
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.6864,  0.3166]], device='cuda:0')
# 7話-1
# 文: チョコ一つしかないねはんぶんこしよっか
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[-0.1724, -0.7028]], device='cuda:0')
# 8話-0
# 文: 今日は良い実験結果が出たな
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-1.8889,  1.6852]], device='cuda:0')
# 8話-0
# 文: 国際会議でスペインにいるBさんからだ
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[-0.0953, -0.1094]], device='cuda:0')
# 8話-1
# 文: もう少し頑張るか
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.6331,  0.1090]], device='cuda:0')
# 9話-1
# 文: ここは よその研究室…!?
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[ 1.7666, -1.8105]], device='cuda:0')
# 9話-1
# 文: おかえりなさい!
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-1.7299,  1.4565]], device='cuda:0')
------------------------test acc------------------------
Test Acc : 0.7846
correct: 51, total: 65
------------------------------------------------
                  喜楽        その他  accuracy  macro avg  weighted avg
precision   0.500000   0.849057  0.784615   0.674528      0.773875
recall      0.428571   0.882353  0.784615   0.655462      0.784615
f1-score    0.461538   0.865385  0.784615   0.663462      0.778402
support    14.000000  51.000000  0.784615  65.000000     65.000000
正例のF1値 : 0.46153846100591717
class weight : tensor([0.7557, 0.1616])
best:lr 3.530538937307538e-05
EPOCH : 1 / 50
VAL_LOSS : 0.20051216720961607 
VAL_ACCURACY : 0.916767189384801
VAL_F1 : 0.8399071920790695

EPOCH : 2 / 50
VAL_LOSS : 0.11766176857054234 
VAL_ACCURACY : 0.9505428226779252
VAL_F1 : 0.8982630267927517

EPOCH : 3 / 50
VAL_LOSS : 0.06904347889268628 
VAL_ACCURACY : 0.9831121833534379
VAL_F1 : 0.9637305694434078

EPOCH : 4 / 50
VAL_LOSS : 0.061444360619554154 
VAL_ACCURACY : 0.9806996381182147
VAL_F1 : 0.9589743584699146

EPOCH : 5 / 50
VAL_LOSS : 0.05868516282106821 
VAL_ACCURACY : 0.9674306393244874
VAL_F1 : 0.9330024808868721

EPOCH : 6 / 50
VAL_LOSS : 0.0589345321775629 
VAL_ACCURACY : 0.985524728588661
VAL_F1 : 0.968421052126496

EPOCH : 7 / 50
VAL_LOSS : 0.049152604375894256 
VAL_ACCURACY : 0.9722557297949337
VAL_F1 : 0.9423558892209724

EPOCH : 8 / 50
VAL_LOSS : 0.043467134291019574 
VAL_ACCURACY : 0.9867310012062727
VAL_F1 : 0.9715762268854303

EPOCH : 9 / 50
VAL_LOSS : 0.03115161468919653 
VAL_ACCURACY : 0.9927623642943305
VAL_F1 : 0.984293193212179

EPOCH : 10 / 50
VAL_LOSS : 0.03720119355532985 
VAL_ACCURACY : 0.9867310012062727
VAL_F1 : 0.9717223645339643

EPOCH : 11 / 50
VAL_LOSS : 0.03266728841341459 
VAL_ACCURACY : 0.97708082026538
VAL_F1 : 0.9521410574308574

EPOCH : 12 / 50
VAL_LOSS : 0.02567508565978362 
VAL_ACCURACY : 0.9951749095295537
VAL_F1 : 0.9895287953063925

EPOCH : 13 / 50
VAL_LOSS : 0.033578908939559296 
VAL_ACCURACY : 0.9758745476477684
VAL_F1 : 0.949748743215083

EPOCH : 14 / 50
VAL_LOSS : 0.03027288309441736 
VAL_ACCURACY : 0.9758745476477684
VAL_F1 : 0.9494949489911871

EPOCH : 15 / 50
VAL_LOSS : 0.02632117774695731 
VAL_ACCURACY : 0.9927623642943305
VAL_F1 : 0.9843749994949951

EPOCH : 16 / 50
VAL_LOSS : 0.026632472111556966 
VAL_ACCURACY : 0.9939686369119421
VAL_F1 : 0.9869451692077252

EPOCH : 17 / 50
VAL_LOSS : 0.026350737907565557 
VAL_ACCURACY : 0.9927623642943305
VAL_F1 : 0.984293193212179

EPOCH : 18 / 50
VAL_LOSS : 0.02147408635713733 
VAL_ACCURACY : 0.9951749095295537
VAL_F1 : 0.9895287953063925

EPOCH : 19 / 50
VAL_LOSS : 0.027060399897611484 
VAL_ACCURACY : 0.9782870928829915
VAL_F1 : 0.9545454540416668

EPOCH : 20 / 50
VAL_LOSS : 0.021917517583530683 
VAL_ACCURACY : 0.9939686369119421
VAL_F1 : 0.9869451692077252

EPOCH : 21 / 50
VAL_LOSS : 0.019700646749697626 
VAL_ACCURACY : 0.9927623642943305
VAL_F1 : 0.9843749994949951

EPOCH : 22 / 50
VAL_LOSS : 0.025673544759718843 
VAL_ACCURACY : 0.9782870928829915
VAL_F1 : 0.9545454540416668

EPOCH : 23 / 50
VAL_LOSS : 0.022120012812173136 
VAL_ACCURACY : 0.9927623642943305
VAL_F1 : 0.9843749994949951

EPOCH : 24 / 50
VAL_LOSS : 0.020410981853134356 
VAL_ACCURACY : 0.9806996381182147
VAL_F1 : 0.9593908624401171

EPOCH : 25 / 50
VAL_LOSS : 0.0259534354106738 
VAL_ACCURACY : 0.97708082026538
VAL_F1 : 0.9521410574308574

EPOCH : 26 / 50
VAL_LOSS : 0.01946949787760297 
VAL_ACCURACY : 0.9951749095295537
VAL_F1 : 0.9895287953063925

EPOCH : 27 / 50
VAL_LOSS : 0.019599293949655615 
VAL_ACCURACY : 0.9939686369119421
VAL_F1 : 0.9869451692077252

EPOCH : 28 / 50
VAL_LOSS : 0.02414828880976599 
VAL_ACCURACY : 0.9794933655006032
VAL_F1 : 0.9569620248125366

EPOCH : 29 / 50
VAL_LOSS : 0.024703780363779515 
VAL_ACCURACY : 0.9794933655006032
VAL_F1 : 0.9569620248125366

EPOCH : 30 / 50
VAL_LOSS : 0.023796069091006827 
VAL_ACCURACY : 0.991556091676719
VAL_F1 : 0.9818181813132467

EPOCH : 31 / 50
VAL_LOSS : 0.0252493119556815 
VAL_ACCURACY : 0.97708082026538
VAL_F1 : 0.9521410574308574

EPOCH : 32 / 50
VAL_LOSS : 0.023199217958160892 
VAL_ACCURACY : 0.9782870928829915
VAL_F1 : 0.9545454540416668

EPOCH : 33 / 50
VAL_LOSS : 0.019780685847553495 
VAL_ACCURACY : 0.9939686369119421
VAL_F1 : 0.9869451692077252

EPOCH : 34 / 50
VAL_LOSS : 0.02590325027435588 
VAL_ACCURACY : 0.991556091676719
VAL_F1 : 0.9818181813132467

EPOCH : 35 / 50
VAL_LOSS : 0.020619759662972335 
VAL_ACCURACY : 0.9794933655006032
VAL_F1 : 0.9569620248125366

EPOCH : 36 / 50
VAL_LOSS : 0.019353974140428293 
VAL_ACCURACY : 0.9939686369119421
VAL_F1 : 0.9869451692077252

EPOCH : 37 / 50
VAL_LOSS : 0.018265686562069908 
VAL_ACCURACY : 0.9951749095295537
VAL_F1 : 0.9895287953063925

EPOCH : 38 / 50
VAL_LOSS : 0.029855182461548023 
VAL_ACCURACY : 0.9782870928829915
VAL_F1 : 0.9543147203081631

EPOCH : 39 / 50
VAL_LOSS : 0.018614900011855822 
VAL_ACCURACY : 0.9939686369119421
VAL_F1 : 0.9869451692077252

EPOCH : 40 / 50
VAL_LOSS : 0.02761280799481588 
VAL_ACCURACY : 0.9794933655006032
VAL_F1 : 0.9569620248125366

EPOCH : 41 / 50
VAL_LOSS : 0.017518314371745173 
VAL_ACCURACY : 0.9951749095295537
VAL_F1 : 0.9895287953063925

EPOCH : 42 / 50
VAL_LOSS : 0.019732969132466957 
VAL_ACCURACY : 0.9939686369119421
VAL_F1 : 0.9869451692077252

EPOCH : 43 / 50
VAL_LOSS : 0.021885385880103476 
VAL_ACCURACY : 0.9782870928829915
VAL_F1 : 0.9545454540416668

EPOCH : 44 / 50
VAL_LOSS : 0.020637018131450392 
VAL_ACCURACY : 0.9794933655006032
VAL_F1 : 0.9569620248125366

EPOCH : 45 / 50
VAL_LOSS : 0.020093376125889614 
VAL_ACCURACY : 0.9794933655006032
VAL_F1 : 0.9569620248125366

EPOCH : 46 / 50
VAL_LOSS : 0.02341158620457953 
VAL_ACCURACY : 0.9927623642943305
VAL_F1 : 0.984293193212179

EPOCH : 47 / 50
VAL_LOSS : 0.02491092891432345 
VAL_ACCURACY : 0.9794933655006032
VAL_F1 : 0.9567430020403889

EPOCH : 48 / 50
VAL_LOSS : 0.022182461039987035 
VAL_ACCURACY : 0.9782870928829915
VAL_F1 : 0.9545454540416668

EPOCH : 49 / 50
VAL_LOSS : 0.020255295814982113 
VAL_ACCURACY : 0.9951749095295537
VAL_F1 : 0.9895287953063925

EPOCH : 50 / 50
VAL_LOSS : 0.021581034896931108 
VAL_ACCURACY : 0.9951749095295537
VAL_F1 : 0.9895287953063925

# 5話-0
# 文: 夏目漱石だよ〜 Aくんはどんな本を読むの?
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-1.9660,  2.7772]], device='cuda:0')
# 5話-1
# 文: これ読んだよ
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 2.1303, -2.4678]], device='cuda:0')
# 5話-1
# 文: ありがとうございます… それ、何読んでるんですか?
正解 : 1 , 予測 : 0 / 元クラス : 恐怖
tensor([[ 1.4261, -1.8328]], device='cuda:0')
# 5話-1
# 文: 夏目漱石だよ〜 Aくんはどんな本を読むの?
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-1.9660,  2.7772]], device='cuda:0')
# 6話-0
# 文: 見てもいいですか?
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[0.1714, 0.6640]], device='cuda:0')
# 6話-0
# 文: どうぞどうぞ
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-1.0643,  1.5051]], device='cuda:0')
# 6話-1
# 文: ありがとう…
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
tensor([[ 1.6099, -1.7869]], device='cuda:0')
# 7話-0
# 文: どれがいいですか?
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-1.8987,  2.7040]], device='cuda:0')
# 7話-0
# 文: ジャーン!パフェを作ってみました〜!
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-1.0961,  1.8603]], device='cuda:0')
# 7話-1
# 文: ジャーン!パフェを作ってみました〜!
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-1.0961,  1.8603]], device='cuda:0')
# 7話-1
# 文: こうやっていろんな食べ方をすれば飽きないですね
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.2594,  0.2209]], device='cuda:0')
# 8話-0
# 文: 今日は良い実験結果が出たな
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-1.0877,  1.6770]], device='cuda:0')
# 8話-0
# 文: 国際会議でスペインにいるBさんからだ
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[ 0.8026, -1.2467]], device='cuda:0')
# 9話-1
# 文: ここは よその研究室…!?
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[ 1.9974, -2.3855]], device='cuda:0')
# 9話-1
# 文: ただいま〜
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.0085,  0.7135]], device='cuda:0')
# 9話-1
# 文: おかえりなさい!
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-1.4954,  2.3253]], device='cuda:0')
------------------------test acc------------------------
Test Acc : 0.7538
correct: 49, total: 65
------------------------------------------------
                  喜楽        その他  accuracy  macro avg  weighted avg
precision   0.375000   0.807018  0.753846   0.591009      0.713968
recall      0.214286   0.901961  0.753846   0.558123      0.753846
f1-score    0.272727   0.851852  0.753846   0.562290      0.727117
support    14.000000  51.000000  0.753846  65.000000     65.000000
正例のF1値 : 0.27272727223966947
class weight : tensor([0.7557, 0.1616])
best:lr 0.00015853168269293962
EPOCH : 1 / 50
VAL_LOSS : 0.12503502797335386 
VAL_ACCURACY : 0.9215922798552473
VAL_F1 : 0.8526077092569043

EPOCH : 2 / 50
VAL_LOSS : 0.05000206009628108 
VAL_ACCURACY : 0.9867310012062727
VAL_F1 : 0.9715762268854303

EPOCH : 3 / 50
VAL_LOSS : 0.036234885543728106 
VAL_ACCURACY : 0.9903498190591074
VAL_F1 : 0.979166666161689

EPOCH : 4 / 50
VAL_LOSS : 0.041545850466578625 
VAL_ACCURACY : 0.9879372738238842
VAL_F1 : 0.9739583328283827

EPOCH : 5 / 50
VAL_LOSS : 0.03800012244699666 
VAL_ACCURACY : 0.9903498190591074
VAL_F1 : 0.979166666161689

EPOCH : 6 / 50
VAL_LOSS : 0.03871002432424575 
VAL_ACCURACY : 0.9674306393244874
VAL_F1 : 0.9333333328309464

EPOCH : 7 / 50
VAL_LOSS : 0.027286495744752195 
VAL_ACCURACY : 0.9782870928829915
VAL_F1 : 0.9545454540416668

EPOCH : 8 / 50
VAL_LOSS : 0.026390635605471637 
VAL_ACCURACY : 0.97708082026538
VAL_F1 : 0.9518987336733217

EPOCH : 9 / 50
VAL_LOSS : 0.028924685705883 
VAL_ACCURACY : 0.9891435464414958
VAL_F1 : 0.9766233761184686

EPOCH : 10 / 50
VAL_LOSS : 0.028897128900727972 
VAL_ACCURACY : 0.9867310012062727
VAL_F1 : 0.9717223645339643

EPOCH : 11 / 50
VAL_LOSS : 0.020992522056286152 
VAL_ACCURACY : 0.991556091676719
VAL_F1 : 0.9818181813132467

EPOCH : 12 / 50
VAL_LOSS : 0.022202450150731377 
VAL_ACCURACY : 0.9794933655006032
VAL_F1 : 0.9569620248125366

EPOCH : 13 / 50
VAL_LOSS : 0.022705047391355038 
VAL_ACCURACY : 0.9939686369119421
VAL_F1 : 0.9868766399147981

EPOCH : 14 / 50
VAL_LOSS : 0.031095481423947673 
VAL_ACCURACY : 0.9903498190591074
VAL_F1 : 0.979166666161689

EPOCH : 15 / 50
VAL_LOSS : 0.036921780225104436 
VAL_ACCURACY : 0.9819059107358263
VAL_F1 : 0.9616368281401352

EPOCH : 16 / 50
VAL_LOSS : 0.02242954900989739 
VAL_ACCURACY : 0.9951749095295537
VAL_F1 : 0.9895287953063925

EPOCH : 17 / 50
VAL_LOSS : 0.02539092826191336 
VAL_ACCURACY : 0.9927623642943305
VAL_F1 : 0.9842105258106233

EPOCH : 18 / 50
VAL_LOSS : 0.04543823030186244 
VAL_ACCURACY : 0.9806996381182147
VAL_F1 : 0.9591836729651319

EPOCH : 19 / 50
VAL_LOSS : 0.03462323556260134 
VAL_ACCURACY : 0.9867310012062727
VAL_F1 : 0.9717223645339643

EPOCH : 20 / 50
VAL_LOSS : 0.022436173077529438 
VAL_ACCURACY : 0.9927623642943305
VAL_F1 : 0.9843749994949951

EPOCH : 21 / 50
VAL_LOSS : 0.023294663697015494 
VAL_ACCURACY : 0.9939686369119421
VAL_F1 : 0.9869451692077252

EPOCH : 22 / 50
VAL_LOSS : 0.028068942250683904 
VAL_ACCURACY : 0.9758745476477684
VAL_F1 : 0.949748743215083

EPOCH : 23 / 50
VAL_LOSS : 0.021135386142234962 
VAL_ACCURACY : 0.9927623642943305
VAL_F1 : 0.9843749994949951

EPOCH : 24 / 50
VAL_LOSS : 0.02737942396197468 
VAL_ACCURACY : 0.9867310012062727
VAL_F1 : 0.9717223645339643

EPOCH : 25 / 50
VAL_LOSS : 0.018917958068553932 
VAL_ACCURACY : 0.9951749095295537
VAL_F1 : 0.9895287953063925

EPOCH : 26 / 50
VAL_LOSS : 0.01870579209823448 
VAL_ACCURACY : 0.9951749095295537
VAL_F1 : 0.9895287953063925

EPOCH : 27 / 50
VAL_LOSS : 0.0168378471952075 
VAL_ACCURACY : 0.9951749095295537
VAL_F1 : 0.9895287953063925

EPOCH : 28 / 50
VAL_LOSS : 0.02833256049780175 
VAL_ACCURACY : 0.9698431845597105
VAL_F1 : 0.9376558598460956

EPOCH : 29 / 50
VAL_LOSS : 0.022500047334828056 
VAL_ACCURACY : 0.991556091676719
VAL_F1 : 0.9818181813132467

EPOCH : 30 / 50
VAL_LOSS : 0.0252822926805283 
VAL_ACCURACY : 0.991556091676719
VAL_F1 : 0.98172323709287

EPOCH : 31 / 50
VAL_LOSS : 0.020108084068991817 
VAL_ACCURACY : 0.991556091676719
VAL_F1 : 0.9818181813132467

EPOCH : 32 / 50
VAL_LOSS : 0.02327712690636802 
VAL_ACCURACY : 0.9939686369119421
VAL_F1 : 0.9868766399147981

EPOCH : 33 / 50
VAL_LOSS : 0.019267672466902204 
VAL_ACCURACY : 0.9951749095295537
VAL_F1 : 0.9895287953063925

EPOCH : 34 / 50
VAL_LOSS : 0.027357707113529053 
VAL_ACCURACY : 0.9879372738238842
VAL_F1 : 0.9742268036190217

EPOCH : 35 / 50
VAL_LOSS : 0.03237931528845085 
VAL_ACCURACY : 0.985524728588661
VAL_F1 : 0.9692307687262721

EPOCH : 36 / 50
VAL_LOSS : 0.022877333197706882 
VAL_ACCURACY : 0.991556091676719
VAL_F1 : 0.9818181813132467

EPOCH : 37 / 50
VAL_LOSS : 0.023549599631223828 
VAL_ACCURACY : 0.9951749095295537
VAL_F1 : 0.9895287953063925

EPOCH : 38 / 50
VAL_LOSS : 0.019398702801061936 
VAL_ACCURACY : 0.9951749095295537
VAL_F1 : 0.9895287953063925

EPOCH : 39 / 50
VAL_LOSS : 0.01884629108155003 
VAL_ACCURACY : 0.9951749095295537
VAL_F1 : 0.9895287953063925

EPOCH : 40 / 50
VAL_LOSS : 0.019474523392720863 
VAL_ACCURACY : 0.9927623642943305
VAL_F1 : 0.9843749994949951

EPOCH : 41 / 50
VAL_LOSS : 0.023491336330502797 
VAL_ACCURACY : 0.9903498190591074
VAL_F1 : 0.9792746108941045

EPOCH : 42 / 50
VAL_LOSS : 0.02422085157237374 
VAL_ACCURACY : 0.9927623642943305
VAL_F1 : 0.984293193212179

EPOCH : 43 / 50
VAL_LOSS : 0.03829848211115369 
VAL_ACCURACY : 0.9782870928829915
VAL_F1 : 0.9543147203081631

EPOCH : 44 / 50
VAL_LOSS : 0.025640750863553528 
VAL_ACCURACY : 0.9794933655006032
VAL_F1 : 0.9569620248125366

EPOCH : 45 / 50
VAL_LOSS : 0.026412191827638216 
VAL_ACCURACY : 0.9782870928829915
VAL_F1 : 0.9545454540416668

EPOCH : 46 / 50
VAL_LOSS : 0.019362479347574454 
VAL_ACCURACY : 0.9794933655006032
VAL_F1 : 0.9569620248125366

EPOCH : 47 / 50
VAL_LOSS : 0.023616923686439313 
VAL_ACCURACY : 0.9758745476477684
VAL_F1 : 0.949748743215083

EPOCH : 48 / 50
VAL_LOSS : 0.021734450684072308 
VAL_ACCURACY : 0.9782870928829915
VAL_F1 : 0.9545454540416668

EPOCH : 49 / 50
VAL_LOSS : 0.027627308709690206 
VAL_ACCURACY : 0.985524728588661
VAL_F1 : 0.9692307687262721

EPOCH : 50 / 50
VAL_LOSS : 0.02301841904856981 
VAL_ACCURACY : 0.9758745476477684
VAL_F1 : 0.949748743215083

# 5話-0
# 文: 夏目漱石だよ〜 Aくんはどんな本を読むの?
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-2.4149,  2.4371]], device='cuda:0')
# 5話-0
# 文: Bさん、苦手そうだよな…
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
tensor([[0.8765, 0.2565]], device='cuda:0')
# 5話-1
# 文: これ読んだよ
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 2.5822, -3.0501]], device='cuda:0')
# 5話-1
# 文: ありがとうございます… それ、何読んでるんですか?
正解 : 1 , 予測 : 0 / 元クラス : 恐怖
tensor([[ 1.5042, -1.7878]], device='cuda:0')
# 5話-1
# 文: 夏目漱石だよ〜 Aくんはどんな本を読むの?
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-2.4149,  2.4371]], device='cuda:0')
# 5話-1
# 文: 本当に今ハマってる本はこの二冊…
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 2.2243, -2.5657]], device='cuda:0')
# 6話-0
# 文: どうぞどうぞ
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-2.9378,  2.8527]], device='cuda:0')
# 6話-1
# 文: ありがとう…
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
tensor([[ 2.7842, -2.9528]], device='cuda:0')
# 7話-0
# 文: どれがいいですか?
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-2.4453,  2.3270]], device='cuda:0')
# 7話-1
# 文: こうやっていろんな食べ方をすれば飽きないですね
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.7829,  0.7663]], device='cuda:0')
# 8話-0
# 文: 国際会議でスペインにいるBさんからだ
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[ 2.7089, -2.8663]], device='cuda:0')
# 8話-1
# 文: もう少し頑張るか
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.9746,  0.7320]], device='cuda:0')
# 9話-1
# 文: ここは よその研究室…!?
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[ 2.6497, -2.8719]], device='cuda:0')
# 9話-1
# 文: ただいま〜
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-1.3804,  1.3359]], device='cuda:0')
# 9話-1
# 文: おかえりなさい!
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-2.1744,  2.0245]], device='cuda:0')
------------------------test acc------------------------
Test Acc : 0.7692
correct: 50, total: 65
------------------------------------------------
                  喜楽        その他  accuracy  macro avg  weighted avg
precision   0.461538   0.846154  0.769231   0.653846      0.763314
recall      0.428571   0.862745  0.769231   0.645658      0.769231
f1-score    0.444444   0.854369  0.769231   0.649407      0.766078
support    14.000000  51.000000  0.769231  65.000000     65.000000
正例のF1値 : 0.4444444439122085
class weight : tensor([0.7557, 0.1616])
best:lr 0.00033762813524921333
EPOCH : 1 / 50
VAL_LOSS : 0.09993804333946453 
VAL_ACCURACY : 0.962605548854041
VAL_F1 : 0.9211195923713589

EPOCH : 2 / 50
VAL_LOSS : 0.06465282171176603 
VAL_ACCURACY : 0.9746682750301568
VAL_F1 : 0.9468354425341067

EPOCH : 3 / 50
VAL_LOSS : 0.08176633767568721 
VAL_ACCURACY : 0.9674306393244874
VAL_F1 : 0.9326683286740507

EPOCH : 4 / 50
VAL_LOSS : 0.03645371723597726 
VAL_ACCURACY : 0.9891435464414958
VAL_F1 : 0.9763779522508113

EPOCH : 5 / 50
VAL_LOSS : 0.04912563682032319 
VAL_ACCURACY : 0.9831121833534379
VAL_F1 : 0.9641025635980934

EPOCH : 6 / 50
VAL_LOSS : 0.0669448579607818 
VAL_ACCURACY : 0.9650180940892642
VAL_F1 : 0.9258312015418529

EPOCH : 7 / 50
VAL_LOSS : 0.04763927967108499 
VAL_ACCURACY : 0.985524728588661
VAL_F1 : 0.9685863869295388

EPOCH : 8 / 50
VAL_LOSS : 0.04709770171365772 
VAL_ACCURACY : 0.9686369119420989
VAL_F1 : 0.9356435638538747

EPOCH : 9 / 50
VAL_LOSS : 0.03459863773941134 
VAL_ACCURACY : 0.9879372738238842
VAL_F1 : 0.9739583328283827

EPOCH : 10 / 50
VAL_LOSS : 0.03614374688969782 
VAL_ACCURACY : 0.9746682750301568
VAL_F1 : 0.9471032740555679

EPOCH : 11 / 50
VAL_LOSS : 0.03845073447491114 
VAL_ACCURACY : 0.991556091676719
VAL_F1 : 0.98172323709287

EPOCH : 12 / 50
VAL_LOSS : 0.030628636649523217 
VAL_ACCURACY : 0.991556091676719
VAL_F1 : 0.9816272960828047

EPOCH : 13 / 50
VAL_LOSS : 0.0434489478625787 
VAL_ACCURACY : 0.9734620024125452
VAL_F1 : 0.9444444439407075

EPOCH : 14 / 50
VAL_LOSS : 0.03252001952988884 
VAL_ACCURACY : 0.9746682750301568
VAL_F1 : 0.9465648849920945

EPOCH : 15 / 50
VAL_LOSS : 0.03914840287045361 
VAL_ACCURACY : 0.991556091676719
VAL_F1 : 0.9816272960828047

EPOCH : 16 / 50
VAL_LOSS : 0.03388183411712257 
VAL_ACCURACY : 0.9722557297949337
VAL_F1 : 0.9420654906802785

EPOCH : 17 / 50
VAL_LOSS : 0.040264052097112514 
VAL_ACCURACY : 0.9698431845597105
VAL_F1 : 0.9376558598460956

EPOCH : 18 / 50
VAL_LOSS : 0.04737668747727115 
VAL_ACCURACY : 0.9674306393244874
VAL_F1 : 0.9333333328309464

EPOCH : 19 / 50
VAL_LOSS : 0.03467507269502116 
VAL_ACCURACY : 0.9867310012062727
VAL_F1 : 0.9715762268854303

EPOCH : 20 / 50
VAL_LOSS : 0.037188601827857874 
VAL_ACCURACY : 0.971049457177322
VAL_F1 : 0.9402985069597907

EPOCH : 21 / 50
VAL_LOSS : 0.03468469221395655 
VAL_ACCURACY : 0.9734620024125452
VAL_F1 : 0.9447236175869677

EPOCH : 22 / 50
VAL_LOSS : 0.03609656707312052 
VAL_ACCURACY : 0.9879372738238842
VAL_F1 : 0.9738219890237522

EPOCH : 23 / 50
VAL_LOSS : 0.02621339723611107 
VAL_ACCURACY : 0.991556091676719
VAL_F1 : 0.9816272960828047

EPOCH : 24 / 50
VAL_LOSS : 0.02281711950378779 
VAL_ACCURACY : 0.991556091676719
VAL_F1 : 0.9818181813132467

EPOCH : 25 / 50
VAL_LOSS : 0.021893838447375365 
VAL_ACCURACY : 0.9794933655006032
VAL_F1 : 0.9569620248125366

EPOCH : 26 / 50
VAL_LOSS : 0.019382672648554526 
VAL_ACCURACY : 0.9951749095295537
VAL_F1 : 0.9895287953063925

EPOCH : 27 / 50
VAL_LOSS : 0.029817244423051868 
VAL_ACCURACY : 0.9879372738238842
VAL_F1 : 0.9742268036190217

EPOCH : 28 / 50
VAL_LOSS : 0.0244243692767878 
VAL_ACCURACY : 0.9903498190591074
VAL_F1 : 0.9792746108941045

EPOCH : 29 / 50
VAL_LOSS : 0.019258218951738224 
VAL_ACCURACY : 0.9891435464414958
VAL_F1 : 0.9766233761184686

EPOCH : 30 / 50
VAL_LOSS : 0.027047080995264247 
VAL_ACCURACY : 0.9758745476477684
VAL_F1 : 0.949748743215083

EPOCH : 31 / 50
VAL_LOSS : 0.026187182610066466 
VAL_ACCURACY : 0.97708082026538
VAL_F1 : 0.9521410574308574

EPOCH : 32 / 50
VAL_LOSS : 0.03477935998055797 
VAL_ACCURACY : 0.9819059107358263
VAL_F1 : 0.961832060564536

EPOCH : 33 / 50
VAL_LOSS : 0.03289082134142518 
VAL_ACCURACY : 0.9746682750301568
VAL_F1 : 0.9473684205492681

EPOCH : 34 / 50
VAL_LOSS : 0.025185860648679618 
VAL_ACCURACY : 0.9794933655006032
VAL_F1 : 0.9569620248125366

EPOCH : 35 / 50
VAL_LOSS : 0.027233871613414243 
VAL_ACCURACY : 0.9782870928829915
VAL_F1 : 0.9545454540416668

EPOCH : 36 / 50
VAL_LOSS : 0.025322790853141878 
VAL_ACCURACY : 0.9927623642943305
VAL_F1 : 0.9842105258106233

EPOCH : 37 / 50
VAL_LOSS : 0.02981670555891469 
VAL_ACCURACY : 0.97708082026538
VAL_F1 : 0.9518987336733217

EPOCH : 38 / 50
VAL_LOSS : 0.026363286158392348 
VAL_ACCURACY : 0.9891435464414958
VAL_F1 : 0.9765013049780148

EPOCH : 39 / 50
VAL_LOSS : 0.025781804265884254 
VAL_ACCURACY : 0.9734620024125452
VAL_F1 : 0.9449999994967876

EPOCH : 40 / 50
VAL_LOSS : 0.02697953697329817 
VAL_ACCURACY : 0.9927623642943305
VAL_F1 : 0.984293193212179

EPOCH : 41 / 50
VAL_LOSS : 0.04083440608631533 
VAL_ACCURACY : 0.9686369119420989
VAL_F1 : 0.9356435638538747

EPOCH : 42 / 50
VAL_LOSS : 0.031000643950672105 
VAL_ACCURACY : 0.971049457177322
VAL_F1 : 0.9399999994968126

EPOCH : 43 / 50
VAL_LOSS : 0.032767370934239946 
VAL_ACCURACY : 0.9746682750301568
VAL_F1 : 0.9473684205492681

EPOCH : 44 / 50
VAL_LOSS : 0.02702575919773573 
VAL_ACCURACY : 0.9758745476477684
VAL_F1 : 0.949748743215083

EPOCH : 45 / 50
VAL_LOSS : 0.19269553323885283 
VAL_ACCURACY : 0.9155609167671894
VAL_F1 : 0.8437499995084403

EPOCH : 46 / 50
VAL_LOSS : 0.02493958874569776 
VAL_ACCURACY : 0.9927623642943305
VAL_F1 : 0.984293193212179

EPOCH : 47 / 50
VAL_LOSS : 0.023098042064632934 
VAL_ACCURACY : 0.9927623642943305
VAL_F1 : 0.984293193212179

EPOCH : 48 / 50
VAL_LOSS : 0.02907408483308525 
VAL_ACCURACY : 0.991556091676719
VAL_F1 : 0.9816272960828047

EPOCH : 49 / 50
VAL_LOSS : 0.030202297198299605 
VAL_ACCURACY : 0.991556091676719
VAL_F1 : 0.9818181813132467

EPOCH : 50 / 50
VAL_LOSS : 0.02927237235976813 
VAL_ACCURACY : 0.9891435464414958
VAL_F1 : 0.9765013049780148

# 5話-0
# 文: 夏目漱石だよ〜 Aくんはどんな本を読むの?
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-2.2266,  3.3384]], device='cuda:0')
# 5話-1
# 文: これ読んだよ
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 2.3330, -3.4276]], device='cuda:0')
# 5話-1
# 文: ありがとうございます… それ、何読んでるんですか?
正解 : 1 , 予測 : 0 / 元クラス : 恐怖
tensor([[ 1.6133, -1.7138]], device='cuda:0')
# 5話-1
# 文: 夏目漱石だよ〜 Aくんはどんな本を読むの?
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-2.2266,  3.3384]], device='cuda:0')
# 5話-1
# 文: 本当に今ハマってる本はこの二冊…
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[1.2000, 0.1868]], device='cuda:0')
# 6話-0
# 文: 見てもいいですか?
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-1.0667,  2.2248]], device='cuda:0')
# 6話-0
# 文: どうぞどうぞ
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-1.9404,  3.1479]], device='cuda:0')
# 6話-1
# 文: ありがとう…
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
tensor([[ 1.6231, -1.8973]], device='cuda:0')
# 7話-0
# 文: どれがいいですか?
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.6697,  2.2245]], device='cuda:0')
# 8話-0
# 文: 今日は良い実験結果が出たな
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.9262,  2.1562]], device='cuda:0')
# 8話-1
# 文: もう少し頑張るか
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[0.5367, 0.8031]], device='cuda:0')
# 9話-1
# 文: ここは よその研究室…!?
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[ 2.3458, -3.5022]], device='cuda:0')
# 9話-1
# 文: ただいま〜
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.1691,  1.8489]], device='cuda:0')
# 9話-1
# 文: おかえりなさい!
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-1.5674,  2.8559]], device='cuda:0')
------------------------test acc------------------------
Test Acc : 0.7846
correct: 51, total: 65
------------------------------------------------
                  喜楽        その他  accuracy  macro avg  weighted avg
precision   0.500000   0.836364  0.784615   0.668182      0.763916
recall      0.357143   0.901961  0.784615   0.629552      0.784615
f1-score    0.416667   0.867925  0.784615   0.642296      0.770731
support    14.000000  51.000000  0.784615  65.000000     65.000000
正例のF1値 : 0.4166666661458333
class weight : tensor([0.7557, 0.1616])
best:lr 3.616215366355474e-05
EPOCH : 1 / 50
VAL_LOSS : 0.19971299099807555 
VAL_ACCURACY : 0.8902291917973462
VAL_F1 : 0.8043010747828605

EPOCH : 2 / 50
VAL_LOSS : 0.09454487178188103 
VAL_ACCURACY : 0.9758745476477684
VAL_F1 : 0.9481865279927112

EPOCH : 3 / 50
VAL_LOSS : 0.07293862043521725 
VAL_ACCURACY : 0.9650180940892642
VAL_F1 : 0.9283950612260327

EPOCH : 4 / 50
VAL_LOSS : 0.06208235014659854 
VAL_ACCURACY : 0.9831121833534379
VAL_F1 : 0.9641025635980934

EPOCH : 5 / 50
VAL_LOSS : 0.057556037773163274 
VAL_ACCURACY : 0.985524728588661
VAL_F1 : 0.9685863869295388

EPOCH : 6 / 50
VAL_LOSS : 0.056142918926735334 
VAL_ACCURACY : 0.9891435464414958
VAL_F1 : 0.9765013049780148

EPOCH : 7 / 50
VAL_LOSS : 0.05307395398043669 
VAL_ACCURACY : 0.9746682750301568
VAL_F1 : 0.9468354425341067

EPOCH : 8 / 50
VAL_LOSS : 0.04520235251850234 
VAL_ACCURACY : 0.9746682750301568
VAL_F1 : 0.9471032740555679

EPOCH : 9 / 50
VAL_LOSS : 0.03756959698736095 
VAL_ACCURACY : 0.9879372738238842
VAL_F1 : 0.9740932637438724

EPOCH : 10 / 50
VAL_LOSS : 0.030280315263483387 
VAL_ACCURACY : 0.9891435464414958
VAL_F1 : 0.9766233761184686

EPOCH : 11 / 50
VAL_LOSS : 0.03519880578208428 
VAL_ACCURACY : 0.97708082026538
VAL_F1 : 0.9521410574308574

EPOCH : 12 / 50
VAL_LOSS : 0.024182380499461524 
VAL_ACCURACY : 0.9939686369119421
VAL_F1 : 0.9869451692077252

EPOCH : 13 / 50
VAL_LOSS : 0.02667425953460714 
VAL_ACCURACY : 0.9927623642943305
VAL_F1 : 0.9843749994949951

EPOCH : 14 / 50
VAL_LOSS : 0.029085614234925464 
VAL_ACCURACY : 0.9867310012062727
VAL_F1 : 0.9717223645339643

EPOCH : 15 / 50
VAL_LOSS : 0.023767796739076193 
VAL_ACCURACY : 0.9951749095295537
VAL_F1 : 0.9895287953063925

EPOCH : 16 / 50
VAL_LOSS : 0.02305478084151848 
VAL_ACCURACY : 0.9927623642943305
VAL_F1 : 0.9843749994949951

EPOCH : 17 / 50
VAL_LOSS : 0.02735293145255687 
VAL_ACCURACY : 0.97708082026538
VAL_F1 : 0.9521410574308574

EPOCH : 18 / 50
VAL_LOSS : 0.024993275166847385 
VAL_ACCURACY : 0.9939686369119421
VAL_F1 : 0.9868766399147981

EPOCH : 19 / 50
VAL_LOSS : 0.026014796583555065 
VAL_ACCURACY : 0.9782870928829915
VAL_F1 : 0.9545454540416668

EPOCH : 20 / 50
VAL_LOSS : 0.023930584671548925 
VAL_ACCURACY : 0.9939686369119421
VAL_F1 : 0.9869451692077252

EPOCH : 21 / 50
VAL_LOSS : 0.026201277433966216 
VAL_ACCURACY : 0.9927623642943305
VAL_F1 : 0.9843749994949951

EPOCH : 22 / 50
VAL_LOSS : 0.027066698409796048 
VAL_ACCURACY : 0.9782870928829915
VAL_F1 : 0.9545454540416668

EPOCH : 23 / 50
VAL_LOSS : 0.02578784738524029 
VAL_ACCURACY : 0.97708082026538
VAL_F1 : 0.9521410574308574

EPOCH : 24 / 50
VAL_LOSS : 0.02617166605957139 
VAL_ACCURACY : 0.9794933655006032
VAL_F1 : 0.9569620248125366

EPOCH : 25 / 50
VAL_LOSS : 0.028839360165875405 
VAL_ACCURACY : 0.9758745476477684
VAL_F1 : 0.949748743215083

EPOCH : 26 / 50
VAL_LOSS : 0.02669216805280974 
VAL_ACCURACY : 0.9782870928829915
VAL_F1 : 0.9545454540416668

EPOCH : 27 / 50
VAL_LOSS : 0.025329699211467344 
VAL_ACCURACY : 0.9806996381182147
VAL_F1 : 0.9593908624401171

EPOCH : 28 / 50
VAL_LOSS : 0.031441358589710526 
VAL_ACCURACY : 0.9746682750301568
VAL_F1 : 0.9473684205492681

EPOCH : 29 / 50
VAL_LOSS : 0.027591334015596658 
VAL_ACCURACY : 0.9891435464414958
VAL_F1 : 0.9763779522508113

EPOCH : 30 / 50
VAL_LOSS : 0.022942331525532957 
VAL_ACCURACY : 0.991556091676719
VAL_F1 : 0.98172323709287

EPOCH : 31 / 50
VAL_LOSS : 0.01983766105079737 
VAL_ACCURACY : 0.9939686369119421
VAL_F1 : 0.9868766399147981

EPOCH : 32 / 50
VAL_LOSS : 0.019474098360380873 
VAL_ACCURACY : 0.9951749095295537
VAL_F1 : 0.9895287953063925

EPOCH : 33 / 50
VAL_LOSS : 0.022980959526298996 
VAL_ACCURACY : 0.9939686369119421
VAL_F1 : 0.9869451692077252

EPOCH : 34 / 50
VAL_LOSS : 0.021426961300536417 
VAL_ACCURACY : 0.991556091676719
VAL_F1 : 0.9818181813132467

EPOCH : 35 / 50
VAL_LOSS : 0.017219299137090836 
VAL_ACCURACY : 0.9951749095295537
VAL_F1 : 0.9895287953063925

EPOCH : 36 / 50
VAL_LOSS : 0.020734844075587507 
VAL_ACCURACY : 0.9951749095295537
VAL_F1 : 0.9895287953063925

EPOCH : 37 / 50
VAL_LOSS : 0.019078740259059347 
VAL_ACCURACY : 0.9939686369119421
VAL_F1 : 0.9869451692077252

EPOCH : 38 / 50
VAL_LOSS : 0.017733007409753136 
VAL_ACCURACY : 0.9951749095295537
VAL_F1 : 0.9895287953063925

EPOCH : 39 / 50
VAL_LOSS : 0.022774368923049994 
VAL_ACCURACY : 0.9927623642943305
VAL_F1 : 0.984293193212179

EPOCH : 40 / 50
VAL_LOSS : 0.019510262374891542 
VAL_ACCURACY : 0.9939686369119421
VAL_F1 : 0.9868766399147981

EPOCH : 41 / 50
VAL_LOSS : 0.01845455772127025 
VAL_ACCURACY : 0.9927623642943305
VAL_F1 : 0.9843749994949951

EPOCH : 42 / 50
VAL_LOSS : 0.01710423040248525 
VAL_ACCURACY : 0.9939686369119421
VAL_F1 : 0.9869451692077252

EPOCH : 43 / 50
VAL_LOSS : 0.0197144597746396 
VAL_ACCURACY : 0.9939686369119421
VAL_F1 : 0.9869451692077252

EPOCH : 44 / 50
VAL_LOSS : 0.016827962029940233 
VAL_ACCURACY : 0.9939686369119421
VAL_F1 : 0.9868766399147981

EPOCH : 45 / 50
VAL_LOSS : 0.022981886729562227 
VAL_ACCURACY : 0.9782870928829915
VAL_F1 : 0.9545454540416668

EPOCH : 46 / 50
VAL_LOSS : 0.023044314636186194 
VAL_ACCURACY : 0.9794933655006032
VAL_F1 : 0.9569620248125366

EPOCH : 47 / 50
VAL_LOSS : 0.02272270124208612 
VAL_ACCURACY : 0.9806996381182147
VAL_F1 : 0.9593908624401171

EPOCH : 48 / 50
VAL_LOSS : 0.01969916843630087 
VAL_ACCURACY : 0.9951749095295537
VAL_F1 : 0.9895287953063925

EPOCH : 49 / 50
VAL_LOSS : 0.021992702865435813 
VAL_ACCURACY : 0.97708082026538
VAL_F1 : 0.9521410574308574

EPOCH : 50 / 50
VAL_LOSS : 0.02055270677038397 
VAL_ACCURACY : 0.9794933655006032
VAL_F1 : 0.9569620248125366

# 5話-0
# 文: 夏目漱石だよ〜 Aくんはどんな本を読むの?
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-2.2659,  2.9264]], device='cuda:0')
# 5話-0
# 文: あと、これも読んだよ
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.7285,  1.0039]], device='cuda:0')
# 5話-1
# 文: これ読んだよ
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 1.7060, -2.5139]], device='cuda:0')
# 5話-1
# 文: 夏目漱石だよ〜 Aくんはどんな本を読むの?
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-2.2659,  2.9264]], device='cuda:0')
# 6話-0
# 文: そうなんだ〜 父の分と2つ作ったの
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.1701,  0.6262]], device='cuda:0')
# 6話-0
# 文: 見てもいいですか?
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-1.2887,  1.4671]], device='cuda:0')
# 6話-0
# 文: どうぞどうぞ
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-2.0663,  2.7285]], device='cuda:0')
# 6話-1
# 文: ありがとう…
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
tensor([[ 1.7248, -2.1854]], device='cuda:0')
# 7話-0
# 文: どれがいいですか?
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-1.3231,  2.3652]], device='cuda:0')
# 7話-0
# 文: ジャーン!パフェを作ってみました〜!
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.8813,  1.2620]], device='cuda:0')
# 7話-1
# 文: ジャーン!パフェを作ってみました〜!
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.8813,  1.2620]], device='cuda:0')
# 7話-1
# 文: こうやっていろんな食べ方をすれば飽きないですね
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.8803,  1.3994]], device='cuda:0')
# 8話-0
# 文: 今日は良い実験結果が出たな
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.1997,  0.8500]], device='cuda:0')
# 8話-0
# 文: 国際会議でスペインにいるBさんからだ
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[ 1.4317, -1.9202]], device='cuda:0')
# 8話-1
# 文: もう少し頑張るか
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[0.2094, 0.2386]], device='cuda:0')
# 9話-1
# 文: ここは よその研究室…!?
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[ 1.2475, -1.2589]], device='cuda:0')
# 9話-1
# 文: ただいま〜
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.1163,  0.5206]], device='cuda:0')
# 9話-1
# 文: おかえりなさい!
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-1.6687,  2.3116]], device='cuda:0')
------------------------test acc------------------------
Test Acc : 0.7231
correct: 47, total: 65
------------------------------------------------
             喜楽        その他  accuracy  macro avg  weighted avg
precision   0.0   0.770492  0.723077   0.385246      0.604540
recall      0.0   0.921569  0.723077   0.460784      0.723077
f1-score    0.0   0.839286  0.723077   0.419643      0.658516
support    14.0  51.000000  0.723077  65.000000     65.000000
正例のF1値 : 0.0
class weight : tensor([0.7557, 0.1616])
best:lr 0.00015872285366400684
EPOCH : 1 / 50
VAL_LOSS : 0.08435518366213028 
VAL_ACCURACY : 0.971049457177322
VAL_F1 : 0.9393939388902282

EPOCH : 2 / 50
VAL_LOSS : 0.07165239488061231 
VAL_ACCURACY : 0.9698431845597105
VAL_F1 : 0.9370277073049889

EPOCH : 3 / 50
VAL_LOSS : 0.05340672685549809 
VAL_ACCURACY : 0.9843184559710495
VAL_F1 : 0.9662337657289122

EPOCH : 4 / 50
VAL_LOSS : 0.05058951324854906 
VAL_ACCURACY : 0.971049457177322
VAL_F1 : 0.9399999994968126

EPOCH : 5 / 50
VAL_LOSS : 0.055909899833540506 
VAL_ACCURACY : 0.9734620024125452
VAL_F1 : 0.9435897430853781

EPOCH : 6 / 50
VAL_LOSS : 0.04012471296860335 
VAL_ACCURACY : 0.991556091676719
VAL_F1 : 0.98172323709287

EPOCH : 7 / 50
VAL_LOSS : 0.0351028699750224 
VAL_ACCURACY : 0.9746682750301568
VAL_F1 : 0.9473684205492681

EPOCH : 8 / 50
VAL_LOSS : 0.03728782647074415 
VAL_ACCURACY : 0.9939686369119421
VAL_F1 : 0.9868766399147981

EPOCH : 9 / 50
VAL_LOSS : 0.029288712638215378 
VAL_ACCURACY : 0.9903498190591074
VAL_F1 : 0.9792746108941045

EPOCH : 10 / 50
VAL_LOSS : 0.023527998983179435 
VAL_ACCURACY : 0.9927623642943305
VAL_F1 : 0.984293193212179

EPOCH : 11 / 50
VAL_LOSS : 0.02970037021441385 
VAL_ACCURACY : 0.9891435464414958
VAL_F1 : 0.9767441855417343

EPOCH : 12 / 50
VAL_LOSS : 0.03422147413948551 
VAL_ACCURACY : 0.9746682750301568
VAL_F1 : 0.9473684205492681

EPOCH : 13 / 50
VAL_LOSS : 0.028005338341105156 
VAL_ACCURACY : 0.97708082026538
VAL_F1 : 0.9521410574308574

EPOCH : 14 / 50
VAL_LOSS : 0.030820701508603703 
VAL_ACCURACY : 0.9746682750301568
VAL_F1 : 0.9473684205492681

EPOCH : 15 / 50
VAL_LOSS : 0.03145126702013211 
VAL_ACCURACY : 0.985524728588661
VAL_F1 : 0.9690721644437906

EPOCH : 16 / 50
VAL_LOSS : 0.056166208152157754 
VAL_ACCURACY : 0.9734620024125452
VAL_F1 : 0.9447236175869677

EPOCH : 17 / 50
VAL_LOSS : 0.02839373632405813 
VAL_ACCURACY : 0.9746682750301568
VAL_F1 : 0.9473684205492681

EPOCH : 18 / 50
VAL_LOSS : 0.021077783402198784 
VAL_ACCURACY : 0.991556091676719
VAL_F1 : 0.98172323709287

EPOCH : 19 / 50
VAL_LOSS : 0.022019608720886305 
VAL_ACCURACY : 0.9939686369119421
VAL_F1 : 0.9869451692077252

EPOCH : 20 / 50
VAL_LOSS : 0.02919111983367027 
VAL_ACCURACY : 0.9927623642943305
VAL_F1 : 0.984293193212179

EPOCH : 21 / 50
VAL_LOSS : 0.02103548183087976 
VAL_ACCURACY : 0.9951749095295537
VAL_F1 : 0.9895287953063925

EPOCH : 22 / 50
VAL_LOSS : 0.029550911710919954 
VAL_ACCURACY : 0.9843184559710495
VAL_F1 : 0.9667519176541755

EPOCH : 23 / 50
VAL_LOSS : 0.02042882268478234 
VAL_ACCURACY : 0.9939686369119421
VAL_F1 : 0.9869451692077252

EPOCH : 24 / 50
VAL_LOSS : 0.026070574580584295 
VAL_ACCURACY : 0.9903498190591074
VAL_F1 : 0.9792746108941045

EPOCH : 25 / 50
VAL_LOSS : 0.02380558442718421 
VAL_ACCURACY : 0.9939686369119421
VAL_F1 : 0.9869451692077252

EPOCH : 26 / 50
VAL_LOSS : 0.02496940849456363 
VAL_ACCURACY : 0.9939686369119421
VAL_F1 : 0.9868766399147981

EPOCH : 27 / 50
VAL_LOSS : 0.024215488421479955 
VAL_ACCURACY : 0.9927623642943305
VAL_F1 : 0.984293193212179

EPOCH : 28 / 50
VAL_LOSS : 0.028370271938351486 
VAL_ACCURACY : 0.9867310012062727
VAL_F1 : 0.9717223645339643

EPOCH : 29 / 50
VAL_LOSS : 0.020126659432067893 
VAL_ACCURACY : 0.991556091676719
VAL_F1 : 0.9818181813132467

EPOCH : 30 / 50
VAL_LOSS : 0.027913266564540278 
VAL_ACCURACY : 0.9879372738238842
VAL_F1 : 0.9742268036190217

EPOCH : 31 / 50
VAL_LOSS : 0.02113267934272209 
VAL_ACCURACY : 0.9782870928829915
VAL_F1 : 0.9545454540416668

EPOCH : 32 / 50
VAL_LOSS : 0.018847404437390372 
VAL_ACCURACY : 0.9927623642943305
VAL_F1 : 0.9843749994949951

EPOCH : 33 / 50
VAL_LOSS : 0.022620459069282964 
VAL_ACCURACY : 0.991556091676719
VAL_F1 : 0.9818181813132467

EPOCH : 34 / 50
VAL_LOSS : 0.01895058788627816 
VAL_ACCURACY : 0.9951749095295537
VAL_F1 : 0.9895287953063925

EPOCH : 35 / 50
VAL_LOSS : 0.021449356604045115 
VAL_ACCURACY : 0.9951749095295537
VAL_F1 : 0.9895287953063925

EPOCH : 36 / 50
VAL_LOSS : 0.023723234507577635 
VAL_ACCURACY : 0.9927623642943305
VAL_F1 : 0.9843749994949951

EPOCH : 37 / 50
VAL_LOSS : 0.024744038371584162 
VAL_ACCURACY : 0.9879372738238842
VAL_F1 : 0.9742268036190217

EPOCH : 38 / 50
VAL_LOSS : 0.0198198334278109 
VAL_ACCURACY : 0.991556091676719
VAL_F1 : 0.9818181813132467

EPOCH : 39 / 50
VAL_LOSS : 0.024097544584387485 
VAL_ACCURACY : 0.9843184559710495
VAL_F1 : 0.9667519176541755

EPOCH : 40 / 50
VAL_LOSS : 0.02288274585421627 
VAL_ACCURACY : 0.97708082026538
VAL_F1 : 0.9521410574308574

EPOCH : 41 / 50
VAL_LOSS : 0.019853311420704883 
VAL_ACCURACY : 0.9927623642943305
VAL_F1 : 0.9843749994949951

EPOCH : 42 / 50
VAL_LOSS : 0.024613611856833674 
VAL_ACCURACY : 0.9927623642943305
VAL_F1 : 0.984293193212179

EPOCH : 43 / 50
VAL_LOSS : 0.024524763208599046 
VAL_ACCURACY : 0.9927623642943305
VAL_F1 : 0.984293193212179

EPOCH : 44 / 50
VAL_LOSS : 0.01769832402575188 
VAL_ACCURACY : 0.9951749095295537
VAL_F1 : 0.9895287953063925

EPOCH : 45 / 50
VAL_LOSS : 0.0198608484531108 
VAL_ACCURACY : 0.9927623642943305
VAL_F1 : 0.9843749994949951

EPOCH : 46 / 50
VAL_LOSS : 0.019896689766588118 
VAL_ACCURACY : 0.9939686369119421
VAL_F1 : 0.9869451692077252

EPOCH : 47 / 50
VAL_LOSS : 0.016943607152475473 
VAL_ACCURACY : 0.9939686369119421
VAL_F1 : 0.9869451692077252

EPOCH : 48 / 50
VAL_LOSS : 0.020927563016392432 
VAL_ACCURACY : 0.9939686369119421
VAL_F1 : 0.9868766399147981

EPOCH : 49 / 50
VAL_LOSS : 0.016743925019489743 
VAL_ACCURACY : 0.9939686369119421
VAL_F1 : 0.9869451692077252

EPOCH : 50 / 50
VAL_LOSS : 0.021151633080220424 
VAL_ACCURACY : 0.9939686369119421
VAL_F1 : 0.9868766399147981

# 5話-1
# 文: これ読んだよ
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 3.0595, -2.9478]], device='cuda:0')
# 5話-1
# 文: ありがとうございます… それ、何読んでるんですか?
正解 : 1 , 予測 : 0 / 元クラス : 恐怖
tensor([[ 0.5077, -1.0891]], device='cuda:0')
# 6話-0
# 文: そうなんだ〜 父の分と2つ作ったの
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.7920,  1.1532]], device='cuda:0')
# 6話-0
# 文: 見てもいいですか?
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-1.3978,  1.7235]], device='cuda:0')
# 6話-0
# 文: どうぞどうぞ
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-1.2320,  1.4333]], device='cuda:0')
# 6話-1
# 文: ありがとう…
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
tensor([[ 2.8959, -2.6651]], device='cuda:0')
# 7話-0
# 文: どれがいいですか?
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.6493,  0.4284]], device='cuda:0')
# 8話-0
# 文: 国際会議でスペインにいるBさんからだ
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[ 1.6931, -1.8373]], device='cuda:0')
# 9話-1
# 文: ここは よその研究室…!?
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[ 2.9879, -2.7921]], device='cuda:0')
# 9話-1
# 文: おかえりなさい!
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-1.1576,  1.4068]], device='cuda:0')
------------------------test acc------------------------
Test Acc : 0.8462
correct: 55, total: 65
------------------------------------------------
                  喜楽        その他  accuracy  macro avg  weighted avg
precision   0.642857   0.901961  0.846154   0.772409      0.846154
recall      0.642857   0.901961  0.846154   0.772409      0.846154
f1-score    0.642857   0.901961  0.846154   0.772409      0.846154
support    14.000000  51.000000  0.846154  65.000000     65.000000
正例のF1値 : 0.6428571423112246
class weight : tensor([0.7557, 0.1616])
best:lr 0.000351844779152935
EPOCH : 1 / 50
VAL_LOSS : 0.0807547857089398 
VAL_ACCURACY : 0.9819059107358263
VAL_F1 : 0.9602122010864217

EPOCH : 2 / 50
VAL_LOSS : 0.057299597636581615 
VAL_ACCURACY : 0.9794933655006032
VAL_F1 : 0.9565217386260949

EPOCH : 3 / 50
VAL_LOSS : 0.05963049395582997 
VAL_ACCURACY : 0.9746682750301568
VAL_F1 : 0.9460154236600605

EPOCH : 4 / 50
VAL_LOSS : 0.059685328464883454 
VAL_ACCURACY : 0.9650180940892642
VAL_F1 : 0.9265822779772473

EPOCH : 5 / 50
VAL_LOSS : 0.043006778515588776 
VAL_ACCURACY : 0.9867310012062727
VAL_F1 : 0.9714285709236905

EPOCH : 6 / 50
VAL_LOSS : 0.04423415987716558 
VAL_ACCURACY : 0.971049457177322
VAL_F1 : 0.9393939388902282

EPOCH : 7 / 50
VAL_LOSS : 0.0686856904783501 
VAL_ACCURACY : 0.9867310012062727
VAL_F1 : 0.9709762527930327

EPOCH : 8 / 50
VAL_LOSS : 0.038229524525097355 
VAL_ACCURACY : 0.991556091676719
VAL_F1 : 0.9816272960828047

EPOCH : 9 / 50
VAL_LOSS : 0.05234531797647763 
VAL_ACCURACY : 0.9674306393244874
VAL_F1 : 0.9326683286740507

EPOCH : 10 / 50
VAL_LOSS : 0.04268214952809593 
VAL_ACCURACY : 0.9867310012062727
VAL_F1 : 0.9709762527930327

EPOCH : 11 / 50
VAL_LOSS : 0.05244913896939789 
VAL_ACCURACY : 0.9831121833534379
VAL_F1 : 0.9633507848353253

EPOCH : 12 / 50
VAL_LOSS : 0.047253329754592135 
VAL_ACCURACY : 0.9831121833534379
VAL_F1 : 0.9641025635980934

EPOCH : 13 / 50
VAL_LOSS : 0.04789973412138911 
VAL_ACCURACY : 0.9734620024125452
VAL_F1 : 0.9441624360442553

EPOCH : 14 / 50
VAL_LOSS : 0.041056686385463066 
VAL_ACCURACY : 0.9891435464414958
VAL_F1 : 0.9766233761184686

EPOCH : 15 / 50
VAL_LOSS : 0.04631315294402437 
VAL_ACCURACY : 0.985524728588661
VAL_F1 : 0.9690721644437906

EPOCH : 16 / 50
VAL_LOSS : 0.054251172875340745 
VAL_ACCURACY : 0.9903498190591074
VAL_F1 : 0.9790575911179655

EPOCH : 17 / 50
VAL_LOSS : 0.04959327903074714 
VAL_ACCURACY : 0.9698431845597105
VAL_F1 : 0.9373433578926765

EPOCH : 18 / 50
VAL_LOSS : 0.030069111649376843 
VAL_ACCURACY : 0.9891435464414958
VAL_F1 : 0.9765013049780148

EPOCH : 19 / 50
VAL_LOSS : 0.032726091699889645 
VAL_ACCURACY : 0.9903498190591074
VAL_F1 : 0.9790575911179655

EPOCH : 20 / 50
VAL_LOSS : 0.032855655326364704 
VAL_ACCURACY : 0.991556091676719
VAL_F1 : 0.9816272960828047

EPOCH : 21 / 50
VAL_LOSS : 0.03537781037784253 
VAL_ACCURACY : 0.9867310012062727
VAL_F1 : 0.9715762268854303

EPOCH : 22 / 50
VAL_LOSS : 0.030925607066959716 
VAL_ACCURACY : 0.9903498190591074
VAL_F1 : 0.9790575911179655

EPOCH : 23 / 50
VAL_LOSS : 0.02823884692043066 
VAL_ACCURACY : 0.991556091676719
VAL_F1 : 0.9816272960828047

EPOCH : 24 / 50
VAL_LOSS : 0.03249445403567874 
VAL_ACCURACY : 0.9927623642943305
VAL_F1 : 0.9842105258106233

EPOCH : 25 / 50
VAL_LOSS : 0.02535553297135406 
VAL_ACCURACY : 0.991556091676719
VAL_F1 : 0.9816272960828047

EPOCH : 26 / 50
VAL_LOSS : 0.05894022515545098 
VAL_ACCURACY : 0.9469240048250904
VAL_F1 : 0.8957345966575886

EPOCH : 27 / 50
VAL_LOSS : 0.041165972415071264 
VAL_ACCURACY : 0.9758745476477684
VAL_F1 : 0.9494949489911871

EPOCH : 28 / 50
VAL_LOSS : 0.040712299197016716 
VAL_ACCURACY : 0.9794933655006032
VAL_F1 : 0.9567430020403889

EPOCH : 29 / 50
VAL_LOSS : 0.031752951707368575 
VAL_ACCURACY : 0.9879372738238842
VAL_F1 : 0.9740932637438724

EPOCH : 30 / 50
VAL_LOSS : 0.044465693922785036 
VAL_ACCURACY : 0.9831121833534379
VAL_F1 : 0.9641025635980934

EPOCH : 31 / 50
VAL_LOSS : 0.030877686123578593 
VAL_ACCURACY : 0.985524728588661
VAL_F1 : 0.9689119165936401

EPOCH : 32 / 50
VAL_LOSS : 0.032002974807535514 
VAL_ACCURACY : 0.9734620024125452
VAL_F1 : 0.9447236175869677

EPOCH : 33 / 50
VAL_LOSS : 0.030695958143601623 
VAL_ACCURACY : 0.9891435464414958
VAL_F1 : 0.9766233761184686

EPOCH : 34 / 50
VAL_LOSS : 0.034437899773295685 
VAL_ACCURACY : 0.9674306393244874
VAL_F1 : 0.9333333328309464

EPOCH : 35 / 50
VAL_LOSS : 0.023485417056900378 
VAL_ACCURACY : 0.9939686369119421
VAL_F1 : 0.9868766399147981

EPOCH : 36 / 50
VAL_LOSS : 0.028483174400977217 
VAL_ACCURACY : 0.991556091676719
VAL_F1 : 0.9816272960828047

EPOCH : 37 / 50
VAL_LOSS : 0.023498501803260297 
VAL_ACCURACY : 0.9903498190591074
VAL_F1 : 0.979166666161689

EPOCH : 38 / 50
VAL_LOSS : 0.024881674702135988 
VAL_ACCURACY : 0.9927623642943305
VAL_F1 : 0.984293193212179

EPOCH : 39 / 50
VAL_LOSS : 0.028540489478753164 
VAL_ACCURACY : 0.97708082026538
VAL_F1 : 0.9521410574308574

EPOCH : 40 / 50
VAL_LOSS : 0.021392813789694067 
VAL_ACCURACY : 0.9939686369119421
VAL_F1 : 0.9869451692077252

EPOCH : 41 / 50
VAL_LOSS : 0.022244675653592613 
VAL_ACCURACY : 0.9939686369119421
VAL_F1 : 0.9869451692077252

EPOCH : 42 / 50
VAL_LOSS : 0.04164252621838106 
VAL_ACCURACY : 0.9879372738238842
VAL_F1 : 0.9740932637438724

EPOCH : 43 / 50
VAL_LOSS : 0.03395956511107775 
VAL_ACCURACY : 0.9722557297949337
VAL_F1 : 0.9426433910181404

EPOCH : 44 / 50
VAL_LOSS : 0.030011993098574188 
VAL_ACCURACY : 0.9939686369119421
VAL_F1 : 0.9868766399147981

EPOCH : 45 / 50
VAL_LOSS : 0.029803630439206384 
VAL_ACCURACY : 0.9662243667068757
VAL_F1 : 0.9310344822564125

EPOCH : 46 / 50
VAL_LOSS : 0.038174296411363266 
VAL_ACCURACY : 0.9674306393244874
VAL_F1 : 0.9333333328309464

EPOCH : 47 / 50
VAL_LOSS : 0.03280808812884901 
VAL_ACCURACY : 0.9734620024125452
VAL_F1 : 0.9449999994967876

EPOCH : 48 / 50
VAL_LOSS : 0.022753899276722223 
VAL_ACCURACY : 0.9927623642943305
VAL_F1 : 0.984293193212179

EPOCH : 49 / 50
VAL_LOSS : 0.027725243157384775 
VAL_ACCURACY : 0.97708082026538
VAL_F1 : 0.9518987336733217

EPOCH : 50 / 50
VAL_LOSS : 0.030761612946382508 
VAL_ACCURACY : 0.971049457177322
VAL_F1 : 0.9399999994968126

# 5話-0
# 文: 夏目漱石だよ〜 Aくんはどんな本を読むの?
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-2.4394,  3.1232]], device='cuda:0')
# 5話-1
# 文: これ読んだよ
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 2.6565, -3.3319]], device='cuda:0')
# 5話-1
# 文: 夏目漱石だよ〜 Aくんはどんな本を読むの?
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-2.4394,  3.1232]], device='cuda:0')
# 6話-0
# 文: そうなんだ〜 父の分と2つ作ったの
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.4948,  0.4760]], device='cuda:0')
# 6話-0
# 文: 見てもいいですか?
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-2.4399,  3.1247]], device='cuda:0')
# 6話-0
# 文: どうぞどうぞ
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-1.5394,  1.8937]], device='cuda:0')
# 6話-1
# 文: ありがとう…
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
tensor([[ 2.6346, -3.1999]], device='cuda:0')
# 7話-0
# 文: どれがいいですか?
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-1.8713,  2.8690]], device='cuda:0')
# 7話-0
# 文: ジャーン!パフェを作ってみました〜!
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-1.3976,  2.2435]], device='cuda:0')
# 7話-1
# 文: ジャーン!パフェを作ってみました〜!
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-1.3976,  2.2435]], device='cuda:0')
# 7話-1
# 文: こうやっていろんな食べ方をすれば飽きないですね
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.5104,  0.7034]], device='cuda:0')
# 7話-1
# 文: チョコ一つしかないねはんぶんこしよっか
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 1.0203, -1.8149]], device='cuda:0')
# 8話-0
# 文: 今日は良い実験結果が出たな
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-2.4334,  3.0933]], device='cuda:0')
# 8話-1
# 文: もう少し頑張るか
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-2.1343,  2.4840]], device='cuda:0')
# 9話-1
# 文: ここは よその研究室…!?
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[ 2.5347, -3.3028]], device='cuda:0')
# 9話-1
# 文: ただいま〜
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.2550,  0.0367]], device='cuda:0')
# 9話-1
# 文: おかえりなさい!
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.2268,  0.2261]], device='cuda:0')
------------------------test acc------------------------
Test Acc : 0.7385
correct: 48, total: 65
------------------------------------------------
                  喜楽        その他  accuracy  macro avg  weighted avg
precision   0.200000   0.783333  0.738462   0.491667      0.657692
recall      0.071429   0.921569  0.738462   0.496499      0.738462
f1-score    0.105263   0.846847  0.738462   0.476055      0.687121
support    14.000000  51.000000  0.738462  65.000000     65.000000
正例のF1値 : 0.10526315749584486
