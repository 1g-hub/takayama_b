class weight : tensor([0.5648, 0.3853])
best:lr 3.8309923081325195e-07
EPOCH : 1 / 50
VAL_LOSS : 0.6909411274469816 
VAL_ACCURACY : 0.5207823960880196
VAL_F1 : 0.557562076274167

EPOCH : 2 / 50
VAL_LOSS : 0.6682925522327423 
VAL_ACCURACY : 0.5843520782396088
VAL_F1 : 0.609195401820304

EPOCH : 3 / 50
VAL_LOSS : 0.6459010484126898 
VAL_ACCURACY : 0.6430317848410758
VAL_F1 : 0.658079624811012

EPOCH : 4 / 50
VAL_LOSS : 0.6228273109747813 
VAL_ACCURACY : 0.6687041564792175
VAL_F1 : 0.6808009418023229

EPOCH : 5 / 50
VAL_LOSS : 0.6047594604583887 
VAL_ACCURACY : 0.6992665036674817
VAL_F1 : 0.7057416263090991

EPOCH : 6 / 50
VAL_LOSS : 0.5877786530898168 
VAL_ACCURACY : 0.7444987775061125
VAL_F1 : 0.7397260269063988

EPOCH : 7 / 50
VAL_LOSS : 0.5705144594495113 
VAL_ACCURACY : 0.7713936430317848
VAL_F1 : 0.7647798737216597

EPOCH : 8 / 50
VAL_LOSS : 0.5502599053657972 
VAL_ACCURACY : 0.7799511002444988
VAL_F1 : 0.7727272722346189

EPOCH : 9 / 50
VAL_LOSS : 0.5330533780730687 
VAL_ACCURACY : 0.8007334963325183
VAL_F1 : 0.7918263085736591

EPOCH : 10 / 50
VAL_LOSS : 0.5206839138498673 
VAL_ACCURACY : 0.8202933985330073
VAL_F1 : 0.8093385209050452

EPOCH : 11 / 50
VAL_LOSS : 0.5050250710203097 
VAL_ACCURACY : 0.8251833740831296
VAL_F1 : 0.8135593215376321

EPOCH : 12 / 50
VAL_LOSS : 0.4907841527691254 
VAL_ACCURACY : 0.8361858190709046
VAL_F1 : 0.8236842100291483

EPOCH : 13 / 50
VAL_LOSS : 0.47944968423018086 
VAL_ACCURACY : 0.8422982885085575
VAL_F1 : 0.8291390723499075

EPOCH : 14 / 50
VAL_LOSS : 0.4626977105553334 
VAL_ACCURACY : 0.8459657701711492
VAL_F1 : 0.8328912461864503

EPOCH : 15 / 50
VAL_LOSS : 0.4517407239629672 
VAL_ACCURACY : 0.8447432762836186
VAL_F1 : 0.8322324961999411

EPOCH : 16 / 50
VAL_LOSS : 0.4393398320445648 
VAL_ACCURACY : 0.8508557457212714
VAL_F1 : 0.8381962859742347

EPOCH : 17 / 50
VAL_LOSS : 0.4256062822846266 
VAL_ACCURACY : 0.8520782396088019
VAL_F1 : 0.8393094284528323

EPOCH : 18 / 50
VAL_LOSS : 0.4192868213240917 
VAL_ACCURACY : 0.8557457212713936
VAL_F1 : 0.8422459888062214

EPOCH : 19 / 50
VAL_LOSS : 0.41057784339556325 
VAL_ACCURACY : 0.8594132029339854
VAL_F1 : 0.8464619487671928

EPOCH : 20 / 50
VAL_LOSS : 0.396723509981082 
VAL_ACCURACY : 0.8618581907090465
VAL_F1 : 0.8487282458198918

EPOCH : 21 / 50
VAL_LOSS : 0.38843097537755966 
VAL_ACCURACY : 0.8643031784841075
VAL_F1 : 0.8510067109104635

EPOCH : 22 / 50
VAL_LOSS : 0.37849859492136884 
VAL_ACCURACY : 0.8704156479217604
VAL_F1 : 0.8579088466861402

EPOCH : 23 / 50
VAL_LOSS : 0.369403755149016 
VAL_ACCURACY : 0.8740831295843521
VAL_F1 : 0.8613728124214264

EPOCH : 24 / 50
VAL_LOSS : 0.3661111742258072 
VAL_ACCURACY : 0.8765281173594132
VAL_F1 : 0.864064602461796

EPOCH : 25 / 50
VAL_LOSS : 0.3513862550831758 
VAL_ACCURACY : 0.8777506112469438
VAL_F1 : 0.8652291100128523

EPOCH : 26 / 50
VAL_LOSS : 0.35153772968512315 
VAL_ACCURACY : 0.8801955990220048
VAL_F1 : 0.8679245278026025

EPOCH : 27 / 50
VAL_LOSS : 0.3372145661940941 
VAL_ACCURACY : 0.882640586797066
VAL_F1 : 0.8706199455923526

EPOCH : 28 / 50
VAL_LOSS : 0.3321812522525971 
VAL_ACCURACY : 0.8850855745721271
VAL_F1 : 0.872628725787575

EPOCH : 29 / 50
VAL_LOSS : 0.32613640565138596 
VAL_ACCURACY : 0.8924205378973105
VAL_F1 : 0.8797814202647736

EPOCH : 30 / 50
VAL_LOSS : 0.31968192154398334 
VAL_ACCURACY : 0.8960880195599022
VAL_F1 : 0.8834019199384392

EPOCH : 31 / 50
VAL_LOSS : 0.3188577222709472 
VAL_ACCURACY : 0.8973105134474327
VAL_F1 : 0.8849315063488761

EPOCH : 32 / 50
VAL_LOSS : 0.31027178580944353 
VAL_ACCURACY : 0.8985330073349633
VAL_F1 : 0.8861454041633973

EPOCH : 33 / 50
VAL_LOSS : 0.3022372920352679 
VAL_ACCURACY : 0.9009779951100244
VAL_F1 : 0.8885832182063198

EPOCH : 34 / 50
VAL_LOSS : 0.3059761297817414 
VAL_ACCURACY : 0.9009779951100244
VAL_F1 : 0.8885832182063198

EPOCH : 35 / 50
VAL_LOSS : 0.29224978244075406 
VAL_ACCURACY : 0.902200488997555
VAL_F1 : 0.8895027619300084

EPOCH : 36 / 50
VAL_LOSS : 0.28992461097928196 
VAL_ACCURACY : 0.9046454767726161
VAL_F1 : 0.8919667585016843

EPOCH : 37 / 50
VAL_LOSS : 0.28461647463532597 
VAL_ACCURACY : 0.9083129584352079
VAL_F1 : 0.8959778080979993

EPOCH : 38 / 50
VAL_LOSS : 0.27621057414664674 
VAL_ACCURACY : 0.9083129584352079
VAL_F1 : 0.8956884556878449

EPOCH : 39 / 50
VAL_LOSS : 0.2757470657905707 
VAL_ACCURACY : 0.9095354523227384
VAL_F1 : 0.89722222172098

EPOCH : 40 / 50
VAL_LOSS : 0.28247160063340115 
VAL_ACCURACY : 0.9095354523227384
VAL_F1 : 0.89722222172098

EPOCH : 41 / 50
VAL_LOSS : 0.2637279002139202 
VAL_ACCURACY : 0.9095354523227384
VAL_F1 : 0.89722222172098

EPOCH : 42 / 50
VAL_LOSS : 0.2610167187566941 
VAL_ACCURACY : 0.9095354523227384
VAL_F1 : 0.89722222172098

EPOCH : 43 / 50
VAL_LOSS : 0.25885956533826315 
VAL_ACCURACY : 0.910757946210269
VAL_F1 : 0.8984700968561266

EPOCH : 44 / 50
VAL_LOSS : 0.2551239665884238 
VAL_ACCURACY : 0.91320293398533
VAL_F1 : 0.900976289596175

EPOCH : 45 / 50
VAL_LOSS : 0.25171746514164484 
VAL_ACCURACY : 0.91320293398533
VAL_F1 : 0.9012517380244082

EPOCH : 46 / 50
VAL_LOSS : 0.24877955606923655 
VAL_ACCURACY : 0.9144254278728606
VAL_F1 : 0.9022346363699869

EPOCH : 47 / 50
VAL_LOSS : 0.24168490905028123 
VAL_ACCURACY : 0.9144254278728606
VAL_F1 : 0.9022346363699869

EPOCH : 48 / 50
VAL_LOSS : 0.23910881034456766 
VAL_ACCURACY : 0.91320293398533
VAL_F1 : 0.9006993001977212

EPOCH : 49 / 50
VAL_LOSS : 0.23363949172198772 
VAL_ACCURACY : 0.9144254278728606
VAL_F1 : 0.9019607838120817

EPOCH : 50 / 50
VAL_LOSS : 0.2298324083766112 
VAL_ACCURACY : 0.9168704156479217
VAL_F1 : 0.9044943815207046

# 5話-0
# 文: 今ハマってる本はこの二冊…
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.0489,  0.1361]], device='cuda:0')
# 5話-0
# 文: Bさん、苦手そうだよな…
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
tensor([[ 0.7363, -0.6738]], device='cuda:0')
# 5話-0
# 文: そうなんだ〜
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 0.4534, -0.5116]], device='cuda:0')
# 5話-0
# 文: あと、これも読んだよ
正解 : 1 , 予測 : 0 / 元クラス : 憤怒
tensor([[ 0.6749, -1.0753]], device='cuda:0')
# 5話-1
# 文: これ読んだよ
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 0.6201, -0.9615]], device='cuda:0')
# 6話-0
# 文: ほとんど冷凍食品詰めただけだよ
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.2514,  0.8746]], device='cuda:0')
# 6話-0
# 文: 見てもいいですか?
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.2273,  0.7802]], device='cuda:0')
# 6話-0
# 文: キャー!
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[ 0.6685, -0.0826]], device='cuda:0')
# 6話-1
# 文: キャー!
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[ 0.6685, -0.0826]], device='cuda:0')
# 6話-1
# 文: ええ…父の分と2つ作ったんだけど
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
tensor([[0.2435, 0.1728]], device='cuda:0')
# 6話-1
# 文: 俺も今日弁当なんでおかず分けますよ
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.6230,  0.4940]], device='cuda:0')
# 7話-0
# 文: チョコは一つしかないし悪いよ〜
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[ 0.2152, -0.2751]], device='cuda:0')
# 7話-0
# 文: ジャーン!パフェを作ってみました〜!
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[0.1515, 0.1579]], device='cuda:0')
# 7話-1
# 文: ジャーン!パフェを作ってみました〜!
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[0.1515, 0.1579]], device='cuda:0')
# 7話-1
# 文: こうやっていろんな食べ方をすれば飽きないですね
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.4348,  0.5652]], device='cuda:0')
# 7話-1
# 文: とか言い出すのかと思った…
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.3059,  0.6126]], device='cuda:0')
# 7話-1
# 文: Aくんがいなければ独り占めできたのにな…
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
tensor([[ 0.3152, -0.1735]], device='cuda:0')
# 8話-0
# 文: 今日は良い実験結果が出たな
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.2475,  0.6157]], device='cuda:0')
# 8話-1
# 文: でもわざわざ国際会議から送ってくれたんだよな…
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.0161,  0.0501]], device='cuda:0')
# 8話-1
# 文: もう少し頑張るか
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.0118,  0.0668]], device='cuda:0')
# 9話-0
# 文: あれ?スペインからもう戻ってきたのか.
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.0098,  0.5216]], device='cuda:0')
# 9話-0
# 文: Bさん…あれ?
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
tensor([[0.3532, 0.0946]], device='cuda:0')
# 9話-0
# 文: Bさ…ちょっと!
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
tensor([[ 0.5644, -0.1204]], device='cuda:0')
# 9話-1
# 文: ここは よその研究室…!?
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[ 0.5724, -0.1560]], device='cuda:0')
# 9話-1
# 文: ただいま〜
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.8279,  0.9205]], device='cuda:0')
------------------------test acc------------------------
Test Acc : 0.6094
correct: 39, total: 64
------------------------------------------------
                  喜楽        その他  accuracy  macro avg  weighted avg
precision   0.428571   0.697674  0.609375   0.563123      0.605170
recall      0.409091   0.714286  0.609375   0.561688      0.609375
f1-score    0.418605   0.705882  0.609375   0.562244      0.607131
support    22.000000  42.000000  0.609375  64.000000     64.000000
正例のF1値 : 0.41860465064359115
class weight : tensor([0.5648, 0.3853])
best:lr 1.5939974942385405e-06
EPOCH : 1 / 50
VAL_LOSS : 0.5873759973507661 
VAL_ACCURACY : 0.793398533007335
VAL_F1 : 0.7602836874415493

EPOCH : 2 / 50
VAL_LOSS : 0.51417214767291 
VAL_ACCURACY : 0.8288508557457213
VAL_F1 : 0.8102981024815108

EPOCH : 3 / 50
VAL_LOSS : 0.46036083709735137 
VAL_ACCURACY : 0.8667481662591687
VAL_F1 : 0.8512960431561191

EPOCH : 4 / 50
VAL_LOSS : 0.41000426847201127 
VAL_ACCURACY : 0.882640586797066
VAL_F1 : 0.8692098087642569

EPOCH : 5 / 50
VAL_LOSS : 0.3777693561636485 
VAL_ACCURACY : 0.8850855745721271
VAL_F1 : 0.8719346044045766

EPOCH : 6 / 50
VAL_LOSS : 0.3449301470357638 
VAL_ACCURACY : 0.8997555012224939
VAL_F1 : 0.887362636862026

EPOCH : 7 / 50
VAL_LOSS : 0.32018379064706654 
VAL_ACCURACY : 0.9046454767726161
VAL_F1 : 0.8922651928692273

EPOCH : 8 / 50
VAL_LOSS : 0.2923599301049343 
VAL_ACCURACY : 0.9070904645476773
VAL_F1 : 0.8947368416041698

EPOCH : 9 / 50
VAL_LOSS : 0.2723800087204346 
VAL_ACCURACY : 0.9144254278728606
VAL_F1 : 0.9014084502023567

EPOCH : 10 / 50
VAL_LOSS : 0.25404493209834283 
VAL_ACCURACY : 0.9144254278728606
VAL_F1 : 0.900849857854874

EPOCH : 11 / 50
VAL_LOSS : 0.24262360913249162 
VAL_ACCURACY : 0.9180929095354523
VAL_F1 : 0.9038737441173794

EPOCH : 12 / 50
VAL_LOSS : 0.22393754325233972 
VAL_ACCURACY : 0.9242053789731052
VAL_F1 : 0.9106628237049722

EPOCH : 13 / 50
VAL_LOSS : 0.2149824922761092 
VAL_ACCURACY : 0.9278728606356969
VAL_F1 : 0.9146164973266371

EPOCH : 14 / 50
VAL_LOSS : 0.20982160705786485 
VAL_ACCURACY : 0.9290953545232273
VAL_F1 : 0.9159420284828903

EPOCH : 15 / 50
VAL_LOSS : 0.18977693969813678 
VAL_ACCURACY : 0.9364303178484108
VAL_F1 : 0.924637680656778

EPOCH : 16 / 50
VAL_LOSS : 0.17974284678124464 
VAL_ACCURACY : 0.9449877750611247
VAL_F1 : 0.9343065688403389

EPOCH : 17 / 50
VAL_LOSS : 0.17223759110157305 
VAL_ACCURACY : 0.9437652811735942
VAL_F1 : 0.9329446059112786

EPOCH : 18 / 50
VAL_LOSS : 0.16248677864384192 
VAL_ACCURACY : 0.9486552567237164
VAL_F1 : 0.938775509701349

EPOCH : 19 / 50
VAL_LOSS : 0.15992718662780064 
VAL_ACCURACY : 0.9511002444987775
VAL_F1 : 0.9415204673335045

EPOCH : 20 / 50
VAL_LOSS : 0.14851028020851886 
VAL_ACCURACY : 0.9559902200488998
VAL_F1 : 0.9472140757435609

EPOCH : 21 / 50
VAL_LOSS : 0.14633032464637205 
VAL_ACCURACY : 0.9572127139364304
VAL_F1 : 0.94860499215508

EPOCH : 22 / 50
VAL_LOSS : 0.13655174595232195 
VAL_ACCURACY : 0.9596577017114915
VAL_F1 : 0.9515418497174795

EPOCH : 23 / 50
VAL_LOSS : 0.1307378357562881 
VAL_ACCURACY : 0.9633251833740831
VAL_F1 : 0.9557522118866003

EPOCH : 24 / 50
VAL_LOSS : 0.13059811301242846 
VAL_ACCURACY : 0.9633251833740831
VAL_F1 : 0.9557522118866003

EPOCH : 25 / 50
VAL_LOSS : 0.12134264405960074 
VAL_ACCURACY : 0.9682151589242054
VAL_F1 : 0.961538461035687

EPOCH : 26 / 50
VAL_LOSS : 0.11813701094629672 
VAL_ACCURACY : 0.9669926650366748
VAL_F1 : 0.9599999994972445

EPOCH : 27 / 50
VAL_LOSS : 0.11387095235001582 
VAL_ACCURACY : 0.969437652811736
VAL_F1 : 0.9630723776360562

EPOCH : 28 / 50
VAL_LOSS : 0.11009680325738512 
VAL_ACCURACY : 0.9706601466992665
VAL_F1 : 0.9646017694086982

EPOCH : 29 / 50
VAL_LOSS : 0.10623375448183371 
VAL_ACCURACY : 0.9718826405867971
VAL_F1 : 0.9661266563454877

EPOCH : 30 / 50
VAL_LOSS : 0.105443185625168 
VAL_ACCURACY : 0.9718826405867971
VAL_F1 : 0.9660265873849397

EPOCH : 31 / 50
VAL_LOSS : 0.10499071544752671 
VAL_ACCURACY : 0.9743276283618582
VAL_F1 : 0.9690721644456264

EPOCH : 32 / 50
VAL_LOSS : 0.09882734866382983 
VAL_ACCURACY : 0.9743276283618582
VAL_F1 : 0.9690721644456264

EPOCH : 33 / 50
VAL_LOSS : 0.09763679585347955 
VAL_ACCURACY : 0.9743276283618582
VAL_F1 : 0.9690721644456264

EPOCH : 34 / 50
VAL_LOSS : 0.09302936641212839 
VAL_ACCURACY : 0.9743276283618582
VAL_F1 : 0.9690721644456264

EPOCH : 35 / 50
VAL_LOSS : 0.0898364819586277 
VAL_ACCURACY : 0.9743276283618582
VAL_F1 : 0.9689807971338231

EPOCH : 36 / 50
VAL_LOSS : 0.09917645360558079 
VAL_ACCURACY : 0.9743276283618582
VAL_F1 : 0.9689807971338231

EPOCH : 37 / 50
VAL_LOSS : 0.09321993997750375 
VAL_ACCURACY : 0.9755501222493888
VAL_F1 : 0.97050147442343

EPOCH : 38 / 50
VAL_LOSS : 0.08549072321217793 
VAL_ACCURACY : 0.9755501222493888
VAL_F1 : 0.97050147442343

EPOCH : 39 / 50
VAL_LOSS : 0.08577152198323837 
VAL_ACCURACY : 0.9767726161369193
VAL_F1 : 0.9719350068827065

EPOCH : 40 / 50
VAL_LOSS : 0.08125461165148479 
VAL_ACCURACY : 0.9767726161369193
VAL_F1 : 0.972017672545765

EPOCH : 41 / 50
VAL_LOSS : 0.07756910054013133 
VAL_ACCURACY : 0.9755501222493888
VAL_F1 : 0.97050147442343

EPOCH : 42 / 50
VAL_LOSS : 0.08531423898127216 
VAL_ACCURACY : 0.9767726161369193
VAL_F1 : 0.9719350068827065

EPOCH : 43 / 50
VAL_LOSS : 0.0753485940110225 
VAL_ACCURACY : 0.9767726161369193
VAL_F1 : 0.972017672545765

EPOCH : 44 / 50
VAL_LOSS : 0.07294214699560633 
VAL_ACCURACY : 0.9767726161369193
VAL_F1 : 0.972017672545765

EPOCH : 45 / 50
VAL_LOSS : 0.07225378355584465 
VAL_ACCURACY : 0.9767726161369193
VAL_F1 : 0.9719350068827065

EPOCH : 46 / 50
VAL_LOSS : 0.07752525301363605 
VAL_ACCURACY : 0.980440097799511
VAL_F1 : 0.9765395889399557

EPOCH : 47 / 50
VAL_LOSS : 0.06934675889519545 
VAL_ACCURACY : 0.9779951100244498
VAL_F1 : 0.973451326930796

EPOCH : 48 / 50
VAL_LOSS : 0.06695204475321449 
VAL_ACCURACY : 0.980440097799511
VAL_F1 : 0.9765395889399557

EPOCH : 49 / 50
VAL_LOSS : 0.06878995375994307 
VAL_ACCURACY : 0.9792176039119804
VAL_F1 : 0.9750367102166763

EPOCH : 50 / 50
VAL_LOSS : 0.0653984142252459 
VAL_ACCURACY : 0.9779951100244498
VAL_F1 : 0.97352941126186

# 5話-0
# 文: 今ハマってる本はこの二冊…
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-1.2608,  1.3533]], device='cuda:0')
# 5話-0
# 文: Bさん、苦手そうだよな…
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
tensor([[ 0.7350, -1.8701]], device='cuda:0')
# 5話-0
# 文: あと、これも読んだよ
正解 : 1 , 予測 : 0 / 元クラス : 憤怒
tensor([[ 0.0472, -1.0866]], device='cuda:0')
# 5話-1
# 文: これ読んだよ
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 1.1430, -2.4796]], device='cuda:0')
# 5話-1
# 文: そうなんだ〜
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.7954,  0.6867]], device='cuda:0')
# 6話-0
# 文: ほとんど冷凍食品詰めただけだよ
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-1.4676,  2.1101]], device='cuda:0')
# 6話-0
# 文: 見てもいいですか?
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.9586,  0.4840]], device='cuda:0')
# 6話-1
# 文: 俺も今日弁当なんでおかず分けますよ
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-1.3517,  1.3528]], device='cuda:0')
# 7話-0
# 文: どれがいいですか?
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[-0.0285, -0.5403]], device='cuda:0')
# 7話-0
# 文: ジャーン!パフェを作ってみました〜!
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.3814, -0.2797]], device='cuda:0')
# 7話-1
# 文: ジャーン!パフェを作ってみました〜!
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.3814, -0.2797]], device='cuda:0')
# 7話-1
# 文: こうやっていろんな食べ方をすれば飽きないですね
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.9871,  0.6719]], device='cuda:0')
# 7話-1
# 文: とか言い出すのかと思った…
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.6931,  0.7648]], device='cuda:0')
# 7話-1
# 文: Aくんがいなければ独り占めできたのにな…
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
tensor([[ 0.7395, -1.4507]], device='cuda:0')
# 8話-0
# 文: 今日は良い実験結果が出たな
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-1.0441,  1.3550]], device='cuda:0')
# 8話-1
# 文: でもわざわざ国際会議から送ってくれたんだよな…
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.1906,  0.0721]], device='cuda:0')
# 9話-0
# 文: あれ?スペインからもう戻ってきたのか.
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.1095,  0.0737]], device='cuda:0')
# 9話-0
# 文: Bさん…あれ?
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
tensor([[-0.1423, -0.4212]], device='cuda:0')
# 9話-0
# 文: Bさ…ちょっと!
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
tensor([[ 1.0542, -1.9503]], device='cuda:0')
# 9話-1
# 文: ここは よその研究室…!?
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[ 0.6250, -1.3900]], device='cuda:0')
# 9話-1
# 文: ただいま〜
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-1.4052,  1.9422]], device='cuda:0')
------------------------test acc------------------------
Test Acc : 0.6719
correct: 43, total: 64
------------------------------------------------
                  喜楽        その他  accuracy  macro avg  weighted avg
precision   0.529412   0.723404  0.671875   0.626408      0.656719
recall      0.409091   0.809524  0.671875   0.609307      0.671875
f1-score    0.461538   0.764045  0.671875   0.612792      0.660058
support    22.000000  42.000000  0.671875  64.000000     64.000000
正例のF1値 : 0.4615384610230111
class weight : tensor([0.5648, 0.3853])
best:lr 3.28531198860853e-06
EPOCH : 1 / 50
VAL_LOSS : 0.5227308422327042 
VAL_ACCURACY : 0.8092909535452323
VAL_F1 : 0.7739130429760556

EPOCH : 2 / 50
VAL_LOSS : 0.40932351981218046 
VAL_ACCURACY : 0.8679706601466992
VAL_F1 : 0.8470254952487942

EPOCH : 3 / 50
VAL_LOSS : 0.3365471815833679 
VAL_ACCURACY : 0.8789731051344744
VAL_F1 : 0.8634482753612861

EPOCH : 4 / 50
VAL_LOSS : 0.2894212594972207 
VAL_ACCURACY : 0.8948655256723717
VAL_F1 : 0.8808864260917427

EPOCH : 5 / 50
VAL_LOSS : 0.24795379761893016 
VAL_ACCURACY : 0.9070904645476773
VAL_F1 : 0.8953168039069205

EPOCH : 6 / 50
VAL_LOSS : 0.21762277372181416 
VAL_ACCURACY : 0.9193154034229829
VAL_F1 : 0.9067796605149622

EPOCH : 7 / 50
VAL_LOSS : 0.19018634480352586 
VAL_ACCURACY : 0.9290953545232273
VAL_F1 : 0.917142856640498

EPOCH : 8 / 50
VAL_LOSS : 0.17104898844487393 
VAL_ACCURACY : 0.9364303178484108
VAL_F1 : 0.9248554908268736

EPOCH : 9 / 50
VAL_LOSS : 0.16054744710429356 
VAL_ACCURACY : 0.9474327628361858
VAL_F1 : 0.9372262768695273

EPOCH : 10 / 50
VAL_LOSS : 0.14416199571524674 
VAL_ACCURACY : 0.9596577017114915
VAL_F1 : 0.9512555386405224

EPOCH : 11 / 50
VAL_LOSS : 0.13764106324658945 
VAL_ACCURACY : 0.9645476772616137
VAL_F1 : 0.9571639581382894

EPOCH : 12 / 50
VAL_LOSS : 0.11695387597697285 
VAL_ACCURACY : 0.9657701711491442
VAL_F1 : 0.9582089547212387

EPOCH : 13 / 50
VAL_LOSS : 0.10890878217581373 
VAL_ACCURACY : 0.9706601466992665
VAL_F1 : 0.9646017694086982

EPOCH : 14 / 50
VAL_LOSS : 0.09917482740890521 
VAL_ACCURACY : 0.9743276283618582
VAL_F1 : 0.9690721644456264

EPOCH : 15 / 50
VAL_LOSS : 0.09267883719160007 
VAL_ACCURACY : 0.9755501222493888
VAL_F1 : 0.970414200680631

EPOCH : 16 / 50
VAL_LOSS : 0.0868522785962201 
VAL_ACCURACY : 0.9743276283618582
VAL_F1 : 0.9691629950918772

EPOCH : 17 / 50
VAL_LOSS : 0.08343954891181336 
VAL_ACCURACY : 0.9779951100244498
VAL_F1 : 0.97352941126186

EPOCH : 18 / 50
VAL_LOSS : 0.07888860311000966 
VAL_ACCURACY : 0.9792176039119804
VAL_F1 : 0.9749631806459036

EPOCH : 19 / 50
VAL_LOSS : 0.07531134807504714 
VAL_ACCURACY : 0.9792176039119804
VAL_F1 : 0.9751098091603961

EPOCH : 20 / 50
VAL_LOSS : 0.07240020474777199 
VAL_ACCURACY : 0.980440097799511
VAL_F1 : 0.9765395889399557

EPOCH : 21 / 50
VAL_LOSS : 0.0712846232793079 
VAL_ACCURACY : 0.9816625916870416
VAL_F1 : 0.9780380668470638

EPOCH : 22 / 50
VAL_LOSS : 0.06840678363536987 
VAL_ACCURACY : 0.9828850855745721
VAL_F1 : 0.9794721402595953

EPOCH : 23 / 50
VAL_LOSS : 0.063317038745691 
VAL_ACCURACY : 0.9828850855745721
VAL_F1 : 0.9794117642030191

EPOCH : 24 / 50
VAL_LOSS : 0.06208114084214545 
VAL_ACCURACY : 0.9841075794621027
VAL_F1 : 0.9809104253414754

EPOCH : 25 / 50
VAL_LOSS : 0.059786507895646185 
VAL_ACCURACY : 0.9841075794621027
VAL_F1 : 0.9809104253414754

EPOCH : 26 / 50
VAL_LOSS : 0.06857245787978172 
VAL_ACCURACY : 0.9841075794621027
VAL_F1 : 0.9809104253414754

EPOCH : 27 / 50
VAL_LOSS : 0.05527425663044246 
VAL_ACCURACY : 0.9841075794621027
VAL_F1 : 0.9809104253414754

EPOCH : 28 / 50
VAL_LOSS : 0.0581343280724608 
VAL_ACCURACY : 0.9841075794621027
VAL_F1 : 0.9809104253414754

EPOCH : 29 / 50
VAL_LOSS : 0.0494753667511619 
VAL_ACCURACY : 0.9841075794621027
VAL_F1 : 0.9809104253414754

EPOCH : 30 / 50
VAL_LOSS : 0.04933206360930434 
VAL_ACCURACY : 0.9841075794621027
VAL_F1 : 0.9809104253414754

EPOCH : 31 / 50
VAL_LOSS : 0.047965616220608354 
VAL_ACCURACY : 0.9853300733496333
VAL_F1 : 0.9824046915792349

EPOCH : 32 / 50
VAL_LOSS : 0.04600870383616824 
VAL_ACCURACY : 0.9853300733496333
VAL_F1 : 0.9824046915792349

EPOCH : 33 / 50
VAL_LOSS : 0.04631780021680662 
VAL_ACCURACY : 0.9853300733496333
VAL_F1 : 0.9824046915792349

EPOCH : 34 / 50
VAL_LOSS : 0.0452486659364345 
VAL_ACCURACY : 0.9853300733496333
VAL_F1 : 0.9824046915792349

EPOCH : 35 / 50
VAL_LOSS : 0.04296531571218601 
VAL_ACCURACY : 0.9865525672371638
VAL_F1 : 0.9838472829038751

EPOCH : 36 / 50
VAL_LOSS : 0.04085895352853605 
VAL_ACCURACY : 0.9877750611246944
VAL_F1 : 0.9853372428988744

EPOCH : 37 / 50
VAL_LOSS : 0.04116952455101105 
VAL_ACCURACY : 0.9877750611246944
VAL_F1 : 0.9853372428988744

EPOCH : 38 / 50
VAL_LOSS : 0.040180293341668755 
VAL_ACCURACY : 0.9877750611246944
VAL_F1 : 0.9853372428988744

EPOCH : 39 / 50
VAL_LOSS : 0.038423509104177356 
VAL_ACCURACY : 0.9877750611246944
VAL_F1 : 0.9853372428988744

EPOCH : 40 / 50
VAL_LOSS : 0.03714537095779983 
VAL_ACCURACY : 0.9877750611246944
VAL_F1 : 0.9853372428988744

EPOCH : 41 / 50
VAL_LOSS : 0.03626633882343482 
VAL_ACCURACY : 0.9877750611246944
VAL_F1 : 0.9853372428988744

EPOCH : 42 / 50
VAL_LOSS : 0.03889399798264584 
VAL_ACCURACY : 0.9877750611246944
VAL_F1 : 0.9853372428988744

EPOCH : 43 / 50
VAL_LOSS : 0.039875999809457705 
VAL_ACCURACY : 0.988997555012225
VAL_F1 : 0.9867841404662747

EPOCH : 44 / 50
VAL_LOSS : 0.036610833199049994 
VAL_ACCURACY : 0.988997555012225
VAL_F1 : 0.9867841404662747

EPOCH : 45 / 50
VAL_LOSS : 0.03445713775447355 
VAL_ACCURACY : 0.988997555012225
VAL_F1 : 0.9867841404662747

EPOCH : 46 / 50
VAL_LOSS : 0.032012211078276426 
VAL_ACCURACY : 0.988997555012225
VAL_F1 : 0.9867841404662747

EPOCH : 47 / 50
VAL_LOSS : 0.03188578730735641 
VAL_ACCURACY : 0.9926650366748166
VAL_F1 : 0.9912280696725404

EPOCH : 48 / 50
VAL_LOSS : 0.03260223663304574 
VAL_ACCURACY : 0.9902200488997555
VAL_F1 : 0.9882352936147579

EPOCH : 49 / 50
VAL_LOSS : 0.03284663546722955 
VAL_ACCURACY : 0.988997555012225
VAL_F1 : 0.9867841404662747

EPOCH : 50 / 50
VAL_LOSS : 0.03250489763628978 
VAL_ACCURACY : 0.9902200488997555
VAL_F1 : 0.9882697942185138

# 5話-0
# 文: 今ハマってる本はこの二冊…
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-1.6652,  2.0576]], device='cuda:0')
# 5話-0
# 文: Bさん、苦手そうだよな…
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
tensor([[ 1.4750, -1.7286]], device='cuda:0')
# 5話-0
# 文: 適当に流したな
正解 : 1 , 予測 : 0 / 元クラス : 憤怒
tensor([[ 0.0321, -0.0008]], device='cuda:0')
# 5話-1
# 文: これ読んだよ
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 2.2728, -2.4692]], device='cuda:0')
# 5話-1
# 文: そうなんだ〜
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-1.3128,  1.3361]], device='cuda:0')
# 6話-0
# 文: ほとんど冷凍食品詰めただけだよ
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-1.9622,  2.4518]], device='cuda:0')
# 6話-0
# 文: 見てもいいですか?
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-1.0854,  1.6545]], device='cuda:0')
# 6話-0
# 文: どうぞどうぞ
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.0531,  0.2232]], device='cuda:0')
# 6話-1
# 文: 俺も今日弁当なんでおかず分けますよ
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-1.8392,  2.0014]], device='cuda:0')
# 7話-0
# 文: どれがいいですか?
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 1.0349, -0.7914]], device='cuda:0')
# 7話-0
# 文: じゃあチョコですね
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 1.1260, -0.8862]], device='cuda:0')
# 7話-0
# 文: チョコは一つしかないし悪いよ〜
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[ 0.4590, -0.2148]], device='cuda:0')
# 7話-1
# 文: こうやっていろんな食べ方をすれば飽きないですね
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-1.4076,  1.7220]], device='cuda:0')
# 7話-1
# 文: とか言い出すのかと思った…
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.1058,  0.6811]], device='cuda:0')
# 8話-0
# 文: 今日は良い実験結果が出たな
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.9976,  0.9243]], device='cuda:0')
# 9話-0
# 文: Bさん…あれ?
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
tensor([[ 1.4752, -1.2724]], device='cuda:0')
# 9話-0
# 文: Bさ…ちょっと!
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
tensor([[ 1.1512, -1.2277]], device='cuda:0')
# 9話-1
# 文: ここは よその研究室…!?
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[ 1.8112, -2.2559]], device='cuda:0')
# 9話-1
# 文: ただいま〜
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-2.0673,  2.3340]], device='cuda:0')
# 9話-1
# 文: おかえりなさい!
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.6634,  0.3550]], device='cuda:0')
------------------------test acc------------------------
Test Acc : 0.6875
correct: 44, total: 64
------------------------------------------------
                 喜楽        その他  accuracy  macro avg  weighted avg
precision   0.55000   0.750000    0.6875   0.650000      0.681250
recall      0.50000   0.785714    0.6875   0.642857      0.687500
f1-score    0.52381   0.767442    0.6875   0.645626      0.683693
support    22.00000  42.000000    0.6875  64.000000     64.000000
正例のF1値 : 0.5238095232857143
class weight : tensor([0.5648, 0.3853])
best:lr 3.7781275056873494e-05
EPOCH : 1 / 50
VAL_LOSS : 0.15377887338399887 
VAL_ACCURACY : 0.9572127139364304
VAL_F1 : 0.949201741151843

EPOCH : 2 / 50
VAL_LOSS : 0.08290518093137787 
VAL_ACCURACY : 0.9816625916870416
VAL_F1 : 0.9779735677790758

EPOCH : 3 / 50
VAL_LOSS : 0.06879528604734403 
VAL_ACCURACY : 0.9828850855745721
VAL_F1 : 0.9798850569685972

EPOCH : 4 / 50
VAL_LOSS : 0.050136678476029865 
VAL_ACCURACY : 0.9865525672371638
VAL_F1 : 0.9837997049463193

EPOCH : 5 / 50
VAL_LOSS : 0.0480662881790732 
VAL_ACCURACY : 0.988997555012225
VAL_F1 : 0.9868228399070674

EPOCH : 6 / 50
VAL_LOSS : 0.0367518958922189 
VAL_ACCURACY : 0.9877750611246944
VAL_F1 : 0.9854227400219125

EPOCH : 7 / 50
VAL_LOSS : 0.030807383000277556 
VAL_ACCURACY : 0.9926650366748166
VAL_F1 : 0.9912280696725404

EPOCH : 8 / 50
VAL_LOSS : 0.02748034385820994 
VAL_ACCURACY : 0.9938875305623472
VAL_F1 : 0.9926793552804033

EPOCH : 9 / 50
VAL_LOSS : 0.03140534500842197 
VAL_ACCURACY : 0.9926650366748166
VAL_F1 : 0.9912280696725404

EPOCH : 10 / 50
VAL_LOSS : 0.03617666074289726 
VAL_ACCURACY : 0.9926650366748166
VAL_F1 : 0.9912280696725404

EPOCH : 11 / 50
VAL_LOSS : 0.02519905724777625 
VAL_ACCURACY : 0.9926650366748166
VAL_F1 : 0.9912280696725404

EPOCH : 12 / 50
VAL_LOSS : 0.026518941552449878 
VAL_ACCURACY : 0.9938875305623472
VAL_F1 : 0.99270072942411

EPOCH : 13 / 50
VAL_LOSS : 0.02349450325485892 
VAL_ACCURACY : 0.991442542787286
VAL_F1 : 0.9897810213949215

EPOCH : 14 / 50
VAL_LOSS : 0.018120535886667382 
VAL_ACCURACY : 0.9951100244498777
VAL_F1 : 0.9941690957070183

EPOCH : 15 / 50
VAL_LOSS : 0.021508691151841328 
VAL_ACCURACY : 0.9926650366748166
VAL_F1 : 0.9912280696725404

EPOCH : 16 / 50
VAL_LOSS : 0.019955306430347264 
VAL_ACCURACY : 0.9951100244498777
VAL_F1 : 0.9941690957070183

EPOCH : 17 / 50
VAL_LOSS : 0.01956472037664543 
VAL_ACCURACY : 0.9938875305623472
VAL_F1 : 0.99270072942411

EPOCH : 18 / 50
VAL_LOSS : 0.015149142302107066 
VAL_ACCURACY : 0.9975550122249389
VAL_F1 : 0.9970760228888975

EPOCH : 19 / 50
VAL_LOSS : 0.01973143112487518 
VAL_ACCURACY : 0.9926650366748166
VAL_F1 : 0.9912536438119831

EPOCH : 20 / 50
VAL_LOSS : 0.013551483315845521 
VAL_ACCURACY : 0.9987775061124694
VAL_F1 : 0.9985358706537388

EPOCH : 21 / 50
VAL_LOSS : 0.015577897111562869 
VAL_ACCURACY : 0.9951100244498777
VAL_F1 : 0.9941176465559171

EPOCH : 22 / 50
VAL_LOSS : 0.012537520557928544 
VAL_ACCURACY : 0.9975550122249389
VAL_F1 : 0.9970760228888975

EPOCH : 23 / 50
VAL_LOSS : 0.019658762298954222 
VAL_ACCURACY : 0.9951100244498777
VAL_F1 : 0.9941348968577929

EPOCH : 24 / 50
VAL_LOSS : 0.0178817983967467 
VAL_ACCURACY : 0.9963325183374083
VAL_F1 : 0.9955947131534735

EPOCH : 25 / 50
VAL_LOSS : 0.024223029488124527 
VAL_ACCURACY : 0.9963325183374083
VAL_F1 : 0.9955947131534735

EPOCH : 26 / 50
VAL_LOSS : 0.02168277117352073 
VAL_ACCURACY : 0.9951100244498777
VAL_F1 : 0.9941348968577929

EPOCH : 27 / 50
VAL_LOSS : 0.021215100983121935 
VAL_ACCURACY : 0.9951100244498777
VAL_F1 : 0.9941348968577929

EPOCH : 28 / 50
VAL_LOSS : 0.035093408613017976 
VAL_ACCURACY : 0.9938875305623472
VAL_F1 : 0.9926578555910739

EPOCH : 29 / 50
VAL_LOSS : 0.02338683622880266 
VAL_ACCURACY : 0.9926650366748166
VAL_F1 : 0.9911764700853374

EPOCH : 30 / 50
VAL_LOSS : 0.014307842263056396 
VAL_ACCURACY : 0.9963325183374083
VAL_F1 : 0.9956076129670711

EPOCH : 31 / 50
VAL_LOSS : 0.01471623826252583 
VAL_ACCURACY : 0.9951100244498777
VAL_F1 : 0.9941348968577929

EPOCH : 32 / 50
VAL_LOSS : 0.01180316216330259 
VAL_ACCURACY : 0.9963325183374083
VAL_F1 : 0.9955947131534735

EPOCH : 33 / 50
VAL_LOSS : 0.01732414631316295 
VAL_ACCURACY : 0.9963325183374083
VAL_F1 : 0.9955947131534735

EPOCH : 34 / 50
VAL_LOSS : 0.04321648078845241 
VAL_ACCURACY : 0.9938875305623472
VAL_F1 : 0.9926578555910739

EPOCH : 35 / 50
VAL_LOSS : 0.009843226188632589 
VAL_ACCURACY : 0.9975550122249389
VAL_F1 : 0.9970674481774323

EPOCH : 36 / 50
VAL_LOSS : 0.011260268916465485 
VAL_ACCURACY : 0.9975550122249389
VAL_F1 : 0.9970760228888975

EPOCH : 37 / 50
VAL_LOSS : 0.010214077080420863 
VAL_ACCURACY : 0.9951100244498777
VAL_F1 : 0.9941690957070183

EPOCH : 38 / 50
VAL_LOSS : 0.013824537532995097 
VAL_ACCURACY : 0.9963325183374083
VAL_F1 : 0.9955947131534735

EPOCH : 39 / 50
VAL_LOSS : 0.008784913482556406 
VAL_ACCURACY : 0.9987775061124694
VAL_F1 : 0.9985358706537388

EPOCH : 40 / 50
VAL_LOSS : 0.007433814997337042 
VAL_ACCURACY : 0.9987775061124694
VAL_F1 : 0.9985358706537388

EPOCH : 41 / 50
VAL_LOSS : 0.014396127519341042 
VAL_ACCURACY : 0.9963325183374083
VAL_F1 : 0.9955947131534735

EPOCH : 42 / 50
VAL_LOSS : 0.008734185763527282 
VAL_ACCURACY : 0.9975550122249389
VAL_F1 : 0.9970674481774323

EPOCH : 43 / 50
VAL_LOSS : 0.008102862945704076 
VAL_ACCURACY : 0.9987775061124694
VAL_F1 : 0.9985358706537388

EPOCH : 44 / 50
VAL_LOSS : 0.015574095497588413 
VAL_ACCURACY : 0.9938875305623472
VAL_F1 : 0.9927219791186626

EPOCH : 45 / 50
VAL_LOSS : 0.008760073799819041 
VAL_ACCURACY : 0.9975550122249389
VAL_F1 : 0.9970760228888975

EPOCH : 46 / 50
VAL_LOSS : 0.010869892242436226 
VAL_ACCURACY : 0.9963325183374083
VAL_F1 : 0.9955947131534735

EPOCH : 47 / 50
VAL_LOSS : 0.009794146760563867 
VAL_ACCURACY : 0.9975550122249389
VAL_F1 : 0.9970674481774323

EPOCH : 48 / 50
VAL_LOSS : 0.0074642251442688014 
VAL_ACCURACY : 0.9975550122249389
VAL_F1 : 0.9970674481774323

EPOCH : 49 / 50
VAL_LOSS : 0.0068637240687027 
VAL_ACCURACY : 0.9987775061124694
VAL_F1 : 0.9985358706537388

EPOCH : 50 / 50
VAL_LOSS : 0.009210917008413862 
VAL_ACCURACY : 0.9975550122249389
VAL_F1 : 0.9970760228888975

# 5話-0
# 文: 今ハマってる本はこの二冊…
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-3.1568,  2.8460]], device='cuda:0')
# 5話-0
# 文: Bさん、苦手そうだよな…
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
tensor([[ 0.9123, -0.6227]], device='cuda:0')
# 5話-0
# 文: 適当に流そう
正解 : 1 , 予測 : 0 / 元クラス : 嫌悪
tensor([[ 0.0447, -0.2384]], device='cuda:0')
# 5話-0
# 文: 適当に流したな
正解 : 1 , 予測 : 0 / 元クラス : 憤怒
tensor([[ 2.2869, -1.7376]], device='cuda:0')
# 5話-1
# 文: これ読んだよ
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 2.8699, -2.3811]], device='cuda:0')
# 5話-1
# 文: そうなんだ〜
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-3.1212,  2.7744]], device='cuda:0')
# 5話-1
# 文: 本当に今ハマってる本はこの二冊…
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-2.8640,  2.5745]], device='cuda:0')
# 6話-0
# 文: そうなんだ〜 父の分と2つ作ったの
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.3325,  0.2059]], device='cuda:0')
# 6話-0
# 文: ほとんど冷凍食品詰めただけだよ
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-3.0950,  2.7918]], device='cuda:0')
# 6話-0
# 文: 見てもいいですか?
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.0224,  0.6882]], device='cuda:0')
# 6話-0
# 文: どうぞどうぞ
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-1.9364,  1.8527]], device='cuda:0')
# 6話-1
# 文: 俺も今日弁当なんでおかず分けますよ
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-2.9555,  2.6697]], device='cuda:0')
# 7話-0
# 文: どれがいいですか?
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 1.1479, -0.7817]], device='cuda:0')
# 7話-0
# 文: じゃあチョコですね
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 0.7151, -0.0363]], device='cuda:0')
# 7話-0
# 文: チョコは一つしかないし悪いよ〜
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[ 0.3268, -0.8891]], device='cuda:0')
# 7話-0
# 文: ジャーン!パフェを作ってみました〜!
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-1.6307,  0.8373]], device='cuda:0')
# 7話-1
# 文: ジャーン!パフェを作ってみました〜!
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-1.6307,  0.8373]], device='cuda:0')
# 7話-1
# 文: こうやっていろんな食べ方をすれば飽きないですね
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-1.3571,  1.1576]], device='cuda:0')
# 7話-1
# 文: とか言い出すのかと思った…
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[0.1545, 0.7982]], device='cuda:0')
# 8話-0
# 文: 今日は良い実験結果が出たな
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.1980,  0.1189]], device='cuda:0')
# 9話-0
# 文: あれ?スペインからもう戻ってきたのか.
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-2.9455,  2.5121]], device='cuda:0')
# 9話-0
# 文: Bさん…あれ?
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
tensor([[ 2.0992, -1.2891]], device='cuda:0')
# 9話-0
# 文: Bさ…ちょっと!
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
tensor([[ 2.7369, -2.4086]], device='cuda:0')
# 9話-1
# 文: ここは よその研究室…!?
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[ 2.6472, -2.3658]], device='cuda:0')
# 9話-1
# 文: ただいま〜
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-3.0062,  2.7081]], device='cuda:0')
# 9話-1
# 文: おかえりなさい!
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-2.6483,  2.0425]], device='cuda:0')
------------------------test acc------------------------
Test Acc : 0.5938
correct: 38, total: 64
------------------------------------------------
                  喜楽        その他  accuracy  macro avg  weighted avg
precision   0.375000   0.666667   0.59375   0.520833      0.566406
recall      0.272727   0.761905   0.59375   0.517316      0.593750
f1-score    0.315789   0.711111   0.59375   0.513450      0.575219
support    22.000000  42.000000   0.59375  64.000000     64.000000
正例のF1値 : 0.3157894731800554
class weight : tensor([0.5648, 0.3853])
best:lr 0.00015625583532278466
EPOCH : 1 / 50
VAL_LOSS : 0.07749322350495137 
VAL_ACCURACY : 0.980440097799511
VAL_F1 : 0.976331360443927

EPOCH : 2 / 50
VAL_LOSS : 0.07399625791451679 
VAL_ACCURACY : 0.9779951100244498
VAL_F1 : 0.9731343278555225

EPOCH : 3 / 50
VAL_LOSS : 0.035481172488429226 
VAL_ACCURACY : 0.9951100244498777
VAL_F1 : 0.9941176465559171

EPOCH : 4 / 50
VAL_LOSS : 0.04590091421806182 
VAL_ACCURACY : 0.9877750611246944
VAL_F1 : 0.9852071000888711

EPOCH : 5 / 50
VAL_LOSS : 0.03590474601906653 
VAL_ACCURACY : 0.9902200488997555
VAL_F1 : 0.9882352936147579

EPOCH : 6 / 50
VAL_LOSS : 0.04050986215364761 
VAL_ACCURACY : 0.9877750611246944
VAL_F1 : 0.9853372428988744

EPOCH : 7 / 50
VAL_LOSS : 0.03162948232448588 
VAL_ACCURACY : 0.988997555012225
VAL_F1 : 0.9867452130464579

EPOCH : 8 / 50
VAL_LOSS : 0.028330227109388664 
VAL_ACCURACY : 0.991442542787286
VAL_F1 : 0.9897209980286744

EPOCH : 9 / 50
VAL_LOSS : 0.02297911547178116 
VAL_ACCURACY : 0.9951100244498777
VAL_F1 : 0.9941176465559171

EPOCH : 10 / 50
VAL_LOSS : 0.048313514629486375 
VAL_ACCURACY : 0.9816625916870416
VAL_F1 : 0.9776453050114318

EPOCH : 11 / 50
VAL_LOSS : 0.013309551143230727 
VAL_ACCURACY : 0.9963325183374083
VAL_F1 : 0.9956204374532985

EPOCH : 12 / 50
VAL_LOSS : 0.016155341366986528 
VAL_ACCURACY : 0.9963325183374083
VAL_F1 : 0.9956076129670711

EPOCH : 13 / 50
VAL_LOSS : 0.030737805081746325 
VAL_ACCURACY : 0.9902200488997555
VAL_F1 : 0.9881656799705194

EPOCH : 14 / 50
VAL_LOSS : 0.02477853569927482 
VAL_ACCURACY : 0.9938875305623472
VAL_F1 : 0.9926793552804033

EPOCH : 15 / 50
VAL_LOSS : 0.01944669847188589 
VAL_ACCURACY : 0.9938875305623472
VAL_F1 : 0.9926793552804033

EPOCH : 16 / 50
VAL_LOSS : 0.014998895371368585 
VAL_ACCURACY : 0.9963325183374083
VAL_F1 : 0.9955947131534735

EPOCH : 17 / 50
VAL_LOSS : 0.021645648357941985 
VAL_ACCURACY : 0.9951100244498777
VAL_F1 : 0.9941348968577929

EPOCH : 18 / 50
VAL_LOSS : 0.02508646891398642 
VAL_ACCURACY : 0.9938875305623472
VAL_F1 : 0.9926578555910739

EPOCH : 19 / 50
VAL_LOSS : 0.034770219488284335 
VAL_ACCURACY : 0.9902200488997555
VAL_F1 : 0.9882352936147579

EPOCH : 20 / 50
VAL_LOSS : 0.02483797382312612 
VAL_ACCURACY : 0.991442542787286
VAL_F1 : 0.9897810213949215

EPOCH : 21 / 50
VAL_LOSS : 0.036271433731039554 
VAL_ACCURACY : 0.991442542787286
VAL_F1 : 0.9897209980286744

EPOCH : 22 / 50
VAL_LOSS : 0.03574673246699744 
VAL_ACCURACY : 0.988997555012225
VAL_F1 : 0.9868228399070674

EPOCH : 23 / 50
VAL_LOSS : 0.020653960124876063 
VAL_ACCURACY : 0.9938875305623472
VAL_F1 : 0.9926793552804033

EPOCH : 24 / 50
VAL_LOSS : 0.021839339760705255 
VAL_ACCURACY : 0.9938875305623472
VAL_F1 : 0.9926578555910739

EPOCH : 25 / 50
VAL_LOSS : 0.0299027355974361 
VAL_ACCURACY : 0.9975550122249389
VAL_F1 : 0.9970760228888975

EPOCH : 26 / 50
VAL_LOSS : 0.013811581031544708 
VAL_ACCURACY : 0.9963325183374083
VAL_F1 : 0.9956204374532985

EPOCH : 27 / 50
VAL_LOSS : 0.016510518131186612 
VAL_ACCURACY : 0.9938875305623472
VAL_F1 : 0.9926793552804033

EPOCH : 28 / 50
VAL_LOSS : 0.014523687114258511 
VAL_ACCURACY : 0.9963325183374083
VAL_F1 : 0.9955947131534735

EPOCH : 29 / 50
VAL_LOSS : 0.03517297311694934 
VAL_ACCURACY : 0.991442542787286
VAL_F1 : 0.9896602653760073

EPOCH : 30 / 50
VAL_LOSS : 0.02184405116041979 
VAL_ACCURACY : 0.9951100244498777
VAL_F1 : 0.9941176465559171

EPOCH : 31 / 50
VAL_LOSS : 0.019425093565727226 
VAL_ACCURACY : 0.9926650366748166
VAL_F1 : 0.9912280696725404

EPOCH : 32 / 50
VAL_LOSS : 0.013895677375750473 
VAL_ACCURACY : 0.9951100244498777
VAL_F1 : 0.994152046280719

EPOCH : 33 / 50
VAL_LOSS : 0.019241836038418114 
VAL_ACCURACY : 0.9951100244498777
VAL_F1 : 0.9941348968577929

EPOCH : 34 / 50
VAL_LOSS : 0.017491444347587485 
VAL_ACCURACY : 0.9951100244498777
VAL_F1 : 0.9941348968577929

EPOCH : 35 / 50
VAL_LOSS : 0.03273470132486322 
VAL_ACCURACY : 0.9938875305623472
VAL_F1 : 0.9926578555910739

EPOCH : 36 / 50
VAL_LOSS : 0.020453346105149157 
VAL_ACCURACY : 0.9963325183374083
VAL_F1 : 0.9955947131534735

EPOCH : 37 / 50
VAL_LOSS : 0.021161838860000268 
VAL_ACCURACY : 0.9951100244498777
VAL_F1 : 0.9941348968577929

EPOCH : 38 / 50
VAL_LOSS : 0.018228678160364956 
VAL_ACCURACY : 0.9963325183374083
VAL_F1 : 0.9956076129670711

EPOCH : 39 / 50
VAL_LOSS : 0.03220000920835166 
VAL_ACCURACY : 0.9951100244498777
VAL_F1 : 0.9941176465559171

EPOCH : 40 / 50
VAL_LOSS : 0.04128356499131769 
VAL_ACCURACY : 0.9938875305623472
VAL_F1 : 0.9926362292467352

EPOCH : 41 / 50
VAL_LOSS : 0.03702649096018062 
VAL_ACCURACY : 0.991442542787286
VAL_F1 : 0.9896907211465965

EPOCH : 42 / 50
VAL_LOSS : 0.03348997633796758 
VAL_ACCURACY : 0.9926650366748166
VAL_F1 : 0.9911504419749915

EPOCH : 43 / 50
VAL_LOSS : 0.021772849467547182 
VAL_ACCURACY : 0.991442542787286
VAL_F1 : 0.9897209980286744

EPOCH : 44 / 50
VAL_LOSS : 0.022411892768174697 
VAL_ACCURACY : 0.9951100244498777
VAL_F1 : 0.9941176465559171

EPOCH : 45 / 50
VAL_LOSS : 0.022776877796366952 
VAL_ACCURACY : 0.9963325183374083
VAL_F1 : 0.9955947131534735

EPOCH : 46 / 50
VAL_LOSS : 0.04382604828480488 
VAL_ACCURACY : 0.9902200488997555
VAL_F1 : 0.9881656799705194

EPOCH : 47 / 50
VAL_LOSS : 0.05904930146285691 
VAL_ACCURACY : 0.9902200488997555
VAL_F1 : 0.9882005894676257

EPOCH : 48 / 50
VAL_LOSS : 0.036936128919478506 
VAL_ACCURACY : 0.988997555012225
VAL_F1 : 0.9867452130464579

EPOCH : 49 / 50
VAL_LOSS : 0.03852411247163008 
VAL_ACCURACY : 0.991442542787286
VAL_F1 : 0.9897209980286744

EPOCH : 50 / 50
VAL_LOSS : 0.030442350344786134 
VAL_ACCURACY : 0.9938875305623472
VAL_F1 : 0.9926793552804033

# 5話-0
# 文: 今ハマってる本はこの二冊…
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-3.1108,  2.8328]], device='cuda:0')
# 5話-0
# 文: 少々マニアックだろうか…
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
tensor([[ 0.2066, -0.5895]], device='cuda:0')
# 5話-0
# 文: Bさん、苦手そうだよな…
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
tensor([[ 1.9499, -2.4113]], device='cuda:0')
# 5話-1
# 文: これ読んだよ
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 2.9879, -3.3828]], device='cuda:0')
# 5話-1
# 文: ありがとうございます …それ、何読んでるんですか?
正解 : 1 , 予測 : 0 / 元クラス : 恐怖
tensor([[ 1.4690, -1.8117]], device='cuda:0')
# 5話-1
# 文: そうなんだ〜
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-2.7593,  2.9109]], device='cuda:0')
# 6話-0
# 文: ほとんど冷凍食品詰めただけだよ
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-2.9461,  2.5914]], device='cuda:0')
# 6話-0
# 文: 見てもいいですか?
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-1.9617,  1.1658]], device='cuda:0')
# 6話-0
# 文: どうぞどうぞ
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-3.1952,  3.2315]], device='cuda:0')
# 6話-1
# 文: 俺も今日弁当なんでおかず分けますよ
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-3.2842,  3.1959]], device='cuda:0')
# 7話-0
# 文: どれがいいですか?
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 0.2266, -0.7724]], device='cuda:0')
# 7話-0
# 文: じゃあチョコですね
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 1.0032, -0.8829]], device='cuda:0')
# 7話-0
# 文: ジャーン!パフェを作ってみました〜!
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.5481, -0.2651]], device='cuda:0')
# 7話-0
# 文: 器用だ!?
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[ 0.4288, -1.2390]], device='cuda:0')
# 7話-1
# 文: ジャーン!パフェを作ってみました〜!
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.5481, -0.2651]], device='cuda:0')
# 7話-1
# 文: 器用だ!?
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[ 0.4288, -1.2390]], device='cuda:0')
# 7話-1
# 文: とか言い出すのかと思った…
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.2063,  1.5064]], device='cuda:0')
# 8話-0
# 文: 今日は良い実験結果が出たな
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.7882,  0.6162]], device='cuda:0')
# 8話-1
# 文: でもわざわざ国際会議から送ってくれたんだよな…
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-2.5794,  1.9045]], device='cuda:0')
# 8話-1
# 文: もう少し頑張るか
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-1.9478,  1.6602]], device='cuda:0')
# 9話-0
# 文: あれ?スペインからもう戻ってきたのか.
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-3.0921,  2.9280]], device='cuda:0')
# 9話-0
# 文: Bさん…あれ?
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
tensor([[ 3.0179, -3.4807]], device='cuda:0')
# 9話-0
# 文: Bさ…ちょっと!
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
tensor([[ 1.6513, -1.7751]], device='cuda:0')
# 9話-0
# 文: ?
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 1.3764, -1.7843]], device='cuda:0')
# 9話-1
# 文: ?
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 1.3764, -1.7843]], device='cuda:0')
# 9話-1
# 文: ここは よその研究室…!?
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[ 3.0651, -3.5284]], device='cuda:0')
# 9話-1
# 文: ただいま〜
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-3.2765,  3.2871]], device='cuda:0')
# 9話-1
# 文: おかえりなさい!
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-2.7133,  2.7728]], device='cuda:0')
# 9話-1
# 文: ?
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[ 1.3764, -1.7843]], device='cuda:0')
------------------------test acc------------------------
Test Acc : 0.5469
correct: 35, total: 64
------------------------------------------------
                  喜楽        その他  accuracy  macro avg  weighted avg
precision   0.333333   0.651163  0.546875   0.492248      0.541909
recall      0.318182   0.666667  0.546875   0.492424      0.546875
f1-score    0.325581   0.658824  0.546875   0.492202      0.544272
support    22.000000  42.000000  0.546875  64.000000     64.000000
正例のF1値 : 0.3255813948339642
class weight : tensor([0.5648, 0.3853])
best:lr 0.00031814918182980733
EPOCH : 1 / 50
VAL_LOSS : 0.06351696889704236 
VAL_ACCURACY : 0.9841075794621027
VAL_F1 : 0.9810771465131651

EPOCH : 2 / 50
VAL_LOSS : 0.04308296287826334 
VAL_ACCURACY : 0.9853300733496333
VAL_F1 : 0.982658959034799

EPOCH : 3 / 50
VAL_LOSS : 0.03530228390501669 
VAL_ACCURACY : 0.991442542787286
VAL_F1 : 0.9897810213949215

EPOCH : 4 / 50
VAL_LOSS : 0.026855044254961494 
VAL_ACCURACY : 0.991442542787286
VAL_F1 : 0.9897510975937354

EPOCH : 5 / 50
VAL_LOSS : 0.02907067269552499 
VAL_ACCURACY : 0.988997555012225
VAL_F1 : 0.9869375902083372

EPOCH : 6 / 50
VAL_LOSS : 0.03625566353842329 
VAL_ACCURACY : 0.9902200488997555
VAL_F1 : 0.9882352936147579

EPOCH : 7 / 50
VAL_LOSS : 0.037537795348236196 
VAL_ACCURACY : 0.9865525672371638
VAL_F1 : 0.9840810414653652

EPOCH : 8 / 50
VAL_LOSS : 0.03762124640007432 
VAL_ACCURACY : 0.9865525672371638
VAL_F1 : 0.9840810414653652

EPOCH : 9 / 50
VAL_LOSS : 0.03818627923744945 
VAL_ACCURACY : 0.9902200488997555
VAL_F1 : 0.9882005894676257

EPOCH : 10 / 50
VAL_LOSS : 0.0372276274764982 
VAL_ACCURACY : 0.9865525672371638
VAL_F1 : 0.9838472829038751

EPOCH : 11 / 50
VAL_LOSS : 0.04564409990920327 
VAL_ACCURACY : 0.9792176039119804
VAL_F1 : 0.9753265597294158

EPOCH : 12 / 50
VAL_LOSS : 0.026659222207784366 
VAL_ACCURACY : 0.9926650366748166
VAL_F1 : 0.9912023455381533

EPOCH : 13 / 50
VAL_LOSS : 0.028215481805650946 
VAL_ACCURACY : 0.991442542787286
VAL_F1 : 0.9897209980286744

EPOCH : 14 / 50
VAL_LOSS : 0.02378672535996884 
VAL_ACCURACY : 0.9926650366748166
VAL_F1 : 0.9912023455381533

EPOCH : 15 / 50
VAL_LOSS : 0.019501147697715517 
VAL_ACCURACY : 0.9938875305623472
VAL_F1 : 0.9927219791186626

EPOCH : 16 / 50
VAL_LOSS : 0.02049683496947042 
VAL_ACCURACY : 0.9938875305623472
VAL_F1 : 0.99270072942411

EPOCH : 17 / 50
VAL_LOSS : 0.03413737705425145 
VAL_ACCURACY : 0.988997555012225
VAL_F1 : 0.9867060556271238

EPOCH : 18 / 50
VAL_LOSS : 0.027694503772251595 
VAL_ACCURACY : 0.9926650366748166
VAL_F1 : 0.9912536438119831

EPOCH : 19 / 50
VAL_LOSS : 0.02064178988355427 
VAL_ACCURACY : 0.9951100244498777
VAL_F1 : 0.9941176465559171

EPOCH : 20 / 50
VAL_LOSS : 0.018606740497769073 
VAL_ACCURACY : 0.9938875305623472
VAL_F1 : 0.9926362292467352

EPOCH : 21 / 50
VAL_LOSS : 0.01662243944324123 
VAL_ACCURACY : 0.9926650366748166
VAL_F1 : 0.9912536438119831

EPOCH : 22 / 50
VAL_LOSS : 0.020317683891894724 
VAL_ACCURACY : 0.9926650366748166
VAL_F1 : 0.9912536438119831

EPOCH : 23 / 50
VAL_LOSS : 0.018667444922567274 
VAL_ACCURACY : 0.9926650366748166
VAL_F1 : 0.9911504419749915

EPOCH : 24 / 50
VAL_LOSS : 0.02610180471898415 
VAL_ACCURACY : 0.991442542787286
VAL_F1 : 0.9896602653760073

EPOCH : 25 / 50
VAL_LOSS : 0.025088735435229655 
VAL_ACCURACY : 0.991442542787286
VAL_F1 : 0.9896907211465965

EPOCH : 26 / 50
VAL_LOSS : 0.026068051191172205 
VAL_ACCURACY : 0.9938875305623472
VAL_F1 : 0.9926362292467352

EPOCH : 27 / 50
VAL_LOSS : 0.01997215796011285 
VAL_ACCURACY : 0.991442542787286
VAL_F1 : 0.9897810213949215

EPOCH : 28 / 50
VAL_LOSS : 0.02935161221942578 
VAL_ACCURACY : 0.9902200488997555
VAL_F1 : 0.9881656799705194

EPOCH : 29 / 50
VAL_LOSS : 0.022155185686782576 
VAL_ACCURACY : 0.9926650366748166
VAL_F1 : 0.9912790692645772

EPOCH : 30 / 50
VAL_LOSS : 0.02809224083634595 
VAL_ACCURACY : 0.9938875305623472
VAL_F1 : 0.9926362292467352

EPOCH : 31 / 50
VAL_LOSS : 0.019937182241567195 
VAL_ACCURACY : 0.9951100244498777
VAL_F1 : 0.9941176465559171

EPOCH : 32 / 50
VAL_LOSS : 0.05050818630171797 
VAL_ACCURACY : 0.9669926650366748
VAL_F1 : 0.9618104662587702

EPOCH : 33 / 50
VAL_LOSS : 0.023490832491706196 
VAL_ACCURACY : 0.9926650366748166
VAL_F1 : 0.9911504419749915

EPOCH : 34 / 50
VAL_LOSS : 0.011761358128681492 
VAL_ACCURACY : 0.9975550122249389
VAL_F1 : 0.9970674481774323

EPOCH : 35 / 50
VAL_LOSS : 0.014544902893248945 
VAL_ACCURACY : 0.9951100244498777
VAL_F1 : 0.9941348968577929

EPOCH : 36 / 50
VAL_LOSS : 0.02683689883381773 
VAL_ACCURACY : 0.991442542787286
VAL_F1 : 0.9897209980286744

EPOCH : 37 / 50
VAL_LOSS : 0.028364593436260924 
VAL_ACCURACY : 0.988997555012225
VAL_F1 : 0.9867060556271238

EPOCH : 38 / 50
VAL_LOSS : 0.019024020199699756 
VAL_ACCURACY : 0.9938875305623472
VAL_F1 : 0.9926578555910739

EPOCH : 39 / 50
VAL_LOSS : 0.01972071647357482 
VAL_ACCURACY : 0.9926650366748166
VAL_F1 : 0.9911504419749915

EPOCH : 40 / 50
VAL_LOSS : 0.019306908260869723 
VAL_ACCURACY : 0.9938875305623472
VAL_F1 : 0.9926362292467352

EPOCH : 41 / 50
VAL_LOSS : 0.01492158475314052 
VAL_ACCURACY : 0.9938875305623472
VAL_F1 : 0.99270072942411

EPOCH : 42 / 50
VAL_LOSS : 0.019575230105636783 
VAL_ACCURACY : 0.9938875305623472
VAL_F1 : 0.9926578555910739

EPOCH : 43 / 50
VAL_LOSS : 0.017587532210969724 
VAL_ACCURACY : 0.9975550122249389
VAL_F1 : 0.9970760228888975

EPOCH : 44 / 50
VAL_LOSS : 0.01723837324579318 
VAL_ACCURACY : 0.9963325183374083
VAL_F1 : 0.9955947131534735

EPOCH : 45 / 50
VAL_LOSS : 0.027643309055397716 
VAL_ACCURACY : 0.9926650366748166
VAL_F1 : 0.9912790692645772

EPOCH : 46 / 50
VAL_LOSS : 0.029543291710209675 
VAL_ACCURACY : 0.9902200488997555
VAL_F1 : 0.9883381919169479

EPOCH : 47 / 50
VAL_LOSS : 0.019144771421381917 
VAL_ACCURACY : 0.9963325183374083
VAL_F1 : 0.9955947131534735

EPOCH : 48 / 50
VAL_LOSS : 0.014587020964916939 
VAL_ACCURACY : 0.9963325183374083
VAL_F1 : 0.9955947131534735

EPOCH : 49 / 50
VAL_LOSS : 0.012774052517040847 
VAL_ACCURACY : 0.9951100244498777
VAL_F1 : 0.9941348968577929

EPOCH : 50 / 50
VAL_LOSS : 0.01108363013750372 
VAL_ACCURACY : 0.9975550122249389
VAL_F1 : 0.9970760228888975

# 5話-0
# 文: 何読んでるんですか?
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 0.4928, -0.6745]], device='cuda:0')
# 5話-0
# 文: 今ハマってる本はこの二冊…
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-2.4060,  3.8575]], device='cuda:0')
# 5話-0
# 文: Bさん、苦手そうだよな…
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
tensor([[ 2.1442, -3.0263]], device='cuda:0')
# 5話-0
# 文: 適当に流したな
正解 : 1 , 予測 : 0 / 元クラス : 憤怒
tensor([[ 2.0071, -2.6434]], device='cuda:0')
# 5話-0
# 文: あと、これも読んだよ
正解 : 1 , 予測 : 0 / 元クラス : 憤怒
tensor([[ 1.4103, -2.3638]], device='cuda:0')
# 5話-1
# 文: これ読んだよ
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 2.2025, -3.4874]], device='cuda:0')
# 5話-1
# 文: そうなんだ〜
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-1.3767,  1.6860]], device='cuda:0')
# 5話-1
# 文: 本当に今ハマってる本はこの二冊…
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-2.4762,  3.3805]], device='cuda:0')
# 6話-0
# 文: 今日弁当なんですね
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[0.6126, 0.1645]], device='cuda:0')
# 6話-0
# 文: ほとんど冷凍食品詰めただけだよ
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-2.4045,  3.8683]], device='cuda:0')
# 6話-0
# 文: 見てもいいですか?
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.8433,  1.8785]], device='cuda:0')
# 6話-1
# 文: 今日弁当なの珍しいですね
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 1.7532, -2.6920]], device='cuda:0')
# 6話-1
# 文: 俺も今日弁当なんでおかず分けますよ
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-2.4061,  3.8576]], device='cuda:0')
# 7話-0
# 文: どれがいいですか?
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 2.6235, -3.9240]], device='cuda:0')
# 7話-0
# 文: じゃあチョコですね
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 2.2474, -2.7384]], device='cuda:0')
# 7話-1
# 文: とか言い出すのかと思った…
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[0.1140, 1.1176]], device='cuda:0')
# 8話-0
# 文: 今日は良い実験結果が出たな
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-2.2089,  3.4850]], device='cuda:0')
# 8話-1
# 文: でもわざわざ国際会議から送ってくれたんだよな…
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-2.4288,  3.2972]], device='cuda:0')
# 9話-0
# 文: あれ?スペインからもう戻ってきたのか.
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-2.3876,  3.2162]], device='cuda:0')
# 9話-0
# 文: Bさん…あれ?
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
tensor([[ 2.6257, -3.9271]], device='cuda:0')
# 9話-0
# 文: Bさ…ちょっと!
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
tensor([[ 2.6006, -3.9089]], device='cuda:0')
# 9話-0
# 文: ?
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 1.3259, -1.3605]], device='cuda:0')
# 9話-1
# 文: ?
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 1.3259, -1.3605]], device='cuda:0')
# 9話-1
# 文: ここは よその研究室…!?
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[ 2.1703, -3.4915]], device='cuda:0')
# 9話-1
# 文: ただいま〜
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-2.3188,  3.7609]], device='cuda:0')
# 9話-1
# 文: ?
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[ 1.3259, -1.3605]], device='cuda:0')
------------------------test acc------------------------
Test Acc : 0.5938
correct: 38, total: 64
------------------------------------------------
                  喜楽        その他  accuracy  macro avg  weighted avg
precision   0.423077   0.710526   0.59375   0.566802      0.611716
recall      0.500000   0.642857   0.59375   0.571429      0.593750
f1-score    0.458333   0.675000   0.59375   0.566667      0.600521
support    22.000000  42.000000   0.59375  64.000000     64.000000
正例のF1値 : 0.4583333328177083
class weight : tensor([0.5648, 0.3853])
best:lr 3.983034573372373e-05
EPOCH : 1 / 50
VAL_LOSS : 0.13173888466106012 
VAL_ACCURACY : 0.9559902200488998
VAL_F1 : 0.9467455616274466

EPOCH : 2 / 50
VAL_LOSS : 0.08082403274826132 
VAL_ACCURACY : 0.9767726161369193
VAL_F1 : 0.972017672545765

EPOCH : 3 / 50
VAL_LOSS : 0.05503175051238101 
VAL_ACCURACY : 0.9841075794621027
VAL_F1 : 0.9809104253414754

EPOCH : 4 / 50
VAL_LOSS : 0.037096189764829784 
VAL_ACCURACY : 0.991442542787286
VAL_F1 : 0.9897510975937354

EPOCH : 5 / 50
VAL_LOSS : 0.03639318502078263 
VAL_ACCURACY : 0.9877750611246944
VAL_F1 : 0.9853372428988744

EPOCH : 6 / 50
VAL_LOSS : 0.03051720495120837 
VAL_ACCURACY : 0.9926650366748166
VAL_F1 : 0.9912280696725404

EPOCH : 7 / 50
VAL_LOSS : 0.03620553999028813 
VAL_ACCURACY : 0.988997555012225
VAL_F1 : 0.9867452130464579

EPOCH : 8 / 50
VAL_LOSS : 0.023696490178386178 
VAL_ACCURACY : 0.9938875305623472
VAL_F1 : 0.9926793552804033

EPOCH : 9 / 50
VAL_LOSS : 0.026507461443543434 
VAL_ACCURACY : 0.991442542787286
VAL_F1 : 0.9898403478280674

EPOCH : 10 / 50
VAL_LOSS : 0.01826167733480151 
VAL_ACCURACY : 0.9963325183374083
VAL_F1 : 0.9956204374532985

EPOCH : 11 / 50
VAL_LOSS : 0.01938977846517586 
VAL_ACCURACY : 0.9877750611246944
VAL_F1 : 0.9855907775952462

EPOCH : 12 / 50
VAL_LOSS : 0.015500516129227785 
VAL_ACCURACY : 0.9975550122249389
VAL_F1 : 0.9970760228888975

EPOCH : 13 / 50
VAL_LOSS : 0.015314704335581224 
VAL_ACCURACY : 0.9963325183374083
VAL_F1 : 0.9956076129670711

EPOCH : 14 / 50
VAL_LOSS : 0.01579396621449492 
VAL_ACCURACY : 0.9975550122249389
VAL_F1 : 0.9970760228888975

EPOCH : 15 / 50
VAL_LOSS : 0.015503085258667572 
VAL_ACCURACY : 0.9963325183374083
VAL_F1 : 0.9956204374532985

EPOCH : 16 / 50
VAL_LOSS : 0.014059342452898048 
VAL_ACCURACY : 0.9963325183374083
VAL_F1 : 0.9956204374532985

EPOCH : 17 / 50
VAL_LOSS : 0.017370551864867315 
VAL_ACCURACY : 0.9938875305623472
VAL_F1 : 0.9927219791186626

EPOCH : 18 / 50
VAL_LOSS : 0.0201383981665668 
VAL_ACCURACY : 0.9926650366748166
VAL_F1 : 0.9912280696725404

EPOCH : 19 / 50
VAL_LOSS : 0.018977876206358466 
VAL_ACCURACY : 0.9926650366748166
VAL_F1 : 0.9911764700853374

EPOCH : 20 / 50
VAL_LOSS : 0.012705536106995378 
VAL_ACCURACY : 0.9963325183374083
VAL_F1 : 0.9956076129670711

EPOCH : 21 / 50
VAL_LOSS : 0.013600251440388652 
VAL_ACCURACY : 0.9963325183374083
VAL_F1 : 0.9956076129670711

EPOCH : 22 / 50
VAL_LOSS : 0.011431536153675271 
VAL_ACCURACY : 0.9975550122249389
VAL_F1 : 0.9970760228888975

EPOCH : 23 / 50
VAL_LOSS : 0.01348815701651172 
VAL_ACCURACY : 0.9963325183374083
VAL_F1 : 0.9955947131534735

EPOCH : 24 / 50
VAL_LOSS : 0.012987759492646616 
VAL_ACCURACY : 0.9963325183374083
VAL_F1 : 0.9956076129670711

EPOCH : 25 / 50
VAL_LOSS : 0.009688603114157628 
VAL_ACCURACY : 0.9963325183374083
VAL_F1 : 0.9956076129670711

EPOCH : 26 / 50
VAL_LOSS : 0.01806236581894784 
VAL_ACCURACY : 0.9938875305623472
VAL_F1 : 0.9926362292467352

EPOCH : 27 / 50
VAL_LOSS : 0.009518159864595734 
VAL_ACCURACY : 0.9975550122249389
VAL_F1 : 0.9970760228888975

EPOCH : 28 / 50
VAL_LOSS : 0.01295072395945541 
VAL_ACCURACY : 0.9951100244498777
VAL_F1 : 0.9941348968577929

EPOCH : 29 / 50
VAL_LOSS : 0.013752821465739263 
VAL_ACCURACY : 0.9963325183374083
VAL_F1 : 0.9955947131534735

EPOCH : 30 / 50
VAL_LOSS : 0.010101020839871265 
VAL_ACCURACY : 0.9975550122249389
VAL_F1 : 0.9970674481774323

EPOCH : 31 / 50
VAL_LOSS : 0.00871596397840991 
VAL_ACCURACY : 0.9987775061124694
VAL_F1 : 0.9985358706537388

EPOCH : 32 / 50
VAL_LOSS : 0.014081933490860347 
VAL_ACCURACY : 0.9963325183374083
VAL_F1 : 0.9955947131534735

EPOCH : 33 / 50
VAL_LOSS : 0.009672379739081057 
VAL_ACCURACY : 0.9975550122249389
VAL_F1 : 0.9970674481774323

EPOCH : 34 / 50
VAL_LOSS : 0.00878953089704737 
VAL_ACCURACY : 0.9975550122249389
VAL_F1 : 0.9970674481774323

EPOCH : 35 / 50
VAL_LOSS : 0.010073980034436457 
VAL_ACCURACY : 0.9975550122249389
VAL_F1 : 0.9970674481774323

EPOCH : 36 / 50
VAL_LOSS : 0.017653451995171893 
VAL_ACCURACY : 0.9951100244498777
VAL_F1 : 0.9941176465559171

EPOCH : 37 / 50
VAL_LOSS : 0.014429435033189993 
VAL_ACCURACY : 0.9963325183374083
VAL_F1 : 0.9955947131534735

EPOCH : 38 / 50
VAL_LOSS : 0.009512098991903119 
VAL_ACCURACY : 0.9963325183374083
VAL_F1 : 0.9955947131534735

EPOCH : 39 / 50
VAL_LOSS : 0.009530885982362984 
VAL_ACCURACY : 0.9963325183374083
VAL_F1 : 0.9955947131534735

EPOCH : 40 / 50
VAL_LOSS : 0.01133964971701901 
VAL_ACCURACY : 0.9951100244498777
VAL_F1 : 0.9941348968577929

EPOCH : 41 / 50
VAL_LOSS : 0.017153593172014762 
VAL_ACCURACY : 0.9951100244498777
VAL_F1 : 0.9941176465559171

EPOCH : 42 / 50
VAL_LOSS : 0.015359930279933346 
VAL_ACCURACY : 0.9926650366748166
VAL_F1 : 0.9912280696725404

EPOCH : 43 / 50
VAL_LOSS : 0.010804100239721056 
VAL_ACCURACY : 0.9963325183374083
VAL_F1 : 0.9956076129670711

EPOCH : 44 / 50
VAL_LOSS : 0.014534213022740845 
VAL_ACCURACY : 0.9963325183374083
VAL_F1 : 0.9956076129670711

EPOCH : 45 / 50
VAL_LOSS : 0.01038726608385332 
VAL_ACCURACY : 0.9975550122249389
VAL_F1 : 0.9970760228888975

EPOCH : 46 / 50
VAL_LOSS : 0.009591382171493024 
VAL_ACCURACY : 0.9975550122249389
VAL_F1 : 0.9970760228888975

EPOCH : 47 / 50
VAL_LOSS : 0.012061835360677483 
VAL_ACCURACY : 0.9951100244498777
VAL_F1 : 0.994152046280719

EPOCH : 48 / 50
VAL_LOSS : 0.011032217824742055 
VAL_ACCURACY : 0.9963325183374083
VAL_F1 : 0.9956076129670711

EPOCH : 49 / 50
VAL_LOSS : 0.014406218609880082 
VAL_ACCURACY : 0.9963325183374083
VAL_F1 : 0.9956076129670711

EPOCH : 50 / 50
VAL_LOSS : 0.016256875060767364 
VAL_ACCURACY : 0.9951100244498777
VAL_F1 : 0.9941348968577929

# 5話-0
# 文: 今ハマってる本はこの二冊…
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-2.3122,  3.5457]], device='cuda:0')
# 5話-0
# 文: Bさん、苦手そうだよな…
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
tensor([[ 1.1492, -1.9970]], device='cuda:0')
# 5話-0
# 文: 適当に流そう
正解 : 1 , 予測 : 0 / 元クラス : 嫌悪
tensor([[0.2897, 0.1045]], device='cuda:0')
# 5話-1
# 文: これ読んだよ
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 2.2438, -3.8054]], device='cuda:0')
# 5話-1
# 文: そうなんだ〜
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-2.3074,  3.6458]], device='cuda:0')
# 5話-1
# 文: 本当に今ハマってる本はこの二冊…
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-1.3916,  1.8205]], device='cuda:0')
# 6話-0
# 文: 今日弁当なんですね
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[ 0.0413, -0.2882]], device='cuda:0')
# 6話-0
# 文: ほとんど冷凍食品詰めただけだよ
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-2.0266,  3.1315]], device='cuda:0')
# 6話-0
# 文: 見てもいいですか?
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-1.7568,  2.8173]], device='cuda:0')
# 6話-0
# 文: どうぞどうぞ
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-2.0357,  3.0984]], device='cuda:0')
# 6話-1
# 文: 俺も今日弁当なんでおかず分けますよ
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-2.4160,  3.7554]], device='cuda:0')
# 7話-0
# 文: どれがいいですか?
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 0.9862, -1.4906]], device='cuda:0')
# 7話-0
# 文: じゃあチョコですね
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 1.5075, -2.2662]], device='cuda:0')
# 7話-0
# 文: チョコは一つしかないし悪いよ〜
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[ 1.7909, -3.2141]], device='cuda:0')
# 7話-1
# 文: こうやっていろんな食べ方をすれば飽きないですね
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-1.0868,  1.8481]], device='cuda:0')
# 7話-1
# 文: とか言い出すのかと思った…
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.6784,  0.8856]], device='cuda:0')
# 8話-1
# 文: もう少し頑張るか
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.4826,  1.1789]], device='cuda:0')
# 9話-0
# 文: あれ?スペインからもう戻ってきたのか.
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-1.7205,  2.5515]], device='cuda:0')
# 9話-0
# 文: Bさん…あれ?
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
tensor([[ 1.6377, -2.9839]], device='cuda:0')
# 9話-0
# 文: Bさ…ちょっと!
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
tensor([[ 2.3025, -3.8218]], device='cuda:0')
# 9話-0
# 文: ?
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 0.5427, -1.1555]], device='cuda:0')
# 9話-1
# 文: ?
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 0.5427, -1.1555]], device='cuda:0')
# 9話-1
# 文: ここは よその研究室…!?
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[ 2.3219, -3.9017]], device='cuda:0')
# 9話-1
# 文: ただいま〜
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-2.3024,  3.6271]], device='cuda:0')
# 9話-1
# 文: おかえりなさい!
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-1.4751,  1.9112]], device='cuda:0')
# 9話-1
# 文: ?
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[ 0.5427, -1.1555]], device='cuda:0')
------------------------test acc------------------------
Test Acc : 0.5938
correct: 38, total: 64
------------------------------------------------
                  喜楽        その他  accuracy  macro avg  weighted avg
precision   0.409091   0.690476   0.59375   0.549784       0.59375
recall      0.409091   0.690476   0.59375   0.549784       0.59375
f1-score    0.409091   0.690476   0.59375   0.549784       0.59375
support    22.000000  42.000000   0.59375  64.000000      64.00000
正例のF1値 : 0.409090908572314
class weight : tensor([0.5648, 0.3853])
best:lr 0.00015891420819324307
EPOCH : 1 / 50
VAL_LOSS : 0.08015796133818534 
VAL_ACCURACY : 0.9792176039119804
VAL_F1 : 0.9749631806459036

EPOCH : 2 / 50
VAL_LOSS : 0.06757073553923804 
VAL_ACCURACY : 0.9779951100244498
VAL_F1 : 0.9729729724704164

EPOCH : 3 / 50
VAL_LOSS : 0.05969794805591496 
VAL_ACCURACY : 0.9816625916870416
VAL_F1 : 0.9777777772749696

EPOCH : 4 / 50
VAL_LOSS : 0.03813701971040036 
VAL_ACCURACY : 0.9853300733496333
VAL_F1 : 0.9823008844528938

EPOCH : 5 / 50
VAL_LOSS : 0.028446923305567067 
VAL_ACCURACY : 0.991442542787286
VAL_F1 : 0.9898107709672882

EPOCH : 6 / 50
VAL_LOSS : 0.0265355881016988 
VAL_ACCURACY : 0.991442542787286
VAL_F1 : 0.9897810213949215

EPOCH : 7 / 50
VAL_LOSS : 0.01889115408098755 
VAL_ACCURACY : 0.9963325183374083
VAL_F1 : 0.9956204374532985

EPOCH : 8 / 50
VAL_LOSS : 0.016004290109357007 
VAL_ACCURACY : 0.9951100244498777
VAL_F1 : 0.9941348968577929

EPOCH : 9 / 50
VAL_LOSS : 0.01818434149922373 
VAL_ACCURACY : 0.9951100244498777
VAL_F1 : 0.9941690957070183

EPOCH : 10 / 50
VAL_LOSS : 0.02122908073047606 
VAL_ACCURACY : 0.9902200488997555
VAL_F1 : 0.9882352936147579

EPOCH : 11 / 50
VAL_LOSS : 0.01921730543164393 
VAL_ACCURACY : 0.9902200488997555
VAL_F1 : 0.9882352936147579

EPOCH : 12 / 50
VAL_LOSS : 0.014010437074690484 
VAL_ACCURACY : 0.9951100244498777
VAL_F1 : 0.994152046280719

EPOCH : 13 / 50
VAL_LOSS : 0.026932510717485387 
VAL_ACCURACY : 0.9926650366748166
VAL_F1 : 0.9911504419749915

EPOCH : 14 / 50
VAL_LOSS : 0.022769879426610153 
VAL_ACCURACY : 0.9938875305623472
VAL_F1 : 0.9926578555910739

EPOCH : 15 / 50
VAL_LOSS : 0.030109918497216243 
VAL_ACCURACY : 0.9926650366748166
VAL_F1 : 0.9912023455381533

EPOCH : 16 / 50
VAL_LOSS : 0.04294782071016156 
VAL_ACCURACY : 0.988997555012225
VAL_F1 : 0.9866666661638321

EPOCH : 17 / 50
VAL_LOSS : 0.02584010304641337 
VAL_ACCURACY : 0.9938875305623472
VAL_F1 : 0.9926793552804033

EPOCH : 18 / 50
VAL_LOSS : 0.027007033520091612 
VAL_ACCURACY : 0.9938875305623472
VAL_F1 : 0.9926578555910739

EPOCH : 19 / 50
VAL_LOSS : 0.02183867472026927 
VAL_ACCURACY : 0.991442542787286
VAL_F1 : 0.9897510975937354

EPOCH : 20 / 50
VAL_LOSS : 0.018202927097893104 
VAL_ACCURACY : 0.9938875305623472
VAL_F1 : 0.9926793552804033

EPOCH : 21 / 50
VAL_LOSS : 0.0315970051003835 
VAL_ACCURACY : 0.991442542787286
VAL_F1 : 0.9896602653760073

EPOCH : 22 / 50
VAL_LOSS : 0.0311304615080679 
VAL_ACCURACY : 0.9938875305623472
VAL_F1 : 0.9926793552804033

EPOCH : 23 / 50
VAL_LOSS : 0.02277555953612766 
VAL_ACCURACY : 0.991442542787286
VAL_F1 : 0.9896907211465965

EPOCH : 24 / 50
VAL_LOSS : 0.04008599387732549 
VAL_ACCURACY : 0.991442542787286
VAL_F1 : 0.9896907211465965

EPOCH : 25 / 50
VAL_LOSS : 0.027835690194758803 
VAL_ACCURACY : 0.9938875305623472
VAL_F1 : 0.9926578555910739

EPOCH : 26 / 50
VAL_LOSS : 0.029476040889186643 
VAL_ACCURACY : 0.991442542787286
VAL_F1 : 0.9896602653760073

EPOCH : 27 / 50
VAL_LOSS : 0.018647260706459817 
VAL_ACCURACY : 0.9938875305623472
VAL_F1 : 0.9926362292467352

EPOCH : 28 / 50
VAL_LOSS : 0.017314162391882677 
VAL_ACCURACY : 0.9951100244498777
VAL_F1 : 0.9941690957070183

EPOCH : 29 / 50
VAL_LOSS : 0.014584395369568553 
VAL_ACCURACY : 0.9963325183374083
VAL_F1 : 0.9956204374532985

EPOCH : 30 / 50
VAL_LOSS : 0.011956911780334149 
VAL_ACCURACY : 0.9975550122249389
VAL_F1 : 0.9970760228888975

EPOCH : 31 / 50
VAL_LOSS : 0.012036352709401399 
VAL_ACCURACY : 0.9938875305623472
VAL_F1 : 0.9927219791186626

EPOCH : 32 / 50
VAL_LOSS : 0.013070316170342267 
VAL_ACCURACY : 0.9963325183374083
VAL_F1 : 0.9955947131534735

EPOCH : 33 / 50
VAL_LOSS : 0.01920432811199974 
VAL_ACCURACY : 0.9951100244498777
VAL_F1 : 0.9941176465559171

EPOCH : 34 / 50
VAL_LOSS : 0.014861442829267336 
VAL_ACCURACY : 0.9963325183374083
VAL_F1 : 0.9955947131534735

EPOCH : 35 / 50
VAL_LOSS : 0.02546511149669711 
VAL_ACCURACY : 0.9951100244498777
VAL_F1 : 0.9941690957070183

EPOCH : 36 / 50
VAL_LOSS : 0.017069870012794405 
VAL_ACCURACY : 0.9951100244498777
VAL_F1 : 0.9941176465559171

EPOCH : 37 / 50
VAL_LOSS : 0.02089719365288217 
VAL_ACCURACY : 0.9938875305623472
VAL_F1 : 0.9926362292467352

EPOCH : 38 / 50
VAL_LOSS : 0.024578100269606624 
VAL_ACCURACY : 0.991442542787286
VAL_F1 : 0.9896907211465965

EPOCH : 39 / 50
VAL_LOSS : 0.02248036042930415 
VAL_ACCURACY : 0.991442542787286
VAL_F1 : 0.9898107709672882

EPOCH : 40 / 50
VAL_LOSS : 0.017019355403205667 
VAL_ACCURACY : 0.9951100244498777
VAL_F1 : 0.994152046280719

EPOCH : 41 / 50
VAL_LOSS : 0.017530936745550625 
VAL_ACCURACY : 0.9951100244498777
VAL_F1 : 0.994152046280719

EPOCH : 42 / 50
VAL_LOSS : 0.014045500789786903 
VAL_ACCURACY : 0.9938875305623472
VAL_F1 : 0.9927219791186626

EPOCH : 43 / 50
VAL_LOSS : 0.02528994945057023 
VAL_ACCURACY : 0.9841075794621027
VAL_F1 : 0.9811320749688764

EPOCH : 44 / 50
VAL_LOSS : 0.012955810704555076 
VAL_ACCURACY : 0.9975550122249389
VAL_F1 : 0.9970674481774323

EPOCH : 45 / 50
VAL_LOSS : 0.014508096243774232 
VAL_ACCURACY : 0.9938875305623472
VAL_F1 : 0.9926362292467352

EPOCH : 46 / 50
VAL_LOSS : 0.01127513078524946 
VAL_ACCURACY : 0.9963325183374083
VAL_F1 : 0.9955947131534735

EPOCH : 47 / 50
VAL_LOSS : 0.014606103160006639 
VAL_ACCURACY : 0.9951100244498777
VAL_F1 : 0.9941176465559171

EPOCH : 48 / 50
VAL_LOSS : 0.02778875233175663 
VAL_ACCURACY : 0.9902200488997555
VAL_F1 : 0.9883381919169479

EPOCH : 49 / 50
VAL_LOSS : 0.01408801355640977 
VAL_ACCURACY : 0.9951100244498777
VAL_F1 : 0.9941348968577929

EPOCH : 50 / 50
VAL_LOSS : 0.01641527487215801 
VAL_ACCURACY : 0.9951100244498777
VAL_F1 : 0.9941176465559171

# 5話-0
# 文: 今ハマってる本はこの二冊…
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-3.1966,  3.3535]], device='cuda:0')
# 5話-0
# 文: Bさん、苦手そうだよな…
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
tensor([[ 3.4871, -3.2198]], device='cuda:0')
# 5話-0
# 文: 適当に流そう
正解 : 1 , 予測 : 0 / 元クラス : 嫌悪
tensor([[0.5127, 0.2314]], device='cuda:0')
# 5話-0
# 文: あと、これも読んだよ
正解 : 1 , 予測 : 0 / 元クラス : 憤怒
tensor([[ 3.1577, -2.0969]], device='cuda:0')
# 5話-1
# 文: これ読んだよ
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 3.5003, -3.1973]], device='cuda:0')
# 5話-1
# 文: そうなんだ〜
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-2.5874,  2.8748]], device='cuda:0')
# 5話-1
# 文: 本当に今ハマってる本はこの二冊…
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-2.8063,  3.0221]], device='cuda:0')
# 6話-0
# 文: ほとんど冷凍食品詰めただけだよ
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-2.8164,  2.9062]], device='cuda:0')
# 6話-0
# 文: 見てもいいですか?
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-2.5671,  3.1564]], device='cuda:0')
# 6話-0
# 文: どうぞどうぞ
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-3.0542,  3.2065]], device='cuda:0')
# 6話-1
# 文: 俺も今日弁当なんでおかず分けますよ
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-3.2014,  3.3635]], device='cuda:0')
# 7話-0
# 文: どれがいいですか?
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 1.5275, -2.0154]], device='cuda:0')
# 7話-0
# 文: じゃあチョコですね
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 2.4873, -1.4350]], device='cuda:0')
# 7話-1
# 文: こうやっていろんな食べ方をすれば飽きないですね
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-1.8749,  2.5975]], device='cuda:0')
# 7話-1
# 文: とか言い出すのかと思った…
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.7216,  0.6102]], device='cuda:0')
# 7話-1
# 文: Aくんがいなければ独り占めできたのにな…
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
tensor([[ 0.2017, -0.0333]], device='cuda:0')
# 8話-1
# 文: でもわざわざ国際会議から送ってくれたんだよな…
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-2.9579,  2.7825]], device='cuda:0')
# 8話-1
# 文: もう少し頑張るか
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-1.8756,  2.0567]], device='cuda:0')
# 9話-0
# 文: あれ?スペインからもう戻ってきたのか.
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.5006,  0.4319]], device='cuda:0')
# 9話-0
# 文: Bさん…あれ?
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
tensor([[ 2.1147, -2.4702]], device='cuda:0')
# 9話-0
# 文: Bさ…ちょっと!
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
tensor([[ 3.4920, -3.2148]], device='cuda:0')
# 9話-1
# 文: ここは よその研究室…!?
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[ 3.5038, -3.2148]], device='cuda:0')
# 9話-1
# 文: ただいま〜
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-3.1301,  3.3492]], device='cuda:0')
# 9話-1
# 文: おかえりなさい!
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-1.7500,  2.1830]], device='cuda:0')
------------------------test acc------------------------
Test Acc : 0.6250
correct: 40, total: 64
------------------------------------------------
                  喜楽        その他  accuracy  macro avg  weighted avg
precision   0.444444   0.695652     0.625   0.570048      0.609300
recall      0.363636   0.761905     0.625   0.562771      0.625000
f1-score    0.400000   0.727273     0.625   0.563636      0.614773
support    22.000000  42.000000     0.625  64.000000     64.000000
正例のF1値 : 0.399999999485
class weight : tensor([0.5648, 0.3853])
best:lr 0.00031673075322888035
EPOCH : 1 / 50
VAL_LOSS : 0.06987619663302141 
VAL_ACCURACY : 0.980440097799511
VAL_F1 : 0.976331360443927

EPOCH : 2 / 50
VAL_LOSS : 0.06324805528856814 
VAL_ACCURACY : 0.9828850855745721
VAL_F1 : 0.9793510319455278

EPOCH : 3 / 50
VAL_LOSS : 0.05108263088354411 
VAL_ACCURACY : 0.9816625916870416
VAL_F1 : 0.9779086887460421

EPOCH : 4 / 50
VAL_LOSS : 0.049668751388358384 
VAL_ACCURACY : 0.980440097799511
VAL_F1 : 0.9761194024823792

EPOCH : 5 / 50
VAL_LOSS : 0.04008763929148419 
VAL_ACCURACY : 0.9865525672371638
VAL_F1 : 0.9840810414653652

EPOCH : 6 / 50
VAL_LOSS : 0.03696401005324263 
VAL_ACCURACY : 0.9865525672371638
VAL_F1 : 0.9839883546645395

EPOCH : 7 / 50
VAL_LOSS : 0.07419208735406685 
VAL_ACCURACY : 0.9853300733496333
VAL_F1 : 0.982195845194525

EPOCH : 8 / 50
VAL_LOSS : 0.025499894628480364 
VAL_ACCURACY : 0.9926650366748166
VAL_F1 : 0.9912023455381533

EPOCH : 9 / 50
VAL_LOSS : 0.04690941051991943 
VAL_ACCURACY : 0.9865525672371638
VAL_F1 : 0.9838945822203996

EPOCH : 10 / 50
VAL_LOSS : 0.024394739155048646 
VAL_ACCURACY : 0.9938875305623472
VAL_F1 : 0.9926362292467352

EPOCH : 11 / 50
VAL_LOSS : 0.02621140365058986 
VAL_ACCURACY : 0.991442542787286
VAL_F1 : 0.9897510975937354

EPOCH : 12 / 50
VAL_LOSS : 0.054806481254322886 
VAL_ACCURACY : 0.9792176039119804
VAL_F1 : 0.9756795417005859

EPOCH : 13 / 50
VAL_LOSS : 0.02560892752192628 
VAL_ACCURACY : 0.9951100244498777
VAL_F1 : 0.9941348968577929

EPOCH : 14 / 50
VAL_LOSS : 0.040667874277390256 
VAL_ACCURACY : 0.9877750611246944
VAL_F1 : 0.9852071000888711

EPOCH : 15 / 50
VAL_LOSS : 0.03311978702325947 
VAL_ACCURACY : 0.9902200488997555
VAL_F1 : 0.9882352936147579

EPOCH : 16 / 50
VAL_LOSS : 0.021314626729760606 
VAL_ACCURACY : 0.9926650366748166
VAL_F1 : 0.9912790692645772

EPOCH : 17 / 50
VAL_LOSS : 0.012549772798173273 
VAL_ACCURACY : 0.9975550122249389
VAL_F1 : 0.9970760228888975

EPOCH : 18 / 50
VAL_LOSS : 0.0297609362213944 
VAL_ACCURACY : 0.9926650366748166
VAL_F1 : 0.9911504419749915

EPOCH : 19 / 50
VAL_LOSS : 0.026381262497474942 
VAL_ACCURACY : 0.9902200488997555
VAL_F1 : 0.9882697942185138

EPOCH : 20 / 50
VAL_LOSS : 0.01748495161658726 
VAL_ACCURACY : 0.9938875305623472
VAL_F1 : 0.9927219791186626

EPOCH : 21 / 50
VAL_LOSS : 0.021828262124192685 
VAL_ACCURACY : 0.9926650366748166
VAL_F1 : 0.9911504419749915

EPOCH : 22 / 50
VAL_LOSS : 0.021695941290370405 
VAL_ACCURACY : 0.9902200488997555
VAL_F1 : 0.9883040930643616

EPOCH : 23 / 50
VAL_LOSS : 0.014953167101619048 
VAL_ACCURACY : 0.9951100244498777
VAL_F1 : 0.9941348968577929

EPOCH : 24 / 50
VAL_LOSS : 0.02075368592676778 
VAL_ACCURACY : 0.991442542787286
VAL_F1 : 0.9897810213949215

EPOCH : 25 / 50
VAL_LOSS : 0.026127041993626896 
VAL_ACCURACY : 0.991442542787286
VAL_F1 : 0.9896602653760073

EPOCH : 26 / 50
VAL_LOSS : 0.023417307269902758 
VAL_ACCURACY : 0.9938875305623472
VAL_F1 : 0.9926362292467352

EPOCH : 27 / 50
VAL_LOSS : 0.02444120406737336 
VAL_ACCURACY : 0.9853300733496333
VAL_F1 : 0.9825072881268774

EPOCH : 28 / 50
VAL_LOSS : 0.02810363032264062 
VAL_ACCURACY : 0.9951100244498777
VAL_F1 : 0.9941176465559171

EPOCH : 29 / 50
VAL_LOSS : 0.014948872840390183 
VAL_ACCURACY : 0.9987775061124694
VAL_F1 : 0.9985358706537388

EPOCH : 30 / 50
VAL_LOSS : 0.021038245624647692 
VAL_ACCURACY : 0.9951100244498777
VAL_F1 : 0.9941348968577929

EPOCH : 31 / 50
VAL_LOSS : 0.019969973858678713 
VAL_ACCURACY : 0.9938875305623472
VAL_F1 : 0.9926793552804033

EPOCH : 32 / 50
VAL_LOSS : 0.030473390475470714 
VAL_ACCURACY : 0.9902200488997555
VAL_F1 : 0.9881656799705194

EPOCH : 33 / 50
VAL_LOSS : 0.02889519344451121 
VAL_ACCURACY : 0.9902200488997555
VAL_F1 : 0.9884057965986223

EPOCH : 34 / 50
VAL_LOSS : 0.01849006556081944 
VAL_ACCURACY : 0.9938875305623472
VAL_F1 : 0.9926793552804033

EPOCH : 35 / 50
VAL_LOSS : 0.0120805952397999 
VAL_ACCURACY : 0.9963325183374083
VAL_F1 : 0.9955947131534735

EPOCH : 36 / 50
VAL_LOSS : 0.013839468747252025 
VAL_ACCURACY : 0.9963325183374083
VAL_F1 : 0.9956204374532985

EPOCH : 37 / 50
VAL_LOSS : 0.02310044671041676 
VAL_ACCURACY : 0.991442542787286
VAL_F1 : 0.9897510975937354

EPOCH : 38 / 50
VAL_LOSS : 0.019733433654227365 
VAL_ACCURACY : 0.9938875305623472
VAL_F1 : 0.9926578555910739

EPOCH : 39 / 50
VAL_LOSS : 0.02847205091921541 
VAL_ACCURACY : 0.991442542787286
VAL_F1 : 0.9898403478280674

EPOCH : 40 / 50
VAL_LOSS : 0.020609237117101796 
VAL_ACCURACY : 0.991442542787286
VAL_F1 : 0.9896907211465965

EPOCH : 41 / 50
VAL_LOSS : 0.02659645462811638 
VAL_ACCURACY : 0.9902200488997555
VAL_F1 : 0.9882352936147579

EPOCH : 42 / 50
VAL_LOSS : 0.028500960036091365 
VAL_ACCURACY : 0.991442542787286
VAL_F1 : 0.9898403478280674

EPOCH : 43 / 50
VAL_LOSS : 0.023680967592204418 
VAL_ACCURACY : 0.9938875305623472
VAL_F1 : 0.9926362292467352

EPOCH : 44 / 50
VAL_LOSS : 0.019754436914809048 
VAL_ACCURACY : 0.9926650366748166
VAL_F1 : 0.9912023455381533

EPOCH : 45 / 50
VAL_LOSS : 0.01793494840743593 
VAL_ACCURACY : 0.9938875305623472
VAL_F1 : 0.9926362292467352

EPOCH : 46 / 50
VAL_LOSS : 0.010515126912371041 
VAL_ACCURACY : 0.9963325183374083
VAL_F1 : 0.9956204374532985

EPOCH : 47 / 50
VAL_LOSS : 0.018144482717616484 
VAL_ACCURACY : 0.9938875305623472
VAL_F1 : 0.9926362292467352

EPOCH : 48 / 50
VAL_LOSS : 0.014452932751737535 
VAL_ACCURACY : 0.9963325183374083
VAL_F1 : 0.9956076129670711

EPOCH : 49 / 50
VAL_LOSS : 0.018463004333450675 
VAL_ACCURACY : 0.9975550122249389
VAL_F1 : 0.9970760228888975

EPOCH : 50 / 50
VAL_LOSS : 0.018949365879122455 
VAL_ACCURACY : 0.9938875305623472
VAL_F1 : 0.99270072942411

# 5話-0
# 文: 今ハマってる本はこの二冊…
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-2.8708,  3.2211]], device='cuda:0')
# 5話-0
# 文: Bさん、苦手そうだよな…
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
tensor([[ 3.0838, -3.2289]], device='cuda:0')
# 5話-1
# 文: これ読んだよ
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 3.0650, -3.2155]], device='cuda:0')
# 5話-1
# 文: そうなんだ〜
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-1.8355,  1.9939]], device='cuda:0')
# 6話-0
# 文: ほとんど冷凍食品詰めただけだよ
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.8543,  1.5072]], device='cuda:0')
# 6話-0
# 文: 見てもいいですか?
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-2.5834,  2.2491]], device='cuda:0')
# 6話-0
# 文: どうぞどうぞ
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-2.5233,  2.3319]], device='cuda:0')
# 6話-1
# 文: 俺も今日弁当なんでおかず分けますよ
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-2.8714,  3.2284]], device='cuda:0')
# 7話-0
# 文: ジャーン!パフェを作ってみました〜!
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-2.6635,  2.7581]], device='cuda:0')
# 7話-1
# 文: ジャーン!パフェを作ってみました〜!
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-2.6635,  2.7581]], device='cuda:0')
# 7話-1
# 文: こうやっていろんな食べ方をすれば飽きないですね
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[0.3824, 0.7002]], device='cuda:0')
# 7話-1
# 文: とか言い出すのかと思った…
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.4449,  0.7239]], device='cuda:0')
# 7話-1
# 文: Aくんがいなければ独り占めできたのにな…
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
tensor([[ 1.1411, -0.9867]], device='cuda:0')
# 8話-1
# 文: でもわざわざ国際会議から送ってくれたんだよな…
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-1.5450,  2.0017]], device='cuda:0')
# 9話-0
# 文: あれ?スペインからもう戻ってきたのか.
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-2.8713,  3.2300]], device='cuda:0')
# 9話-0
# 文: Bさん…あれ?
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
tensor([[ 0.5509, -0.3816]], device='cuda:0')
# 9話-0
# 文: Bさ…ちょっと!
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
tensor([[ 2.8879, -2.6994]], device='cuda:0')
# 9話-1
# 文: ここは よその研究室…!?
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[ 3.0531, -3.1874]], device='cuda:0')
# 9話-1
# 文: ただいま〜
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-2.8692,  3.2012]], device='cuda:0')
# 9話-1
# 文: おかえりなさい!
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.4385,  0.7181]], device='cuda:0')
------------------------test acc------------------------
Test Acc : 0.6875
correct: 44, total: 64
------------------------------------------------
                  喜楽        その他  accuracy  macro avg  weighted avg
precision   0.571429   0.720000    0.6875   0.645714      0.668929
recall      0.363636   0.857143    0.6875   0.610390      0.687500
f1-score    0.444444   0.782609    0.6875   0.613527      0.666365
support    22.000000  42.000000    0.6875  64.000000     64.000000
正例のF1値 : 0.44444444394444443
