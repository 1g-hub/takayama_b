class weight : tensor([0.7389, 0.1767])
best:lr 3.6302642163115636e-07
class weight : tensor([0.7389, 0.1767])
best:lr 3.525641364127493e-07
EPOCH : 1 / 5
VAL_LOSS : 0.6647635113309931 
VAL_ACCURACY : 0.3414918414918415
VAL_F1 : 0.4021164017594715

EPOCH : 2 / 5
VAL_LOSS : 0.6484284036689334 
VAL_ACCURACY : 0.3543123543123543
VAL_F1 : 0.40811965776032544

EPOCH : 3 / 5
VAL_LOSS : 0.6334735867049959 
VAL_ACCURACY : 0.38927738927738925
VAL_F1 : 0.4229074886198185

EPOCH : 4 / 5
VAL_LOSS : 0.6176286963401018 
VAL_ACCURACY : 0.43123543123543123
VAL_F1 : 0.4429223740532125

EPOCH : 5 / 5
VAL_LOSS : 0.596963624159495 
VAL_ACCURACY : 0.47086247086247085
VAL_F1 : 0.46335697361046846

# 5話-0
# 文: 夏目漱石だよ? Aくんはどんな本を読むの
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 0.2246, -0.0141]], device='cuda:0')
# 5話-0
# 文: オススメの本教えて
正解 : 1 , 予測 : 0 / 元クラス : UNK
tensor([[0.2388, 0.1076]], device='cuda:0')
# 5話-0
# 文: 今ハマってる本はこの二冊…
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
tensor([[ 0.3491, -0.1270]], device='cuda:0')
# 5話-0
# 文: Bさん、苦手そうだよな…
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
tensor([[ 0.3399, -0.0752]], device='cuda:0')
# 5話-0
# 文: 小説はあまり読まないのですが、研究で利用している青空文庫の作品なら少々
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 0.2725, -0.1156]], device='cuda:0')
# 5話-0
# 文: そうなんだ?
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 0.4068, -0.4031]], device='cuda:0')
# 5話-0
# 文: あと、これも読んだよ
正解 : 1 , 予測 : 0 / 元クラス : 憤怒
tensor([[ 0.4210, -0.4284]], device='cuda:0')
# 5話-1
# 文: ありがとうございます…それ何読んでるんですか?
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 0.4415, -0.2861]], device='cuda:0')
# 5話-1
# 文: 夏目漱石だよ? Aくんはどんな本を読むの
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 0.2246, -0.0141]], device='cuda:0')
# 5話-1
# 文: オススメの本教えて
正解 : 1 , 予測 : 0 / 元クラス : UNK
tensor([[0.2388, 0.1076]], device='cuda:0')
# 5話-1
# 文: 小説はあまり読まないのですが 研究で利用している青空文庫の作品なら少々
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 0.2912, -0.1113]], device='cuda:0')
# 5話-1
# 文: そうなんだ?
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 0.4068, -0.4031]], device='cuda:0')
# 5話-1
# 文: 本当に今ハマってる本はこの二冊…
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
tensor([[-0.0111, -0.4368]], device='cuda:0')
# 6話-0
# 文: 父の分と2つ作ったの
正解 : 1 , 予測 : 0 / 元クラス : UNK
tensor([[ 0.3300, -0.4518]], device='cuda:0')
# 6話-0
# 文: ほとんど冷凍食品詰めただけだよ
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[0.1409, 0.0757]], device='cuda:0')
# 6話-0
# 文: どうぞどうぞ
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.0134,  0.2658]], device='cuda:0')
# 6話-0
# 文: キャー!
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[ 0.4624, -0.2606]], device='cuda:0')
# 6話-1
# 文: キャー!
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[ 0.4624, -0.2606]], device='cuda:0')
# 6話-1
# 文: ええ…父の分と2つ作ったんだけど
正解 : 1 , 予測 : 0 / 元クラス : UNK
tensor([[ 0.2048, -0.2702]], device='cuda:0')
# 6話-1
# 文: 入れ替わってしまったみたい
正解 : 1 , 予測 : 0 / 元クラス : UNK
tensor([[0.3129, 0.1311]], device='cuda:0')
# 6話-1
# 文: ほとんど冷凍食品詰めただけだよ…
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
tensor([[0.2576, 0.0612]], device='cuda:0')
# 6話-1
# 文: 俺も今日弁当なんでおかず分けますよ
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
tensor([[ 0.2548, -0.2542]], device='cuda:0')
# 7話-0
# 文: チョコは一つしかないし、悪いよ?
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[0.0856, 0.0830]], device='cuda:0')
# 7話-0
# 文: はんぶんこしよっか
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[0.1356, 0.1542]], device='cuda:0')
# 7話-0
# 文: とか言い出すのかな…
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.0879,  0.2544]], device='cuda:0')
# 7話-1
# 文: こうやっていろんな食べ方をすれば飽きないですね
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
tensor([[0.1183, 0.0914]], device='cuda:0')
# 7話-1
# 文: 差し入れでもらったこの大量のアイスも
正解 : 1 , 予測 : 0 / 元クラス : UNK
tensor([[ 0.2234, -0.4126]], device='cuda:0')
# 7話-1
# 文: チョコ一つしかないね はんぶんこしよっか
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 0.1158, -0.0652]], device='cuda:0')
# 7話-1
# 文: Aくんがいなければ独り占めできたのにな…
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
tensor([[ 0.4309, -0.1336]], device='cuda:0')
# 8話-0
# 文: 国際会議でスペインにいるBさんからだ
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[ 0.2833, -0.3949]], device='cuda:0')
# 8話-1
# 文: でもわざわざ国際会議から送ってくれたんだよな…
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
tensor([[ 0.1788, -0.2049]], device='cuda:0')
# 8話-1
# 文: もう少し頑張るか
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[0.1569, 0.2910]], device='cuda:0')
# 9話-0
# 文: あれ?スペインからもう戻ってきたのか
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[ 0.1885, -0.0824]], device='cuda:0')
# 9話-0
# 文: あれ？
正解 : 1 , 予測 : 0 / 元クラス : UNK
tensor([[ 0.1108, -0.0854]], device='cuda:0')
# 9話-0
# 文: 無視！？
正解 : 1 , 予測 : 0 / 元クラス : UNK
tensor([[0.2508, 0.2345]], device='cuda:0')
# 9話-1
# 文: ハッ
正解 : 1 , 予測 : 0 / 元クラス : UNK
tensor([[ 0.1239, -0.0193]], device='cuda:0')
# 9話-1
# 文: ここは よその研究室…!?
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[0.2237, 0.0880]], device='cuda:0')
# 9話-1
# 文: ただいま
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 0.1676, -0.0747]], device='cuda:0')
------------------------test acc------------------------
Test Acc : 0.5065
correct: 39, total: 77
------------------------------------------------
              喜楽        その他  accuracy  macro avg  weighted avg
precision   0.15   0.891892  0.506494   0.520946      0.795542
recall      0.60   0.492537  0.506494   0.546269      0.506494
f1-score    0.24   0.634615  0.506494   0.437308      0.583367
support    10.00  67.000000  0.506494  77.000000     77.000000
正例のF1値 : 0.2399999996704
class weight : tensor([0.7065, 0.2077])
best:lr 3.9909475334460455e-07
EPOCH : 1 / 50
VAL_LOSS : 0.6945624412322531 
VAL_ACCURACY : 0.7194337194337195
VAL_F1 : 0.2043795616618893

EPOCH : 2 / 50
VAL_LOSS : 0.6633226956639972 
VAL_ACCURACY : 0.7374517374517374
VAL_F1 : 0.3624999995355469

EPOCH : 3 / 50
VAL_LOSS : 0.6358294985732253 
VAL_ACCURACY : 0.767052767052767
VAL_F1 : 0.5370843984751802

EPOCH : 4 / 50
VAL_LOSS : 0.612722502679241 
VAL_ACCURACY : 0.7850707850707851
VAL_F1 : 0.6230248302000826

EPOCH : 5 / 50
VAL_LOSS : 0.5951217619740233 
VAL_ACCURACY : 0.7773487773487774
VAL_F1 : 0.6342494709655343

EPOCH : 6 / 50
VAL_LOSS : 0.5739583494711895 
VAL_ACCURACY : 0.7760617760617761
VAL_F1 : 0.6491935479002178

EPOCH : 7 / 50
VAL_LOSS : 0.5581698375088828 
VAL_ACCURACY : 0.7786357786357786
VAL_F1 : 0.6627450975566167

EPOCH : 8 / 50
VAL_LOSS : 0.5414561355600551 
VAL_ACCURACY : 0.7824967824967825
VAL_F1 : 0.6731141194422516

EPOCH : 9 / 50
VAL_LOSS : 0.5276157107888436 
VAL_ACCURACY : 0.7902187902187903
VAL_F1 : 0.6847195353029418

EPOCH : 10 / 50
VAL_LOSS : 0.5114337668126944 
VAL_ACCURACY : 0.7940797940797941
VAL_F1 : 0.6911196906395701

EPOCH : 11 / 50
VAL_LOSS : 0.4974286750871308 
VAL_ACCURACY : 0.7940797940797941
VAL_F1 : 0.6923076918282249

EPOCH : 12 / 50
VAL_LOSS : 0.48499467664835405 
VAL_ACCURACY : 0.797940797940798
VAL_F1 : 0.6963249511636319

EPOCH : 13 / 50
VAL_LOSS : 0.47181518953673696 
VAL_ACCURACY : 0.8018018018018018
VAL_F1 : 0.7015503871160839

EPOCH : 14 / 50
VAL_LOSS : 0.45445214607277695 
VAL_ACCURACY : 0.803088803088803
VAL_F1 : 0.7040618950707587

EPOCH : 15 / 50
VAL_LOSS : 0.4440260474779168 
VAL_ACCURACY : 0.8082368082368082
VAL_F1 : 0.7117988389778854

EPOCH : 16 / 50
VAL_LOSS : 0.4313052558169073 
VAL_ACCURACY : 0.8133848133848134
VAL_F1 : 0.718446601460541

EPOCH : 17 / 50
VAL_LOSS : 0.42483554871714846 
VAL_ACCURACY : 0.8172458172458172
VAL_F1 : 0.7226562495178072

EPOCH : 18 / 50
VAL_LOSS : 0.41127204834198466 
VAL_ACCURACY : 0.8185328185328186
VAL_F1 : 0.7262135917517731

EPOCH : 19 / 50
VAL_LOSS : 0.40249328041563226 
VAL_ACCURACY : 0.8236808236808236
VAL_F1 : 0.7329434693036642

EPOCH : 20 / 50
VAL_LOSS : 0.3919805963428653 
VAL_ACCURACY : 0.8275418275418276
VAL_F1 : 0.7372549014778932

EPOCH : 21 / 50
VAL_LOSS : 0.3837702055366672 
VAL_ACCURACY : 0.833976833976834
VAL_F1 : 0.7445544549610431

EPOCH : 22 / 50
VAL_LOSS : 0.3724840146546461 
VAL_ACCURACY : 0.8352638352638353
VAL_F1 : 0.7460317455469262

EPOCH : 23 / 50
VAL_LOSS : 0.36778492951879693 
VAL_ACCURACY : 0.842985842985843
VAL_F1 : 0.7550200798345833

EPOCH : 24 / 50
VAL_LOSS : 0.3560824591894539 
VAL_ACCURACY : 0.8455598455598455
VAL_F1 : 0.7590361440915954

EPOCH : 25 / 50
VAL_LOSS : 0.3502840068267316 
VAL_ACCURACY : 0.8481338481338482
VAL_F1 : 0.7620967737062142

EPOCH : 26 / 50
VAL_LOSS : 0.3428308787394543 
VAL_ACCURACY : 0.8507078507078507
VAL_F1 : 0.7651821857468734

EPOCH : 27 / 50
VAL_LOSS : 0.3373178261883405 
VAL_ACCURACY : 0.8558558558558559
VAL_F1 : 0.7723577230886709

EPOCH : 28 / 50
VAL_LOSS : 0.3285219836599973 
VAL_ACCURACY : 0.861003861003861
VAL_F1 : 0.7786885241004098

EPOCH : 29 / 50
VAL_LOSS : 0.32757089363068953 
VAL_ACCURACY : 0.8635778635778636
VAL_F1 : 0.7827868847561308

EPOCH : 30 / 50
VAL_LOSS : 0.32131592777310586 
VAL_ACCURACY : 0.8648648648648649
VAL_F1 : 0.784394250023283

EPOCH : 31 / 50
VAL_LOSS : 0.3127545832979436 
VAL_ACCURACY : 0.8661518661518661
VAL_F1 : 0.7860082299623194

EPOCH : 32 / 50
VAL_LOSS : 0.30674321158808104 
VAL_ACCURACY : 0.8674388674388674
VAL_F1 : 0.7876288654887362

EPOCH : 33 / 50
VAL_LOSS : 0.3035228337560381 
VAL_ACCURACY : 0.8687258687258688
VAL_F1 : 0.7901234562997511

EPOCH : 34 / 50
VAL_LOSS : 0.2968465801404447 
VAL_ACCURACY : 0.8725868725868726
VAL_F1 : 0.7958762881691147

EPOCH : 35 / 50
VAL_LOSS : 0.2901454596799247 
VAL_ACCURACY : 0.8751608751608752
VAL_F1 : 0.7999999995093039

EPOCH : 36 / 50
VAL_LOSS : 0.2854281262475617 
VAL_ACCURACY : 0.8777348777348777
VAL_F1 : 0.8033126289083155

EPOCH : 37 / 50
VAL_LOSS : 0.2828580861797138 
VAL_ACCURACY : 0.8815958815958816
VAL_F1 : 0.8091286302138221

EPOCH : 38 / 50
VAL_LOSS : 0.27730456633227213 
VAL_ACCURACY : 0.8803088803088803
VAL_F1 : 0.8074534156577807

EPOCH : 39 / 50
VAL_LOSS : 0.2771022036975744 
VAL_ACCURACY : 0.8828828828828829
VAL_F1 : 0.8108108103189562

EPOCH : 40 / 50
VAL_LOSS : 0.2676860649062663 
VAL_ACCURACY : 0.888030888030888
VAL_F1 : 0.8176100624001161

EPOCH : 41 / 50
VAL_LOSS : 0.2687388591620387 
VAL_ACCURACY : 0.8867438867438867
VAL_F1 : 0.8158995810972672

EPOCH : 42 / 50
VAL_LOSS : 0.2644819624874057 
VAL_ACCURACY : 0.8867438867438867
VAL_F1 : 0.8158995810972672

EPOCH : 43 / 50
VAL_LOSS : 0.2577040085987169 
VAL_ACCURACY : 0.8906048906048906
VAL_F1 : 0.8210526310854381

EPOCH : 44 / 50
VAL_LOSS : 0.25418866045620975 
VAL_ACCURACY : 0.8944658944658944
VAL_F1 : 0.8262711859463696

EPOCH : 45 / 50
VAL_LOSS : 0.2519744736503582 
VAL_ACCURACY : 0.8970398970398971
VAL_F1 : 0.8297872335477229

EPOCH : 46 / 50
VAL_LOSS : 0.25335800328425 
VAL_ACCURACY : 0.8970398970398971
VAL_F1 : 0.8297872335477229

EPOCH : 47 / 50
VAL_LOSS : 0.2453160588534511 
VAL_ACCURACY : 0.8957528957528957
VAL_F1 : 0.828025477212436

EPOCH : 48 / 50
VAL_LOSS : 0.2422497635897325 
VAL_ACCURACY : 0.8957528957528957
VAL_F1 : 0.828025477212436

EPOCH : 49 / 50
VAL_LOSS : 0.23589100430206378 
VAL_ACCURACY : 0.8983268983268984
VAL_F1 : 0.8315565027032066

EPOCH : 50 / 50
VAL_LOSS : 0.2411114016965944 
VAL_ACCURACY : 0.8983268983268984
VAL_F1 : 0.8322717617134796

# 5話-0
# 文: 何読んでるんですか?
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[0.2297, 0.1543]], device='cuda:0')
# 5話-0
# 文: Bさん、苦手そうだよな…
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
tensor([[ 0.3587, -0.2456]], device='cuda:0')
# 5話-0
# 文: 適当に流そう
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 0.3235, -0.0150]], device='cuda:0')
# 5話-0
# 文: そうなんだ?
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[0.4905, 0.0080]], device='cuda:0')
# 5話-0
# 文: 適当に流したな
正解 : 1 , 予測 : 0 / 元クラス : 憤怒
tensor([[ 0.4687, -0.2303]], device='cuda:0')
# 5話-0
# 文: あと、これも読んだよ
正解 : 1 , 予測 : 0 / 元クラス : 憤怒
tensor([[ 0.2318, -0.3302]], device='cuda:0')
# 5話-1
# 文: これ読んだよ
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 0.2058, -0.2687]], device='cuda:0')
# 5話-1
# 文: そうなんだ?
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[0.4905, 0.0080]], device='cuda:0')
# 5話-1
# 文: 本当に今ハマってる本はこの二冊…
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
tensor([[ 0.2080, -0.5140]], device='cuda:0')
# 6話-0
# 文: 手作りなんですか?
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 0.0845, -0.1054]], device='cuda:0')
# 6話-0
# 文: キャー!
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[ 0.7534, -0.3539]], device='cuda:0')
# 6話-1
# 文: キャー!
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[ 0.7534, -0.3539]], device='cuda:0')
# 6話-1
# 文: 手作りなんですか?
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
tensor([[ 0.0845, -0.1054]], device='cuda:0')
# 7話-0
# 文: どれがいいですか?
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 0.2331, -0.2250]], device='cuda:0')
# 7話-0
# 文: とか言い出すのかな…
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.0718,  0.4700]], device='cuda:0')
# 7話-1
# 文: チョコ一つしかないね はんぶんこしよっか
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 0.6110, -1.1152]], device='cuda:0')
# 7話-1
# 文: Aくんがいなければ独り占めできたのにな…
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
tensor([[ 0.4738, -0.2553]], device='cuda:0')
# 8話-0
# 文: 今日は良い実験結果が出たな
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.6504,  0.4560]], device='cuda:0')
# 8話-0
# 文: 国際会議でスペインにいるBさんからだ
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[ 0.3812, -0.2333]], device='cuda:0')
# 8話-1
# 文: でもわざわざ国際会議から送ってくれたんだよな…
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
tensor([[ 0.3901, -0.7973]], device='cuda:0')
# 9話-0
# 文: Bさ…ちょっと!
正解 : 1 , 予測 : 0 / 元クラス : 憤怒
tensor([[ 0.1680, -0.3724]], device='cuda:0')
------------------------test acc------------------------
Test Acc : 0.6818
correct: 45, total: 66
------------------------------------------------
                  喜楽        その他  accuracy  macro avg  weighted avg
precision   0.296296   0.948718  0.681818   0.622507      0.849866
recall      0.800000   0.660714  0.681818   0.730357      0.681818
f1-score    0.432432   0.778947  0.681818   0.605690      0.726445
support    10.000000  56.000000  0.681818  66.000000     66.000000
正例のF1値 : 0.4324324320146092
class weight : tensor([0.7065, 0.2077])
best:lr 1.5336146124988728e-06
EPOCH : 1 / 50
VAL_LOSS : 0.6041214131579107 
VAL_ACCURACY : 0.5366795366795367
VAL_F1 : 0.5212765953479233

EPOCH : 2 / 50
VAL_LOSS : 0.5382209116098832 
VAL_ACCURACY : 0.6846846846846847
VAL_F1 : 0.6141732279084184

EPOCH : 3 / 50
VAL_LOSS : 0.4891508209462069 
VAL_ACCURACY : 0.7348777348777349
VAL_F1 : 0.652027026573126

EPOCH : 4 / 50
VAL_LOSS : 0.44608243874141146 
VAL_ACCURACY : 0.7824967824967825
VAL_F1 : 0.6910420470617529

EPOCH : 5 / 50
VAL_LOSS : 0.4033941906325671 
VAL_ACCURACY : 0.8056628056628057
VAL_F1 : 0.7177570088712867

EPOCH : 6 / 50
VAL_LOSS : 0.37016275981251073 
VAL_ACCURACY : 0.8198198198198198
VAL_F1 : 0.7318007658045684

EPOCH : 7 / 50
VAL_LOSS : 0.34965832105704714 
VAL_ACCURACY : 0.8365508365508365
VAL_F1 : 0.749506902869165

EPOCH : 8 / 50
VAL_LOSS : 0.32249336644094817 
VAL_ACCURACY : 0.8558558558558559
VAL_F1 : 0.7732793517387436

EPOCH : 9 / 50
VAL_LOSS : 0.30250644835890556 
VAL_ACCURACY : 0.8725868725868726
VAL_F1 : 0.7941787936870088

EPOCH : 10 / 50
VAL_LOSS : 0.2856757157311148 
VAL_ACCURACY : 0.8751608751608752
VAL_F1 : 0.7974947803009749

EPOCH : 11 / 50
VAL_LOSS : 0.2738323622212118 
VAL_ACCURACY : 0.8918918918918919
VAL_F1 : 0.8189655167451323

EPOCH : 12 / 50
VAL_LOSS : 0.2590556845677142 
VAL_ACCURACY : 0.8957528957528957
VAL_F1 : 0.8272921103791309

EPOCH : 13 / 50
VAL_LOSS : 0.24519015331657565 
VAL_ACCURACY : 0.9047619047619048
VAL_F1 : 0.8398268393300351

EPOCH : 14 / 50
VAL_LOSS : 0.2364731155792061 
VAL_ACCURACY : 0.9163449163449163
VAL_F1 : 0.8571428566444247

EPOCH : 15 / 50
VAL_LOSS : 0.2262564505241355 
VAL_ACCURACY : 0.9227799227799228
VAL_F1 : 0.8666666661671704

EPOCH : 16 / 50
VAL_LOSS : 0.21650816576213253 
VAL_ACCURACY : 0.924066924066924
VAL_F1 : 0.868596881460211

EPOCH : 17 / 50
VAL_LOSS : 0.2028742902437035 
VAL_ACCURACY : 0.9292149292149292
VAL_F1 : 0.8764044938815402

EPOCH : 18 / 50
VAL_LOSS : 0.19987721330657296 
VAL_ACCURACY : 0.9305019305019305
VAL_F1 : 0.877828053797629

EPOCH : 19 / 50
VAL_LOSS : 0.18813457020691463 
VAL_ACCURACY : 0.9330759330759331
VAL_F1 : 0.8823529406754367

EPOCH : 20 / 50
VAL_LOSS : 0.18208760540096128 
VAL_ACCURACY : 0.9343629343629344
VAL_F1 : 0.8843537409953878

EPOCH : 21 / 50
VAL_LOSS : 0.17704900665854922 
VAL_ACCURACY : 0.9369369369369369
VAL_F1 : 0.8888888883876574

EPOCH : 22 / 50
VAL_LOSS : 0.17181181709985344 
VAL_ACCURACY : 0.9369369369369369
VAL_F1 : 0.8888888883876574

EPOCH : 23 / 50
VAL_LOSS : 0.16698209728513444 
VAL_ACCURACY : 0.9395109395109396
VAL_F1 : 0.8929384960815687

EPOCH : 24 / 50
VAL_LOSS : 0.16036342411321036 
VAL_ACCURACY : 0.9459459459459459
VAL_F1 : 0.9036697242685591

EPOCH : 25 / 50
VAL_LOSS : 0.15692976063915662 
VAL_ACCURACY : 0.9446589446589446
VAL_F1 : 0.9016018301616913

EPOCH : 26 / 50
VAL_LOSS : 0.15171987434126893 
VAL_ACCURACY : 0.9446589446589446
VAL_F1 : 0.9016018301616913

EPOCH : 27 / 50
VAL_LOSS : 0.1460059184048857 
VAL_ACCURACY : 0.9446589446589446
VAL_F1 : 0.9016018301616913

EPOCH : 28 / 50
VAL_LOSS : 0.14517247030625538 
VAL_ACCURACY : 0.9485199485199485
VAL_F1 : 0.9078341008800994

EPOCH : 29 / 50
VAL_LOSS : 0.14106251922797183 
VAL_ACCURACY : 0.9498069498069498
VAL_F1 : 0.9099307154327988

EPOCH : 30 / 50
VAL_LOSS : 0.1343145507330797 
VAL_ACCURACY : 0.9498069498069498
VAL_F1 : 0.9099307154327988

EPOCH : 31 / 50
VAL_LOSS : 0.13633333313830046 
VAL_ACCURACY : 0.9498069498069498
VAL_F1 : 0.9103448270839477

EPOCH : 32 / 50
VAL_LOSS : 0.1313195645200963 
VAL_ACCURACY : 0.9523809523809523
VAL_F1 : 0.9145496530771192

EPOCH : 33 / 50
VAL_LOSS : 0.12892586418560573 
VAL_ACCURACY : 0.9536679536679536
VAL_F1 : 0.916666666163966

EPOCH : 34 / 50
VAL_LOSS : 0.12751634073044574 
VAL_ACCURACY : 0.954954954954955
VAL_F1 : 0.9187935029774388

EPOCH : 35 / 50
VAL_LOSS : 0.12800651632857565 
VAL_ACCURACY : 0.9498069498069498
VAL_F1 : 0.9103448270839477

EPOCH : 36 / 50
VAL_LOSS : 0.12885556195159348 
VAL_ACCURACY : 0.9485199485199485
VAL_F1 : 0.9082568802318408

EPOCH : 37 / 50
VAL_LOSS : 0.12470364053638613 
VAL_ACCURACY : 0.9485199485199485
VAL_F1 : 0.9082568802318408

EPOCH : 38 / 50
VAL_LOSS : 0.11982387045816499 
VAL_ACCURACY : 0.9575289575289575
VAL_F1 : 0.9234338742071156

EPOCH : 39 / 50
VAL_LOSS : 0.11572031897245622 
VAL_ACCURACY : 0.9588159588159588
VAL_F1 : 0.9255813948458411

EPOCH : 40 / 50
VAL_LOSS : 0.119030322917566 
VAL_ACCURACY : 0.9601029601029601
VAL_F1 : 0.9277389272358009

EPOCH : 41 / 50
VAL_LOSS : 0.11727332559471228 
VAL_ACCURACY : 0.9613899613899614
VAL_F1 : 0.9302325576365171

EPOCH : 42 / 50
VAL_LOSS : 0.10925431454516187 
VAL_ACCURACY : 0.9613899613899614
VAL_F1 : 0.9302325576365171

EPOCH : 43 / 50
VAL_LOSS : 0.11133201743419073 
VAL_ACCURACY : 0.9613899613899614
VAL_F1 : 0.9302325576365171

EPOCH : 44 / 50
VAL_LOSS : 0.10908994188874352 
VAL_ACCURACY : 0.9613899613899614
VAL_F1 : 0.9302325576365171

EPOCH : 45 / 50
VAL_LOSS : 0.1086168603173324 
VAL_ACCURACY : 0.9613899613899614
VAL_F1 : 0.9302325576365171

EPOCH : 46 / 50
VAL_LOSS : 0.10292292690398741 
VAL_ACCURACY : 0.9613899613899614
VAL_F1 : 0.9302325576365171

EPOCH : 47 / 50
VAL_LOSS : 0.10667962987660146 
VAL_ACCURACY : 0.9613899613899614
VAL_F1 : 0.9302325576365171

EPOCH : 48 / 50
VAL_LOSS : 0.10644295279468809 
VAL_ACCURACY : 0.9613899613899614
VAL_F1 : 0.9302325576365171

EPOCH : 49 / 50
VAL_LOSS : 0.10249821552816703 
VAL_ACCURACY : 0.9613899613899614
VAL_F1 : 0.9302325576365171

EPOCH : 50 / 50
VAL_LOSS : 0.1070599207768635 
VAL_ACCURACY : 0.9613899613899614
VAL_F1 : 0.9302325576365171

# 5話-0
# 文: Bさん、苦手そうだよな…
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
tensor([[ 0.1601, -0.0700]], device='cuda:0')
# 5話-0
# 文: あと、これも読んだよ
正解 : 1 , 予測 : 0 / 元クラス : 憤怒
tensor([[ 0.4391, -0.3703]], device='cuda:0')
# 5話-1
# 文: これ読んだよ
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 0.6881, -1.0329]], device='cuda:0')
# 6話-0
# 文: そうなんだ?
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.8003,  1.0609]], device='cuda:0')
# 6話-0
# 文: キャー!
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[ 0.0516, -0.1267]], device='cuda:0')
# 6話-1
# 文: キャー!
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[ 0.0516, -0.1267]], device='cuda:0')
# 7話-0
# 文: とか言い出すのかな…
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.2266,  0.3148]], device='cuda:0')
# 7話-0
# 文: ジャーン!パフェを作ってみました?!
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.5419,  0.4571]], device='cuda:0')
# 7話-1
# 文: ジャーン!パフェを作ってみました?!
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.5419,  0.4571]], device='cuda:0')
# 7話-1
# 文: チョコ一つしかないね はんぶんこしよっか
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 0.9220, -1.0416]], device='cuda:0')
# 8話-0
# 文: 今日は良い実験結果が出たな
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-1.4908,  1.6489]], device='cuda:0')
# 8話-0
# 文: 国際会議でスペインにいるBさんからだ
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[ 0.4219, -1.1270]], device='cuda:0')
# 8話-1
# 文: でもわざわざ国際会議から送ってくれたんだよな…
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
tensor([[ 0.2177, -0.3602]], device='cuda:0')
# 8話-1
# 文: もう少し頑張るか
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.3217,  0.3622]], device='cuda:0')
# 9話-0
# 文: Bさ…ちょっと!
正解 : 1 , 予測 : 0 / 元クラス : 憤怒
tensor([[ 1.1133, -1.5804]], device='cuda:0')
# 9話-1
# 文: ここは よその研究室…!?
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[-0.0787, -0.2048]], device='cuda:0')
# 9話-1
# 文: おかえりなさい!
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.3744,  0.2242]], device='cuda:0')
------------------------test acc------------------------
Test Acc : 0.7424
correct: 49, total: 66
------------------------------------------------
                  喜楽        その他  accuracy  macro avg  weighted avg
precision   0.230769   0.867925  0.742424   0.549347      0.771386
recall      0.300000   0.821429  0.742424   0.560714      0.742424
f1-score    0.260870   0.844037  0.742424   0.552453      0.755678
support    10.000000  56.000000  0.742424  66.000000     66.000000
正例のF1値 : 0.26086956470321365
class weight : tensor([0.7065, 0.2077])
best:lr 3.327819596641876e-06
EPOCH : 1 / 50
VAL_LOSS : 0.524013092931436 
VAL_ACCURACY : 0.7374517374517374
VAL_F1 : 0.6518771326497106

EPOCH : 2 / 50
VAL_LOSS : 0.42441994742471345 
VAL_ACCURACY : 0.7915057915057915
VAL_F1 : 0.7022058818816096

EPOCH : 3 / 50
VAL_LOSS : 0.3523364054913424 
VAL_ACCURACY : 0.8391248391248392
VAL_F1 : 0.7514910531927798

EPOCH : 4 / 50
VAL_LOSS : 0.30904899750437054 
VAL_ACCURACY : 0.8545688545688546
VAL_F1 : 0.7679671453005579

EPOCH : 5 / 50
VAL_LOSS : 0.2672934802819271 
VAL_ACCURACY : 0.8931788931788932
VAL_F1 : 0.8191721127923639

EPOCH : 6 / 50
VAL_LOSS : 0.24460795825841475 
VAL_ACCURACY : 0.8983268983268984
VAL_F1 : 0.8293736496114643

EPOCH : 7 / 50
VAL_LOSS : 0.2213847346755923 
VAL_ACCURACY : 0.9176319176319176
VAL_F1 : 0.8584070791469575

EPOCH : 8 / 50
VAL_LOSS : 0.19990917371243846 
VAL_ACCURACY : 0.9343629343629344
VAL_F1 : 0.8843537409953878

EPOCH : 9 / 50
VAL_LOSS : 0.1835742498538932 
VAL_ACCURACY : 0.9382239382239382
VAL_F1 : 0.8914027144310519

EPOCH : 10 / 50
VAL_LOSS : 0.16918286658367332 
VAL_ACCURACY : 0.9395109395109396
VAL_F1 : 0.8929384960815687

EPOCH : 11 / 50
VAL_LOSS : 0.16583167487869457 
VAL_ACCURACY : 0.9433719433719434
VAL_F1 : 0.8990825683052773

EPOCH : 12 / 50
VAL_LOSS : 0.15291508819375718 
VAL_ACCURACY : 0.9446589446589446
VAL_F1 : 0.9016018301616913

EPOCH : 13 / 50
VAL_LOSS : 0.1429842444402831 
VAL_ACCURACY : 0.9459459459459459
VAL_F1 : 0.9045454540439877

EPOCH : 14 / 50
VAL_LOSS : 0.1466525786993455 
VAL_ACCURACY : 0.9459459459459459
VAL_F1 : 0.9045454540439877

EPOCH : 15 / 50
VAL_LOSS : 0.13488970058304922 
VAL_ACCURACY : 0.9485199485199485
VAL_F1 : 0.9086757985849546

EPOCH : 16 / 50
VAL_LOSS : 0.12805496703605262 
VAL_ACCURACY : 0.9523809523809523
VAL_F1 : 0.9149425282333518

EPOCH : 17 / 50
VAL_LOSS : 0.12667005942488202 
VAL_ACCURACY : 0.9498069498069498
VAL_F1 : 0.9107551482394525

EPOCH : 18 / 50
VAL_LOSS : 0.1268955785781145 
VAL_ACCURACY : 0.954954954954955
VAL_F1 : 0.9191685907214399

EPOCH : 19 / 50
VAL_LOSS : 0.11854323733369915 
VAL_ACCURACY : 0.9562419562419563
VAL_F1 : 0.920930232055165

EPOCH : 20 / 50
VAL_LOSS : 0.11836075938629861 
VAL_ACCURACY : 0.9575289575289575
VAL_F1 : 0.9237875283657602

EPOCH : 21 / 50
VAL_LOSS : 0.11387218386695093 
VAL_ACCURACY : 0.9575289575289575
VAL_F1 : 0.9237875283657602

EPOCH : 22 / 50
VAL_LOSS : 0.10888726279443624 
VAL_ACCURACY : 0.9626769626769627
VAL_F1 : 0.9324009318977838

EPOCH : 23 / 50
VAL_LOSS : 0.10573005934759062 
VAL_ACCURACY : 0.9575289575289575
VAL_F1 : 0.9237875283657602

EPOCH : 24 / 50
VAL_LOSS : 0.10308769117204511 
VAL_ACCURACY : 0.9601029601029601
VAL_F1 : 0.9280742454367925

EPOCH : 25 / 50
VAL_LOSS : 0.1005504443405234 
VAL_ACCURACY : 0.9626769626769627
VAL_F1 : 0.9327146166664694

EPOCH : 26 / 50
VAL_LOSS : 0.10409104949509611 
VAL_ACCURACY : 0.9613899613899614
VAL_F1 : 0.9305555550527906

EPOCH : 27 / 50
VAL_LOSS : 0.10056626948775077 
VAL_ACCURACY : 0.9626769626769627
VAL_F1 : 0.9327146166664694

EPOCH : 28 / 50
VAL_LOSS : 0.10178328005178851 
VAL_ACCURACY : 0.9613899613899614
VAL_F1 : 0.9299065415528213

EPOCH : 29 / 50
VAL_LOSS : 0.10053496606343863 
VAL_ACCURACY : 0.9626769626769627
VAL_F1 : 0.9330254036544011

EPOCH : 30 / 50
VAL_LOSS : 0.09751781965700948 
VAL_ACCURACY : 0.963963963963964
VAL_F1 : 0.9351851846823989

EPOCH : 31 / 50
VAL_LOSS : 0.09518140820520264 
VAL_ACCURACY : 0.963963963963964
VAL_F1 : 0.9351851846823989

EPOCH : 32 / 50
VAL_LOSS : 0.09824277038628958 
VAL_ACCURACY : 0.9613899613899614
VAL_F1 : 0.9302325576365171

EPOCH : 33 / 50
VAL_LOSS : 0.09475979687912124 
VAL_ACCURACY : 0.963963963963964
VAL_F1 : 0.9351851846823989

EPOCH : 34 / 50
VAL_LOSS : 0.09461975150874682 
VAL_ACCURACY : 0.963963963963964
VAL_F1 : 0.9351851846823989

EPOCH : 35 / 50
VAL_LOSS : 0.09180351833299714 
VAL_ACCURACY : 0.963963963963964
VAL_F1 : 0.9348837204271931

EPOCH : 36 / 50
VAL_LOSS : 0.08800284556892453 
VAL_ACCURACY : 0.963963963963964
VAL_F1 : 0.9351851846823989

EPOCH : 37 / 50
VAL_LOSS : 0.08653453672874947 
VAL_ACCURACY : 0.9626769626769627
VAL_F1 : 0.9324009318977838

EPOCH : 38 / 50
VAL_LOSS : 0.08994607494345733 
VAL_ACCURACY : 0.9613899613899614
VAL_F1 : 0.9305555550527906

EPOCH : 39 / 50
VAL_LOSS : 0.08634941755052732 
VAL_ACCURACY : 0.9626769626769627
VAL_F1 : 0.9327146166664694

EPOCH : 40 / 50
VAL_LOSS : 0.08782102209420836 
VAL_ACCURACY : 0.963963963963964
VAL_F1 : 0.9348837204271931

EPOCH : 41 / 50
VAL_LOSS : 0.08214059147071473 
VAL_ACCURACY : 0.963963963963964
VAL_F1 : 0.9351851846823989

EPOCH : 42 / 50
VAL_LOSS : 0.08115247211286 
VAL_ACCURACY : 0.963963963963964
VAL_F1 : 0.9348837204271931

EPOCH : 43 / 50
VAL_LOSS : 0.08443861952697744 
VAL_ACCURACY : 0.9652509652509652
VAL_F1 : 0.9370629365597666

EPOCH : 44 / 50
VAL_LOSS : 0.0818000434308636 
VAL_ACCURACY : 0.9652509652509652
VAL_F1 : 0.9370629365597666

EPOCH : 45 / 50
VAL_LOSS : 0.08497410193465803 
VAL_ACCURACY : 0.9575289575289575
VAL_F1 : 0.9241379305321602

EPOCH : 46 / 50
VAL_LOSS : 0.0834676190564523 
VAL_ACCURACY : 0.9575289575289575
VAL_F1 : 0.9241379305321602

EPOCH : 47 / 50
VAL_LOSS : 0.08005412491228507 
VAL_ACCURACY : 0.963963963963964
VAL_F1 : 0.9348837204271931

EPOCH : 48 / 50
VAL_LOSS : 0.08186933483776389 
VAL_ACCURACY : 0.963963963963964
VAL_F1 : 0.9348837204271931

EPOCH : 49 / 50
VAL_LOSS : 0.07682853000124498 
VAL_ACCURACY : 0.963963963963964
VAL_F1 : 0.9348837204271931

EPOCH : 50 / 50
VAL_LOSS : 0.0755768329931461 
VAL_ACCURACY : 0.963963963963964
VAL_F1 : 0.9348837204271931

# 5話-0
# 文: 適当に流したな
正解 : 1 , 予測 : 0 / 元クラス : 憤怒
tensor([[ 0.1899, -0.3520]], device='cuda:0')
# 6話-0
# 文: そうなんだ?
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-1.4745,  1.9857]], device='cuda:0')
# 7話-0
# 文: とか言い出すのかな…
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.0969,  0.5946]], device='cuda:0')
# 7話-0
# 文: ジャーン!パフェを作ってみました?!
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-1.2031,  1.4468]], device='cuda:0')
# 7話-1
# 文: ジャーン!パフェを作ってみました?!
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-1.2031,  1.4468]], device='cuda:0')
# 7話-1
# 文: チョコ一つしかないね はんぶんこしよっか
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 1.7448, -1.7893]], device='cuda:0')
# 8話-0
# 文: 今日は良い実験結果が出たな
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-1.6257,  2.1881]], device='cuda:0')
# 8話-0
# 文: 国際会議でスペインにいるBさんからだ
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[ 0.9024, -0.6394]], device='cuda:0')
# 8話-1
# 文: でもわざわざ国際会議から送ってくれたんだよな…
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
tensor([[ 0.5126, -0.5716]], device='cuda:0')
# 8話-1
# 文: もう少し頑張るか
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.1902,  0.4943]], device='cuda:0')
# 9話-0
# 文: Bさ…ちょっと!
正解 : 1 , 予測 : 0 / 元クラス : 憤怒
tensor([[ 1.7549, -1.8137]], device='cuda:0')
# 9話-1
# 文: おかえりなさい!
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.4582,  1.0222]], device='cuda:0')
------------------------test acc------------------------
Test Acc : 0.8182
correct: 54, total: 66
------------------------------------------------
                  喜楽        その他  accuracy  macro avg  weighted avg
precision   0.375000   0.879310  0.818182   0.627155      0.802900
recall      0.300000   0.910714  0.818182   0.605357      0.818182
f1-score    0.333333   0.894737  0.818182   0.614035      0.809676
support    10.000000  56.000000  0.818182  66.000000     66.000000
正例のF1値 : 0.3333333328024692
class weight : tensor([0.7065, 0.2077])
best:lr 3.5677143805433637e-05
EPOCH : 1 / 50
VAL_LOSS : 0.19021671440224258 
VAL_ACCURACY : 0.9124839124839125
VAL_F1 : 0.8547008542054204

EPOCH : 2 / 50
VAL_LOSS : 0.12557725996083144 
VAL_ACCURACY : 0.9472329472329473
VAL_F1 : 0.9074492094313041

EPOCH : 3 / 50
VAL_LOSS : 0.0960573425934631 
VAL_ACCURACY : 0.9601029601029601
VAL_F1 : 0.9290617843949752

EPOCH : 4 / 50
VAL_LOSS : 0.08452894447409377 
VAL_ACCURACY : 0.9652509652509652
VAL_F1 : 0.9370629365597666

EPOCH : 5 / 50
VAL_LOSS : 0.08221587268825696 
VAL_ACCURACY : 0.963963963963964
VAL_F1 : 0.9345794387490611

EPOCH : 6 / 50
VAL_LOSS : 0.07921290473670375 
VAL_ACCURACY : 0.9575289575289575
VAL_F1 : 0.9248291566736786

EPOCH : 7 / 50
VAL_LOSS : 0.07280846934157367 
VAL_ACCURACY : 0.963963963963964
VAL_F1 : 0.9357798160115312

EPOCH : 8 / 50
VAL_LOSS : 0.0731257495793457 
VAL_ACCURACY : 0.9613899613899614
VAL_F1 : 0.9311926600482494

EPOCH : 9 / 50
VAL_LOSS : 0.06693213165034445 
VAL_ACCURACY : 0.9665379665379665
VAL_F1 : 0.9398148143120071

EPOCH : 10 / 50
VAL_LOSS : 0.06741726872682267 
VAL_ACCURACY : 0.9678249678249679
VAL_F1 : 0.9417249412217495

EPOCH : 11 / 50
VAL_LOSS : 0.0761032523682379 
VAL_ACCURACY : 0.9588159588159588
VAL_F1 : 0.9269406387675195

EPOCH : 12 / 50
VAL_LOSS : 0.06032165126608951 
VAL_ACCURACY : 0.9703989703989704
VAL_F1 : 0.9463869458837324

EPOCH : 13 / 50
VAL_LOSS : 0.06193462399081612 
VAL_ACCURACY : 0.9703989703989704
VAL_F1 : 0.9466357303554999

EPOCH : 14 / 50
VAL_LOSS : 0.0576613363334719 
VAL_ACCURACY : 0.9703989703989704
VAL_F1 : 0.9466357303554999

EPOCH : 15 / 50
VAL_LOSS : 0.06103309207804957 
VAL_ACCURACY : 0.9665379665379665
VAL_F1 : 0.9392523359453009

EPOCH : 16 / 50
VAL_LOSS : 0.0634474453174186 
VAL_ACCURACY : 0.9626769626769627
VAL_F1 : 0.9317647053787682

EPOCH : 17 / 50
VAL_LOSS : 0.06352171879641864 
VAL_ACCURACY : 0.9588159588159588
VAL_F1 : 0.9266055040849677

EPOCH : 18 / 50
VAL_LOSS : 0.06742253462422867 
VAL_ACCURACY : 0.9652509652509652
VAL_F1 : 0.9373549878961462

EPOCH : 19 / 50
VAL_LOSS : 0.0654304969808733 
VAL_ACCURACY : 0.9665379665379665
VAL_F1 : 0.9395348832178692

EPOCH : 20 / 50
VAL_LOSS : 0.06094831564672747 
VAL_ACCURACY : 0.9678249678249679
VAL_F1 : 0.9417249412217495

EPOCH : 21 / 50
VAL_LOSS : 0.06161724348381466 
VAL_ACCURACY : 0.9575289575289575
VAL_F1 : 0.9244851253560944

EPOCH : 22 / 50
VAL_LOSS : 0.06997690177807699 
VAL_ACCURACY : 0.963963963963964
VAL_F1 : 0.9348837204271931

EPOCH : 23 / 50
VAL_LOSS : 0.06559959046865757 
VAL_ACCURACY : 0.9652509652509652
VAL_F1 : 0.9370629365597666

EPOCH : 24 / 50
VAL_LOSS : 0.06331151781831773 
VAL_ACCURACY : 0.9665379665379665
VAL_F1 : 0.9395348832178692

EPOCH : 25 / 50
VAL_LOSS : 0.06319362342794788 
VAL_ACCURACY : 0.9613899613899614
VAL_F1 : 0.9308755755343712

EPOCH : 26 / 50
VAL_LOSS : 0.06281763732395305 
VAL_ACCURACY : 0.9652509652509652
VAL_F1 : 0.9373549878961462

EPOCH : 27 / 50
VAL_LOSS : 0.056226528377975434 
VAL_ACCURACY : 0.9703989703989704
VAL_F1 : 0.9466357303554999

EPOCH : 28 / 50
VAL_LOSS : 0.060693914398589004 
VAL_ACCURACY : 0.9703989703989704
VAL_F1 : 0.9466357303554999

EPOCH : 29 / 50
VAL_LOSS : 0.06656078450685861 
VAL_ACCURACY : 0.963963963963964
VAL_F1 : 0.93427229996599

EPOCH : 30 / 50
VAL_LOSS : 0.0772395560384861 
VAL_ACCURACY : 0.954954954954955
VAL_F1 : 0.9191685907214399

EPOCH : 31 / 50
VAL_LOSS : 0.06424089709334836 
VAL_ACCURACY : 0.9691119691119691
VAL_F1 : 0.9439252331415409

EPOCH : 32 / 50
VAL_LOSS : 0.06550694786829456 
VAL_ACCURACY : 0.9665379665379665
VAL_F1 : 0.9398148143120071

EPOCH : 33 / 50
VAL_LOSS : 0.06566388076836509 
VAL_ACCURACY : 0.9601029601029601
VAL_F1 : 0.9280742454367925

EPOCH : 34 / 50
VAL_LOSS : 0.06471045198850334 
VAL_ACCURACY : 0.9678249678249679
VAL_F1 : 0.9417249412217495

EPOCH : 35 / 50
VAL_LOSS : 0.06147254353427157 
VAL_ACCURACY : 0.9691119691119691
VAL_F1 : 0.9439252331415409

EPOCH : 36 / 50
VAL_LOSS : 0.05806151835951118 
VAL_ACCURACY : 0.9678249678249679
VAL_F1 : 0.941995359125823

EPOCH : 37 / 50
VAL_LOSS : 0.06240252965624083 
VAL_ACCURACY : 0.9678249678249679
VAL_F1 : 0.9417249412217495

EPOCH : 38 / 50
VAL_LOSS : 0.07596020569207565 
VAL_ACCURACY : 0.963963963963964
VAL_F1 : 0.9348837204271931

EPOCH : 39 / 50
VAL_LOSS : 0.06723591260497971 
VAL_ACCURACY : 0.9678249678249679
VAL_F1 : 0.9414519901288989

EPOCH : 40 / 50
VAL_LOSS : 0.06964171473031902 
VAL_ACCURACY : 0.9665379665379665
VAL_F1 : 0.9389671356467192

EPOCH : 41 / 50
VAL_LOSS : 0.07360940122482729 
VAL_ACCURACY : 0.9652509652509652
VAL_F1 : 0.9364705877316873

EPOCH : 42 / 50
VAL_LOSS : 0.06749716645809917 
VAL_ACCURACY : 0.9665379665379665
VAL_F1 : 0.9392523359453009

EPOCH : 43 / 50
VAL_LOSS : 0.06767144118796806 
VAL_ACCURACY : 0.963963963963964
VAL_F1 : 0.93427229996599

EPOCH : 44 / 50
VAL_LOSS : 0.07806528150103986 
VAL_ACCURACY : 0.963963963963964
VAL_F1 : 0.93396226364725

EPOCH : 45 / 50
VAL_LOSS : 0.07634676073449759 
VAL_ACCURACY : 0.9626769626769627
VAL_F1 : 0.9324009318977838

EPOCH : 46 / 50
VAL_LOSS : 0.07691326834337443 
VAL_ACCURACY : 0.963963963963964
VAL_F1 : 0.93396226364725

EPOCH : 47 / 50
VAL_LOSS : 0.07944967054134729 
VAL_ACCURACY : 0.9665379665379665
VAL_F1 : 0.9389671356467192

EPOCH : 48 / 50
VAL_LOSS : 0.06739478322620295 
VAL_ACCURACY : 0.9665379665379665
VAL_F1 : 0.9389671356467192

EPOCH : 49 / 50
VAL_LOSS : 0.07641995454454148 
VAL_ACCURACY : 0.9652509652509652
VAL_F1 : 0.9364705877316873

EPOCH : 50 / 50
VAL_LOSS : 0.07808710716436712 
VAL_ACCURACY : 0.9652509652509652
VAL_F1 : 0.9364705877316873

# 5話-0
# 文: 少々マニアックだろうか…
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
tensor([[ 0.3613, -0.1996]], device='cuda:0')
# 5話-0
# 文: Bさん、苦手そうだよな…
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
tensor([[ 1.5750, -1.9337]], device='cuda:0')
# 5話-0
# 文: 適当に流したな
正解 : 1 , 予測 : 0 / 元クラス : 憤怒
tensor([[ 0.0263, -0.1314]], device='cuda:0')
# 6話-0
# 文: そうなんだ?
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-2.0765,  2.7205]], device='cuda:0')
# 6話-0
# 文: どうぞどうぞ
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.3556,  0.3394]], device='cuda:0')
# 7話-0
# 文: とか言い出すのかな…
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.5449,  0.9432]], device='cuda:0')
# 7話-0
# 文: ジャーン!パフェを作ってみました?!
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-1.4275,  2.3322]], device='cuda:0')
# 7話-1
# 文: ジャーン!パフェを作ってみました?!
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-1.4275,  2.3322]], device='cuda:0')
# 7話-1
# 文: チョコ一つしかないね はんぶんこしよっか
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 1.2985, -1.3086]], device='cuda:0')
# 8話-0
# 文: 今日は良い実験結果が出たな
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-2.0032,  2.7293]], device='cuda:0')
# 8話-0
# 文: 国際会議でスペインにいるBさんからだ
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[ 1.6544, -2.1719]], device='cuda:0')
# 8話-1
# 文: でもわざわざ国際会議から送ってくれたんだよな…
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
tensor([[ 1.7619, -2.0779]], device='cuda:0')
# 8話-1
# 文: もう少し頑張るか
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-1.2953,  1.6417]], device='cuda:0')
# 9話-0
# 文: Bさ…ちょっと!
正解 : 1 , 予測 : 0 / 元クラス : 憤怒
tensor([[ 2.0437, -2.5405]], device='cuda:0')
# 9話-1
# 文: おかえりなさい!
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-1.2579,  2.1640]], device='cuda:0')
------------------------test acc------------------------
Test Acc : 0.7727
correct: 51, total: 66
------------------------------------------------
                  喜楽        その他  accuracy  macro avg  weighted avg
precision   0.222222   0.859649  0.772727   0.540936      0.763069
recall      0.200000   0.875000  0.772727   0.537500      0.772727
f1-score    0.210526   0.867257  0.772727   0.538891      0.767752
support    10.000000  56.000000  0.772727  66.000000     66.000000
正例のF1値 : 0.21052631526869806
class weight : tensor([0.7065, 0.2077])
best:lr 0.00015349722790594918
EPOCH : 1 / 50
VAL_LOSS : 0.09394011194152492 
VAL_ACCURACY : 0.9678249678249679
VAL_F1 : 0.9414519901288989

EPOCH : 2 / 50
VAL_LOSS : 0.07405264388617812 
VAL_ACCURACY : 0.9652509652509652
VAL_F1 : 0.9376443412987217

EPOCH : 3 / 50
VAL_LOSS : 0.060907281650116246 
VAL_ACCURACY : 0.9691119691119691
VAL_F1 : 0.9441860460085453

EPOCH : 4 / 50
VAL_LOSS : 0.07387668229829596 
VAL_ACCURACY : 0.9665379665379665
VAL_F1 : 0.9395348832178692

EPOCH : 5 / 50
VAL_LOSS : 0.06638220794574946 
VAL_ACCURACY : 0.9626769626769627
VAL_F1 : 0.9330254036544011

EPOCH : 6 / 50
VAL_LOSS : 0.061075911115931004 
VAL_ACCURACY : 0.9691119691119691
VAL_F1 : 0.9441860460085453

EPOCH : 7 / 50
VAL_LOSS : 0.05473744773248933 
VAL_ACCURACY : 0.9716859716859717
VAL_F1 : 0.9485981303377806

EPOCH : 8 / 50
VAL_LOSS : 0.060233947935000975 
VAL_ACCURACY : 0.963963963963964
VAL_F1 : 0.9357798160115312

EPOCH : 9 / 50
VAL_LOSS : 0.05927139041679246 
VAL_ACCURACY : 0.9703989703989704
VAL_F1 : 0.9458823524375253

EPOCH : 10 / 50
VAL_LOSS : 0.055187168236517786 
VAL_ACCURACY : 0.9716859716859717
VAL_F1 : 0.9488372087992213

EPOCH : 11 / 50
VAL_LOSS : 0.04843609635147969 
VAL_ACCURACY : 0.972972972972973
VAL_F1 : 0.9510489505457154

EPOCH : 12 / 50
VAL_LOSS : 0.04870256261748015 
VAL_ACCURACY : 0.972972972972973
VAL_F1 : 0.9510489505457154

EPOCH : 13 / 50
VAL_LOSS : 0.04949172456957856 
VAL_ACCURACY : 0.972972972972973
VAL_F1 : 0.9510489505457154

EPOCH : 14 / 50
VAL_LOSS : 0.04924177581786501 
VAL_ACCURACY : 0.9716859716859717
VAL_F1 : 0.9488372087992213

EPOCH : 15 / 50
VAL_LOSS : 0.06103137545097543 
VAL_ACCURACY : 0.9626769626769627
VAL_F1 : 0.9336384434338557

EPOCH : 16 / 50
VAL_LOSS : 0.059959027136923096 
VAL_ACCURACY : 0.9652509652509652
VAL_F1 : 0.9379310339803726

EPOCH : 17 / 50
VAL_LOSS : 0.04773499378554371 
VAL_ACCURACY : 0.9703989703989704
VAL_F1 : 0.9466357303554999

EPOCH : 18 / 50
VAL_LOSS : 0.052711565817269136 
VAL_ACCURACY : 0.9703989703989704
VAL_F1 : 0.9466357303554999

EPOCH : 19 / 50
VAL_LOSS : 0.05057504016677944 
VAL_ACCURACY : 0.9716859716859717
VAL_F1 : 0.9488372087992213

EPOCH : 20 / 50
VAL_LOSS : 0.0525847998571259 
VAL_ACCURACY : 0.9665379665379665
VAL_F1 : 0.9400921653960798

EPOCH : 21 / 50
VAL_LOSS : 0.05227997422940573 
VAL_ACCURACY : 0.9691119691119691
VAL_F1 : 0.9444444439416154

EPOCH : 22 / 50
VAL_LOSS : 0.049228456332253256 
VAL_ACCURACY : 0.9716859716859717
VAL_F1 : 0.9488372087992213

EPOCH : 23 / 50
VAL_LOSS : 0.054485526192477166 
VAL_ACCURACY : 0.9691119691119691
VAL_F1 : 0.9444444439416154

EPOCH : 24 / 50
VAL_LOSS : 0.04814093415530361 
VAL_ACCURACY : 0.9703989703989704
VAL_F1 : 0.9466357303554999

EPOCH : 25 / 50
VAL_LOSS : 0.04879861728440286 
VAL_ACCURACY : 0.9703989703989704
VAL_F1 : 0.9466357303554999

EPOCH : 26 / 50
VAL_LOSS : 0.05262334185785481 
VAL_ACCURACY : 0.9716859716859717
VAL_F1 : 0.9483568070081775

EPOCH : 27 / 50
VAL_LOSS : 0.050153267194459936 
VAL_ACCURACY : 0.9716859716859717
VAL_F1 : 0.9488372087992213

EPOCH : 28 / 50
VAL_LOSS : 0.04987082720677159 
VAL_ACCURACY : 0.9691119691119691
VAL_F1 : 0.9444444439416154

EPOCH : 29 / 50
VAL_LOSS : 0.05539135487122955 
VAL_ACCURACY : 0.9652509652509652
VAL_F1 : 0.9379310339803726

EPOCH : 30 / 50
VAL_LOSS : 0.04800611841302289 
VAL_ACCURACY : 0.9716859716859717
VAL_F1 : 0.9488372087992213

EPOCH : 31 / 50
VAL_LOSS : 0.04689875479350437 
VAL_ACCURACY : 0.972972972972973
VAL_F1 : 0.9510489505457154

EPOCH : 32 / 50
VAL_LOSS : 0.06071974938659339 
VAL_ACCURACY : 0.954954954954955
VAL_F1 : 0.9209932274899337

EPOCH : 33 / 50
VAL_LOSS : 0.04832660061383278 
VAL_ACCURACY : 0.9678249678249679
VAL_F1 : 0.942263278943042

EPOCH : 34 / 50
VAL_LOSS : 0.04930067571754358 
VAL_ACCURACY : 0.9652509652509652
VAL_F1 : 0.9379310339803726

EPOCH : 35 / 50
VAL_LOSS : 0.060249146691770575 
VAL_ACCURACY : 0.9601029601029601
VAL_F1 : 0.9293849653296943

EPOCH : 36 / 50
VAL_LOSS : 0.05178247575591109 
VAL_ACCURACY : 0.9716859716859717
VAL_F1 : 0.9488372087992213

EPOCH : 37 / 50
VAL_LOSS : 0.049456144915893674 
VAL_ACCURACY : 0.9703989703989704
VAL_F1 : 0.9466357303554999

EPOCH : 38 / 50
VAL_LOSS : 0.049446835995138605 
VAL_ACCURACY : 0.9716859716859717
VAL_F1 : 0.9488372087992213

EPOCH : 39 / 50
VAL_LOSS : 0.05262778490800791 
VAL_ACCURACY : 0.9613899613899614
VAL_F1 : 0.9315068488131607

EPOCH : 40 / 50
VAL_LOSS : 0.05170498172068322 
VAL_ACCURACY : 0.963963963963964
VAL_F1 : 0.9357798160115312

EPOCH : 41 / 50
VAL_LOSS : 0.049440134844115496 
VAL_ACCURACY : 0.9665379665379665
VAL_F1 : 0.9400921653960798

EPOCH : 42 / 50
VAL_LOSS : 0.049618663242542924 
VAL_ACCURACY : 0.9678249678249679
VAL_F1 : 0.942263278943042

EPOCH : 43 / 50
VAL_LOSS : 0.048782054059283465 
VAL_ACCURACY : 0.9716859716859717
VAL_F1 : 0.9488372087992213

EPOCH : 44 / 50
VAL_LOSS : 0.05087320325059854 
VAL_ACCURACY : 0.9665379665379665
VAL_F1 : 0.9398148143120071

EPOCH : 45 / 50
VAL_LOSS : 0.045437430673069795 
VAL_ACCURACY : 0.9716859716859717
VAL_F1 : 0.9488372087992213

EPOCH : 46 / 50
VAL_LOSS : 0.05018601785128822 
VAL_ACCURACY : 0.9691119691119691
VAL_F1 : 0.9444444439416154

EPOCH : 47 / 50
VAL_LOSS : 0.05183858156432303 
VAL_ACCURACY : 0.9665379665379665
VAL_F1 : 0.9400921653960798

EPOCH : 48 / 50
VAL_LOSS : 0.0474095550527302 
VAL_ACCURACY : 0.972972972972973
VAL_F1 : 0.9510489505457154

EPOCH : 49 / 50
VAL_LOSS : 0.05145009535801958 
VAL_ACCURACY : 0.9703989703989704
VAL_F1 : 0.9463869458837324

EPOCH : 50 / 50
VAL_LOSS : 0.054980031361955464 
VAL_ACCURACY : 0.9691119691119691
VAL_F1 : 0.9441860460085453

# 5話-0
# 文: 少々マニアックだろうか…
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
tensor([[ 1.4391, -0.8311]], device='cuda:0')
# 5話-0
# 文: Bさん、苦手そうだよな…
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
tensor([[ 2.9658, -2.6118]], device='cuda:0')
# 6話-0
# 文: そうなんだ?
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-2.8144,  2.5234]], device='cuda:0')
# 6話-0
# 文: どうぞどうぞ
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-2.1492,  1.4153]], device='cuda:0')
# 7話-0
# 文: はんぶんこしよっか
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-2.8327,  2.5006]], device='cuda:0')
# 7話-0
# 文: とか言い出すのかな…
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.8152,  0.0801]], device='cuda:0')
# 7話-0
# 文: ジャーン!パフェを作ってみました?!
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-2.8437,  2.5496]], device='cuda:0')
# 7話-1
# 文: ジャーン!パフェを作ってみました?!
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-2.8437,  2.5496]], device='cuda:0')
# 8話-0
# 文: 今日は良い実験結果が出たな
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-2.8767,  2.5938]], device='cuda:0')
# 8話-0
# 文: 国際会議でスペインにいるBさんからだ
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[ 2.9645, -2.6147]], device='cuda:0')
# 8話-1
# 文: でもわざわざ国際会議から送ってくれたんだよな…
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
tensor([[ 0.4970, -0.2434]], device='cuda:0')
# 8話-1
# 文: もう少し頑張るか
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-1.6291,  1.5547]], device='cuda:0')
# 9話-0
# 文: Bさ…ちょっと!
正解 : 1 , 予測 : 0 / 元クラス : 憤怒
tensor([[ 2.9167, -2.5981]], device='cuda:0')
# 9話-1
# 文: おかえりなさい!
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-1.6084,  1.0878]], device='cuda:0')
------------------------test acc------------------------
Test Acc : 0.7879
correct: 52, total: 66
------------------------------------------------
                  喜楽        その他  accuracy  macro avg  weighted avg
precision   0.166667   0.850000  0.787879   0.508333      0.746465
recall      0.100000   0.910714  0.787879   0.505357      0.787879
f1-score    0.125000   0.879310  0.787879   0.502155      0.765021
support    10.000000  56.000000  0.787879  66.000000     66.000000
正例のF1値 : 0.12499999951562499
class weight : tensor([0.7065, 0.2077])
best:lr 0.0003575875780192057
EPOCH : 1 / 50
VAL_LOSS : 0.10530870411621064 
VAL_ACCURACY : 0.9588159588159588
VAL_F1 : 0.9255813948458411

EPOCH : 2 / 50
VAL_LOSS : 0.0915050645339854 
VAL_ACCURACY : 0.9498069498069498
VAL_F1 : 0.911963882117514

EPOCH : 3 / 50
VAL_LOSS : 0.10926499263364442 
VAL_ACCURACY : 0.9253539253539254
VAL_F1 : 0.8755364801906832

EPOCH : 4 / 50
VAL_LOSS : 0.0643450588520084 
VAL_ACCURACY : 0.9703989703989704
VAL_F1 : 0.9463869458837324

EPOCH : 5 / 50
VAL_LOSS : 0.056892687055681436 
VAL_ACCURACY : 0.9678249678249679
VAL_F1 : 0.941995359125823

EPOCH : 6 / 50
VAL_LOSS : 0.059986896537320346 
VAL_ACCURACY : 0.9678249678249679
VAL_F1 : 0.9417249412217495

EPOCH : 7 / 50
VAL_LOSS : 0.07822888410099003 
VAL_ACCURACY : 0.9665379665379665
VAL_F1 : 0.9392523359453009

EPOCH : 8 / 50
VAL_LOSS : 0.059053085240706495 
VAL_ACCURACY : 0.9665379665379665
VAL_F1 : 0.9389671356467192

EPOCH : 9 / 50
VAL_LOSS : 0.05427954969357471 
VAL_ACCURACY : 0.9678249678249679
VAL_F1 : 0.941995359125823

EPOCH : 10 / 50
VAL_LOSS : 0.059228389048758816 
VAL_ACCURACY : 0.9665379665379665
VAL_F1 : 0.9398148143120071

EPOCH : 11 / 50
VAL_LOSS : 0.059200294943032215 
VAL_ACCURACY : 0.9716859716859717
VAL_F1 : 0.9485981303377806

EPOCH : 12 / 50
VAL_LOSS : 0.05270858771376768 
VAL_ACCURACY : 0.9665379665379665
VAL_F1 : 0.9400921653960798

EPOCH : 13 / 50
VAL_LOSS : 0.07266386343660403 
VAL_ACCURACY : 0.9678249678249679
VAL_F1 : 0.9417249412217495

EPOCH : 14 / 50
VAL_LOSS : 0.07081976045417238 
VAL_ACCURACY : 0.9588159588159588
VAL_F1 : 0.9269406387675195

EPOCH : 15 / 50
VAL_LOSS : 0.06711567297805937 
VAL_ACCURACY : 0.9703989703989704
VAL_F1 : 0.9461358308782915

EPOCH : 16 / 50
VAL_LOSS : 0.06192102050408721 
VAL_ACCURACY : 0.9588159588159588
VAL_F1 : 0.9272727267711571

EPOCH : 17 / 50
VAL_LOSS : 0.07239345285319249 
VAL_ACCURACY : 0.9665379665379665
VAL_F1 : 0.9398148143120071

EPOCH : 18 / 50
VAL_LOSS : 0.06655485774580465 
VAL_ACCURACY : 0.9588159588159588
VAL_F1 : 0.9269406387675195

EPOCH : 19 / 50
VAL_LOSS : 0.06379940287609186 
VAL_ACCURACY : 0.963963963963964
VAL_F1 : 0.9354838704652254

EPOCH : 20 / 50
VAL_LOSS : 0.06110030646454923 
VAL_ACCURACY : 0.9703989703989704
VAL_F1 : 0.9461358308782915

EPOCH : 21 / 50
VAL_LOSS : 0.05865800755136475 
VAL_ACCURACY : 0.9716859716859717
VAL_F1 : 0.9483568070081775

EPOCH : 22 / 50
VAL_LOSS : 0.05792884883584873 
VAL_ACCURACY : 0.9691119691119691
VAL_F1 : 0.9444444439416154

EPOCH : 23 / 50
VAL_LOSS : 0.06260411064045465 
VAL_ACCURACY : 0.9575289575289575
VAL_F1 : 0.9251700675258149

EPOCH : 24 / 50
VAL_LOSS : 0.047060599465075195 
VAL_ACCURACY : 0.972972972972973
VAL_F1 : 0.9510489505457154

EPOCH : 25 / 50
VAL_LOSS : 0.06149972602725029 
VAL_ACCURACY : 0.9703989703989704
VAL_F1 : 0.9463869458837324

EPOCH : 26 / 50
VAL_LOSS : 0.05630085584992657 
VAL_ACCURACY : 0.9678249678249679
VAL_F1 : 0.942263278943042

EPOCH : 27 / 50
VAL_LOSS : 0.055087708150587826 
VAL_ACCURACY : 0.9691119691119691
VAL_F1 : 0.9444444439416154

EPOCH : 28 / 50
VAL_LOSS : 0.05065837257294631 
VAL_ACCURACY : 0.9716859716859717
VAL_F1 : 0.9488372087992213

EPOCH : 29 / 50
VAL_LOSS : 0.05001109509671829 
VAL_ACCURACY : 0.9703989703989704
VAL_F1 : 0.9466357303554999

EPOCH : 30 / 50
VAL_LOSS : 0.04855522250623575 
VAL_ACCURACY : 0.9703989703989704
VAL_F1 : 0.9466357303554999

EPOCH : 31 / 50
VAL_LOSS : 0.05387507493569687 
VAL_ACCURACY : 0.9703989703989704
VAL_F1 : 0.9466357303554999

EPOCH : 32 / 50
VAL_LOSS : 0.051937339200201084 
VAL_ACCURACY : 0.9703989703989704
VAL_F1 : 0.9466357303554999

EPOCH : 33 / 50
VAL_LOSS : 0.04991103808528611 
VAL_ACCURACY : 0.9678249678249679
VAL_F1 : 0.942263278943042

EPOCH : 34 / 50
VAL_LOSS : 0.052412801422178745 
VAL_ACCURACY : 0.9691119691119691
VAL_F1 : 0.9444444439416154

EPOCH : 35 / 50
VAL_LOSS : 0.061011497130883593 
VAL_ACCURACY : 0.9678249678249679
VAL_F1 : 0.942263278943042

EPOCH : 36 / 50
VAL_LOSS : 0.07056539861618408 
VAL_ACCURACY : 0.9652509652509652
VAL_F1 : 0.9376443412987217

EPOCH : 37 / 50
VAL_LOSS : 0.08698633832058736 
VAL_ACCURACY : 0.9420849420849421
VAL_F1 : 0.9006622511565867

EPOCH : 38 / 50
VAL_LOSS : 0.05203147032963378 
VAL_ACCURACY : 0.9691119691119691
VAL_F1 : 0.9444444439416154

EPOCH : 39 / 50
VAL_LOSS : 0.05287644287514291 
VAL_ACCURACY : 0.9601029601029601
VAL_F1 : 0.9293849653296943

EPOCH : 40 / 50
VAL_LOSS : 0.06190463769895842 
VAL_ACCURACY : 0.9536679536679536
VAL_F1 : 0.9189189184180667

EPOCH : 41 / 50
VAL_LOSS : 0.0518344485020379 
VAL_ACCURACY : 0.963963963963964
VAL_F1 : 0.9357798160115312

EPOCH : 42 / 50
VAL_LOSS : 0.052270652674024504 
VAL_ACCURACY : 0.963963963963964
VAL_F1 : 0.9357798160115312

EPOCH : 43 / 50
VAL_LOSS : 0.05032424224844696 
VAL_ACCURACY : 0.972972972972973
VAL_F1 : 0.9510489505457154

EPOCH : 44 / 50
VAL_LOSS : 0.054949814244648634 
VAL_ACCURACY : 0.9678249678249679
VAL_F1 : 0.942263278943042

EPOCH : 45 / 50
VAL_LOSS : 0.050959840302868764 
VAL_ACCURACY : 0.9703989703989704
VAL_F1 : 0.9466357303554999

EPOCH : 46 / 50
VAL_LOSS : 0.05662673357303957 
VAL_ACCURACY : 0.9678249678249679
VAL_F1 : 0.942263278943042

EPOCH : 47 / 50
VAL_LOSS : 0.05363455344447676 
VAL_ACCURACY : 0.9691119691119691
VAL_F1 : 0.9444444439416154

EPOCH : 48 / 50
VAL_LOSS : 0.058789205571104376 
VAL_ACCURACY : 0.9523809523809523
VAL_F1 : 0.9168539320836057

EPOCH : 49 / 50
VAL_LOSS : 0.08048120841421948 
VAL_ACCURACY : 0.9459459459459459
VAL_F1 : 0.9066666661669925

EPOCH : 50 / 50
VAL_LOSS : 0.04994675507103758 
VAL_ACCURACY : 0.9716859716859717
VAL_F1 : 0.9488372087992213

# 5話-0
# 文: Bさん、苦手そうだよな…
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
tensor([[ 2.7877, -1.9704]], device='cuda:0')
# 6話-0
# 文: そうなんだ?
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-3.5896,  1.8991]], device='cuda:0')
# 6話-0
# 文: どうぞどうぞ
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.0170,  0.2062]], device='cuda:0')
# 7話-0
# 文: はんぶんこしよっか
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-3.2133,  1.5201]], device='cuda:0')
# 7話-0
# 文: とか言い出すのかな…
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[0.1268, 0.7505]], device='cuda:0')
# 7話-0
# 文: ジャーン!パフェを作ってみました?!
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-3.5892,  1.8997]], device='cuda:0')
# 7話-1
# 文: ジャーン!パフェを作ってみました?!
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-3.5892,  1.8997]], device='cuda:0')
# 7話-1
# 文: チョコ一つしかないね はんぶんこしよっか
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 1.8446, -0.7846]], device='cuda:0')
# 8話-0
# 文: 今日は良い実験結果が出たな
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-3.5736,  1.9042]], device='cuda:0')
# 8話-0
# 文: 国際会議でスペインにいるBさんからだ
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[ 3.4397, -1.9311]], device='cuda:0')
# 8話-1
# 文: もう少し頑張るか
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-3.4824,  1.9063]], device='cuda:0')
# 9話-0
# 文: Bさ…ちょっと!
正解 : 1 , 予測 : 0 / 元クラス : 憤怒
tensor([[ 2.8275, -1.9393]], device='cuda:0')
# 9話-1
# 文: おかえりなさい!
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-2.8635,  1.6606]], device='cuda:0')
------------------------test acc------------------------
Test Acc : 0.8030
correct: 53, total: 66
------------------------------------------------
                  喜楽        その他  accuracy  macro avg  weighted avg
precision   0.200000   0.852459   0.80303   0.526230      0.753602
recall      0.100000   0.928571   0.80303   0.514286      0.803030
f1-score    0.133333   0.888889   0.80303   0.511111      0.774411
support    10.000000  56.000000   0.80303  66.000000     66.000000
正例のF1値 : 0.13333333287111113
