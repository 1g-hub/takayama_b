class weight : tensor([0.7724, 0.1474])
best:lr 3.6617054137323073e-07
EPOCH : 1 / 5
VAL_LOSS : 0.716243544450173 
VAL_ACCURACY : 0.40096618357487923
VAL_F1 : 0.2853025932654245

EPOCH : 2 / 5
VAL_LOSS : 0.6883848252204748 
VAL_ACCURACY : 0.4444444444444444
VAL_F1 : 0.37837837799966767

EPOCH : 3 / 5
VAL_LOSS : 0.6584320389307462 
VAL_ACCURACY : 0.47946859903381644
VAL_F1 : 0.429139072473874

EPOCH : 4 / 5
VAL_LOSS : 0.6354805953227557 
VAL_ACCURACY : 0.5120772946859904
VAL_F1 : 0.46419098105812684

EPOCH : 5 / 5
VAL_LOSS : 0.6082512335135386 
VAL_ACCURACY : 0.5289855072463768
VAL_F1 : 0.47721179586970014

# 5話-0
# 文: 何読んでるんですか?
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[-0.0947, -0.3196]], device='cuda:0')
# 5話-0
# 文: 僕ですか?
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 0.1078, -0.3128]], device='cuda:0')
# 5話-0
# 文: 今ハマってる本はこの二冊…
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 0.3636, -0.5254]], device='cuda:0')
# 5話-0
# 文: 少々マニアックだろうか…
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[0.1582, 0.0062]], device='cuda:0')
# 5話-0
# 文: Bさん、苦手そうだよな…
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 0.0393, -0.0471]], device='cuda:0')
# 5話-0
# 文: 適当に流そう
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 0.0877, -0.3426]], device='cuda:0')
# 5話-0
# 文: 小説はあまり読まないのですが、研究で利用している青空文庫の作品なら少々
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 0.4174, -0.4393]], device='cuda:0')
# 5話-0
# 文: そうなんだ〜
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.0254,  0.0307]], device='cuda:0')
# 5話-0
# 文: 適当に流したな
正解 : 1 , 予測 : 0 / 元クラス : 憤怒
tensor([[ 0.1091, -0.1528]], device='cuda:0')
# 5話-0
# 文: あと、これも読んだよ
正解 : 1 , 予測 : 0 / 元クラス : 憤怒
tensor([[-0.0152, -0.0550]], device='cuda:0')
# 5話-1
# 文: これ読んだよ
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[-0.0650, -0.2677]], device='cuda:0')
# 5話-1
# 文: ありがとうございます…それ何読んでるんですか?
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
tensor([[ 0.4650, -0.0891]], device='cuda:0')
# 5話-1
# 文: オススメの本教えて
正解 : 1 , 予測 : 0 / 元クラス : UNK
tensor([[ 0.1968, -0.2208]], device='cuda:0')
# 5話-1
# 文: 僕ですか?
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 0.1078, -0.3128]], device='cuda:0')
# 5話-1
# 文: 小説はあまり読まないのですが 研究で利用している青空文庫の作品なら少々
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 0.7021, -0.3292]], device='cuda:0')
# 6話-0
# 文: 今日弁当なんですね
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[-0.2879, -0.3674]], device='cuda:0')
# 6話-0
# 文: そうなんだ〜 父の分と2つ作ったの
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 0.2980, -0.0764]], device='cuda:0')
# 6話-0
# 文: 手作りなんですか?
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 0.1844, -0.3871]], device='cuda:0')
# 6話-0
# 文: どうぞどうぞ
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 0.3942, -0.0358]], device='cuda:0')
# 6話-0
# 文: ベタだなあ
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
tensor([[ 0.2536, -0.3598]], device='cuda:0')
# 6話-1
# 文: ベタだなあ
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
tensor([[ 0.2536, -0.3598]], device='cuda:0')
# 6話-1
# 文: 今日弁当なの珍しいですね
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 0.2401, -0.3332]], device='cuda:0')
# 6話-1
# 文: ええ…父の分と2つ作ったんだけど
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
tensor([[0.1197, 0.0550]], device='cuda:0')
# 6話-1
# 文: 入れ替わってしまったみたい…
正解 : 1 , 予測 : 0 / 元クラス : UNK
tensor([[-0.1743, -0.2459]], device='cuda:0')
# 6話-1
# 文: 手作りなんですか?
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 0.1844, -0.3871]], device='cuda:0')
# 6話-1
# 文: ありがとう…
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.2836,  0.2289]], device='cuda:0')
# 7話-0
# 文: どれがいいですか?
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 0.2021, -0.2487]], device='cuda:0')
# 7話-0
# 文: じゃあチョコですね
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[-0.0681, -0.1147]], device='cuda:0')
# 7話-0
# 文: チョコは一つしかないし、悪いよ〜
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 0.0417, -0.1259]], device='cuda:0')
# 7話-0
# 文: はんぶんこしよっか
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 0.2657, -0.0281]], device='cuda:0')
# 7話-1
# 文: 差し入れでもらったこの大量のアイスも
正解 : 1 , 予測 : 0 / 元クラス : UNK
tensor([[ 0.2360, -0.0881]], device='cuda:0')
# 7話-1
# 文: てっきり…
正解 : 1 , 予測 : 0 / 元クラス : UNK
tensor([[-0.0163, -0.0993]], device='cuda:0')
# 7話-1
# 文: チョコ一つしかないね はんぶんこしよっか
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 0.3741, -0.4418]], device='cuda:0')
# 7話-1
# 文: Aくんがいなければ独り占めできたのにな…
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
tensor([[0.2997, 0.0706]], device='cuda:0')
# 8話-0
# 文: 今日は良い実験結果が出たな
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.0376,  0.1677]], device='cuda:0')
# 8話-0
# 文: 国際会議でスペインにいるBさんからだ
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[0.2562, 0.0853]], device='cuda:0')
# 8話-0
# 文: ここは日本。何も見ていない
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 0.2647, -0.1228]], device='cuda:0')
# 8話-1
# 文: ここは日本。何も見ていない
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 0.2647, -0.1228]], device='cuda:0')
# 8話-1
# 文: でもわざわざ国際会議から送ってくれたんだよな…
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
tensor([[ 0.1555, -0.1508]], device='cuda:0')
# 8話-1
# 文: もう少し頑張るか
正解 : 1 , 予測 : 0 / 元クラス : UNK
tensor([[ 0.0462, -0.3854]], device='cuda:0')
# 9話-0
# 文: あれ?スペインからもう戻ってきたのか。
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 0.0469, -0.0465]], device='cuda:0')
# 9話-0
# 文: Bさん…あれ?
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 0.0110, -0.1036]], device='cuda:0')
# 9話-0
# 文: Bさ…ちょっと!
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 0.1971, -0.1602]], device='cuda:0')
# 9話-0
# 文: ハッ
正解 : 1 , 予測 : 0 / 元クラス : UNK
tensor([[ 0.1413, -0.0230]], device='cuda:0')
# 9話-0
# 文: 人違い!?
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[-0.0029, -0.2949]], device='cuda:0')
# 9話-0
# 文: ？
正解 : 1 , 予測 : 0 / 元クラス : UNK
tensor([[ 0.3835, -0.5705]], device='cuda:0')
# 9話-1
# 文: Bさ… 人違い!?
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[0.1311, 0.0085]], device='cuda:0')
# 9話-1
# 文: ？
正解 : 1 , 予測 : 0 / 元クラス : UNK
tensor([[ 0.3835, -0.5705]], device='cuda:0')
# 9話-1
# 文: ここは よその研究室…!?
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[ 0.1697, -0.2526]], device='cuda:0')
# 9話-1
# 文: 恥ずかしい…
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
tensor([[ 0.1350, -0.1306]], device='cuda:0')
# 9話-1
# 文: ただいま〜
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.1433,  0.2774]], device='cuda:0')
# 9話-1
# 文: ？
正解 : 1 , 予測 : 0 / 元クラス : UNK
tensor([[ 0.3835, -0.5705]], device='cuda:0')
------------------------test acc------------------------
Test Acc : 0.2877
correct: 21, total: 73
------------------------------------------------
                  喜楽        その他  accuracy  macro avg  weighted avg
precision   0.142857   0.764706  0.287671   0.453782      0.662484
recall      0.666667   0.213115  0.287671   0.439891      0.287671
f1-score    0.235294   0.333333  0.287671   0.284314      0.317217
support    12.000000  61.000000  0.287671  73.000000     73.000000
正例のF1値 : 0.23529411734948097
class weight : tensor([0.7635, 0.1549])
best:lr 3.846459527750008e-07
EPOCH : 1 / 50
VAL_LOSS : 0.6713853770611333 
VAL_ACCURACY : 0.7848258706467661
VAL_F1 : 0.3929824556722192

EPOCH : 2 / 50
VAL_LOSS : 0.6434867206741782 
VAL_ACCURACY : 0.7873134328358209
VAL_F1 : 0.5128205123179196

EPOCH : 3 / 50
VAL_LOSS : 0.6052717636613285 
VAL_ACCURACY : 0.8009950248756219
VAL_F1 : 0.6172248798894486

EPOCH : 4 / 50
VAL_LOSS : 0.5852021919746025 
VAL_ACCURACY : 0.7985074626865671
VAL_F1 : 0.6462882091270571

EPOCH : 5 / 50
VAL_LOSS : 0.5654555401381325 
VAL_ACCURACY : 0.7761194029850746
VAL_F1 : 0.6296296291606462

EPOCH : 6 / 50
VAL_LOSS : 0.5396087193021587 
VAL_ACCURACY : 0.7860696517412935
VAL_F1 : 0.6518218618823288

EPOCH : 7 / 50
VAL_LOSS : 0.5220197585283541 
VAL_ACCURACY : 0.804726368159204
VAL_F1 : 0.6789366048489929

EPOCH : 8 / 50
VAL_LOSS : 0.5040178889153051 
VAL_ACCURACY : 0.818407960199005
VAL_F1 : 0.6970954352137877

EPOCH : 9 / 50
VAL_LOSS : 0.48436511556307477 
VAL_ACCURACY : 0.8333333333333334
VAL_F1 : 0.7184873944846586

EPOCH : 10 / 50
VAL_LOSS : 0.4674943346603244 
VAL_ACCURACY : 0.8507462686567164
VAL_F1 : 0.7413793098667509

EPOCH : 11 / 50
VAL_LOSS : 0.4557497004667918 
VAL_ACCURACY : 0.8706467661691543
VAL_F1 : 0.7678571423730071

EPOCH : 12 / 50
VAL_LOSS : 0.4324768956969766 
VAL_ACCURACY : 0.8868159203980099
VAL_F1 : 0.791762013241877

EPOCH : 13 / 50
VAL_LOSS : 0.4195880942484912 
VAL_ACCURACY : 0.9029850746268657
VAL_F1 : 0.8151658762841806

EPOCH : 14 / 50
VAL_LOSS : 0.40286900658233493 
VAL_ACCURACY : 0.9104477611940298
VAL_F1 : 0.826923076428162

EPOCH : 15 / 50
VAL_LOSS : 0.39477572370977965 
VAL_ACCURACY : 0.914179104477612
VAL_F1 : 0.8337349392638004

EPOCH : 16 / 50
VAL_LOSS : 0.38115553119603324 
VAL_ACCURACY : 0.9291044776119403
VAL_F1 : 0.8585607935460966

EPOCH : 17 / 50
VAL_LOSS : 0.35882555094419744 
VAL_ACCURACY : 0.9340796019900498
VAL_F1 : 0.867167919299929

EPOCH : 18 / 50
VAL_LOSS : 0.34978146938716664 
VAL_ACCURACY : 0.9353233830845771
VAL_F1 : 0.8693467331685312

EPOCH : 19 / 50
VAL_LOSS : 0.34355787319295544 
VAL_ACCURACY : 0.9378109452736318
VAL_F1 : 0.8737373732370932

EPOCH : 20 / 50
VAL_LOSS : 0.32573097301464454 
VAL_ACCURACY : 0.9402985074626866
VAL_F1 : 0.8787878782875728

EPOCH : 21 / 50
VAL_LOSS : 0.3185148274197298 
VAL_ACCURACY : 0.9440298507462687
VAL_F1 : 0.8854961827051261

EPOCH : 22 / 50
VAL_LOSS : 0.3062972803326214 
VAL_ACCURACY : 0.945273631840796
VAL_F1 : 0.8877551015396189

EPOCH : 23 / 50
VAL_LOSS : 0.29186971836230335 
VAL_ACCURACY : 0.9465174129353234
VAL_F1 : 0.8900255749461607

EPOCH : 24 / 50
VAL_LOSS : 0.28511518678244424 
VAL_ACCURACY : 0.9477611940298507
VAL_F1 : 0.8923076918060749

EPOCH : 25 / 50
VAL_LOSS : 0.2724052550745945 
VAL_ACCURACY : 0.9539800995024875
VAL_F1 : 0.9043927643556411

EPOCH : 26 / 50
VAL_LOSS : 0.26329703833542617 
VAL_ACCURACY : 0.9552238805970149
VAL_F1 : 0.9067357507929072

EPOCH : 27 / 50
VAL_LOSS : 0.2569869958302554 
VAL_ACCURACY : 0.9539800995024875
VAL_F1 : 0.9043927643556411

EPOCH : 28 / 50
VAL_LOSS : 0.2449679953210494 
VAL_ACCURACY : 0.9539800995024875
VAL_F1 : 0.9043927643556411

EPOCH : 29 / 50
VAL_LOSS : 0.24764304564279668 
VAL_ACCURACY : 0.9552238805970149
VAL_F1 : 0.9067357507929072

EPOCH : 30 / 50
VAL_LOSS : 0.23520445852887398 
VAL_ACCURACY : 0.9552238805970149
VAL_F1 : 0.9067357507929072

EPOCH : 31 / 50
VAL_LOSS : 0.2286289752114053 
VAL_ACCURACY : 0.9564676616915423
VAL_F1 : 0.9090909085882949

EPOCH : 32 / 50
VAL_LOSS : 0.2217783644503238 
VAL_ACCURACY : 0.9564676616915423
VAL_F1 : 0.9090909085882949

EPOCH : 33 / 50
VAL_LOSS : 0.2136663251063403 
VAL_ACCURACY : 0.9577114427860697
VAL_F1 : 0.9114583328305395

EPOCH : 34 / 50
VAL_LOSS : 0.20928633870447383 
VAL_ACCURACY : 0.9577114427860697
VAL_F1 : 0.9114583328305395

EPOCH : 35 / 50
VAL_LOSS : 0.2018213098247846 
VAL_ACCURACY : 0.9577114427860697
VAL_F1 : 0.9114583328305395

EPOCH : 36 / 50
VAL_LOSS : 0.19809680899568632 
VAL_ACCURACY : 0.9614427860696517
VAL_F1 : 0.9190600517163251

EPOCH : 37 / 50
VAL_LOSS : 0.19600950166875242 
VAL_ACCURACY : 0.9614427860696517
VAL_F1 : 0.9190600517163251

EPOCH : 38 / 50
VAL_LOSS : 0.18859567712335026 
VAL_ACCURACY : 0.9614427860696517
VAL_F1 : 0.9190600517163251

EPOCH : 39 / 50
VAL_LOSS : 0.18228387335936228 
VAL_ACCURACY : 0.9626865671641791
VAL_F1 : 0.9214659680832216

EPOCH : 40 / 50
VAL_LOSS : 0.1832711568065718 
VAL_ACCURACY : 0.9639303482587065
VAL_F1 : 0.9234828491006051

EPOCH : 41 / 50
VAL_LOSS : 0.17670801764025407 
VAL_ACCURACY : 0.9651741293532339
VAL_F1 : 0.9263157889701941

EPOCH : 42 / 50
VAL_LOSS : 0.16747924174163856 
VAL_ACCURACY : 0.9639303482587065
VAL_F1 : 0.9234828491006051

EPOCH : 43 / 50
VAL_LOSS : 0.16423499452717163 
VAL_ACCURACY : 0.9639303482587065
VAL_F1 : 0.9234828491006051

EPOCH : 44 / 50
VAL_LOSS : 0.161670348953967 
VAL_ACCURACY : 0.9639303482587065
VAL_F1 : 0.9234828491006051

EPOCH : 45 / 50
VAL_LOSS : 0.16336928059657416 
VAL_ACCURACY : 0.9664179104477612
VAL_F1 : 0.9287598939554585

EPOCH : 46 / 50
VAL_LOSS : 0.1542184271064459 
VAL_ACCURACY : 0.9664179104477612
VAL_F1 : 0.9287598939554585

EPOCH : 47 / 50
VAL_LOSS : 0.15238470291974499 
VAL_ACCURACY : 0.9689054726368159
VAL_F1 : 0.9336870021485834

EPOCH : 48 / 50
VAL_LOSS : 0.1437301577306261 
VAL_ACCURACY : 0.9689054726368159
VAL_F1 : 0.9336870021485834

EPOCH : 49 / 50
VAL_LOSS : 0.14352607873140596 
VAL_ACCURACY : 0.9689054726368159
VAL_F1 : 0.9336870021485834

EPOCH : 50 / 50
VAL_LOSS : 0.1404276157126707 
VAL_ACCURACY : 0.9689054726368159
VAL_F1 : 0.9336870021485834

# 5話-0
# 文: 夏目漱石だよ〜 Aくんはどんな本を読むの
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.6768,  0.3539]], device='cuda:0')
# 5話-0
# 文: そうなんだ〜
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.1519,  0.1625]], device='cuda:0')
# 5話-0
# 文: あと、これも読んだよ
正解 : 1 , 予測 : 0 / 元クラス : 憤怒
tensor([[ 0.6335, -0.8169]], device='cuda:0')
# 5話-1
# 文: これ読んだよ
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 0.9090, -0.8109]], device='cuda:0')
# 5話-1
# 文: 夏目漱石だよ〜 Aくんはどんな本を読むの
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.6768,  0.3539]], device='cuda:0')
# 6話-0
# 文: そうなんだ〜 父の分と2つ作ったの
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 0.4663, -0.5653]], device='cuda:0')
# 6話-0
# 文: キャー!
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[ 0.2903, -0.5607]], device='cuda:0')
# 6話-1
# 文: キャー!
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[ 0.2903, -0.5607]], device='cuda:0')
# 6話-1
# 文: 俺も今日弁当なんでおかず分けますよ
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.8840,  0.7818]], device='cuda:0')
# 7話-0
# 文: ジャーン!パフェを作ってみました〜!
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.5245,  0.5576]], device='cuda:0')
# 7話-1
# 文: ジャーン!パフェを作ってみました〜!
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.5245,  0.5576]], device='cuda:0')
# 7話-1
# 文: こうやっていろんな食べ方をすれば飽きないですね
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.6183,  0.3467]], device='cuda:0')
# 7話-1
# 文: チョコ一つしかないね はんぶんこしよっか
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 0.6279, -0.1497]], device='cuda:0')
# 8話-0
# 文: 今日は良い実験結果が出たな
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.4469,  0.4325]], device='cuda:0')
# 8話-1
# 文: でもわざわざ国際会議から送ってくれたんだよな…
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
tensor([[ 0.7769, -0.4420]], device='cuda:0')
# 9話-1
# 文: ここは よその研究室…!?
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[-0.0712, -0.2930]], device='cuda:0')
# 9話-1
# 文: ただいま〜
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-1.0575,  0.4950]], device='cuda:0')
# 9話-1
# 文: おかえりなさい!
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.2977,  0.1524]], device='cuda:0')
------------------------test acc------------------------
Test Acc : 0.7188
correct: 46, total: 64
------------------------------------------------
                  喜楽        その他  accuracy  macro avg  weighted avg
precision   0.200000   0.814815   0.71875   0.507407      0.699537
recall      0.166667   0.846154   0.71875   0.506410      0.718750
f1-score    0.181818   0.830189   0.71875   0.506003      0.708619
support    12.000000  52.000000   0.71875  64.000000     64.000000
正例のF1値 : 0.18181818130578511
class weight : tensor([0.7635, 0.1549])
best:lr 1.5582129179628608e-06
EPOCH : 1 / 50
VAL_LOSS : 0.5969860168064341 
VAL_ACCURACY : 0.5174129353233831
VAL_F1 : 0.4728260865857308

EPOCH : 2 / 50
VAL_LOSS : 0.5017504528457043 
VAL_ACCURACY : 0.7201492537313433
VAL_F1 : 0.6073298424989082

EPOCH : 3 / 50
VAL_LOSS : 0.42397575343356414 
VAL_ACCURACY : 0.8544776119402985
VAL_F1 : 0.7462039040760773

EPOCH : 4 / 50
VAL_LOSS : 0.3619205118978725 
VAL_ACCURACY : 0.8731343283582089
VAL_F1 : 0.7702702697846968

EPOCH : 5 / 50
VAL_LOSS : 0.3175261523209366 
VAL_ACCURACY : 0.8930348258706468
VAL_F1 : 0.799065420069635

EPOCH : 6 / 50
VAL_LOSS : 0.272939807936257 
VAL_ACCURACY : 0.904228855721393
VAL_F1 : 0.8162291164511253

EPOCH : 7 / 50
VAL_LOSS : 0.2473190660570182 
VAL_ACCURACY : 0.917910447761194
VAL_F1 : 0.8390243897472457

EPOCH : 8 / 50
VAL_LOSS : 0.22728059879120657 
VAL_ACCURACY : 0.9328358208955224
VAL_F1 : 0.8663366331650084

EPOCH : 9 / 50
VAL_LOSS : 0.19726984641131232 
VAL_ACCURACY : 0.9440298507462687
VAL_F1 : 0.886075948866528

EPOCH : 10 / 50
VAL_LOSS : 0.17533444131121917 
VAL_ACCURACY : 0.9477611940298507
VAL_F1 : 0.8928571423559194

EPOCH : 11 / 50
VAL_LOSS : 0.1614620688499189 
VAL_ACCURACY : 0.9564676616915423
VAL_F1 : 0.9095607230119452

EPOCH : 12 / 50
VAL_LOSS : 0.14664086955142955 
VAL_ACCURACY : 0.9601990049751243
VAL_F1 : 0.9162303659890081

EPOCH : 13 / 50
VAL_LOSS : 0.14122186623075428 
VAL_ACCURACY : 0.9614427860696517
VAL_F1 : 0.9190600517163251

EPOCH : 14 / 50
VAL_LOSS : 0.12587946507276274 
VAL_ACCURACY : 0.9614427860696517
VAL_F1 : 0.9190600517163251

EPOCH : 15 / 50
VAL_LOSS : 0.11339902322666318 
VAL_ACCURACY : 0.9651741293532339
VAL_F1 : 0.9263157889701941

EPOCH : 16 / 50
VAL_LOSS : 0.11128421350583143 
VAL_ACCURACY : 0.9651741293532339
VAL_F1 : 0.9259259254221608

EPOCH : 17 / 50
VAL_LOSS : 0.10098908209771502 
VAL_ACCURACY : 0.9689054726368159
VAL_F1 : 0.9333333328291558

EPOCH : 18 / 50
VAL_LOSS : 0.09110791199639731 
VAL_ACCURACY : 0.9701492537313433
VAL_F1 : 0.935828876501044

EPOCH : 19 / 50
VAL_LOSS : 0.08820419448117416 
VAL_ACCURACY : 0.972636815920398
VAL_F1 : 0.9411764700839029

EPOCH : 20 / 50
VAL_LOSS : 0.08319699990690924 
VAL_ACCURACY : 0.972636815920398
VAL_F1 : 0.9411764700839029

EPOCH : 21 / 50
VAL_LOSS : 0.07685428620407395 
VAL_ACCURACY : 0.9776119402985075
VAL_F1 : 0.9510869560168065

EPOCH : 22 / 50
VAL_LOSS : 0.07603705104659586 
VAL_ACCURACY : 0.9776119402985075
VAL_F1 : 0.9510869560168065

EPOCH : 23 / 50
VAL_LOSS : 0.0706566118215229 
VAL_ACCURACY : 0.9800995024875622
VAL_F1 : 0.9567567562519504

EPOCH : 24 / 50
VAL_LOSS : 0.06641790172194734 
VAL_ACCURACY : 0.9800995024875622
VAL_F1 : 0.9567567562519504

EPOCH : 25 / 50
VAL_LOSS : 0.06571514535622269 
VAL_ACCURACY : 0.9813432835820896
VAL_F1 : 0.9593495929910327

EPOCH : 26 / 50
VAL_LOSS : 0.06356521739679225 
VAL_ACCURACY : 0.9813432835820896
VAL_F1 : 0.9593495929910327

EPOCH : 27 / 50
VAL_LOSS : 0.06023124203670258 
VAL_ACCURACY : 0.9813432835820896
VAL_F1 : 0.9593495929910327

EPOCH : 28 / 50
VAL_LOSS : 0.058372294566794936 
VAL_ACCURACY : 0.9825870646766169
VAL_F1 : 0.9619565212341388

EPOCH : 29 / 50
VAL_LOSS : 0.054853699005701965 
VAL_ACCURACY : 0.9850746268656716
VAL_F1 : 0.9673913038428049

EPOCH : 30 / 50
VAL_LOSS : 0.05070383357358914 
VAL_ACCURACY : 0.9850746268656716
VAL_F1 : 0.9673913038428049

EPOCH : 31 / 50
VAL_LOSS : 0.04832463565410352 
VAL_ACCURACY : 0.9850746268656716
VAL_F1 : 0.9673913038428049

EPOCH : 32 / 50
VAL_LOSS : 0.04736459974710848 
VAL_ACCURACY : 0.986318407960199
VAL_F1 : 0.970189701392058

EPOCH : 33 / 50
VAL_LOSS : 0.04364400579794949 
VAL_ACCURACY : 0.986318407960199
VAL_F1 : 0.970189701392058

EPOCH : 34 / 50
VAL_LOSS : 0.04645116495735505 
VAL_ACCURACY : 0.986318407960199
VAL_F1 : 0.970189701392058

EPOCH : 35 / 50
VAL_LOSS : 0.04448248935388584 
VAL_ACCURACY : 0.986318407960199
VAL_F1 : 0.970189701392058

EPOCH : 36 / 50
VAL_LOSS : 0.04189593476407668 
VAL_ACCURACY : 0.986318407960199
VAL_F1 : 0.970189701392058

EPOCH : 37 / 50
VAL_LOSS : 0.041023617464245536 
VAL_ACCURACY : 0.986318407960199
VAL_F1 : 0.970189701392058

EPOCH : 38 / 50
VAL_LOSS : 0.039323657824128284 
VAL_ACCURACY : 0.986318407960199
VAL_F1 : 0.970189701392058

EPOCH : 39 / 50
VAL_LOSS : 0.03666120172277385 
VAL_ACCURACY : 0.986318407960199
VAL_F1 : 0.970189701392058

EPOCH : 40 / 50
VAL_LOSS : 0.03607244039063945 
VAL_ACCURACY : 0.986318407960199
VAL_F1 : 0.970189701392058

EPOCH : 41 / 50
VAL_LOSS : 0.03727097053299932 
VAL_ACCURACY : 0.986318407960199
VAL_F1 : 0.970189701392058

EPOCH : 42 / 50
VAL_LOSS : 0.03494828921176639 
VAL_ACCURACY : 0.986318407960199
VAL_F1 : 0.970189701392058

EPOCH : 43 / 50
VAL_LOSS : 0.03462007249175918 
VAL_ACCURACY : 0.9875621890547264
VAL_F1 : 0.972972972468079

EPOCH : 44 / 50
VAL_LOSS : 0.0328791559692107 
VAL_ACCURACY : 0.986318407960199
VAL_F1 : 0.970189701392058

EPOCH : 45 / 50
VAL_LOSS : 0.03128101972534376 
VAL_ACCURACY : 0.986318407960199
VAL_F1 : 0.970189701392058

EPOCH : 46 / 50
VAL_LOSS : 0.030839945810536545 
VAL_ACCURACY : 0.986318407960199
VAL_F1 : 0.970189701392058

EPOCH : 47 / 50
VAL_LOSS : 0.03175142787250818 
VAL_ACCURACY : 0.9875621890547264
VAL_F1 : 0.972972972468079

EPOCH : 48 / 50
VAL_LOSS : 0.03152993071239953 
VAL_ACCURACY : 0.9875621890547264
VAL_F1 : 0.972972972468079

EPOCH : 49 / 50
VAL_LOSS : 0.02861967533096379 
VAL_ACCURACY : 0.9875621890547264
VAL_F1 : 0.972972972468079

EPOCH : 50 / 50
VAL_LOSS : 0.02865752303863273 
VAL_ACCURACY : 0.9875621890547264
VAL_F1 : 0.972972972468079

# 5話-0
# 文: 夏目漱石だよ〜 Aくんはどんな本を読むの
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-2.1398,  1.7053]], device='cuda:0')
# 5話-0
# 文: そうなんだ〜
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-1.7759,  1.2236]], device='cuda:0')
# 5話-0
# 文: あと、これも読んだよ
正解 : 1 , 予測 : 0 / 元クラス : 憤怒
tensor([[ 0.7729, -0.4845]], device='cuda:0')
# 5話-1
# 文: これ読んだよ
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 1.9352, -1.3185]], device='cuda:0')
# 5話-1
# 文: 夏目漱石だよ〜 Aくんはどんな本を読むの
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-2.1398,  1.7053]], device='cuda:0')
# 6話-0
# 文: キャー!
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[ 0.7445, -0.6085]], device='cuda:0')
# 6話-1
# 文: キャー!
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[ 0.7445, -0.6085]], device='cuda:0')
# 6話-1
# 文: 俺も今日弁当なんでおかず分けますよ
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-2.1230,  1.7265]], device='cuda:0')
# 7話-0
# 文: ジャーン!パフェを作ってみました〜!
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-1.4193,  1.1996]], device='cuda:0')
# 7話-1
# 文: ジャーン!パフェを作ってみました〜!
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-1.4193,  1.1996]], device='cuda:0')
# 7話-1
# 文: こうやっていろんな食べ方をすれば飽きないですね
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-1.1911,  0.9723]], device='cuda:0')
# 7話-1
# 文: チョコ一つしかないね はんぶんこしよっか
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 1.8117, -1.4709]], device='cuda:0')
# 8話-0
# 文: 今日は良い実験結果が出たな
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-1.3367,  1.4199]], device='cuda:0')
# 8話-1
# 文: でもわざわざ国際会議から送ってくれたんだよな…
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
tensor([[ 1.8413, -1.1413]], device='cuda:0')
# 9話-1
# 文: ここは よその研究室…!?
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[ 0.1650, -0.1191]], device='cuda:0')
# 9話-1
# 文: ただいま〜
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-1.0346,  0.9869]], device='cuda:0')
# 9話-1
# 文: おかえりなさい!
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.9162,  0.7007]], device='cuda:0')
------------------------test acc------------------------
Test Acc : 0.7344
correct: 47, total: 64
------------------------------------------------
                  喜楽        その他  accuracy  macro avg  weighted avg
precision   0.222222   0.818182  0.734375   0.520202      0.706439
recall      0.166667   0.865385  0.734375   0.516026      0.734375
f1-score    0.190476   0.841121  0.734375   0.515799      0.719126
support    12.000000  52.000000  0.734375  64.000000     64.000000
正例のF1値 : 0.19047618996825397
class weight : tensor([0.7635, 0.1549])
best:lr 3.517148989523081e-06
EPOCH : 1 / 50
VAL_LOSS : 0.5050358053515939 
VAL_ACCURACY : 0.6616915422885572
VAL_F1 : 0.568253967844001

EPOCH : 2 / 50
VAL_LOSS : 0.3734879219064526 
VAL_ACCURACY : 0.8569651741293532
VAL_F1 : 0.7547974408883938

EPOCH : 3 / 50
VAL_LOSS : 0.2806447323630838 
VAL_ACCURACY : 0.9427860696517413
VAL_F1 : 0.8849999995005752

EPOCH : 4 / 50
VAL_LOSS : 0.22176825532726213 
VAL_ACCURACY : 0.9651741293532339
VAL_F1 : 0.9267015701774349

EPOCH : 5 / 50
VAL_LOSS : 0.18187888419511272 
VAL_ACCURACY : 0.9614427860696517
VAL_F1 : 0.9194805189778513

EPOCH : 6 / 50
VAL_LOSS : 0.1516606167835348 
VAL_ACCURACY : 0.9689054726368159
VAL_F1 : 0.9340369388103119

EPOCH : 7 / 50
VAL_LOSS : 0.12404726591764711 
VAL_ACCURACY : 0.9763681592039801
VAL_F1 : 0.948787061489934

EPOCH : 8 / 50
VAL_LOSS : 0.11108523870215696 
VAL_ACCURACY : 0.9788557213930348
VAL_F1 : 0.9541778970694199

EPOCH : 9 / 50
VAL_LOSS : 0.09912620959620849 
VAL_ACCURACY : 0.9813432835820896
VAL_F1 : 0.9591280648900505

EPOCH : 10 / 50
VAL_LOSS : 0.08714219891265326 
VAL_ACCURACY : 0.9850746268656716
VAL_F1 : 0.9670329665277142

EPOCH : 11 / 50
VAL_LOSS : 0.08433693048416399 
VAL_ACCURACY : 0.9850746268656716
VAL_F1 : 0.9672131142489475

EPOCH : 12 / 50
VAL_LOSS : 0.07924998785350837 
VAL_ACCURACY : 0.9813432835820896
VAL_F1 : 0.9593495929910327

EPOCH : 13 / 50
VAL_LOSS : 0.07305110311683487 
VAL_ACCURACY : 0.9850746268656716
VAL_F1 : 0.9672131142489475

EPOCH : 14 / 50
VAL_LOSS : 0.06612889702413596 
VAL_ACCURACY : 0.9888059701492538
VAL_F1 : 0.9754768387319233

EPOCH : 15 / 50
VAL_LOSS : 0.06217381803720605 
VAL_ACCURACY : 0.986318407960199
VAL_F1 : 0.970189701392058

EPOCH : 16 / 50
VAL_LOSS : 0.05626297888218188 
VAL_ACCURACY : 0.9900497512437811
VAL_F1 : 0.9781420759975216

EPOCH : 17 / 50
VAL_LOSS : 0.0539200224858873 
VAL_ACCURACY : 0.9900497512437811
VAL_F1 : 0.9781420759975216

EPOCH : 18 / 50
VAL_LOSS : 0.05038374004995122 
VAL_ACCURACY : 0.9888059701492538
VAL_F1 : 0.9754768387319233

EPOCH : 19 / 50
VAL_LOSS : 0.04892061891801217 
VAL_ACCURACY : 0.9900497512437811
VAL_F1 : 0.9782608690601371

EPOCH : 20 / 50
VAL_LOSS : 0.04522887916833747 
VAL_ACCURACY : 0.9900497512437811
VAL_F1 : 0.9782608690601371

EPOCH : 21 / 50
VAL_LOSS : 0.044051626149345845 
VAL_ACCURACY : 0.9912935323383084
VAL_F1 : 0.9809264300125475

EPOCH : 22 / 50
VAL_LOSS : 0.040570337617514184 
VAL_ACCURACY : 0.9925373134328358
VAL_F1 : 0.9836065568718088

EPOCH : 23 / 50
VAL_LOSS : 0.041443404540711756 
VAL_ACCURACY : 0.9912935323383084
VAL_F1 : 0.9809264300125475

EPOCH : 24 / 50
VAL_LOSS : 0.038732449798023 
VAL_ACCURACY : 0.9937810945273632
VAL_F1 : 0.9863013693577032

EPOCH : 25 / 50
VAL_LOSS : 0.039391720813571236 
VAL_ACCURACY : 0.9925373134328358
VAL_F1 : 0.9836065568718088

EPOCH : 26 / 50
VAL_LOSS : 0.037252371509869896 
VAL_ACCURACY : 0.9912935323383084
VAL_F1 : 0.9809264300125475

EPOCH : 27 / 50
VAL_LOSS : 0.034277553140532734 
VAL_ACCURACY : 0.9950248756218906
VAL_F1 : 0.9890109885056154

EPOCH : 28 / 50
VAL_LOSS : 0.0363698402310119 
VAL_ACCURACY : 0.9937810945273632
VAL_F1 : 0.9863013693577032

EPOCH : 29 / 50
VAL_LOSS : 0.03211974286857773 
VAL_ACCURACY : 0.9937810945273632
VAL_F1 : 0.9863013693577032

EPOCH : 30 / 50
VAL_LOSS : 0.030660363242906684 
VAL_ACCURACY : 0.996268656716418
VAL_F1 : 0.9917355366846528

EPOCH : 31 / 50
VAL_LOSS : 0.031142173955837887 
VAL_ACCURACY : 0.9975124378109452
VAL_F1 : 0.994475137616068

EPOCH : 32 / 50
VAL_LOSS : 0.03139402257168994 
VAL_ACCURACY : 0.9975124378109452
VAL_F1 : 0.994475137616068

EPOCH : 33 / 50
VAL_LOSS : 0.02971498189749671 
VAL_ACCURACY : 0.9975124378109452
VAL_F1 : 0.994475137616068

EPOCH : 34 / 50
VAL_LOSS : 0.02729948613719613 
VAL_ACCURACY : 0.9987562189054726
VAL_F1 : 0.997229916391986

EPOCH : 35 / 50
VAL_LOSS : 0.026426849119803485 
VAL_ACCURACY : 0.9987562189054726
VAL_F1 : 0.997229916391986

EPOCH : 36 / 50
VAL_LOSS : 0.024796867816179406 
VAL_ACCURACY : 0.9987562189054726
VAL_F1 : 0.997229916391986

EPOCH : 37 / 50
VAL_LOSS : 0.02476677594377714 
VAL_ACCURACY : 0.9987562189054726
VAL_F1 : 0.997229916391986

EPOCH : 38 / 50
VAL_LOSS : 0.02395025589594654 
VAL_ACCURACY : 0.9987562189054726
VAL_F1 : 0.997229916391986

EPOCH : 39 / 50
VAL_LOSS : 0.02302866582484806 
VAL_ACCURACY : 0.9987562189054726
VAL_F1 : 0.997229916391986

EPOCH : 40 / 50
VAL_LOSS : 0.023743166807381547 
VAL_ACCURACY : 0.9987562189054726
VAL_F1 : 0.997229916391986

EPOCH : 41 / 50
VAL_LOSS : 0.02319070344389069 
VAL_ACCURACY : 0.9987562189054726
VAL_F1 : 0.997229916391986

EPOCH : 42 / 50
VAL_LOSS : 0.02283048169577823 
VAL_ACCURACY : 0.9975124378109452
VAL_F1 : 0.994475137616068

EPOCH : 43 / 50
VAL_LOSS : 0.028377100405301534 
VAL_ACCURACY : 0.996268656716418
VAL_F1 : 0.9917355366846528

EPOCH : 44 / 50
VAL_LOSS : 0.023826837521411626 
VAL_ACCURACY : 0.9987562189054726
VAL_F1 : 0.997229916391986

EPOCH : 45 / 50
VAL_LOSS : 0.02422284407942903 
VAL_ACCURACY : 0.9975124378109452
VAL_F1 : 0.994475137616068

EPOCH : 46 / 50
VAL_LOSS : 0.021504703690023982 
VAL_ACCURACY : 0.9987562189054726
VAL_F1 : 0.997229916391986

EPOCH : 47 / 50
VAL_LOSS : 0.01996639305177857 
VAL_ACCURACY : 0.9987562189054726
VAL_F1 : 0.997229916391986

EPOCH : 48 / 50
VAL_LOSS : 0.020707419087343356 
VAL_ACCURACY : 0.9987562189054726
VAL_F1 : 0.997229916391986

EPOCH : 49 / 50
VAL_LOSS : 0.019579694168094325 
VAL_ACCURACY : 0.9987562189054726
VAL_F1 : 0.997229916391986

EPOCH : 50 / 50
VAL_LOSS : 0.02175701679844482 
VAL_ACCURACY : 0.9987562189054726
VAL_F1 : 0.997229916391986

# 5話-0
# 文: 夏目漱石だよ〜 Aくんはどんな本を読むの
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-1.0331,  2.4889]], device='cuda:0')
# 5話-0
# 文: そうなんだ〜
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.9646,  2.3110]], device='cuda:0')
# 5話-1
# 文: これ読んだよ
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 0.5340, -0.6339]], device='cuda:0')
# 5話-1
# 文: 夏目漱石だよ〜 Aくんはどんな本を読むの
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-1.0331,  2.4889]], device='cuda:0')
# 6話-0
# 文: キャー!
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[ 0.5090, -0.5134]], device='cuda:0')
# 6話-1
# 文: キャー!
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[ 0.5090, -0.5134]], device='cuda:0')
# 6話-1
# 文: 俺も今日弁当なんでおかず分けますよ
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.9853,  2.4592]], device='cuda:0')
# 7話-0
# 文: ジャーン!パフェを作ってみました〜!
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.8453,  2.2650]], device='cuda:0')
# 7話-1
# 文: ジャーン!パフェを作ってみました〜!
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.8453,  2.2650]], device='cuda:0')
# 7話-1
# 文: こうやっていろんな食べ方をすれば飽きないですね
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.9510,  2.1241]], device='cuda:0')
# 7話-1
# 文: チョコ一つしかないね はんぶんこしよっか
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 0.9802, -2.3577]], device='cuda:0')
# 8話-0
# 文: 今日は良い実験結果が出たな
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.9459,  2.4516]], device='cuda:0')
# 8話-1
# 文: でもわざわざ国際会議から送ってくれたんだよな…
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
tensor([[ 1.1866, -2.3970]], device='cuda:0')
# 9話-1
# 文: ここは よその研究室…!?
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
tensor([[0.2262, 0.0569]], device='cuda:0')
# 9話-1
# 文: ただいま〜
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.9541,  2.1235]], device='cuda:0')
# 9話-1
# 文: おかえりなさい!
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.5726,  1.3242]], device='cuda:0')
------------------------test acc------------------------
Test Acc : 0.7500
correct: 48, total: 64
------------------------------------------------
                  喜楽        その他  accuracy  macro avg  weighted avg
precision   0.250000   0.821429      0.75   0.535714      0.714286
recall      0.166667   0.884615      0.75   0.525641      0.750000
f1-score    0.200000   0.851852      0.75   0.525926      0.729630
support    12.000000  52.000000      0.75  64.000000     64.000000
正例のF1値 : 0.1999999995
class weight : tensor([0.7635, 0.1549])
best:lr 3.651805439157155e-05
EPOCH : 1 / 50
VAL_LOSS : 0.08138713861505191 
VAL_ACCURACY : 0.9888059701492538
VAL_F1 : 0.9750692515721643

EPOCH : 2 / 50
VAL_LOSS : 0.05656997731649408 
VAL_ACCURACY : 0.9751243781094527
VAL_F1 : 0.9468085101341672

EPOCH : 3 / 50
VAL_LOSS : 0.04147622014815901 
VAL_ACCURACY : 0.9813432835820896
VAL_F1 : 0.95999999949568

EPOCH : 4 / 50
VAL_LOSS : 0.021866454195012066 
VAL_ACCURACY : 0.9975124378109452
VAL_F1 : 0.994475137616068

EPOCH : 5 / 50
VAL_LOSS : 0.019864094169700846 
VAL_ACCURACY : 0.9975124378109452
VAL_F1 : 0.994475137616068

EPOCH : 6 / 50
VAL_LOSS : 0.01651319540014454 
VAL_ACCURACY : 1.0
VAL_F1 : 0.9999999994944446

EPOCH : 7 / 50
VAL_LOSS : 0.014242983989271462 
VAL_ACCURACY : 0.9975124378109452
VAL_F1 : 0.994475137616068

EPOCH : 8 / 50
VAL_LOSS : 0.012490061623062574 
VAL_ACCURACY : 1.0
VAL_F1 : 0.9999999994944446

EPOCH : 9 / 50
VAL_LOSS : 0.013011888491318506 
VAL_ACCURACY : 1.0
VAL_F1 : 0.9999999994944446

EPOCH : 10 / 50
VAL_LOSS : 0.013992472551763058 
VAL_ACCURACY : 0.9975124378109452
VAL_F1 : 0.994475137616068

EPOCH : 11 / 50
VAL_LOSS : 0.016893444856738344 
VAL_ACCURACY : 0.9950248756218906
VAL_F1 : 0.9890109885056154

EPOCH : 12 / 50
VAL_LOSS : 0.016088251271011197 
VAL_ACCURACY : 0.9937810945273632
VAL_F1 : 0.9863013693577032

EPOCH : 13 / 50
VAL_LOSS : 0.013286240618018544 
VAL_ACCURACY : 0.996268656716418
VAL_F1 : 0.9917355366846528

EPOCH : 14 / 50
VAL_LOSS : 0.016389755103006668 
VAL_ACCURACY : 0.9813432835820896
VAL_F1 : 0.95999999949568

EPOCH : 15 / 50
VAL_LOSS : 0.01566419144179307 
VAL_ACCURACY : 0.9950248756218906
VAL_F1 : 0.9890109885056154

EPOCH : 16 / 50
VAL_LOSS : 0.008774641992560788 
VAL_ACCURACY : 0.996268656716418
VAL_F1 : 0.9917355366846528

EPOCH : 17 / 50
VAL_LOSS : 0.0094509733585166 
VAL_ACCURACY : 0.996268656716418
VAL_F1 : 0.9917355366846528

EPOCH : 18 / 50
VAL_LOSS : 0.012386680096753087 
VAL_ACCURACY : 0.996268656716418
VAL_F1 : 0.9917355366846528

EPOCH : 19 / 50
VAL_LOSS : 0.008817692378572389 
VAL_ACCURACY : 0.9987562189054726
VAL_F1 : 0.997229916391986

EPOCH : 20 / 50
VAL_LOSS : 0.008508104452059842 
VAL_ACCURACY : 0.9975124378109452
VAL_F1 : 0.994475137616068

EPOCH : 21 / 50
VAL_LOSS : 0.009522331020265234 
VAL_ACCURACY : 0.9987562189054726
VAL_F1 : 0.997229916391986

EPOCH : 22 / 50
VAL_LOSS : 0.011640937546925509 
VAL_ACCURACY : 0.9937810945273632
VAL_F1 : 0.9863013693577032

EPOCH : 23 / 50
VAL_LOSS : 0.010039342434930742 
VAL_ACCURACY : 0.9975124378109452
VAL_F1 : 0.994475137616068

EPOCH : 24 / 50
VAL_LOSS : 0.008508084122748935 
VAL_ACCURACY : 0.9975124378109452
VAL_F1 : 0.994475137616068

EPOCH : 25 / 50
VAL_LOSS : 0.012058910183316352 
VAL_ACCURACY : 0.9912935323383084
VAL_F1 : 0.9809264300125475

EPOCH : 26 / 50
VAL_LOSS : 0.007531742684031818 
VAL_ACCURACY : 0.9987562189054726
VAL_F1 : 0.997229916391986

EPOCH : 27 / 50
VAL_LOSS : 0.0062288112171432555 
VAL_ACCURACY : 1.0
VAL_F1 : 0.9999999994944446

EPOCH : 28 / 50
VAL_LOSS : 0.007672171359516534 
VAL_ACCURACY : 0.9987562189054726
VAL_F1 : 0.997229916391986

EPOCH : 29 / 50
VAL_LOSS : 0.011347728667269442 
VAL_ACCURACY : 0.996268656716418
VAL_F1 : 0.9917355366846528

EPOCH : 30 / 50
VAL_LOSS : 0.005825583708892558 
VAL_ACCURACY : 0.9987562189054726
VAL_F1 : 0.997229916391986

EPOCH : 31 / 50
VAL_LOSS : 0.014622988539985289 
VAL_ACCURACY : 0.9950248756218906
VAL_F1 : 0.9890109885056154

EPOCH : 32 / 50
VAL_LOSS : 0.011224498118584355 
VAL_ACCURACY : 0.9975124378109452
VAL_F1 : 0.994475137616068

EPOCH : 33 / 50
VAL_LOSS : 0.010369018345669495 
VAL_ACCURACY : 0.996268656716418
VAL_F1 : 0.9917355366846528

EPOCH : 34 / 50
VAL_LOSS : 0.009655354768220409 
VAL_ACCURACY : 0.9987562189054726
VAL_F1 : 0.997229916391986

EPOCH : 35 / 50
VAL_LOSS : 0.010215063520031525 
VAL_ACCURACY : 0.9975124378109452
VAL_F1 : 0.994475137616068

EPOCH : 36 / 50
VAL_LOSS : 0.007734402281451313 
VAL_ACCURACY : 0.9987562189054726
VAL_F1 : 0.997229916391986

EPOCH : 37 / 50
VAL_LOSS : 0.011476072046777927 
VAL_ACCURACY : 0.996268656716418
VAL_F1 : 0.9917355366846528

EPOCH : 38 / 50
VAL_LOSS : 0.014706821027942294 
VAL_ACCURACY : 0.9937810945273632
VAL_F1 : 0.9863013693577032

EPOCH : 39 / 50
VAL_LOSS : 0.009952007375164506 
VAL_ACCURACY : 0.996268656716418
VAL_F1 : 0.9917355366846528

EPOCH : 40 / 50
VAL_LOSS : 0.00789347703696466 
VAL_ACCURACY : 0.9987562189054726
VAL_F1 : 0.997229916391986

EPOCH : 41 / 50
VAL_LOSS : 0.009521319715799215 
VAL_ACCURACY : 0.9975124378109452
VAL_F1 : 0.994475137616068

EPOCH : 42 / 50
VAL_LOSS : 0.00920932362422201 
VAL_ACCURACY : 0.9975124378109452
VAL_F1 : 0.994475137616068

EPOCH : 43 / 50
VAL_LOSS : 0.009917058607599899 
VAL_ACCURACY : 0.9975124378109452
VAL_F1 : 0.994475137616068

EPOCH : 44 / 50
VAL_LOSS : 0.008091469464239245 
VAL_ACCURACY : 0.9987562189054726
VAL_F1 : 0.997229916391986

EPOCH : 45 / 50
VAL_LOSS : 0.007752511047703379 
VAL_ACCURACY : 0.9987562189054726
VAL_F1 : 0.997229916391986

EPOCH : 46 / 50
VAL_LOSS : 0.00830634141925211 
VAL_ACCURACY : 0.9987562189054726
VAL_F1 : 0.997229916391986

EPOCH : 47 / 50
VAL_LOSS : 0.00651065304683631 
VAL_ACCURACY : 0.9987562189054726
VAL_F1 : 0.997229916391986

EPOCH : 48 / 50
VAL_LOSS : 0.0076375218843310775 
VAL_ACCURACY : 0.9987562189054726
VAL_F1 : 0.997229916391986

EPOCH : 49 / 50
VAL_LOSS : 0.012615313180539683 
VAL_ACCURACY : 0.996268656716418
VAL_F1 : 0.9917355366846528

EPOCH : 50 / 50
VAL_LOSS : 0.005540489070756617 
VAL_ACCURACY : 0.9987562189054726
VAL_F1 : 0.997229916391986

# 5話-0
# 文: 夏目漱石だよ〜 Aくんはどんな本を読むの
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-1.7825,  2.6101]], device='cuda:0')
# 5話-0
# 文: そうなんだ〜
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-1.7688,  2.5736]], device='cuda:0')
# 5話-1
# 文: 夏目漱石だよ〜 Aくんはどんな本を読むの
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-1.7825,  2.6101]], device='cuda:0')
# 5話-1
# 文: 本当に今ハマってる本はこの二冊…
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.2513,  0.2954]], device='cuda:0')
# 6話-0
# 文: 見てもいいですか?
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 0.6109, -0.9659]], device='cuda:0')
# 6話-1
# 文: 俺も今日弁当なんでおかず分けますよ
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-1.7796,  2.5864]], device='cuda:0')
# 7話-0
# 文: ジャーン!パフェを作ってみました〜!
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-1.3918,  1.9973]], device='cuda:0')
# 7話-1
# 文: ジャーン!パフェを作ってみました〜!
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-1.3918,  1.9973]], device='cuda:0')
# 7話-1
# 文: こうやっていろんな食べ方をすれば飽きないですね
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-1.4611,  2.1926]], device='cuda:0')
# 7話-1
# 文: チョコ一つしかないね はんぶんこしよっか
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 1.4946, -2.0080]], device='cuda:0')
# 8話-0
# 文: 今日は良い実験結果が出たな
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-1.7601,  2.5604]], device='cuda:0')
# 8話-1
# 文: でもわざわざ国際会議から送ってくれたんだよな…
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
tensor([[ 1.4369, -1.6492]], device='cuda:0')
# 9話-1
# 文: ただいま〜
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-1.6906,  2.2564]], device='cuda:0')
# 9話-1
# 文: おかえりなさい!
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-1.5132,  2.0559]], device='cuda:0')
------------------------test acc------------------------
Test Acc : 0.7812
correct: 50, total: 64
------------------------------------------------
                  喜楽        その他  accuracy  macro avg  weighted avg
precision   0.250000   0.816667   0.78125   0.533333      0.710417
recall      0.083333   0.942308   0.78125   0.512821      0.781250
f1-score    0.125000   0.875000   0.78125   0.500000      0.734375
support    12.000000  52.000000   0.78125  64.000000     64.000000
正例のF1値 : 0.124999999609375
class weight : tensor([0.7635, 0.1549])
best:lr 0.0001545351292518665
EPOCH : 1 / 50
VAL_LOSS : 0.03506602020021163 
VAL_ACCURACY : 0.9875621890547264
VAL_F1 : 0.972972972468079

EPOCH : 2 / 50
VAL_LOSS : 0.016431105962278796 
VAL_ACCURACY : 0.9975124378109452
VAL_F1 : 0.994475137616068

EPOCH : 3 / 50
VAL_LOSS : 0.03472866465830628 
VAL_ACCURACY : 0.9888059701492538
VAL_F1 : 0.9754768387319233

EPOCH : 4 / 50
VAL_LOSS : 0.014270365283842765 
VAL_ACCURACY : 0.996268656716418
VAL_F1 : 0.9917355366846528

EPOCH : 5 / 50
VAL_LOSS : 0.010816021101074475 
VAL_ACCURACY : 0.9987562189054726
VAL_F1 : 0.997229916391986

EPOCH : 6 / 50
VAL_LOSS : 0.00818793800677739 
VAL_ACCURACY : 0.9987562189054726
VAL_F1 : 0.997229916391986

EPOCH : 7 / 50
VAL_LOSS : 0.009111053680124529 
VAL_ACCURACY : 0.9987562189054726
VAL_F1 : 0.9972144841741142

EPOCH : 8 / 50
VAL_LOSS : 0.008665732560021913 
VAL_ACCURACY : 0.9987562189054726
VAL_F1 : 0.9972144841741142

EPOCH : 9 / 50
VAL_LOSS : 0.00974208326535482 
VAL_ACCURACY : 0.9987562189054726
VAL_F1 : 0.997229916391986

EPOCH : 10 / 50
VAL_LOSS : 0.009911360903916991 
VAL_ACCURACY : 0.9987562189054726
VAL_F1 : 0.997229916391986

EPOCH : 11 / 50
VAL_LOSS : 0.008572412618235046 
VAL_ACCURACY : 0.9975124378109452
VAL_F1 : 0.994475137616068

EPOCH : 12 / 50
VAL_LOSS : 0.018793893293203676 
VAL_ACCURACY : 0.9937810945273632
VAL_F1 : 0.9863013693577032

EPOCH : 13 / 50
VAL_LOSS : 0.007710742070248314 
VAL_ACCURACY : 0.9975124378109452
VAL_F1 : 0.994475137616068

EPOCH : 14 / 50
VAL_LOSS : 0.012771745894889474 
VAL_ACCURACY : 0.9937810945273632
VAL_F1 : 0.9863013693577032

EPOCH : 15 / 50
VAL_LOSS : 0.007799120912072705 
VAL_ACCURACY : 0.9987562189054726
VAL_F1 : 0.997229916391986

EPOCH : 16 / 50
VAL_LOSS : 0.02226969098453136 
VAL_ACCURACY : 0.9788557213930348
VAL_F1 : 0.9549071612996644

EPOCH : 17 / 50
VAL_LOSS : 0.009131592830789148 
VAL_ACCURACY : 0.9975124378109452
VAL_F1 : 0.994475137616068

EPOCH : 18 / 50
VAL_LOSS : 0.00651188798057025 
VAL_ACCURACY : 0.9987562189054726
VAL_F1 : 0.997229916391986

EPOCH : 19 / 50
VAL_LOSS : 0.011535731733174008 
VAL_ACCURACY : 0.9975124378109452
VAL_F1 : 0.994475137616068

EPOCH : 20 / 50
VAL_LOSS : 0.01071252438294537 
VAL_ACCURACY : 0.9987562189054726
VAL_F1 : 0.997229916391986

EPOCH : 21 / 50
VAL_LOSS : 0.013171240392908016 
VAL_ACCURACY : 0.9950248756218906
VAL_F1 : 0.9890109885056154

EPOCH : 22 / 50
VAL_LOSS : 0.013556050145815984 
VAL_ACCURACY : 0.9987562189054726
VAL_F1 : 0.997229916391986

EPOCH : 23 / 50
VAL_LOSS : 0.007496481261435239 
VAL_ACCURACY : 0.9987562189054726
VAL_F1 : 0.997229916391986

EPOCH : 24 / 50
VAL_LOSS : 0.013470242968669124 
VAL_ACCURACY : 0.9975124378109452
VAL_F1 : 0.994475137616068

EPOCH : 25 / 50
VAL_LOSS : 0.0125880990401093 
VAL_ACCURACY : 0.9987562189054726
VAL_F1 : 0.997229916391986

EPOCH : 26 / 50
VAL_LOSS : 0.009615087772116941 
VAL_ACCURACY : 0.9987562189054726
VAL_F1 : 0.997229916391986

EPOCH : 27 / 50
VAL_LOSS : 0.013358730386814796 
VAL_ACCURACY : 0.996268656716418
VAL_F1 : 0.9917355366846528

EPOCH : 28 / 50
VAL_LOSS : 0.021655659230115514 
VAL_ACCURACY : 0.9912935323383084
VAL_F1 : 0.9809264300125475

EPOCH : 29 / 50
VAL_LOSS : 0.011969438811088456 
VAL_ACCURACY : 0.9975124378109452
VAL_F1 : 0.994475137616068

EPOCH : 30 / 50
VAL_LOSS : 0.01507349604028551 
VAL_ACCURACY : 0.9925373134328358
VAL_F1 : 0.9836065568718088

EPOCH : 31 / 50
VAL_LOSS : 0.011912825058543068 
VAL_ACCURACY : 0.9950248756218906
VAL_F1 : 0.9890109885056154

EPOCH : 32 / 50
VAL_LOSS : 0.01604990184526233 
VAL_ACCURACY : 0.9950248756218906
VAL_F1 : 0.9890109885056154

EPOCH : 33 / 50
VAL_LOSS : 0.011076308633931274 
VAL_ACCURACY : 0.9975124378109452
VAL_F1 : 0.994475137616068

EPOCH : 34 / 50
VAL_LOSS : 0.008467350415337612 
VAL_ACCURACY : 0.9987562189054726
VAL_F1 : 0.997229916391986

EPOCH : 35 / 50
VAL_LOSS : 0.011698617446966762 
VAL_ACCURACY : 0.9975124378109452
VAL_F1 : 0.994475137616068

EPOCH : 36 / 50
VAL_LOSS : 0.012443016626753425 
VAL_ACCURACY : 0.9975124378109452
VAL_F1 : 0.994475137616068

EPOCH : 37 / 50
VAL_LOSS : 0.010115640810873433 
VAL_ACCURACY : 0.9987562189054726
VAL_F1 : 0.997229916391986

EPOCH : 38 / 50
VAL_LOSS : 0.007661893733265791 
VAL_ACCURACY : 0.9987562189054726
VAL_F1 : 0.997229916391986

EPOCH : 39 / 50
VAL_LOSS : 0.009607748089668652 
VAL_ACCURACY : 0.996268656716418
VAL_F1 : 0.9917355366846528

EPOCH : 40 / 50
VAL_LOSS : 0.008181934110254195 
VAL_ACCURACY : 0.9987562189054726
VAL_F1 : 0.997229916391986

EPOCH : 41 / 50
VAL_LOSS : 0.008090186324290127 
VAL_ACCURACY : 0.9987562189054726
VAL_F1 : 0.997229916391986

EPOCH : 42 / 50
VAL_LOSS : 0.010183099831920117 
VAL_ACCURACY : 0.9987562189054726
VAL_F1 : 0.997229916391986

EPOCH : 43 / 50
VAL_LOSS : 0.008451115982561354 
VAL_ACCURACY : 0.9987562189054726
VAL_F1 : 0.997229916391986

EPOCH : 44 / 50
VAL_LOSS : 0.007835124289461723 
VAL_ACCURACY : 0.9987562189054726
VAL_F1 : 0.997229916391986

EPOCH : 45 / 50
VAL_LOSS : 0.011712005609582526 
VAL_ACCURACY : 0.996268656716418
VAL_F1 : 0.9917355366846528

EPOCH : 46 / 50
VAL_LOSS : 0.008380385066665635 
VAL_ACCURACY : 0.9987562189054726
VAL_F1 : 0.997229916391986

EPOCH : 47 / 50
VAL_LOSS : 0.010381035062749231 
VAL_ACCURACY : 0.9987562189054726
VAL_F1 : 0.997229916391986

EPOCH : 48 / 50
VAL_LOSS : 0.008671145762919504 
VAL_ACCURACY : 0.9987562189054726
VAL_F1 : 0.997229916391986

EPOCH : 49 / 50
VAL_LOSS : 0.007418726422531786 
VAL_ACCURACY : 0.9987562189054726
VAL_F1 : 0.997229916391986

EPOCH : 50 / 50
VAL_LOSS : 0.009602352666358152 
VAL_ACCURACY : 0.9987562189054726
VAL_F1 : 0.997229916391986

# 5話-0
# 文: 夏目漱石だよ〜 Aくんはどんな本を読むの
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-1.9968,  3.6268]], device='cuda:0')
# 5話-0
# 文: そうなんだ〜
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-1.6294,  3.2680]], device='cuda:0')
# 5話-1
# 文: 夏目漱石だよ〜 Aくんはどんな本を読むの
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-1.9968,  3.6268]], device='cuda:0')
# 5話-1
# 文: 本当に今ハマってる本はこの二冊…
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.6689,  1.2017]], device='cuda:0')
# 6話-1
# 文: 俺も今日弁当なんでおかず分けますよ
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-1.9841,  3.6085]], device='cuda:0')
# 7話-0
# 文: ジャーン!パフェを作ってみました〜!
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.8197,  1.8989]], device='cuda:0')
# 7話-1
# 文: ジャーン!パフェを作ってみました〜!
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.8197,  1.8989]], device='cuda:0')
# 7話-1
# 文: こうやっていろんな食べ方をすれば飽きないですね
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-1.9906,  3.5841]], device='cuda:0')
# 7話-1
# 文: チョコ一つしかないね はんぶんこしよっか
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 1.1258, -0.5770]], device='cuda:0')
# 8話-0
# 文: 今日は良い実験結果が出たな
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-1.8253,  3.4266]], device='cuda:0')
# 8話-1
# 文: でもわざわざ国際会議から送ってくれたんだよな…
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
tensor([[ 1.5197, -2.5529]], device='cuda:0')
# 9話-1
# 文: おかえりなさい!
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-0.2619,  1.5839]], device='cuda:0')
------------------------test acc------------------------
Test Acc : 0.8125
correct: 52, total: 64
------------------------------------------------
                  喜楽        その他  accuracy  macro avg  weighted avg
precision   0.500000   0.833333    0.8125   0.666667      0.770833
recall      0.166667   0.961538    0.8125   0.564103      0.812500
f1-score    0.250000   0.892857    0.8125   0.571429      0.772321
support    12.000000  52.000000    0.8125  64.000000     64.000000
正例のF1値 : 0.24999999959375002
class weight : tensor([0.7635, 0.1549])
best:lr 0.0003431543314949966
EPOCH : 1 / 50
VAL_LOSS : 0.06314418988996277 
VAL_ACCURACY : 0.9763681592039801
VAL_F1 : 0.9496021215118942

EPOCH : 2 / 50
VAL_LOSS : 0.035106809243705926 
VAL_ACCURACY : 0.9925373134328358
VAL_F1 : 0.98351648301114

EPOCH : 3 / 50
VAL_LOSS : 0.026867628006228043 
VAL_ACCURACY : 0.9912935323383084
VAL_F1 : 0.9809264300125475

EPOCH : 4 / 50
VAL_LOSS : 0.021365589087865518 
VAL_ACCURACY : 0.9950248756218906
VAL_F1 : 0.9890109885056154

EPOCH : 5 / 50
VAL_LOSS : 0.03129409331207474 
VAL_ACCURACY : 0.9912935323383084
VAL_F1 : 0.9809264300125475

EPOCH : 6 / 50
VAL_LOSS : 0.023034562607861908 
VAL_ACCURACY : 0.9950248756218906
VAL_F1 : 0.9889502757376454

EPOCH : 7 / 50
VAL_LOSS : 0.014080282323537212 
VAL_ACCURACY : 0.9975124378109452
VAL_F1 : 0.994475137616068

EPOCH : 8 / 50
VAL_LOSS : 0.02475680451493199 
VAL_ACCURACY : 0.996268656716418
VAL_F1 : 0.9916897501870305

EPOCH : 9 / 50
VAL_LOSS : 0.039306371586908605 
VAL_ACCURACY : 0.9912935323383084
VAL_F1 : 0.980716252938157

EPOCH : 10 / 50
VAL_LOSS : 0.04108901256147553 
VAL_ACCURACY : 0.9950248756218906
VAL_F1 : 0.9888888883833951

EPOCH : 11 / 50
VAL_LOSS : 0.017731079845415318 
VAL_ACCURACY : 0.996268656716418
VAL_F1 : 0.9917355366846528

EPOCH : 12 / 50
VAL_LOSS : 0.03515329758417519 
VAL_ACCURACY : 0.9925373134328358
VAL_F1 : 0.98351648301114

EPOCH : 13 / 50
VAL_LOSS : 0.03768510410708247 
VAL_ACCURACY : 0.9925373134328358
VAL_F1 : 0.9833333328278704

EPOCH : 14 / 50
VAL_LOSS : 0.015676165981145174 
VAL_ACCURACY : 0.996268656716418
VAL_F1 : 0.9917355366846528

EPOCH : 15 / 50
VAL_LOSS : 0.04489201784371307 
VAL_ACCURACY : 0.9689054726368159
VAL_F1 : 0.9350649345621859

EPOCH : 16 / 50
VAL_LOSS : 0.025408588737870257 
VAL_ACCURACY : 0.9937810945273632
VAL_F1 : 0.9861495839820751

EPOCH : 17 / 50
VAL_LOSS : 0.02027909931105872 
VAL_ACCURACY : 0.9950248756218906
VAL_F1 : 0.9890109885056154

EPOCH : 18 / 50
VAL_LOSS : 0.02633681749085001 
VAL_ACCURACY : 0.9975124378109452
VAL_F1 : 0.9944444439389197

EPOCH : 19 / 50
VAL_LOSS : 0.036306688767474365 
VAL_ACCURACY : 0.9950248756218906
VAL_F1 : 0.9889502757376454

EPOCH : 20 / 50
VAL_LOSS : 0.008023466613581953 
VAL_ACCURACY : 0.996268656716418
VAL_F1 : 0.9917355366846528

EPOCH : 21 / 50
VAL_LOSS : 0.006253866175207875 
VAL_ACCURACY : 1.0
VAL_F1 : 0.9999999994944446

EPOCH : 22 / 50
VAL_LOSS : 0.01568209596306962 
VAL_ACCURACY : 0.9925373134328358
VAL_F1 : 0.9836065568718088

EPOCH : 23 / 50
VAL_LOSS : 0.01509755227358683 
VAL_ACCURACY : 0.986318407960199
VAL_F1 : 0.9703504038078771

EPOCH : 24 / 50
VAL_LOSS : 0.00932774946148343 
VAL_ACCURACY : 0.9987562189054726
VAL_F1 : 0.997229916391986

EPOCH : 25 / 50
VAL_LOSS : 0.017702225198530975 
VAL_ACCURACY : 0.986318407960199
VAL_F1 : 0.9703504038078771

EPOCH : 26 / 50
VAL_LOSS : 0.012882629441389558 
VAL_ACCURACY : 0.9987562189054726
VAL_F1 : 0.997229916391986

EPOCH : 27 / 50
VAL_LOSS : 0.018118958331315833 
VAL_ACCURACY : 0.9975124378109452
VAL_F1 : 0.9944444439389197

EPOCH : 28 / 50
VAL_LOSS : 0.022197292355236178 
VAL_ACCURACY : 0.9850746268656716
VAL_F1 : 0.9675675670627027

EPOCH : 29 / 50
VAL_LOSS : 0.012473965168693195 
VAL_ACCURACY : 0.9987562189054726
VAL_F1 : 0.997229916391986

EPOCH : 30 / 50
VAL_LOSS : 0.016471588673690956 
VAL_ACCURACY : 0.9987562189054726
VAL_F1 : 0.997229916391986

EPOCH : 31 / 50
VAL_LOSS : 0.013361080109105245 
VAL_ACCURACY : 0.9975124378109452
VAL_F1 : 0.9944444439389197

EPOCH : 32 / 50
VAL_LOSS : 0.018603847496777626 
VAL_ACCURACY : 0.9950248756218906
VAL_F1 : 0.9890109885056154

EPOCH : 33 / 50
VAL_LOSS : 0.008987775816600405 
VAL_ACCURACY : 0.9987562189054726
VAL_F1 : 0.997229916391986

EPOCH : 34 / 50
VAL_LOSS : 0.010265902501950953 
VAL_ACCURACY : 0.9975124378109452
VAL_F1 : 0.994475137616068

EPOCH : 35 / 50
VAL_LOSS : 0.008357648979689852 
VAL_ACCURACY : 0.9987562189054726
VAL_F1 : 0.997229916391986

EPOCH : 36 / 50
VAL_LOSS : 0.03409140547920091 
VAL_ACCURACY : 0.9738805970149254
VAL_F1 : 0.9448818892603386

EPOCH : 37 / 50
VAL_LOSS : 0.015336154074426376 
VAL_ACCURACY : 0.9987562189054726
VAL_F1 : 0.997229916391986

EPOCH : 38 / 50
VAL_LOSS : 0.013813299047030216 
VAL_ACCURACY : 0.9937810945273632
VAL_F1 : 0.9863013693577032

EPOCH : 39 / 50
VAL_LOSS : 0.00876106983096357 
VAL_ACCURACY : 0.9987562189054726
VAL_F1 : 0.997229916391986

EPOCH : 40 / 50
VAL_LOSS : 0.010868823290437315 
VAL_ACCURACY : 0.996268656716418
VAL_F1 : 0.9917355366846528

EPOCH : 41 / 50
VAL_LOSS : 0.01243269175300192 
VAL_ACCURACY : 0.9987562189054726
VAL_F1 : 0.997229916391986

EPOCH : 42 / 50
VAL_LOSS : 0.010734369482972897 
VAL_ACCURACY : 0.9975124378109452
VAL_F1 : 0.994475137616068

EPOCH : 43 / 50
VAL_LOSS : 0.010561156394781874 
VAL_ACCURACY : 0.9987562189054726
VAL_F1 : 0.997229916391986

EPOCH : 44 / 50
VAL_LOSS : 0.018977105076534346 
VAL_ACCURACY : 0.9925373134328358
VAL_F1 : 0.9836065568718088

EPOCH : 45 / 50
VAL_LOSS : 0.015000909108065945 
VAL_ACCURACY : 0.996268656716418
VAL_F1 : 0.9917355366846528

EPOCH : 46 / 50
VAL_LOSS : 0.021305959299663266 
VAL_ACCURACY : 0.986318407960199
VAL_F1 : 0.9703504038078771

EPOCH : 47 / 50
VAL_LOSS : 0.015315045057065492 
VAL_ACCURACY : 0.9838308457711443
VAL_F1 : 0.9651474525785424

EPOCH : 48 / 50
VAL_LOSS : 0.015964935643269736 
VAL_ACCURACY : 0.996268656716418
VAL_F1 : 0.9917355366846528

EPOCH : 49 / 50
VAL_LOSS : 0.01013664161905135 
VAL_ACCURACY : 0.996268656716418
VAL_F1 : 0.9917355366846528

EPOCH : 50 / 50
VAL_LOSS : 0.011593691018574378 
VAL_ACCURACY : 0.996268656716418
VAL_F1 : 0.9917355366846528

# 5話-0
# 文: 夏目漱石だよ〜 Aくんはどんな本を読むの
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-3.3372,  2.4966]], device='cuda:0')
# 5話-0
# 文: そうなんだ〜
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-2.1730,  1.3842]], device='cuda:0')
# 5話-1
# 文: 夏目漱石だよ〜 Aくんはどんな本を読むの
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-3.3372,  2.4966]], device='cuda:0')
# 5話-1
# 文: 本当に今ハマってる本はこの二冊…
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-3.3276,  2.5536]], device='cuda:0')
# 6話-0
# 文: 今日弁当なんですね
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
tensor([[ 0.8921, -0.0898]], device='cuda:0')
# 6話-1
# 文: 俺も今日弁当なんでおかず分けますよ
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-3.3288,  2.5507]], device='cuda:0')
# 7話-0
# 文: ジャーン!パフェを作ってみました〜!
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-3.3259,  2.5585]], device='cuda:0')
# 7話-1
# 文: ジャーン!パフェを作ってみました〜!
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-3.3259,  2.5585]], device='cuda:0')
# 7話-1
# 文: こうやっていろんな食べ方をすれば飽きないですね
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-3.3313,  2.5358]], device='cuda:0')
# 8話-0
# 文: 今日は良い実験結果が出たな
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-3.3024,  2.5604]], device='cuda:0')
# 9話-1
# 文: ただいま〜
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-2.6383,  2.3096]], device='cuda:0')
# 9話-1
# 文: おかえりなさい!
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
tensor([[-1.0849,  0.0535]], device='cuda:0')
------------------------test acc------------------------
Test Acc : 0.8125
correct: 52, total: 64
------------------------------------------------
                  喜楽        その他  accuracy  macro avg  weighted avg
precision   0.500000   0.822581    0.8125   0.661290      0.762097
recall      0.083333   0.980769    0.8125   0.532051      0.812500
f1-score    0.142857   0.894737    0.8125   0.518797      0.753759
support    12.000000  52.000000    0.8125  64.000000     64.000000
正例のF1値 : 0.1428571425918367
